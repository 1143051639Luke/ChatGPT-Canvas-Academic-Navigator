0,1,2
"('page_content', 'Algorithm Design\nJON KLEINBERG · ÉVA TARDOS\nCornell University\n\xa0\n\xa0\n\xa0\n\xa0\n\xa0\n\xa0\n\xa0\n\xa0\nBoston\xa0\xa0San Francisco\xa0\xa0New Y ork \nLondon\xa0\xa0T oronto\xa0\xa0Sydney\xa0\xa0T okyo\xa0\xa0Singapore\xa0\xa0Madrid  \nMexico City\xa0\xa0Munich\xa0\xa0Paris\xa0\xa0Cape T own\xa0\xa0Hong Kong\xa0\xa0Montreal')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1})","('type', 'Document')"
"('page_content', 'Acquisitions Editor: Matt Goldstein  \nProject Editor: Maite Suar ez-Rivas  \nProduction Supervisor: Marilyn Lloyd  \nMarketing Manager: Michelle Br own \nMarketing Coordinator: Jake Zavracky  \nProject Management: Windfall Softwar e \nComposition: Windfall Softwar e, using ZzTEX \nCopyeditor: Carol Leyba  \nTechnical Illustration: Dartmouth Publishing  \nProofreader: Jennifer McClain  \nIndexer: Ted Laux  \nCover Design: Joyce Cosentino W ells \nCover Photo: © 2005 Tim Laman / National Geographic. A pair of\nweaverbir ds work together on their nest in Africa.  \nPrepress and Manufacturing: Caroline Fell  \nPrinter: Courier W estfor d\nAccess the latest information about Addison-W esley titles from our World\nWide W eb site: http://www .aw-bc.com/computing\nMany of the designations used by manufacturers and sellers to distinguish\ntheir products are claimed as trademarks. Where those designations appear\nin this book, and Addison-W esley was aware of a trademark  claim, the\ndesignations have been printed in initial caps or all caps.\nThe programs and applications presented in this book have been included\nfor their instruc tional value. They have been tested with care,  but are not\nguaranteed for any particular purpose. The publisher does not offer any\nwarranties or representations, nor does it accept any liabilities with respect\nto the programs or applications.\nLibrary of Congress Cataloging-in-Publication Data\nKleinber g, Jon.  \nAlgorithm design / Jon Kleinber g, Éva T ardos.—1st ed.  \np. cm. \nIncludes bibliographical references and index.  \nISBN 0-321-29535-8 (alk. paper)  \n1. Comp uter algorithms. 2. Data structures (Computer science ) I. Tardos,\nÉva. II. T itle.\nQA76.9.A43K54 2005  \n005.1—dc22 2005000401')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 2})","('type', 'Document')"
"('page_content', 'Copyright © 2006 by Pearson Education, Inc.\nFor information on obtaining permission for use of material in this work,\nplease submit a written reques t to Pearson Education, Inc., Rights and\nContract Department, 75 Arling ton Street, Suite 300, Boston, MA 02116 or\nfax your request to (617) 848-7047.\nAll rights reserved. No part of this publication may be reproduced, stored in\na retrieval system, or transmitte d, in any form or by any means , electronic,\nmechanical, photocopying, recording, or any toher media embodiments now\nknown or hereafter to become known, without the prior written permission\nof the publisher . Printed in the United States of America.\nISBN 0-321-29535-8\n1 2 3 4 5 6 7 8 9 10-CR W-08 07 06 05')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 3})","('type', 'Document')"
"('page_content', ""About the Authors\nJon Kleinber g is a professor of Computer Science at Cornell University . He\nreceived his Ph.D. from M.I.T . in 1996. He is the recipient of an NSF\nCareer Award, an ONR Young Investigator Award, an IBM Outstanding\nInnovation Award, the National Academy of Sciences Award for Initiatives\nin Research, research fellowships from the Packard and Sloan Foundations,\nand teaching awards from the Cornell Engineering College and Computer\nScience Department.\nKleinber g's research is centered around algorithms, particularly  those\nconcerned with the structure of networks and information, and with\napplications to information science, optimization, data mining, and\ncomputational biology . His work on network analysis using hubs and\nauthorities helped form the foundation for the current generation of Internet\nsearch engines.\nÉva Tardos is a professor of Computer Science at Cornell University . She\nreceived her Ph.D. from Eötvös University in Budapest, Hungary in 1984.\nShe is a membe r of the American Academy of Arts and Sciences, and an\nACM Fellow; she is the recipient of an NSF Presidential Y oung Investigator\nAward, the Fulkerson Prize, research fellowships from the Guggenheim,"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 4})","('type', 'Document')"
"('page_content', ""Packard, and Sloan Foundation s, and teaching awards from the Cornell\nEngineering College and Computer Science Department.\nTardos's research interests are focused on the design and analysis of\nalgorithms for problems on graphs or networks. She is most known for her\nwork on network-flow algorithms and approximation algorithms for\nnetwork problem s. Her recent work focuses on algorithmic game theory , an\nemer ging area concerned with designing systems and algorithm s for selfish\nusers."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 5})","('type', 'Document')"
"('page_content', 'Contents\n\xa0\n\xa0\n\xa0\nAbout the Authors\nPreface\n\xa0\n1 Introduction: Some Representative Problems\n2 Basics of Algorithm Analysis\n3 Graphs\n4 Greedy Algorithms\n5 Divide and Conquer\n6 Dynamic Programming\n7 Network Flow\n8 NP and Computational Intractability\n9 PSPACE: A Class of Problems beyond NP\n10 Extending the Limits of T ractability\n11 Approximation Algorithms\n12 Local Search\n13 Randomized Algorithms\n\xa0\nEpilogue: Algorithms That Run Forever\nReferences\nIndex')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 6})","('type', 'Document')"
"('page_content', ""P r e f a c e\nAlgorithmic ideas are pervasive , and their reach is apparent in examples\nboth within computer science and beyond. Some of the major shifts in\nInternet routing standards can be viewed as debates over the deficiencies of\none shortest-pat h algorithm and the relative advantages of another . The\nbasic notions used by biologists to express similarities among genes and\ngenomes have algorithmic definitions. The concerns voiced by economists\nover the feasibil ity of combinatorial auctions in practice are rooted partly in\nthe fact that these auctions contain computationally intractable search\nproblems as special cases. And algorithmic notions aren't just restricted to\nwell-known and longstanding problems; one sees the reflections of these\nideas on a regular basis, in nove l issues arising across a wide range of areas.\nThe scientist from Yahoo! who told us over lunch one day about their\nsystem for serving ads to users was describing a set of issues that, deep\ndown, could be modeled as a network flow problem. So was the former\nstudent, now a management consultant working on staffing protocols for\nlarge hospitals, whom we happened to meet on a trip to New Y ork City .\nThe point is not simply that algorithms have many applications. The\ndeeper issue is that the subject of algorithms is a powerful lens through\nwhich to view the field of computer science in general. Algorithmic\nproblems form the heart of computer science, but they rarely arrive as\ncleanly packaged, mathematically precise questions. Rather , they tend to\ncome bundled together with lots of messy , application-specific detail, some\nof it essential, some of it extran eous. As a result, the algorithmi c enterprise\nconsists of two fundamental components: the task of getting to the\nmathematically clean core of a problem, and then the task of identifying the\nappropriate algorithm design techniques, based on the struc ture of the\nproblem. These two components  interact: the more comfortable one is with\nthe full array of possible design techniques, the more one starts to recognize\nthe clean formulations that lie within messy problems out in the world. At\ntheir most effective, then, algori thmic ideas do not just provide solutions to\nwell-posed problems; they form  the language that lets you cleanly express\nthe underlying questions."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 7})","('type', 'Document')"
"('page_content', 'The goal of our book is to convey this approach to algorithms, as a\ndesign process that begins with problems arising across the full range of\ncomputing applications, builds on an understanding of algorithm design\ntechniques, and results in the development of efficient solutions to these\nproblems. We seek to explore the role of algorithmic ideas in computer\nscience generall y, and relate these ideas to the range of precisely formulated\nproblems for which we can design and analyze algorithms. In other words,\nwhat are the underlying issues that motivate these problems, and how did\nwe choose these particular ways of formulating them? How did we\nrecognize which design principles were appropriate in dif ferent situations?\nIn keeping with this, our goal is to offer advice on how to identify\nclean algorithmic problem formulations in complex issues from different\nareas of computing and, from this, how to design efficient algorithms for\nthe resulting problems. Sophisticated algorithms are often best understood\nby recon structing the sequence  of ideas—including false starts and dead\nends—that led from simpler initial approaches to the eventual solution. The\nresult is a style of exposition that does not take the most direct route from\nproblem statement to algorithm, but we feel it better reflects the way that\nwe and our colleagues genuinely think about these questions.\n\xa0\nOverview\nThe book is intended for stude nts who have completed a programming-\nbased two-semester introductory computer science sequence (the standard\n“CS1/CS2” courses) in which they have written programs that implement\nbasic algorithms, manipulate discrete structures such as trees and graphs,\nand apply basic data structures  such as arrays, lists, queues, and stacks.\nSince the interface between CS1/CS2 and a first algorithms course is not\nentirely standard , we begin the book with self-contained coverage of topics\nthat at some institutions are familiar to students from CS1/CS2, but which\nat other institutions are included in the syllabi of the first algorithms course.\nThis material can thus be treate d either as a review or as new material; by\nincluding it, we hope the book can be used in a broader array  of courses,\nand with more flexibility in the prerequisite knowledge that is assumed.\nIn keeping with the approach outlined above, we develop the basic\nalgorithm design techniques by drawing on problems from across many\nareas of computer science and related fields. To mention a few')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 8})","('type', 'Document')"
"('page_content', 'representative examples here, we include fairly detailed discussions of\napplications from systems and networks (caching, switching, interdomain\nrouting on the Internet), artificial intelligence (planning, game playing,\nHopfield networks), computer vision (image segmentation), data mining\n(change-point detection, clustering), operations research (airline\nscheduling), and computational biology (sequence alignment, RNA\nsecondary structure).\nThe notion of computational intractability , and NP-completeness in\nparticular , plays a large role in the book. This is consistent with how we\nthink about the overall process of algorithm design. Some of the time, an\ninteresting problem arising in an application area will be amenable to an\nefficient solution , and some of the time it will be provably NP-c omplete; in\norder to fully address a new algorithmic problem, one should be able to\nexplore both of these options with equal familiarity . Since so many natural\nproblems in computer science are NP-complete, the development of\nmethods to deal with intractable  problems has become a crucial  issue in the\nstudy of algorithms, and our book heavily reflects this theme. The discovery\nthat a problem is NP-complete should not be taken as the end of the story ,\nbut as an invitati on to begin looking for approximation algorithms, heuristic\nlocal search techniques, or tractable special cases. We include extensive\ncoverage of each of these three approaches.\n\xa0\nProblems and Solved Exercises\nAn important feature of the book is the collection of problems. Across all\nchapters, the book includes over 200 problems, almost all of them\ndeveloped and class-tested in homework or exams as part of our teaching of\nthe course at Cornell. We view the problems as a crucial component of the\nbook, and they are structured in keeping with our overall approach to the\nmaterial. Most of them consist of extended verbal descriptions of a problem\narising in an application area in computer science or elsewhere out in the\nworld, and part of the problem  is to practice what we discuss in the text:\nsetting up the necessary notation  and formalization, designing an algorithm,\nand then analyzing it and provin g it correct. (We view a complete answer to\none of these problems as consisting of all these components: a fully\nexplained algorithm, an analy sis of the running time, and a proof of\ncorrectness.) The ideas for these problems come in large part from')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 9})","('type', 'Document')"
"('page_content', ""discussions we have had over the years with people working in different\nareas, and in some cases they serve the dual purpose of recording an\ninteresting (though manageable) application of algorithms that we haven't\nseen written down anywhere else.\nTo help with the process of working on these problems, we include in\neach chapter a section entitled “Solved Exercises,” where we take one or\nmore problems and describe how to go about formulating a solution. The\ndiscussion devo ted to each solved exercise is therefore significantly longer\nthan what would  be needed simply to write a complete, correct solution (in\nother words, significantly longer than what it would take to receive full\ncredit if these were being assign ed as homework problems). Rather , as with\nthe rest of the text, the discussions in these sections should be viewed as\ntrying to give a sense of the larger process by which one might  think about\nproblems of this type, culminating in the specification of a precise solution.\nIt is worth menti oning two points concerning the use of these problems\nas home work in a course. First, the problems are sequenced  roughly in\norder of increasi ng difficulty , but this is only an approximate guide and we\nadvise against placing too much weight on it: since the bulk of the problems\nwere designed as homework for our under graduate class, large subsets of\nthe problems in each chapter are really closely comparable in terms of\ndifficulty . Secon d, aside from the lowest-numbered ones, the problems are\ndesigned to involve some investment of time, both to relate the problem\ndescription to the algorithmic techniques in the chapter , and then to actually\ndesign the necessary algorithm. In our under graduate class, we have tended\nto assign roughly three of these problems per week.\n\xa0\nPedagogical Features and Supplements\nIn addition to the problems and solved exercises, the book has a number of\nfurther pedagogical features, as well as additional supplements to facilitate\nits use for teaching.\nAs noted earlier , a lar ge number of the sections in the book are devoted\nto the formulation of an algorithmic problem—including its background\nand underlying motivation—and the design and analysis of an algorithm for\nthis problem. To reflect this style, these sections are consistently structured\naround a sequence of subsections: “The Problem,” where the problem is\ndescribed and a precise formulation is worked out; “Designing the"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 10})","('type', 'Document')"
"('page_content', ""Algorithm,” where the appropriate design technique is employed to develop\nan algor ithm; and “Analyzing the Algorithm,” which proves properties of\nthe algorithm and analyzes its efficiency . These subsections are highlighted\nin the text with an icon depicting a feather . In cases where extensions to the\nproblem or further analysis of the algorithm is pursued, there are additional\nsubsections devo ted to these issues. The goal of this structure is to offer a\nrelatively uniform style of presentation that moves from the initial\ndiscussion of a problem arising  in a computing application through to the\ndetailed analysis of a method to solve it.\nA number of supplements are available in support of the book itself.\nAn instructor's manual works through all the problems, providing full\nsolutions to each. A set of lecture slides, developed by Kevin Wayne of\nPrinceton University , is also available; these slides follow the order of the\nbook's sections and can thus be used as the foundation for lectures in a\ncourse based on the book. These files are available at www .aw .com . For\ninstructions on obtaining a professor login and password, search the site for\neither “Kleinber g” or “Tardos” or contact your local Addison-W esley\nrepresentative.\nFinally , we would appreciate receiving feedback on the book. In\nparticular , as in any book of this length, there are undoubtedly errors that\nhave remained in the final versi on. Comments and reports of errors can be\nsent to us by e-mail, at the address algbook@cs.cornell.edu ; please include\nthe word “feedback” in the subject line of the message.\n\xa0\nChapter-by-Chapter Synopsis\nChapter 1 starts by introducing some representative algorithmic problems.\nWe begin immediately with the Stable Matching Problem, since we feel it\nsets up the basic issues in algorithm design more concretely and more\nelegantly than any abstract discussion could: stable matching is motivated\nby a natural though complex real-world issue, from which one can abstract\nan interesting problem statemen t and a surprisingly effective algorithm to\nsolve this problem. The remai nder of Chapter 1 discuss es a list of five\n“representative problems” that foreshadow topics from the remainder of the\ncourse. These five problems are interrelated in the sense that they are all\nvariations and/or special cases of the Independent Set Problem; but one is\nsolvable by a greedy algorithm, one by dynamic programming, one by"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 11})","('type', 'Document')"
"('page_content', ""network flow, one (the Independent Set Problem itself) is NP-complete, and\none is PSPACE -complete. The fact that closely related problems can vary\ngreatly in complexity is an important theme of the book, and these five\nproblems serve as milestones that reappear as the book progresses.\nChapters 2 and 3 cover the interface to the CS1/CS2 course sequence\nmentioned earlier . Chapter 2 introduces the key mathematic al definitions\nand notations used for analyzi ng algorithms, as well as the motivating\nprinciples behind them. It begins with an informal overview of what it\nmeans for a problem to be computationally tractable, togeth er with the\nconcept of polynomial time as a formal notion of efficiency . It then\ndiscusses growth  rates of functions and asymptotic analysis more formally ,\nand offers a guide to commonly  occurring functions in algorithm analysis,\ntogether with standard applications in which they arise. Chapter 3 covers\nthe basic defini tions and algorithmic primitives needed for working with\ngraphs, which are central to so many of the problems in the book. A number\nof basic graph algorithms are often implemented by students  late in the\nCS1/CS2 course sequence, but it is valuable to present the material here in a\nbroader algorithm design context. In particular , we discuss basic graph\ndefinitions, graph traversal techniques such as breadth-first search and\ndepth-first search, and directed graph concepts includ ing strong\nconnectivity and topological ordering.\nChapters 2 and 3 also present many of the basic data structures that\nwill be used for implementin g algorithms throughout the book; more\nadvanced data structures are presented in subsequent chapters. Our\napproach to data structures is to introduce them as they are needed for the\nimplementation of the algorithms being developed in the book. Thus,\nalthough many of the data structures covered here will be familiar to\nstudents from the CS1/CS2 sequence, our focus is on these data structures\nin the broader context of algorithm design and analysis.\nChapters 4 through 7 cover four major algorithm design techniques:\ngreedy algorithms, divide and conquer , dynamic programming, and network\nflow. With greed y algorithms, the challenge is to recognize when they work\nand when they don't; our covera ge of this topic is centered around a way of\nclassifying the kinds of arguments used to prove greedy algorithms correct.\nThis chapter concludes with some of the main applications of greedy\nalgorithms, for shortest paths, undirected and directed spanning trees,\nclustering, and compression. For divide and conquer , we begin with a"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 12})","('type', 'Document')"
"('page_content', ""discussion of strategies for solving recurrence relations as bounds on\nrunning times; we then show how familiarity with these recurrences can\nguide the design of algorithms that improve over straightforward\napproaches to a number of basic problems, including the comparison of\nrankings, the computation of closest pairs of points in the plane, and the\nFast Fourier Transform. Next we develop dynamic programming  by starting\nwith the recursive intuition behind it, and subsequently building up more\nand more expressive recurrence formulations through applications in which\nthey naturally arise. This chapter concludes with extended discussions of\nthe dynamic programming approach to two fundamental  problems:\nsequence alignment, with applications in computational biology; and\nshortest paths in graphs, with connections to Internet routing protocols.\nFinally , we cover algorithms for network flow problems, devoting much of\nour focus in this chapter to discussing a large array of different flow\napplications. To the extent that network flow is covered in algorithms\ncourses, students  are often left without an appreciation for the wide range of\nproblems to which it can be applied; we try to do justice to its versatility by\npresenting applications to load balancing, scheduling, image segmentation,\nand a number of other problems.\nChapters 8  and 9 cover computational intractability . We devote most of\nour attention to NP-completeness, organizing the basic NP-complete\nproblems thematically to help students recognize candidates for reductions\nwhen they encounter new problems. We build up to some fairly complex\nproofs of NP-completeness, with guidance on how one goes about\nconstructing a difficult reductio n. We also consider types of computational\nhardness beyond NP-completeness, particularly through the topic of\nPSPACE-completeness. We find this is a valuable way to emphasize that\nintractability doesn't end at NP-completeness, and PSPACE-completeness\nalso forms the underpinning for some central notions from artificial\nintelligence—planning and game playing— that would otherwis e not find a\nplace in the algorithmic landscape we are surveying.\nChapters 10 through 12 cover three major techniques for dealing with\ncomputationally intractable problems: identification of structured special\ncases, approximation algorithms, and local search heuristics. Our chapter on\ntractable special cases emphasizes that instances of NP-complete problems\narising in practice may not be nearly as hard as worst-cas e instances,\nbecause they often contain some structure that can be explo ited in the"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 13})","('type', 'Document')"
"('page_content', ""design of an efficient algorithm. We illustrate how NP-complete problems\nare often  efficiently solvable when restricted to tree-structured  inputs, and\nwe conc lude with an extended discussion of tree decompositions of graphs.\nWhile this topic is more suitable for a graduate course than for an\nunder graduate one, it is a technique with considerable practical utility for\nwhich it is hard to find an existing accessible reference for students. Our\nchapter on approximation algorithms discusses both the process of\ndesigning effective algorithms and the task of understanding the optimal\nsolution well enough to obtain good bounds on it. As design techniques for\napproximation algorithms, we focus on greedy algorithms, linear\nprogramming, and a third method we refer to as “prici ng,” which\nincorporates ideas from each of the first two. Finally , we discuss local\nsearch heuristics, including the Metropolis algorithm and simulated\nannealing. This topic is often missing from under graduate algorithms\ncourses, because  very little is known in the way of provable guarantees for\nthese algorithms ; however , given their widespread use in practic e, we feel it\nis valuable for students to know something about them, and we also include\nsome cases in which guarantees can be proved.\nChapter 13 covers  the use of randomization in the design of\nalgorithms. This is a topic on which several nice graduate-level  books have\nbeen written. Our goal here is to provide a more compact introduction to\nsome of the ways in which students can apply randomized techn iques using\nthe kind of background in probability one typically gains from an\nunder graduate discrete math course.\n\xa0\nUse of the Book\nThe book is primarily designed for use in a first under graduate course on\nalgorithms, but it can also be used as the basis for an introductory graduate\ncourse.\nWhen we use the book at the under graduate level, we spend roughly\none lecture per numbered section; in cases where there is more than one\nlecture's worth of material in a section (for example, when a section\nprovides further  applications as additional examples), we treat this extra\nmaterial as a supplement that students can read about outside of lecture. We\nskip the starred sections; while these sections contain important topics, they\nare less central to the development of the subject, and in some  cases they"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 14})","('type', 'Document')"
"('page_content', 'are harder as well. We also tend to skip one or two other sections per\nchapter in the first half of the book (for example, we tend to skip Sections\n4.3, 4.7–4.8, 5.5–5.6, 6.5, 7.6, and 7.11). We cover roughly half of each of\nChapters 1 1–13.\nThis last point is worth empha sizing: rather than viewing the later\nchapters as “advanced,” and hence off-limits to under graduate algorithms\ncourses, we have designed them  with the goal that the first few sections of\neach should be accessible to an under graduate audience. Our own\nunder graduate course involves material from all these chapters , as we feel\nthat all of these topics have an important place at the under graduate level.\nFinally , we treat Chapters 2 and 3 primarily as a review of material\nfrom earlier courses; but, as discussed above, the use of these two chapters\ndepends heavily on the relationship of each specific course to its\nprerequisites.\nThe resulting syllabus looks roughly as follows: Chapter 1; Chapters\n4–8 (exclud ing 4.3, 4.7–4.9, 5.5–5.6, 6.5, 6.10, 7.4, 7.6, 7.11, and 7.13);\nChapter 9 (briefly); Chapter 10, Sections 10.1 and 10.2; Chapter 11,\nSections 11.1, 11.2, 11.6, and 11.8; Chapter 12, Sections 12.1–12.3; and\nChapter 13 , Sections 13.1 –13.5.\nThe book also naturally suppor ts an introductory graduate course on\nalgorithms. Our view of such a course is that it should introdu ce students\ndestined for research in all different areas to the important current themes in\nalgorithm design . Here we find the emphasis on formulating problems to be\nuseful as well, since students will soon be trying to define their own\nresearch problem s in many different subfields. For this type of course, we\ncover the later topics in Chapters 4 and 6 (Sections 4.5–4.9 and 6.5–6.10),\ncover all of Chapter 7 (moving more rapidly through the early sections),\nquickly cover NP-completeness in Chapter 8 (since many beginning\ngraduate studen ts will have seen this topic as under graduates), and then\nspend the remai nder of the time on Chapters 10–13. Although our focus in\nan introductory graduate course is on the more advanced sections, we find it\nuseful for the students to have the full book to consult for reviewing or\nfilling in background knowledge, given the range of different undergraduate\nbackgrounds among the students in such a course.\nFinally , the book can be used to support self-study by graduate\nstudents, researc hers, or computer professionals who want to get a sense for\nhow they might be able to use particular algorithm design techn iques in the')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 15})","('type', 'Document')"
"('page_content', ""context of their own work. A number of graduate students and colleagues\nhave used portions of the book in this way .\n\xa0\nAcknowledgments\nThis book grew  out of the sequence of algorithms courses that we have\ntaught at Cornell. These courses have grown, as the field has grown, over a\nnumber of years, and they reflect the influence of the Cornell faculty who\nhelped to shape them during this time, including Juris Hartmanis, Monika\nHenzinger , John Hopcroft, Dexter Kozen, Ronitt Rubinfeld, and Sam\nToueg. More generally , we would like to thank all our colleagues at Cornell\nfor coun tless discussions both on the material here and on broader issues\nabout the nature of the field.\nThe course staffs we've had in teaching the subject have been\ntremendously helpful in the formulation of this material. We thank our\nunder graduate and graduate teaching assistants, Siddharth Alexander , Rie\nAndo, Elliot Anshelevich, Lars Backstrom, Steve Baker , Ralph Benzinger ,\nJohn Bicket, Doug Burdick, Mike Connor , Vladimir Dizhoor , Shaddin\nDoghmi, Alexander Druyan, Bowei Du, Sasha Evfimievski, Ariful Gani,\nVadim Grinshpun, Ara Hayrape tyan, Chris Jeuell, Igor Kats, Omar Khan,\nMikhail Kobyakov , Alexei Kopylov , Brian Kulis, Amit Kumar , Yeongwee\nLee, Henry Lin, Ash-win Machanavajjhala, Ayan Mandal, Bill McCloskey ,\nLeonid Meyer guz, Evan Moran, Niranjan Nagarajan, Tina Nolte, Travis\nOrtogero, Marti n Pál, Jon Peress, Matt Piotrowski, Joe Polastre, Mike\nPriscott, Xin Qi, Venu Ramasubra-manian, Aditya Rao, David Richardson,\nBrian Sabino, Rachit Siamwalla, Sebastian Silgardo, Alex Slivkins,\nChaitanya Swamy, Perry Tam, Nadya Travinin, Sergei Vassilvitskii,\nMatthew W achs, T om W exler , Shan-Leung Maverick W oo, Justin Y ang, and\nMisha Zatsman. Many of them have provided valuable insights,\nsuggestions, and comments on the text. We also thank all the students in\nthese classes who have provided comments and feedback on early drafts of\nthe book over the years.\nFor the past several years, the development of the book has benefited\ngreatly from the feedback and advice of colleagues who have used prepubli-\ncation drafts for teaching. Anna Karlin fearlessly adopted a draft as her\ncourse textbook at the University of Washington when it was still in an\nearly stage of development; she was followed by a number of people who"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 16})","('type', 'Document')"
"('page_content', 'have used it either as a course textbook or as a resource for teaching: Paul\nBeame, Allan Borodin, Devdatt Dubhashi, David Kempe, Gene Kleinber g,\nDexter Kozen, Amit Kumar , Mike Molloy , Yuval Rabani, Tim\nRoughgarden, Alexa Sharp, Shanghua Teng, Aravind Srinivasan, Dieter van\nMelkebeek, Kevin Wayne, Tom Wexler , and Sue Whitesides. We deeply\nappreciate their input and advice, which has informed many of our revisions\nto the content. We would like to additionally thank Kevin Wayne for\nproducing supp lementary material associated with the book, which\npromises to greatly extend its utility to future instructors.\nIn a number of other cases, our approach to particular topics in the\nbook reflects the infuence of specific colleagues. Many  of these\ncontributions have undoubtedly escaped our notice, but we especially thank\nYuri Boykov , Ron Elber , Dan Huttenlocher , Bobby Kleinber g, Evie\nKleinber g, Lillian Lee, David McAllester , Mark Newman,  Prabhakar\nRaghavan, Bart Selman, David Shmoys, Steve Strogatz, Olga Veksler ,\nDuncan W atts, and Ramin Zabih.\nIt has been a pleasure working with Addison Wesley over the past\nyear. First and foremost, we thank Matt Goldstein for all his advice and\nguidance in this process, and for helping us to synthesize a vast amount of\nreview material  into a concrete plan that improved the book. Our early\nconversations about the book with Susan Hartman were extremely valuable\nas well. We thank Matt and Susan, together with Michelle Brow n, Marilyn\nLloyd, Patty Mahtani, and Maite  Suarez-Rivas at Addison Wesley , and Paul\nAnagnostopoulos and Jacqui Scarlott at Windfall Software, for all their\nwork on the editing, production,  and management of the project. We further\nthank Paul and Jacqui for their expert composition of the book. We thank\nJoyce Wells for the cover design, Nancy Murphy of Dartmouth Publishing\nfor her work on the figures, T ed Laux for the indexing, and Carol Leyba and\nJennifer McClain for the copyediting and proofreading.\nWe thank Anselm Blumer (Tufts University), Richard Chang\n(University of Maryland, Baltim ore County), Kevin Compton (University\nof Michigan), Diane Cook (University of Texas, Arlington), Sariel Har-\nPeled (University of Illinois , Urbana-Champaign), Sanjeev Khanna\n(University of Pennsylvania), Philip Klein (Brown Univers ity), David\nMatthias (Ohio State University), Adam Mey-erson (UCLA), Michael\nMitzenmacher (Harvard University), Stephan Olariu (Old Dominion\nUniversity), Mohan Paturi (UC San Diego), Edgar Ramos (University of')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 17})","('type', 'Document')"
"('page_content', ""Illinois, Urbana-Champaign), Sanjay Ranka (University of Florida,\nGainesville), Leon Reznik (Rochester Institute of Technology ), Subhash\nSuri (UC Santa Barbara), Dieter van Melkebeek (University of Wisconsin,\nMadison), and Bulent Yener (Rensselaer Polytechnic Institute) who\ngenerously contributed their time to provide detailed and thoughtful reviews\nof the manuscri pt; their comments led to numerous improvements, both\nlarge and small, in the final version of the text.\nFinally , we thank our families—Lillian and Alice, and David, Rebecca,\nand Amy . We appreciate their support, patience, and many other\ncontributions more than we can express in any acknowledgments here.\nThis book was begun amid the irrational exuberance of the late\nnineties, when the arc of comp uting technology seemed, to many of us,\nbriefly to pass through a place  traditionally occupied by celebrities and\nother inhabitants of the pop-cultural firmament. (It was probably just in our\nimaginations.) Now , several years after the hype and stock prices have\ncome back to earth, one can appreciate that in some ways comp uter science\nwas forever changed by this period, and in other ways it has remained the\nsame: the driving excitement that has characterized the field since its early\ndays is as strong and enticing as ever, the public's fascination with\ninformation technology is still vibrant, and the reach of computing\ncontinues to extend into new disciplines. And so to all students of the\nsubject, drawn to it for so many different reasons, we hope you find this\nbook an enjoyable and useful guide wherever your computational pursuits\nmay take you.\nJon Kleinber g \nÉva T ardos  \nIthaca, 2005"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 18})","('type', 'Document')"
"('page_content', 'Chapter 1')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 19})","('type', 'Document')"
"('page_content', ""Introduction: Some Representative\nProblems\n1.1 A First Pr oblem: Stable Matching  \n1.2 Five Repr esentative Pr oblems  \nSolved Exer cises  \nExer cises  \nNotes and Further Reading\n1.1 A First Problem: Stable Matching\nAs an opening topic, we look at an algorithmic problem that nicely\nillustrates many  of the themes we will be emphasizing. It is motivated by\nsome very natural and practical concerns, and from these we formulate a\nclean and simple statement of a problem. The algorithm to solve the\nproblem is very clean as well, and most of our work will be spent in\nproving that it is correct and giving an acceptable bound on the amount of\ntime it takes to terminate with an answer . The problem itself—the Stable\nMatching Pr oblem —has several origins.\nThe Problem\nThe Stable Matching Problem originated, in part, in 1962, when  David Gale\nand Lloyd Shapley , two mathematical economists, asked the question:\nCould one design a college admissions process, or a job recruiting process,\nthat was self-enfor cing?  What did they mean by this?\nTo set up the question, let's first think informally about the kind of\nsituation that might arise as a group of friends, all juniors in college\nmajoring in computer science, begin applying to companies for summer\ninternships. The crux of the application process is the interplay between two\ndifferent types of parties: companies (the employers) and students (the"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 20})","('type', 'Document')"
"('page_content', ""applicants). Each applicant has a preference ordering on companies, and\neach company— once the applications come in—forms a preference\nordering on its applicants. Based on these preferences, companies extend\noffers to some of their applicants, applicants choose which of their offers to\naccept, and people begin heading of f to their summer internships.\nGale and Shaple y considered the sorts of things that could start going\nwrong with this process, in the absence of any mechanism to enforce the\nstatus quo. Suppose, for example, that your friend Raj has just accepted a\nsummer job at the large telecommunications company CluNet. A few days\nlater, the small start-up company WebExodus, which had been dragging its\nfeet on making a few final decis ions, calls up Raj and offers him a summer\njob as well. Now , Raj actually prefers WebExodus to CluNet—won over\nperhaps by the laid-back, anything-can-happen atmosphere—and so this\nnew development may well cause him to retract his acceptance of the\nCluNet offer and go to WebEx odus instead. Suddenly down one summer\nintern, CluNet offers a job to one of its wait-listed applicants, who promptly\nretracts his previous acceptance of an offer from the software giant\nBabelsoft, and the situation begins to spiral out of control.\nThings look just as bad, if not worse, from the other direction. Suppose\nthat Raj's friend  Chelsea, destined to go to Babelsoft but having just heard\nRaj's story, calls up the people  at WebExodus and says, “You know , I'd\nreally rather spend the summer with you guys than at Babelsoft.” They find\nthis very easy to believe; and furthermore, on looking at Chelsea's\napplication, they realize that they would have rather hired her than some\nother student who actually is scheduled to spend the summer at\nWebExodus. In this case, if WebExodus were a slightly less scrupulous\ncompany , it might well find some way to retract its offer to this other\nstudent and hire Chelsea instead.\nSituations like this can rapidly generate a lot of chaos, and many\npeople— both applicants and employers—can end up unhappy with the\nprocess as well as the outcome. What has gone wrong? One basic problem\nis that the proces s is not self-enforcing—if people are allowed to act in their\nself-interest, then it risks breaking down.\nWe might well prefer the follo wing, more stable situation, in which\nself-interest itself prevents offers from being retracted and redirected.\nConsider another student, who has arranged to spend the summe r at CluNet\nbut calls up WebExodus and reveals that he, too, would rather work for"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 21})","('type', 'Document')"
"('page_content', ""them. But in this case, based on the offers already accepted, they are able to\nreply , “No, it turns out that we prefer each of the students we've  accepted to\nyou, so we're afraid there's nothing we can do.” Or consider an employer ,\nearnestly follow ing up with its top applicants who went elsew here, being\ntold by each of them, “No, I'm happy where I am.” In such a case, all the\noutcomes are stable—there are no further outside deals that can be made.\nSo this is the question Gale and Shapley asked: Given a set of\npreferences among employers and applicants, can we assign applicants to\nemployers so that for every employer E, and every applicant A who is not\nscheduled to work for E, at least one of the following two things is the\ncase?\n(i) E prefers every one of its accepted applicants to A; or\n(ii) A prefers her current situation over working for employer E.\nIf this holds, the outcome is stable: individual self-interest will prevent any\napplicant/employer deal from being made behind the scenes.\nGale and Shaple y proceeded to develop a striking algorithmic solution\nto this problem, which we will discuss presently . Before doing this, let's\nnote that this is not the only origin of the Stable Matching Problem. It turns\nout that for a decade before the work of Gale and Shapley , unbeknownst to\nthem, the National Resident Matching Program had been using a very\nsimilar procedure, with the same underlying motivation, to match residents\nto hospitals. Indeed, this system, with relatively little change, is still in use\ntoday .\nThis is one testament to the problem's fundamental appeal. And from\nthe point of view of this book,  it provides us with a nice first domain in\nwhich to reason about some basic combinatorial definitio ns and the\nalgorithms that build on them.\nFormulating the Problem  To get at the essence of this concept, it helps to\nmake the problem as clean as possible. The world of companies and\napplicants contains some distracting asymmetries. Each applicant is looking\nfor a single company , but each company is looking for many applicants;\nmoreover , there may be more (or, as is sometimes the case, fewer)\napplicants than there are available slots for summer jobs. Finally , each\napplicant does not typically apply to every company .\nIt is useful, at least initially , to eliminate these complications and arrive\nat a more “bare- bones” version of the problem: each of n applicants applies\nto each of n companies, and each company wants to accept a single"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 22})","('type', 'Document')"
"('page_content', 'applicant. We will see that doing this preserves the fundamental issues\ninherent in the problem; in particular , our solution to this simpli fied version\nwill extend directly to the more general case as well.\nFollowing Gale and Shapley , we observe that this special case can be\nviewed as the problem of devising a system by which each of n men and n\nwomen can end up getting marr ied: our problem naturally has the analogue\nof two “genders ”—the applican ts and the companies—and in the case we\nare considering, everyone is seeking to be paired with exactly one\nindividual of the opposite gender .1\nSo consider a set M = {m1,…, mn} of n men, and a set W = {w1,…, wn]\nof n wom en. Let M × W denote the set of all possible ordered pairs of the\nform (m, w), where m ∊ M and w ∊ W. A matching S is a set of ordered\npairs, each from  M × W, with the property that each member of M and each\nmember of W appears in at most one pair in S. A perfect matching S′ is a\nmatching with the property that each member of M and each member of W\nappears in exactly  one pair in S′.\nMatchings and perfect matchings are objects that will recur frequently\nthroughout the book; they arise naturally in modeling a wide range of\nalgorithmic problems. In the present situation, a perfect matching\ncorresponds simply to a way of pairing of f the men with the women, in such\na way that every one ends up married to somebody , and nobody is married\nto more than one person—there is neither singlehood nor polygamy .\nFigur e 1.1  Perfect matching S with instability ( m,w′).\nNow we can add the notion of preferences  to this setting. Each man m\n∊ M ranks  all the women; we will say that m prefers w to w′ if m ranks w')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 23})","('type', 'Document')"
"('page_content', ""higher than w′. We will refer to the ordered ranking of m as his preference\nlist. We will not allow ties in the ranking. Each woman, analogously , ranks\nall the men.\nGiven a perfect matching S, what can go wrong? Guided by our initial\nmotivation in terms of employ ers and applicants, we should be worried\nabout the following situation: There are two pairs (m, w) and (m′, w′) in S\n(as depicted in Figure 1.1) with the prope rty that m prefers w′ to w, and w′\nprefers m to m′. In this case, there's nothing to stop m and w′ from\nabandoning their current partners and heading off together; the set of\nmarriages is not self-enforcing . We'll say that such a pair (m, w′) is an\ninstability  with respect to S: (m, w′) does not belon g to S, but each of m and\nw′ prefers the other to their partner in S.\nOur goal, then, is a set of marriages with no instabilities. We'll say that\na matching S is stable  if (i) it is perfect, and (ii) there is no instability with\nrespect to S. Two questions spring immediately to mind:\nDoes there exist a stable matching for every set of preference lists?\nGiven a set of preference lists, can we efficiently construct a stable\nmatching if there is one?\nSome Examples  To illustrate these definitions, consider the following two\nvery simple instances of the Stable Matching Problem.\nFirst, suppose we have a set of two men, {m, m′}, and a set of two\nwomen, [ w, w′}. The preference lists are as follows:\nm prefers w to w′.\nm′ prefers w to w′.\nw prefers m to m′.\nw′ prefers m to m′.\nIf we think about this set of preference lists intuitively , it represents\ncomplete agreem ent: the men agree on the order of the women, and the\nwomen agree on the order of the men. There is a unique stable matching"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 24})","('type', 'Document')"
"('page_content', ""here, consisting of the pairs (m, w) and ( m′, w′ ). The other perfect matching,\nconsisting of the pairs (m′, w) and (m, w′), would not be a stable matching,\nbecause the pair (m, w) would form an instability with respect to this\nmatching. (Both m and w would want to leave their respective partners and\npair up.)\nNext, here's an example where things are a bit more intricate. Suppose\nthe preferences are\nm prefers w to w′.\nm′ prefers w′ to w.\nw prefers m′ to m.\nw′ prefers m to m′.\nWhat's going on in this case? The two men's preferences mesh perfectly\nwith each other (they rank different women first), and the two women's\npreferences likewise mesh perfectly with each other . But the men's\npreferences clash completely with the women's preferences.\nIn this second example, there are two different stable matchings. The\nmatching consisting of the pairs (m, w) and (m′, w′) is stable, because both\nmen are as happy as possible, so neither would leave their matc hed partner .\nBut the matching consisting of the pairs (m′, w) and (m, w′) is also stable,\nfor the complem entary reason that both women are as happy as possible.\nThis is an important point to remember as we go forward—it's possible for\nan instance to have more than one stable matching.\nDesigning the Algorithm\nWe now show that there exists a stable matching for every set of preference\nlists among the men and women. Moreover , our means of showing this will\nalso answer the second question that we asked above: we will give an\nefficient algorith m that takes the preference lists and constructs a stable\nmatching.\nLet us consider some of the basic ideas that motivate the algorithm."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 25})","('type', 'Document')"
"('page_content', 'Initially , everyone is unmarried. Suppose an unmarried man m chooses\nthe woman w who ranks highest on his preference list and proposes  to\nher. Can we declare immediately that (m, w) will be one of the pairs in\nour final stable matching? Not necessarily: at some point in the future,\na man m′ whom w prefers may propose to her. On the other hand, it\nwould be dangerous for w to reject m right away; she may never\nreceive a proposal from someone she ranks as highly as m. So a natural\nidea would be to have the pair (m, w) enter an intermediate state—\nengagement.\nSuppose we are now at a state in which some men and women are free\n— not engaged—and some are engaged. The next step could look like\nthis. An arbitrary free man m chooses  the highest-ranked woman w to\nwhom he has not yet proposed, and he proposes to her. If w is also\nfree, then m and w become engaged. Otherwise, w is alrea dy enga ged\nto some other man m′. In this case, she determines which of m or m′\nranks higher on her preference list; this man becomes engage d to w\nand the other becomes free.\nFinally , the algorithm will terminate when no one is free; at this\nmoment, all engagements are declared final, and the resulting perfect\nmatching is returned.\nFigur e 1.2  An intermediate state of the G-S algorithm when a free man m is\nproposing to a woman w.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 26})","('type', 'Document')"
"('page_content', ""Here is a concr ete description of the Gale-Shapley algorithm,  with\nFigure 1.2  depicting a state of the algorithm.\nInitially all m ∊ M and w ∊ W are free\nWhile there is a man m who is free and hasn't proposed to every woman\nChoose such a man m\nLet w be the highest-ranked woman in m's preference list to whom m has not yet proposed\nIf w is free then\n(m, w ) become engaged\nElse w is currently engaged to m′\nIf w prefers m′ to m then\nm remains free\nElse w prefers m to m′\n(m,w) become engaged\nm′ becomes free\nEndif\nEndif\nEndwhile\nReturn the set S of engaged pairs\nAn intriguing thing is that, although the G-S algorithm is quite simple\nto state, it is not immediately obvious that it returns a stable matching, or\neven a perfect matching. We proceed to prove this now, through a sequence\nof intermediate facts.\nAnalyzing the Algorithm\nFirst consider the view of a woman w during the execution of the algorithm.\nFor a while, no one has proposed to her, and she is free. Then a man m may\npropose to her, and she becomes  engaged. As time goes on, she may receive\nadditional proposals, accepting those that increase the rank of her partner .\nSo we discover the following.\n(1.1)  w remains engaged from the point at which she receives her first proposal; and the sequence of\npartners to which she is engaged gets better and better (in terms of her pr eference list).\nThe view of a man m during the execution of the algorithm is rather\ndifferent. He is free until he proposes to the highest-ranked woman on his\nlist; at this point he may or may not become engaged. As time goes on, he\nmay alternate between being free and being engaged; however , the\nfollowing property does hold."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 27})","('type', 'Document')"
"('page_content', '(1.2)  The sequence of women to whom m proposes gets worse and worse (in terms of his preference\nlist).\nNow we show that the algorithm terminates, and give a bound on the\nmaximum number of iterations needed for termination.\n(1.3)  The G-S algorithm terminates after at most n2 iterations of the  While loop.\nProof. A useful strategy for upper -bounding the running time of an algorithm, as we are trying to do\nhere, is to find a measure of progress. Namely , we seek some precise way of saying that each step\ntaken by the algorithm brings it closer to termination.\nIn the case of the present algorithm, each iteration consists of some man proposing (for the only\ntime) to a woman he has never proposed to before. So if we let P(t) denote the set of pairs (m, w)\nsuch that m has proposed to w by the end of iteration t, we see that for all t, the size of P(t + 1) is\nstrictly greater than the size of P(t). But there are only n2 possible pairs of men and women in total,\nso the value of P(·) can increase at most n2 times over the course of the algorithm. It follows that\nthere can be at most n2 iterations. ▪\nTwo points are worth noting about the previous fact and its proof.\nFirst, there are executions of the algorithm (with certain preference lists)\nthat can involve close to n2 iteration s, so this analysis is not far from the\nbest possible. Second, there are many quantities that would not have\nworked well as a progress measur e for the algorithm, since they need not\nstrictly increase in each iteration. For example, the number of free\nindividuals could remain constant from one iteration to the next, as could\nthe number of engaged pairs. Thus, these quantities could not be used\ndirectly in giving an upper bound on the maximum possible number of\niterations, in the style of the previous paragraph.\nLet us now establish that the set S returned at the termination of the\nalgorithm is in fact a perfect  matching. Why is this not immediately\nobvious? Essentially , we have to show that no man can “fall off” the end of\nhis preference list; the only way for the While loop to exit is for there to be\nno free man. In this case, the set of engaged couples would indeed be a\nperfect matching.\nSo the main thing we need to show is the following.\n(1.4)  If m is free at some point in the execution of the algorithm, then there is a woman to whom he\nhas not yet pr oposed.\nProof. Suppose there comes  a point when m is free but has already proposed to every woman. Then\nby (1.1), each of the n women is engaged at this point in time. Since the set of engaged pairs forms a\nmatching, there must also be n engaged men at this point in time. But there are only n men total,  and\nm is not engaged, so this is a contradiction. ▪')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 28})","('type', 'Document')"
"('page_content', ""(1.5)  The set S r eturned at termination is a perfect matching.\nProof. The set of engaged pairs always form s a matching. Let us suppose that the algorithm\nterminates with a free man m. At termination, it must be the case that m had already proposed to\nevery wom an, for otherwise the While loop would not have exited. But this contradi cts (1.4), which\nsays that there cannot be a free man who has proposed to every woman. ▪\nFinally , we prove the main property of the algorithm—namely , that it\nresults in a stable matching.\n(1.6)  Consider an execution of the G-S algorith m that returns a set of pairs S. The set S is a stable\nmatching.\nProof. We have already seen, in (1.5), that S is a perfect matching. Thus, to prove S is a stable\nmatching, we will assume that there is an instability with respect to S and obtain a contrad iction. As\ndefined earlier , such an instability would  involve two pairs, (m, w) and (m′, w′), in S with the\nproperties that\nm prefers w′ to w, and\nw′ prefers m to m′.\nIn the execution of the algorithm that produced S, m's last proposal was, by definition, to w. Now we\nask: Did m propose to w′ at some earlier point in this execution? If he didn't, then w must occur\nhigher on m's preference list than w′, contradicting our assumption that m prefers w′ to w. If he did,\nthen he was rejected by w′ in favor of some other man m″, whom w′ prefers to m. m′ is the final\npartner of w′, so either m″ = m′ or, by (1.1), w′ prefers her final partner m′ to m″; either way this\ncontradicts our assumption that w′ prefers m to m′.\nIt follows that S is a stable matching. ▪\nExtensions\nWe began by defining the notion of a stable matching; we have just proven\nthat the G-S algorithm actually constructs one. We now consider some\nfurther questions about the behavior of the G-S algorithm and its relation to\nthe properties of dif ferent stable matchings.\nTo begin with, recall that we saw an example earlier in which there\ncould be multiple stable matchings. To recap, the preference lists in this\nexample were as follows:\nm prefers w to w′.\nm′ prefers w′ to w."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 29})","('type', 'Document')"
"('page_content', ""w prefers m′ to m.\nw′ prefers m to m′.\nNow , in any execution of the Gale-Shapley algorithm, m will become\nengaged to w, m′ will become engaged to w′ (perhaps in the other order),\nand things will stop there. Thus, the other  stable matching , consisting of the\npairs (m′, w) and (m, w), is not attainable from an execution of the G-S\nalgorithm in which the men propose. On the other hand, it would be reached\nif we ran a version of the algorithm in which the women propose. And in\nlarger examples, with more than two people on each side, we can have an\neven larger collection of possible stable matchings, many of them not\nachievable by any natural algorithm.\nThis example shows a certain “unfairness” in the G-S algorithm,\nfavoring men. If the men's prefe rences mesh perfectly (they all list different\nwomen as their first choice), then in all runs of the G-S algorit hm all men\nend up matched with their first choice, independent of the preferences of the\nwomen. If the women's prefe rences clash completely with the men's\npreferences (as was the case in this example), then the resulting stable\nmatching is as bad as possible for the women. So this simple set of\npreference lists compactly summarizes a world in which someone  is\ndestined to end up unhappy: women are unhappy if men propose, and men\nare unhappy if women propose.\nLet's now analyze the G-S algorithm in more detail and try to\nunderstand how general this “unfairness” phenomenon is.\nTo begin with, our example reinforces the point that the G-S algorithm\nis actual ly under specified: as long as there is a free man, we are allowed to\nchoose any free man to make the next proposal. Different choices specify\ndifferent executi ons of the algorithm; this is why, to be careful, we stated\n(1.6) as “Consider an execution  of the G-S algorithm that returns a set of\npairs S,” instead of “Consider the set S returned by the G-S algorithm.”\nThus, we encounter another very natural question: Do all executions of\nthe G-S algorithm yield the same matching? This is a genre of question that\narises in many settings in computer science: we have an algorithm that runs\nasynchr onously , with different independent components performing actions\nthat can be interleaved in complex ways, and we want to know how much\nvariability this asynchrony causes in the final outcome. To consider a very"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 30})","('type', 'Document')"
"('page_content', ""different kind of example, the independent components may not be men and\nwomen but electronic componen ts activating parts of an airplane wing; the\neffect of asynchrony in their behavior can be a big deal.\nIn the present context, we will see that the answer to our question is\nsurprisingly clean: all executions of the G-S algorithm yield the same\nmatching. W e proceed to prove this now .\nAll Executions Yield the Same Matching  There are a number of possible\nways to prove a statement such as this, many of which would result in quite\ncomplicated arguments. It turns  out that the easiest and most informative\napproach for us will be to uniquely characterize  the matching that is\nobtained and then show that all executions result in the matching with this\ncharacterization.\nWhat is the characterization? We'll show that each man ends up with\nthe “best possible partner” in a concrete sense. (Recall that this is true if all\nmen prefer different women.) First, we will say that a woman w is a valid\npartner  of a man m if there is a stable matching that contains the pair (m,w).\nWe will say that w is the best valid partner  of m if w is a valid partner of m,\nand no woman whom m ranks higher than w is a valid partn er of his. We\nwill use best(m) to denote the best valid partner of m.\nNow , let S* denote  the set of pairs {(m, best(m)) : m ∊ M}. We will\nprove the following fact.\n(1.7)  Every execution of the G-S algorithm r esults in the set S*.\nThis statem ent is surprising at a number of levels. First of all, as defined, there is no reason to believe\nthat S* is a matc hing at all, let alone a stable matching. After all, why couldn't it happen that two men\nhave the same best valid partner? Second, the result shows that the G-S algorithm gives the best\npossible outcome for every man simultaneously; there is no stable matching in which any of the men\ncould have hoped to do better . And finally , it answers our question above by showing that the order\nof proposals in the G-S algorithm has absolutely no ef fect on the final outcome.\nDespite all this, the proof is not so dif ficult.\nProof. Let us suppose, by way of contradiction, that some execution ε of the G-S algorithm results in\na matching S in which some man is paired with a woma n who is not his best valid partner . Since men\npropose in decreasing order of preference, this means that some man is rejected by a valid partner\nduring the execution ε of the algorithm. So consider the first moment during the execution ε in which\nsome man, say m, is rejected by a valid partner w. Again, since men propose in decreasing order of\npreference, and since this is the first time such a rejection has occurred, it must be that w is m's best\nvalid partner best(m).\nThe rejection of m by w may have happened either because m proposed and was turned down in\nfavor of w's existing engagement, or because w broke her engageme nt to m in favor of a better\nproposal. But either way, at this moment w forms or continues an engagement with a man m′ whom\nshe prefers to m.\nSince w is a valid partner of m, there exist s a stable matching S′ containing the pair (m, w). Now\nwe ask: Who is m′ paired with in this matching? Suppose it is a woman w′ ≠ w."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 31})","('type', 'Document')"
"('page_content', ""Since the rejection of m by w was the first rejection  of a man by a valid partner in the execution\nε, it must be that m′ had not been rejected by any valid partner at the point in ε when he became\nengaged to w. Since he proposed in decreasing order of preference, and since w′ is clearly a valid\npartner of m′, it must be that m′ prefers w to w′. But we have already  seen that w prefers m′ to m, for\nin execution ε she rejected m in favor of m′. Since ( m′, w ) ∉ S′, it follows that (m′, w ) is an instability\nin S′.\nThis contradicts our claim that S′ is stable and hence contradicts our initial assumption. ▪\nSo for the men,  the G-S algorithm is ideal. Unfortunately , the same\ncannot be said for the women. For a woman w, we say that m is a valid\npartner if there is a stable matching that contains the pair (m,w). We say that\nm is the worst valid partner  of w if m is a valid partn er of w, and no man\nwhom w ranks lower than m is a valid partner of hers.\n(1.8)  In the stable matching S*, each woman is pair ed with her worst valid partner .\nProof. Suppose there were a pair (m, w) in S* such that m is not the worst valid partner of w. Then\nthere is a stable matching S′ in which w is paired with a man m′ whom she likes less than m. In S′, m\nis paired with a woman w′ ≠ w; since w is the best valid partner of m, and w′ is a valid partner of m,\nwe see that m prefers w to w′.\nBut from this it follows that (m, w) is an insta bility in S′, contradicting the claim that S′ is stable\nand hence contradicting our initial assumption. ▪\nThus, we find that our simple  example above, in which the men's\npreferences clashed with the women's, hinted at a very general\nphenomenon: for any input, the side that does the proposing  in the G-S\nalgorithm ends up with the best possible stable matching (from their\nperspective), while the side that does not do the proposing correspondingly\nends up with the worst possible stable matching.\n1.2 Five Representative Problems\nThe Stable Matching Problem  provides us with a rich example of the\nprocess of algorithm design. For many problems, this process involves a\nfew significant steps: formulating the problem with enough mathematical\nprecision that we can ask a concrete question and start thinking about\nalgorithms to solve it; designing an algorithm for the problem; and\nanalyzing the algorithm by proving it is correct and giving a bound on the\nrunning time so as to establish the algorithm's ef ficiency .\nThis high-level strategy is carrie d out in practice with the help of a few\nfundamental design techniques, which are very useful in assessing the"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 32})","('type', 'Document')"
"('page_content', ""inherent comple xity of a proble m and in formulating an algorit hm to solve\nit. As in any area, becoming familiar with these design techniques is a\ngradual process; but with experience one can start recognizing problems as\nbelonging to identifiable genres and appreciating how subtle changes in the\nstatement of a problem can have an enormous effect on its computational\ndifficulty .\nTo get this discussion started, then, it helps to pick out a few\nrepresentative milestones that we'll be encountering in our study of\nalgorithms: cleanly formulated problems, all resembling one another at a\ngeneral level, but differing greatly in their difficulty and in the kinds of\napproaches that one brings to bear on them. The first three will be solvable\nefficiently by a sequence of increasingly subtle algorithmic techniques; the\nfourth marks a major turning point in our discussion, serving as an example\nof a problem believed to be unsolvable by any efficient algorithm; and the\nfifth hints at a class of problems believed to be harder still.\nThe problems are self-contained  and are all motivated by computing\napplications. To talk about some of them, though, it will help to use the\nterminology of graphs.  While graphs are a common topic in earlier\ncomputer science courses, we'll be introducing them in a fair amount of\ndepth in Chapter 3; due to their enormous expressive power , we'll also be\nusing them extensively through out the book. For the discussio n here, it's\nenough to think of a graph G as simply a way of encoding pairwise\nrelationships among a set of objects. Thus, G consists of a pair of sets (V, E)\n—a collection V of nodes  and a collection E of edges,  each of which “joins”\ntwo of the nodes . We thus represent an edge e ∊ E as a two-element subset\nof V: e = {u, v} for some u, v ∊ V, where we call u and v the ends of e. We\ntypically draw graphs as in Figure 1.3 , with each node as a small circle and\neach edge as a line segment joining its two ends.\nLet's now turn to a discussion of the five representative problems.\nFigur e 1.3  Each of (a) and (b) depicts a graph on four nodes."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 33})","('type', 'Document')"
"('page_content', ""Interval Scheduling\nConsider the following very simple scheduling problem. You have a\nresource— it may be a lectur e room, a supercomputer , or an electron\nmicroscope—and many people request to use the resource for periods of\ntime. A request  takes the form: Can I reserve the resource starting at time s,\nuntil time f? We will assume that the resource can be used by at most one\nperson at a time. A scheduler wants to accept a subset of these requests,\nrejecting all others, so that the accepted requests do not overlap in time. The\ngoal is to maximize the number of requests accepted.\nMore formally , there will be n requests labeled 1,…, n, with each\nrequest i specifyi ng a start time st and a finish time ft. Naturally , we have st\n< ft for all i. Two requests i and; are compatible  if the requested intervals do\nnot overlap: that is, either request i is for an earlier time interval than\nrequest j (ft ≤ sj), or request i is for a later time than request; (ft ≤ sj). We'll\nsay more genera lly that a subse t A of requests is compatible if all pairs of\nrequests i,j ∊ A, i ≠ j are compatible. The goal is to select a compatible\nsubset of requests of maximum possible size.\nWe illustrate an instance of this Interval Scheduling Problem  in Figure\n1.4. Note that there is a single compatible set of size 4, and this is the\nlargest compatible set.\nFigur e 1.4  An instance of the Interval Scheduling Problem."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 34})","('type', 'Document')"
"('page_content', ""We will see shortly that this problem can be solved by a very natural\nalgorithm that orders the set of requests according to a certain heuristic and\nthen “greedily” processes them in one pass, selecting as large a compatible\nsubset as it can. This will be typical of a class of greedy algorithms  that we\nwill consider for various problem s—myopic rules that process the input one\npiece at a time with no apparent look-ahead. When a greedy algorithm can\nbe shown to find an optimal solution for all instances of a problem, it's often\nfairly surprising. We typically learn something about the structure of the\nunderlying problem from the fact that such a simple appro ach can be\noptimal.\nWeighted Interval Scheduling\nIn the Interval Scheduling Problem, we sought to maximize the number  of\nrequests that could be accommodated simultaneously . Now , suppose more\ngenerally that each request interval i has an associated value , or weight , vi >\n0; we could picture this as the amount of money we will make from the ith\nindividual if we schedule his or her request. Our goal will be to find a\ncompatible subset of intervals of maximum total value.\nThe case in which vi = 1 for each i is simp ly the basic Interval\nScheduling Problem; but the appearance of arbitrary values changes the\nnature of the maximization problem quite a bit. Consider , for example, that\nif v1 exceeds the sum of all other vi, then the optimal solution must include\ninterval 1 regardless of the configuration of the full set of intervals. So any\nalgorithm for this problem must be very sensitive to the values, and yet\ndegenerate to a method for solving (unweighted) interval scheduling when\nall the values are equal to 1.\nThere appears to be no simple  greedy rule that walks through the\nintervals one at a time, making the correct decision in the presence of\narbitrary values. Instead, we employ a technique, dynamic programming ,\nthat builds up the optimal value over all possible solutions in a compact,\ntabular way that leads to a very ef ficient algorithm."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 35})","('type', 'Document')"
"('page_content', ""Bipartite Matching\nWhen we considered the Stable Matching Problem, we defined a matching\nto be a set of ordered pairs of men and women with the property that each\nman and each woman belong to at most one of the ordered pairs. We then\ndefined a perfect matching  to be a matching in which every man and every\nwoman belong to some pair .\nWe can express these concepts more generally in terms of graphs, and\nin order to do this it is useful to define the notion of a bipartite graph . We\nsay that a graph G = (V, E) is bipartite  if its node set V can be partitioned\ninto sets X and Y in such a way that every edge has one end in X and the\nother end in Y. A bipartite graph is pictured in Figure 1.5; often, when we\nwant to emphasize a graph's “bipartiteness,” we will draw it this way, with\nthe nodes in X and Y in two parallel columns. But notice, for example, that\nthe two graphs in Figure 1.3  are also bipartite.\nFigur e 1.5  A bipartite graph.\nNow , in the problem of finding a stable matching, matchings were\nbuilt from pairs of men and women. In the case of bipartite graphs, the\nedges are pairs of nodes, so we say that a matching in a graph G = (V, E) is\na set of edges M ⊆ E with the proper ty that each node appears in at most\none edge of M. M  is a perfect matching if every node appears in exactly one\nedge of M.\nTo see that this does capture the same notion we encountered in the\nStable Matching Problem, consider a bipartite graph G′ with a set X of n\nmen, a set Y of n women , and an edge from every node in X to every  node"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 36})","('type', 'Document')"
"('page_content', 'in Y. Then the matchings and perfect matchings in G′ are precisely the\nmatchings and perfect matchings among the set of men and women.\nIn the Stable Matching Problem, we added preferences to this picture.\nHere, we do not consider preferences; but the nature of the problem in\narbitrary bipartit e graphs adds a different source of complexity: there is not\nnecessarily an edge from every x ∊ X to every y ∊ Y, so the set of possible\nmatchings has quite a complicat ed structure. In other words, it is as though\nonly certain pairs of men and women are willing to be paired off, and we\nwant to figure out how to pair off many people in a way that is consistent\nwith this. Consider , for example, the bipartite graph G in Figure 1.5: there\nare many matchings in G, but there is only one perfect matching. (Do you\nsee it?)\nMatchings in bipartite graphs can model situations in which objects are\nbeing assigned  to other objects. Thus, the nodes in X can represent jobs, the\nnodes in Y can represent machines, and an edge (xi,yj) can indicate that\nmachine yj is capab le of processing job xt. A perfe ct matching is then a way\nof assign ing each job to a machine that can process it, with the property that\neach machine is assigned exactly one job. In the spring, computer science\ndepartments across the country are often seen pondering a bipar tite graph in\nwhich X is the set of professors in the department, Y is the set of offered\ncourses, and an edge (xi,yj) indicates that professor xt is capable of teaching\ncourse yj. A perfect matching in this graph consists of an assignment of\neach professor to a course that he or she can teach, in such a way that every\ncourse is covered.\nThus the Bipartite Matching Problem  is the following: Given an\narbitrary bipartite graph G, find a matching of maximum size. If |X| = |Y| =\nn, then there is a perfect matching  if and only if the maximum matching has\nsize n. We will find that the algorithmic techniques discussed earlier do not\nseem adequate for providing an efficient algorithm for this problem. There\nis, howe ver, a very elegant and efficient algorithm to find a maximum\nmatching; it inductively builds up larger and larger matchings , selectively\nbacktracking along the way. This process is called augmentation,  and it\nforms the central component in a large class of efficiently solvable\nproblems called network flow pr oblems.\nFigur e 1.6  A graph whose lar gest independent set has size 4.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 37})","('type', 'Document')"
"('page_content', ""Independent Set\nNow let's talk about an extremely general problem, which inclu des most of\nthese earlier problems as special cases. Given a graph G = (V, E), we say a\nset of nodes S ⊆ V is independent  if no two nodes in S are joined by an\nedge. The Independent Set Pr oblem  is, then, the following: Given G, find an\nindependent set that is as large as possible. For example, the maximum size\nof an independent set in the graph in Figure 1.6 is four, achieved by the\nfour-node independent set {1, 4, 5, 6}.\nThe Independen t Set Problem encodes any situation in which you are\ntrying to choose  from among a collection of objects and there are pairwise\nconflicts  among some of the objects. Say you have n friends, and some pairs\nof them don't get along. How large a group of your friends can you invite to\ndinner if you don't want any interpersonal tensions? This is simply the\nlargest independent set in the graph whose nodes are your friends, with an\nedge between each conflicting pair .\nInterval Scheduling and Bipart ite Matching can both be encoded as\nspecial cases of the Independent Set Problem. For Interval Scheduling,\ndefine a graph G = (V, E) in which the nodes are the intervals and there is an\nedge between each pair of them  that overlap; the independent sets in G are\nthen just the compatible subsets of intervals. Encoding Bipartite Matching\nas a special case of Independent Set is a little trickier to see. Given a\nbipartite graph G′ = (V′, E′), the objects being chosen are edges, and the\nconflicts arise between two edge s that share an end. (These, indeed, are the\npairs of edges that cannot belon g to a common matching.) So we define a\ngraph G = (V, E) in which the node set V is equa l to the edge set E′ of G′.\nWe define an edge between each pair of elements in V that correspond to\nedges of G′ with a common  end. We can now check that the independent\nsets of G are precisely the matchings of G′. While it is not complicated to"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 38})","('type', 'Document')"
"('page_content', ""check this, it takes a little conce ntration to deal with this type of “edges-to-\nnodes, nodes-to-edges” transformation.2\nGiven the generality of the Independent Set Problem, an efficient\nalgorithm to solve it would be quite impressive. It would have to implicitly\ncontain algorithms for Interval Scheduling, Bipartite Matching, and a host\nof other natural optimization problems.\nThe current status of Independent Set is this: no efficient algorithm is\nknown for the problem, and it is conjectured that no such algorithm exists.\nThe obvious brute-force algor ithm would try all subsets of the nodes,\nchecking each to see if it is independent, and then recording the largest one\nencountered. It is possible that this is close to the best we can do on this\nproblem. We will see later in the book that Independent Set is one of a large\nclass of problem s that are termed NP-complete . No efficient algorithm is\nknown for any of them; but they are all equivalent  in the sense that a\nsolution to any one of them would imply , in a precise sense, a solution to all\nof them.\nHere's a natural question: Is there anything good we can say about the\ncomplexity of the Independent  Set Problem? One positive thing is the\nfollowing: If we have a graph G on 1,000 nodes, and we want to convince\nyou that it contains an independe nt set S of size 100, then it's quite easy. We\nsimply show you the graph G, circle the nodes of S in red, and let you check\nthat no two of them are joined by an edge. So there really seems to be a\ngreat difference  in difficulty between checking  that something  is a large\nindependent set and actually finding  a large indepen dent set. This may look\nlike a very basic observation— and it is—but it turns out to be crucial in\nunderstanding this class of problems. Furthermore, as we'll see next, it's\npossible for a problem to be so hard that there isn't even an easy way to\n“check” solutions in this sense.\nCompetitive Facility Location\nFinally , we come to our fifth problem, which is based on the following two-\nplayer game. Consider two large companies that operate café franchises\nacross the country—let's call them JavaPlanet and Queequeg's Coffee—and\nthey are currently competing for market share in a geographic  area. First\nJavaPlanet open s a franchise; then Queequeg's Coffee opens a franchise;\nthen JavaPlanet; then Queequeg 's; and so on. Suppose they must deal with"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 39})","('type', 'Document')"
"('page_content', ""zoning regulatio ns that require no two franchises be located too close\ntogether , and each is trying to make its locations as convenient as possible.\nWho will win?\nLet's make the rules of this “game” more concrete. The geographic\nregion in questio n is divided into n zones, labeled 1, 2, …, n. Each zone i\nhas a value bi, which is the revenue obtained by either of the companies if it\nopens a franchise there. Finally , certain pairs of zones (i, j) are adjacent ,\nand local zoning laws prevent two adjacent zones from each containing a\nfranchise, regardless of which company owns them. (They also prevent two\nfranchises from being opened in the same zone.) We model these conflicts\nvia a graph G = (V, E), where V is the set of zones, and (i, j) is an edge in E\nif the zones i and j are adjacent. The zoning requirement then says that the\nfull set of franchises opened must form an independent set in G.\nFigur e 1.7  An instance of the Competitive Facility Location Problem.\nThus our game consists of two players, P1 and P2, alternately selecting\nnodes in G, with P1 moving first. At all times, the set of all selected nodes\nmust form an independent set in G. Suppose that player P2 has a target\nbound B, and we want to know: is there a strategy for P2 so that no matter\nhow P1 plays, P2 will be able to select a set of nodes with a total value of at\nleast B? We will call this an instance of the Competitive Facility Location\nProblem .\nConsider , for example, the instan ce pictured in Figure 1.7 , and suppose\nthat P2's target bound is B = 20. Then P2 does have a winning strategy . On\nthe other hand, if B = 25, then P2 does not.\nOne can work this out by looking at the figure for a while;  but it\nrequires some amount of case-c hecking of the form, “If P1 goes here, then\nP2 will go there; but if P1 goes over there, then P2 will go here….”  And this\nappears to be intrinsic to the problem: not only is it computationally\ndifficult to determine whether P2 has a winning strategy; on a reasonably\nsized graph, it would even be hard for us to convince  you that P2 has a\nwinning strategy . There does not seem to be a short proof we could present;"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 40})","('type', 'Document')"
"('page_content', ""rather , we'd have to lead you on a lengthy case-by-case analysis of the set of\npossible moves.\nThis is in contra st to the Independent Set Problem, where we believe\nthat finding a large solution is hard but checking a proposed large solution\nis easy. This contrast can be formalized in the class of PSPACE-complete\nproblems , of which Comp etitive Facility Location is an example. PSPACE-\ncomplete problems are believed to be strictly harder than NP-complete\nproblems, and this conjectured lack of short “proofs” for their solutions is\none indication of this greater hardness. The notion of PSPACE-\ncompleteness turns out to capture a large collection of problems involving\ngame-playing and planning; many of these are fundamental issues in the\narea of artificial intelligence.\nSolved Exercises\nSolved Exercise 1\nConsider a town with n men and n women seeking to get married  to one\nanother . Each man has a prefere nce list that ranks all the women, and each\nwoman has a preference list that ranks all the men.\nThe set of all 2n people is divid ed into two categories: good  people\nand bad people. Suppose that for some number k, 1 ≤ k ≤ n - 1, there are k\ngood men and k good women; thus there are n - k bad men and n - k bad\nwomen.\nEveryone would  rather marry any good person than any bad person.\nFormally , each preference list has the property that it ranks  each good\nperson of the opposite gender higher than each bad person of the opposite\ngender: its first k entries are the good people (of the opposite gender) in\nsome order , and its next n - k are the bad people (of the opposite gender) in\nsome order .\nShow that in every stable matching, every good man is married to a\ngood woman.\nSolution  A natural way to get started thinking about this problem is to\nassume the claim is false and try to work toward obtaining a contradiction."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 41})","('type', 'Document')"
"('page_content', ""What would it mean for the claim to be false? There would  exist some\nstable matching M in which a good man m was married to a bad woman w.\nNow , let's consider what the other pairs in M look like. There are k\ngood men and k good women. Could it be the case that every good woman\nis married to a good man in this matching M? No: one of the good men\n(namely , m) is alrea dy married to a bad woman, and that leaves only k - 1\nother good men. So even if all of them were married to good women, that\nwould still leave some good woman who is married to a bad man.\nLet w′ be such a good woman, who is married to a bad man. It is now\neasy to identify an instability in M: consider the pair (m, w′). Each is good,\nbut is married to a bad partner . Thus, each of m and w′ prefers the other to\ntheir current partner , and hence (m, w′) is an instability . This contradicts our\nassumption that M is stable, and hence concludes the proof.\nSolved Exercise 2\nWe can think about a generalization of the Stable Matching Problem in\nwhich certain man-woman pairs are explicitly forbidden.  In the case of\nemployers and applicants, we could imagine that certain applicants simply\nlack the necessary qualification s or certifications, and so they cannot be\nemployed at certain companies,  however desirable they may seem. Using\nthe analogy to marriage betwee n men and women, we have a set M of n\nmen, a set W of n women , and a set F ⊆ M × W of pairs who are simply not\nallowed  to get married. Each man m ranks all the women w for whic h (m,w)\n∉ F, and each woman w′ ranks all the men m′ for which ( m′, w′ ) ∉ F.\nIn this more general setting, we say that a matching S is stable  if it\ndoes not exhibit any of the following types of instability .\n(i) There are two pairs ( m, w) and ( m′, w′ ) in S with the proper ty that (m, w′)\n∉ F, m prefers w′ to w, and w′ prefers m to m′. (The usual kind of\ninstability .)\n(ii) There is a pair ( m,w) ∊ S, and a man m′, so that m′ is not part of any pair\nin the matching , (m′, w) ∉ F, and w prefers m′ to m. (A single man is\nmore desirable and not forbidden.)\n(iii) There is a pair (m,w) ∊ S, and a woman w′, so that w′ is not part of any\npair in the matching, (m, w′) ∉ F, and m prefers w′ to w. (A single wom an\nis mor e desirable and not forbidden.)"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 42})","('type', 'Document')"
"('page_content', ""(iv) There is a man m and a woman w, neither of whom  is part of any pair in\nthe matching, so that (m, w) ∉ F. (Ther e are two single people with\nnothing pr eventing them fr om getting married to each other .)\nNote that under these more general definitions, a stable matching need not\nbe a perfect matching.\nNow we can ask: For every set of preference lists and every  set of\nforbidden pairs, is there always a stable matching? Resolve this question by\ndoing one of the following two things: (a) give an algorithm that, for any set\nof preference lists and forbidde n pairs, produces a stable matching; or (b)\ngive an example  of a set of preference lists and forbidden pairs for which\nthere is no stable matching.\nSolution  The Gale-Shapley algorithm is remarkably robust to variations on\nthe Stable Matching Problem. So, if you're faced with a new variation of the\nproblem and can't find a counterexample to stability , it's often a good idea\nto check whether a direct adaptation of the G-S algorithm will in fact\nproduce stable matchings.\nThat turns out to be the case here. We will show that there is always a\nstable matching, even in this more general model with forbidden pairs, and\nwe will do this by adapting the G-S algorithm. T o do this, let's consider why\nthe original G-S algorithm can't be used directly . The dif ficulty , of course, is\nthat the G-S algorithm doesn't know anything about forbidden pairs, and so\nthe condition in the While loop,\nWhile there is a man m who is free and hasn't proposed to every woman,\nwon't work: we don't want m to propose to a woman w for which the pair\n(m, w) is forbidden.\nThus, let's consi der a variation of the G-S algorithm in which we make\nonly one change: we modify the While loop to say ,\nWhile there is a man m who is free and hasn't proposed to every woman w for which ( m,\nw) ∉ F.\nHere is the algorithm in full.\nInitially all m ∊ M and w ∊ W are free\nWhile there is a man m who is free and hasn't proposed to every woman w for which ( m,w) ∉ F\nChoose such a man m\nLet w be the highest-ranked woman in m's preference list to which m has not yet proposed"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 43})","('type', 'Document')"
"('page_content', ""If w is free then\n(m,w) become engaged\nElse w is currently engaged to m′\nIf w prefers m′ to m then\nm remains free\nElse w prefers m to m′\n(m, w ) become engaged\nm′ becomes free\nEndif\nEndif\nEndwhile\nReturn the set S of engaged pairs\nWe now prove that this yield s a stable matching, under our new\ndefinition of stability .\nTo begin with, facts (1.1), (1.2), and (1.3) from the text remain true (in\nparticular , the algorithm will terminate in at most n2 iteratio ns). Also, we\ndon't have to worry about establishing that the resulting matching S is\nperfect (indeed, it may not be). W e also notice an additional pairs of facts. If\nm is a man who is not part of a pair in S, then m must have proposed to\nevery nonforbidden woman; and if w is a wom an who is not part of a pair in\nS, then it must be that no man ever proposed to w.\nFinally , we need only show\n(1.9)  There is no instability with r espect to the r eturned matching S.\nProof. Our gener al definitio n of instability has four parts: This means that we have to make sure that\nnone of the four bad things happens.\nFirst, supp ose there is an instability of type (i), consisting of pairs (m, w) and (m′, w′) in S with\nthe property that (m, w′) ∉ F, m prefers w′ to w, and w′ prefers m to m′. It follows that m must have\nproposed to w′; so w′ rejected m, and thus she prefers her final partner to m—a contradiction.\nNext, suppose there is an instability of type (ii), consisting of a pair ( m, w) ∊ S, and a man m′, so\nthat m′ is not part of any pair in the matching, (m′, w ) ∉ F, and w prefers m′ to m. Then m′ must have\nproposed to w and been rejected; again, it follows that w prefers her final partner to m′—a\ncontradiction.\nThird, supp ose there is an instability of type (iii), consisting of a pair (m, w) ∊ S, and a woman\nw′, so that w′ is not part of any pair in the matching, (m,w′) ∉ F, and m prefers w′ to w. Then  no man\nproposed to w′ at all; in particular , m never proposed to w′, and so he must prefer w to w′—a\ncontradiction.\nFinally , suppose there is an instability of type (iv), consisting of a man m and a woman w,\nneither of which is part of any pair in the matching, so that ( m,w) ∉ F. But for m to be single, he must\nhave proposed to every nonforbidden woman; in particular , he must have proposed to w, which\nmeans she would no longer be single—a contradiction. ▪"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 44})","('type', 'Document')"
"('page_content', ""Exercises\n1. Decide whether you think the following statement is true or false. If it\nis true, give a short explanation. If it is false, give a counterexample.  \nTrue or false? In every instance of the Stable Matching Problem, there is a stable\nmatching containing a pair (m, w) such that m is ranked first on the preference\nlist of w and w is ranked first on the pr eference list of m.\n2. Decide whether you think the following statement is true or false. If it\nis true, give a short explanation. If it is false, give a counterexample.  \nTrue or false? Consider an instance of the Stable Matching Problem in which\nthere exists a man m and a woman w such that m is ranked first on the preference\nlist of w and w is ranked first on the preference list of m. Then in every stable\nmatching S for this instance, the pair (m, w) belongs to S.\n3. There are many other settings in which we can ask questions related to\nsome type of “stability” principle. Here's one, involving competition\nbetween two enterprises.  \nSuppose we have two television  networks, whom we'll call A and B.\nThere are n prime-time programming slots, and each network has n TV\nshows. Each network wants to devise a schedule—an  assignment of\neach show to a distinct slot-so as to attract as much market share as\npossible.  \nHere is the way we determine how well the two networks perform\nrelative to each other , given their schedules. Each show has a fixed\nrating,  which is based on the number of people who watched it last\nyear; we'll assum e that no two shows have exactly the same rating. A\nnetwork wins a given time slot if the show that it schedules for the\ntime slot has a larger rating than the show the other network schedules\nfor that time slot. The goal of each network is to win as many time\nslots as possible.  \nSuppose in the opening week of the fall season, Network A reveals a\nschedule S and Network B reveals a schedule T. On the basis of this\npair of schedules, each network  wins certain time slots, accord ing to\nthe rule above. We'll say that the pair of schedules (S, T) is stable  if\nneither network can unilaterally change its own schedule and win more"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 45})","('type', 'Document')"
"('page_content', ""time slots. That is, there is no schedule S′ such that Network A wins\nmore slots with the pair (S′, T) than it did with the pair (S, T); and\nsymmetrically , there is no schedule T such that Network B wins more\nslots with the pair ( S, T′) than it did with the pair ( S,T). \nThe analogue of Gale and Shap ley's question for this kind of stability\nis the following: For every set of TV shows and ratings, is there\nalways a stable pair of schedules? Resolve this question by doing one\nof the following two things:  \n(a) give an algorithm that, for any set of TV shows and associated\nratings, produces a stable pair of schedules; or  \n(b) give an example of a set of TV shows and associated ratings for\nwhich there is no stable pair of schedules.\n \n4. Gale and Shapley published their paper on the Stable Matching\nProblem in 1962; but a version of their algorithm had already been in\nuse for ten years by the National Resident Matching Program, for the\nproblem of assigning medical residents to hospitals.  \nBasically , the situation was the following. There were m hospitals,\neach with a certain number of available positions for hiring residents.\nThere were n medical students graduating in a given year, each\ninterested in joining one of the hospitals. Each hospital had a ranking\nof the students in order of preference, and each student had a ranking\nof the hospitals in order of preference. We will assume that there were\nmore students graduating than there were slots available in the m\nhospitals.  \nThe interest, naturally , was in finding a way of assigning each student\nto at most one hospital, in such a way that all available positions in all\nhospitals were filled. (Since we are assuming a surplus of students,\nthere would be some students who do not get assigned to any hospital.)\nWe say that an assignment of students to hospitals is stable  if neither\nof the following situations arises.  \nFirst type of instability: There are students s and s′, and a hospital\nh, so that  \n- s is assigned to h, and \n- s′ is assigned to no hospital, and  \n- h prefers s′ to s."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 46})","('type', 'Document')"
"('page_content', 'Second type of instability: There are students s and s′, and\nhospitals h and h′, so that  \n- s is assigned to h, and \n- s′ is assigned to h′, and \n- h prefers s′ to s, and \n- s′ prefers h to h′.\n \nSo we basically  have the Stable Matching Problem, except that (i)\nhospitals generally want more than one resident, and (ii) there is a\nsurplus of medical students.  \nShow that there is always a stable assignment of students to hospitals,\nand give an algorithm to find one.\n5. The Stable Matching Problem, as discussed in the text, assumes that all\nmen and women have a fully  ordered list of preferences. In this\nproblem we will consider a version of the problem in which men and\nwomen can be indiffer ent between certain options. As before we have\na set M of n men and a set W of n women. Assume each man and each\nwoman ranks the members of the opposite gender , but now we allow\nties in the ranking. For example  (with n = 4), a woman could say that\nm1 is ranked in first place; second place is a tie between m2 and m3\n(she has no preference between them); and m4 is in last place. We will\nsay that w prefers m to m′ if m is ranked higher than m′ on her\npreference list (they are not tied).  \nWith indifferences in the rankings, there could be two natural notions\nfor stabi lity. And for each, we can ask about the existence of stable\nmatchings, as follows.  \n(a) A strong instability  in a perfect matching S consists  of a man m and\na woman w, such that each of m and w prefers the other to their partner\nin S. Does there always exist a perfect matching with no strong\ninstability? Either give an exam ple of a set of men and wome n with\npreference lists for which every perfect matching has a strong\ninstability; or give an algorithm that is guaranteed to find a perfect\nmatching with no strong instability . \n(b) A weak instability  in a perfect matching S consists of a man m and\na woman w, such that their partners in S are w′ and m′, respectively ,\nand one of the following holds:  \n- m prefers w to w′, and w either prefers m to m′ or is indifferent')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 47})","('type', 'Document')"
"('page_content', ""between these two choices; or  \n- w prefers m to m′, and m either prefers w to w′ or is indifferent\nbetween these two choices.  \nIn other words, the pairing between m and w is either preferred by\nboth, or preferred by one while the other is indifferent. Does there\nalways exist a perfect matching with no weak instability? Either give\nan example of a set of men and women with preference lists for which\nevery perfect matching has a weak instability; or give an algorithm that\nis guaranteed to find a perfect matching with no weak instability .\n6. Peripatetic Shipping Lines, Inc., is a shipping company that owns n\nships and provides service to n ports. Each of its ships has a schedule\nthat says, for each day of the month, which of the ports it's currently\nvisiting, or whether it's out at sea. (You can assume the “month” here\nhas m days, for some m > n.) Each ship visits each port for exactly one\nday during the month. For safety reasons, PSL Inc. has the following\nstrict requirement:  \n(†) No two ships can be in the same port on the same day .\n \nThe company wants to perfor m maintenance on all the ships this\nmonth, via the following scheme. They want to truncate  each ship's\nschedule: for each ship Si, there will be some day when it arrives in its\nscheduled port and simply rema ins there for the rest of the month (for\nmaintenance). This means that Si will not visit the remaining ports on\nits schedule (if any) that month, but this is okay . So the truncation  of\nSi's schedule will simply consist of its original schedule up to a certain\nspecified day on which it is in a port P; the remainder of the truncated\nschedule simply has it remain in port P. \nNow the company's question to you is the following: Given the\nschedule for each ship, find a truncation of each so that condition (t)\ncontinues to hold: no two ships are ever in the same port on the same\nday. \nShow that such a set of truncati ons can always be found, and give an\nalgorithm to find them.  \nExample.  Suppose we have two ships and two ports, and the “month”\nhas four days. Suppose the first ship's schedule is"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 48})","('type', 'Document')"
"('page_content', ""port P 1; at sea; port P 2; at sea\n \nand the second ship's schedule is  \nat sea; port P 1; at sea; port P 2\n \nThen the (only) way to choose truncations would be to have the first\nship remain in port P2 starting on day 3, and have the second ship\nremain in port P1 starting on day 2.\n7. Some of your friends are working for CluNet, a builder of large\ncommunication networks, and they are looking at algorithms for\nswitching in a particular type of input/output crossbar . \nHere is the setup. There are n input wires and n output wires, each\ndirected from a source to a terminus . Each input wire meets each\noutput wire in exactly one distinct point, at a special piece of hardware\ncalled a junction box. Points on the wire are naturally ordered in the\ndirection from source to terminus; for two distinct points x and y on the\nsame wire, we say that x is upstr eam from y if x is closer to the source\nthan y, and otherwise we say x is downstr eam from y. The order in\nwhich one input wire meets the output wires is not necessarily the\nsame as the order in which another input wire meets the output  wires.\n(And similarly for the orders in which output wires meet input wires.)\nFigure 1.8 gives an examp le of such a collection of input and output\nwires.  \nNow , here's the switching component of this situation. Each input wire\nis carrying a distinct data stream, and this data stream must be\nswitched  onto one of the output wires. If the stream of Input i is\nswitched onto Output j, at junction box B, then this stream passes\nthrough all junction boxes upstre am from B on Input i, then through B,\nthen through all junction boxes downstream from B on Output j. It\ndoes not matter which input data stream gets switched onto which\noutput wire, but each input data stream must be switched onto a\ndiffer ent output wire. Furthermore—and this is the tricky constraint—\nno two data streams can pass through the same junction box following\nthe switching operation."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 49})","('type', 'Document')"
"('page_content', ""Finally , here's the problem. Show that for any specified pattern in\nwhich the input wires and output wires meet each other (each pair\nmeeting exactly  once), a valid switching of the data stream s can\nalways be found—one in which each input data stream is switched\nonto a different output, and no two of the resulting stream s pass\nthrough the same junction box. Additionally , give an algorithm to find\nsuch a valid switching.  \nFigur e 1.8 An example with two input wires and two output wires.\nInput 1 has its junction with Output 2 upstream from its junctio n with\nOutput 1; Input 2 has its junct ion with Output 1 upstream from its\njunction with Output 2. A valid solution is to switch the data stream of\nInput 1 onto Output 2, and the data stream of Input 2 onto Output 1.\nOn the other hand, if the stream of Input 1 were switched onto Output\n1, and the stream of Input 2 were switched onto Output 2, then both\nstreams would pass through the junction box at the meeting of Input 1\nand Output 2—and this is not allowed.\n8. For this problem , we will explore the issue of truthfulness  in the Stable\nMatching Problem and specifically in the Gale-Shapley algorithm. The\nbasic question is: Can a man or a woman end up better off by lying\nabout his or her preferences?  More concretely , we suppose each\nparticipant has a true preferen ce order . Now consider a wom an w.\nSuppose w prefers man m to m′, but both m and m′ are low on her list\nof prefer ences. Can it be the case that by switching the order of m and"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 50})","('type', 'Document')"
"('page_content', ""m′ on her list of preferences (i.e., by falsely claiming that she prefers\nm′ to m) and running the algorithm with this false preference list, w\nwill end up with a man m″ that she truly prefers to both m and m′? (We\ncan ask the same question for men, but will focus on the case of\nwomen for purposes of this question.)  \nResolve this question by doing one of the following two things:  \n(a) Give a proof that, for any set of preference lists, switching the order\nof a pair on the list cannot improve a woman's partner in the Gale-\nShapley algorithm; or  \n(b) Give an example of a set of preference lists for which there is a\nswitch that would improve the partner of a woman who switched\npreferences.\nNotes and Further Reading\nThe Stable Matching Problem was first defined and analyzed by Gale and\nShapley (1962); according to David Gale, their motivation for the problem\ncame from a story they had recently read in the New Yorker  about the\nintricacies of the college admissions process (Gale, 2001). Stable matching\nhas grow n into an area of study in its own right, covered in books by\nGusfield and Irving (1989) and Knuth (1997c). Gusfield and Irving also\nprovide a nice survey of the “parallel” history of the Stabl e Matching\nProblem as a technique invented for matching applicants with employers in\nmedicine and other professions.\nAs discussed in the chapter , our five representative problems will be\ncentral to the book's discussions, respectively , of greedy algorithms,\ndynamic progra mming, networ k flow, NP-completeness, and PSPACE-\ncompleteness. We will discuss the problems in these contexts later in the\nbook.\n1 Gale and Shapley considered the same-sex Stable Matching Problem as\nwell, where there is only a single gender . This is motivated by related\napplications, but it turns out to be fairly different at a technical level. Given\nthe applicant-employer application we're considering here, we'll be focusing\non the version with two genders."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 51})","('type', 'Document')"
"('page_content', '2 For those who are curious, we note that not every instan ce of the\nIndependent Set Problem can arise in this way from Interval Scheduling or\nfrom Bipartite Matching; the full Independent Set Problem really is more\ngeneral. The graph in Figure 1.3(a)  cannot arise as the “conflict graph” in\nan instance of Interval Scheduling, and the graph in Figure 1.3(b)  cannot\narise as the “conflict graph” in an instance of Bipartite Matching.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 52})","('type', 'Document')"
"('page_content', 'Chapter 2')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 53})","('type', 'Document')"
"('page_content', 'Basics of Algorithm Analysis\n2.1 Computational T ractability  \n2.2 Asymptotic Order of Gr owth  \n2.3 Implementing the Stable Matching Algorithm Using Lists and\nArrays  \n2.4 A Survey of Common Running T imes  \n2.5 A Mor e Complex Data Structur e: Priority Queues  \nSolved Exer cises  \nExer cises  \nNotes and Further Reading\nAnalyzing algorithms involves thinking about how their resource\nrequirements—the amount of time and space they use—will scale with\nincreasing input  size. We begin this chapter by talking about how to put this\nnotion on a conc rete footing, as making it concrete opens the door to a rich\nunderstanding of computational tractability . Having done this, we develop\nthe math ematical machinery needed to talk about the way in which different\nfunctions scale with increasing input size, making precise what it means for\none function to grow faster than another .\nWe then develop running-time bounds for some basic algorithms,\nbeginning with an implementation of the Gale-Shapley algorithm from\nChapter 1 and continuing to a survey of many different running times and\ncertain characteristic types of algorithms that achieve these running times.\nIn some  cases, obtaining a good running-time bound relies on the use of\nmore sophisticat ed data structures, and we conclude this chapter with a very\nuseful example  of such a data structure: priority queues and their\nimplementation using heaps.\n2.1 Computational Tractability')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 54})","('type', 'Document')"
"('page_content', ""A major focus of this book is to find efficient algorithms for computational\nproblems. At this level of generality , our topic seems to encompass the\nwhole of computer science; so what is specific to our approach here?\nFirst, we will try to identify broad themes and design principles in the\ndevelopment of algorithms. We will look for paradigmatic problems and\napproaches that illustrate, with a minimum of irrelevant detail, the basic\napproaches to designing efficien t algorithms. At the same time, it would be\npointless to pursue these design principles in a vacuum, so the problems and\napproaches we consider are drawn from fundamental issue s that arise\nthroughout computer science, and a general study of algorithms  turns out to\nserve as a nice survey of computational ideas that arise in many areas.\nAnother property shared by many of the problems we study is their\nfundamentally discr ete nature. That is, like the Stable Matching Problem,\nthey will involve an implicit search over a large set of combinatorial\npossibilities; and the goal will be to efficiently find a solution that satisfies\ncertain clearly delineated conditions.\nAs we seek to understand the general notion of comput ational\nefficiency , we will focus primar ily on efficiency in running time: we want\nalgorithms that run quickly . But it is important that algorithms be efficient\nin their use of other resources as well. In particular , the amount of space  (or\nmemory) used by an algorithm is an issue that will also arise at a number of\npoints in the book, and we will see techniques for reducing the amount of\nspace needed to perform a computation.\nSome Initial Attempts at Defining Efficiency\nThe first major question we need to answer is the following: How should\nwe turn the fuzzy notion of an “efficient” algorithm into some thing more\nconcrete?\nA first attempt at a working definition of efficiency  is the following.\nProposed Definition of Efficiency (1): An algorithm is efficient if, when implemented, it\nruns quickly on r eal input instances.\nLet's spend a little time considering this definition. At a certain level, it's\nhard to argue with: one of the goals at the bedrock of our study of\nalgorithms is solving real problems quickly . And indeed, there is a"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 55})","('type', 'Document')"
"('page_content', ""significant area of research devoted to the careful implementation and\nprofiling of dif ferent algorithms for discrete computational problems.\nBut there are some crucial things missing from this definition, even if\nour main  goal is to solve real problem instances quickly on real computers.\nThe first is the omission of wher e, and how well, we implement an\nalgorithm. Even  bad algorithms can run quickly when applied to small test\ncases on extremely fast processors; even good algorithms can run slowly\nwhen they are coded sloppily . Also, what is a “real” input instance? We\ndon't know the full range of input instances that will be encountered in\npractice, and some input instances can be much harder than others. Finally ,\nthis proposed definition above does not consider how well, or badly , an\nalgorithm may scale  as problem sizes grow to unexpected levels. A\ncommon situation is that two very different algorithms will perform\ncomparably on inputs of size 100; multiply the input size tenfold, and one\nwill still run quickly while the other consumes a huge amount of time.\nSo what we could ask for is a concrete definition of efficiency that is\nplatform-independent, instance- independent, and of predictive  value with\nrespect to increasing input sizes. Before focusing on any specific\nconsequences of this claim, we can at least explore its implicit, high-level\nsuggestion: that we need to take a more mathematical view of the situation.\nWe can use the Stable Matching Problem as an example to guide us.\nThe input has a natural “size” parameter N; we could take this to be the total\nsize of the representation of all preference lists, since this is what any\nalgorithm for the problem will receive as input. N is closely related to the\nother natural parameter in this problem: n, the number of men and the\nnumber of women. Since there are 2n preference lists, each of length n, we\ncan view N = 2n2, suppre ssing more fine-grained details of how the data is\nrepresented. In considering the problem, we will seek to describe an\nalgorithm at a high level, and then analyze its running time mathematically\nas a function of this input size N.\nWorst-Case Running Times and Brute-Force\nSearch\nTo begin  with, we will focus on analyzing the worst-case  running time: we\nwill look for a bound on the largest possible running time the algorithm\ncould have over all inputs of a given size N, and see how this scales with N."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 56})","('type', 'Document')"
"('page_content', ""The focus on worst-case performance initially seems quite draconian: what\nif an algorithm performs well on most instances and just has a few\npathological inputs on which it is very slow? This certainly is an issue in\nsome cases, but in general the worst-case analysis of an algorithm has been\nfound to do a reasonable job of capturing its efficiency in practice.\nMoreover , once we have decided to go the route of mathematical analysis, it\nis hard to find an effective alternative to worst-case analysis. Average-case\nanalysis—the obvious appealing alternative, in which one studies the\nperformance of an algorithm averaged over “random” instances—can\nsometimes provi de considerable  insight, but very often it can also become a\nquagmire. As we observed earlier , it's very hard to express the full range of\ninput instances that arise in practice, and so attempts to study an algorithm's\nperformance on“random” input instances can quickly devolve into debates\nover how a random input shou ld be generated: the same algorithm can\nperform very well on one class of random inputs and very poorly on\nanother . After all, real inputs to an algorithm are generally  not being\nproduced from a random distri bution, and so average-case analysis risks\ntelling us more about the means by which the random inputs were generated\nthan about the algorithm itself.\nSo in general we will think about the worst-case analysis of an\nalgorithm's running time. But what is a reasonable analytical benchmark\nthat can tell us whether a running-time bound is impressive or weak? A first\nsimple guide is by comparison with brute-force search over the search space\nof possible solutions.\nLet's return to the example of the Stable Matching Problem. Even\nwhen the size of a Stable Matc hing input instance is relatively small, the\nsearch space  it define s is enormous (there are n! possible perfect matchings\nbetween n men and n women), and we need to find a matching that is\nstable. The natural “brute-force ” algorithm for this problem would plow\nthrough all perfect matchings by enumeration, checking each to see if it is\nstable. The surprising punchline, in a sense, to our solution of the Stable\nMatching Proble m is that we needed to spend time proportional only to N in\nfinding a stable matching from  among this stupendously large space of\npossibilities. This was a conclusion we reached at an analytical level . We\ndid not impleme nt the algorithm and try it out on sample preference lists;\nwe reasoned about it mathemat ically . Yet, at the same time, our analysis\nindicated how the algorithm could be implemented in practice and gave"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 57})","('type', 'Document')"
"('page_content', ""fairly conclusiv e evidence that it would be a big improv ement over\nexhaustive enumeration.\nThis will be a common theme in most of the problems we study: a\ncompact represe ntation, implicitly specifying a giant search space. For most\nof these  problems, there will be an obvious brute-force solution: try all\npossibilities and see if any one of them works. Not only is this approach\nalmost always too slow to be useful, it is an intellectual cop-out; it provides\nus with absolutely no insight into the structure of the problem we are\nstudying. And so if there is a common thread in the algorithms we\nemphasize in this book, it woul d be the following alternative definition of\nefficiency .\nProposed Definition of Efficiency (2): An algorithm is efficient if it achieve s\nqualitatively better worst-case performan ce, at an analytical level, than brute-for ce\nsearch.\nThis will turn out to be a very useful working definition for us.\nAlgorithms that improve substantially on brute-force search nearly always\ncontain a valuable heuristic idea that makes them work; and they tell us\nsomething about the intrinsic structure, and computational tractability , of\nthe underlying problem itself.\nBut if there is a problem with our second working definition, it is\nvagueness. What do we mean by “qualitatively better performance?” This\nsuggests that we consider the actual running time of algorithms more\ncarefully , and try to quantify what a reasonable running time would be.\nPolynomial Time as a Definition of Efficiency\nWhen people first began analyzing discrete algorithms mathem atically—a\nthread of resear ch that began gathering momentum through the 1960s—a\nconsensus began to emer ge on how to quantify the notion of a “reasonable”\nrunning time. Search spaces for natural combinatorial problems tend to\ngrow exponentially in the size N of the input; if the input size increases by\none, the number of possibilities increases multiplicatively . We'd like a good\nalgorithm for such a problem to have a better scaling property: when the\ninput size increases by a consta nt factor—say , a factor of 2—the algorithm\nshould only slow down by some constant factor C."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 58})","('type', 'Document')"
"('page_content', ""Arithmetically , we can formulate this scaling behavior as follows.\nSuppose an algorithm has the following property: There are absolute\nconstants c > 0 and d > 0 so that on every input instance of size N, its\nrunning time is bounded by cNd primitive computational steps.  (In other\nwords, its running time is at most proportional to Nd.) For now, we will\nremain deliberately vague on what we mean by the notion of a “primitive\ncomputational step”—but it can be easily formalized in a model where each\nstep correspond s to a single assembly-language instruction on a standard\nprocessor , or one line of a standard programming language such as C or\nJava. In any case, if this runnin g-time bound holds, for some c and d, then\nwe say that the algorithm has a polynomial running time, or that it is a\npolynomial-time algorithm . Note that any polynomial-time bound has the\nscaling property  we're looking for. If the input size increases from N to 2N,\nthe bound on the running time increases from cNd to c(2N)d = c · 2dNd,\nwhich is a slow-down by a factor of 2d. Since d is a constant, so is 2d; of\ncourse, as one might expect, lower -degree polynomials exhibit better\nscaling behavior than higher -degree polynomials.\nFrom this notion, and the intuiti on expressed above, emer ges our third\nattempt at a working definition of ef ficiency .\nProposed Definition of Efficiency (3): An algorithm is efficient if it has a polynomial\nrunning time.\nWhere our previous definition seemed overly vague, this one seems\nmuch too prescriptive. Wouldn't an algorithm with running time\nproportional to n100—and hence polynomial—be hopelessly inefficient?\nWouldn't we be relatively pleas ed with a nonpolynomial running time of\nn1+.02(log n)? The answers are, of course, “yes” and “yes.” And indeed ,\nhowever much one may try to abstractly motivate the definition of\nefficiency in terms of polynomial time, a primary justification for it is this:\nIt really works.  Problems for which polynomial-time algorithms exist\nalmost invariab ly turn out to have algorithms with running times\nproportional to very moderately  growing polynomials like n, n log n, n2, or\nn3. Conversely , problems for whic h no polynomial-time algorithm is known\ntend to be very difficult in practice. There are certainly exceptions to this\nprinciple in both directions: there are cases, for example, in which an\nalgorithm with exponential worst-case behavior generally runs well on the"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 59})","('type', 'Document')"
"('page_content', 'kinds of instances that arise in practice; and there are also cases where the\nbest polynomial -time algorithm for a problem is completely impractical due\nto large constan ts or a high exponent on the polynomial bound. All this\nserves to reinforce the point that our emphasis on worst-case, polynomial-\ntime bounds is only an abstraction of practical situa tions. But\noverwhelmingly , the concrete mathematical definition of polynomial time\nhas turned out to correspond surprisingly well in practice to what we\nobserve about the efficiency of algorithms, and the tractability of problems,\nin real life.\nTable 2.1  The running times (rounded up) of different algorithms on inputs of increasing size, for a\nprocessor performing  a million high-level  instructions per second. In cases where the running time\nexceeds 1025 years, we simply record the algorithm as taking a very long time.\nOne further reason why the mathematical formalism and the empirical\nevidence seem to line up well in the case of polynomial-time solvability is\nthat the gulf between the growth rates of polynomial and exponential\nfunctions is enormous. Suppose, for example, that we have a processor that\nexecutes a million high-level  instructions per second, and we have\nalgorithms with running-time bounds of n, n log2 n, n2, n3, 1.5n, 2n, and n!.\nIn Table 2.1, we show the running times of these algorithms (in seconds,\nminutes, days, or years) for inputs of size n = 10, 30, 50, 100, 1,000,\n10,000, 100,000, and 1,000,000.\nThere is a final, fundamental benefit to making our definition of\nefficiency so specific: it become s negatable. It becomes possible to express\nthe notion that there is no efficient algorithm for a particular problem . In a\nsense, being able to do this is a prerequisite for turning our study of\nalgorithms into good science, for it allows us to ask about the existence or\nnonexistence of efficient algorithms as a well-defined question.  In contrast,\nboth of our previous definitions were completely subjective,  and hence')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 60})","('type', 'Document')"
"('page_content', ""limited the extent to which we could discuss certain issues in concrete\nterms.\nIn particular , the first of our definitions, which was tied to the specific\nimplementation of an algorithm , turned efficiency into a moving target: as\nprocessor speed s increase, more and more algorithms fall under this notion\nof efficiency . Our definition in terms of polynomial time is much more an\nabsolute notion;  it is closely connected with the idea that each problem has\nan intrinsic level of computational tractability: some admit efficient\nsolutions, and others do not.\n2.2 Asymptotic Order of Growth\nOur discussion of computati onal tractability has turned out to be\nintrinsically based on our ability to express the notion that an algorithm's\nworst-case running time on inputs of size n grows at a rate that is at most\nproportional to some function f(n). The function f(n) then becomes a bound\non the running time of the algorithm. We now discuss a framework for\ntalking about this concept.\nWe will mainly express algorithms in the pseudo-code style that we\nused for the Gale-Shapley algorithm. At times we will need to become more\nformal, but this style of specify ing algorithms will be completely adequate\nfor most purposes. When we provide a bound on the running  time of an\nalgorithm, we will generally be counting the number of such pseudo-code\nsteps that are executed; in this context, one step will consist of assigning a\nvalue to a variable, looking up an entry in an array , following a pointer , or\nperforming an arithmetic operation on a fixed-size integer .\nWhen we seek to say somet hing about the running time of an\nalgorithm on inputs of size n, one thing we could aim for would be a very\nconcrete stateme nt such as, “On any input of size n, the algorithm runs for\nat most 1.62n2 + 3.5n + 8 steps.” This may be an interesting statement in\nsome contexts, but as a general goal there are several things wrong with it.\nFirst, getting such a precise bound may be an exhausting activit y, and more\ndetail than we wanted anyway . Second, because our ultimate  goal is to\nidentify broad classes of algorithms that have similar behavior , we'd\nactually like to classify running times at a coarser level of granularity so\nthat similarities among different algorithms, and among different problems,"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 61})","('type', 'Document')"
"('page_content', ""show up more clearly . And finally, extremely detailed statements about the\nnumber of steps an algorithm executes are often—in a strong sense—\nmeaningless. As just discussed, we will generally be counting  steps in a\npseudo-code specification of an algorithm that resembles a high-level\nprogramming language. Each one of these steps will typically unfold into\nsome fixed number of primitive steps when the program is compiled into an\nintermediate representation, and then into some further number of steps\ndepending on the particular architecture being used to do the computing. So\nthe most we can safely say is that as we look at different levels of\ncomputational abstraction, the notion of a “step” may grow or shrink by a\nconstant factor— for example, if it takes 25 low-level machine instructions\nto perfor m one operation in our high-level language, then our algorithm that\ntook at most 1.62n2 + 3.5n + 8 steps can also be viewed as taking 40.5n2 +\n87.5n + 200 steps when we analyze it at a level that is closer to the actual\nhardware.\nO, Ω, and Θ\nFor all these reasons, we want to express the growth rate of running times\nand other functions in a way that is insensitive to constant factors and low-\norder terms. In other words, we'd like to be able to take a running time like\nthe one we discussed above, 1.62 n2 + 3.5 n + 8, and say that it grows like n2,\nup to constant factors. W e now discuss a precise way to do this.\nAsymptotic Upper Bounds  Let T(n) be a function—say , the worst-case\nrunning time of a certain algorithm on an input of size n. (We will assum e\nthat all the functions we talk about here take nonnegative values.) Given\nanother function f(n), we say that T(n) is O(f(n)) (read as “T(n) is order\nf(n)”) if, for sufficiently large n, the function T(n) is bounded above by a\nconstant multip le of f(n). We will also sometimes write this as T(n) =\nO(f(n)). More precisely , T(n) is O(f(n)) if there exist constants c > 0 and n0\n≥ 0 so that for all n ≥ n0, we have T(n) ≤ c · f(n). In this case, we will say\nthat T is asymptotically upper -bounded by f. It is important to note that this\ndefinition requires a constant c to exist  that works for all n; in particular , c\ncannot depend on n.\nAs an example of how this definition lets us express upper bounds on\nrunning times, consider an algorithm whose running time (as in the earlier\ndiscussion) has the form T(n) = pn2 + qn + r for positive constants p, q, and"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 62})","('type', 'Document')"
"('page_content', ""r. We'd like to claim that any such function is O(n2). To see why, we notice\nthat for all n ≥ 1, we have qn ≤ qn2, and r ≤ rn2. So we can write\nfor all n ≥ 1. This inequality is exactly what the definition of O(·) requires:\nT(n) ≤ cn2, where c = p + q + r.\nNote that O(·) expre sses only an upper bound, not the exact growth\nrate of the function. For example, just as we claimed that the function T(n)\n= pn2 + qn + r is O(n2), it's also correct to say that it's O(n3). Indeed, we just\nargued that T(n) ≤ (p + q + r)n2, and since we also have n2 ≤ n3, we can\nconclude that T(n) ≤ (p + q + r)n3 as the definition of O(n3) requires. The\nfact that a function can have many upper bounds is not just a trick of the\nnotation; it shows up in the analysis of running times as well. There are\ncases where an algorithm has been proved to have running time O(n3);\nsome years pass, people analyz e the same algorithm more carefully , and\nthey show that in fact its running time is O(n2). There was nothing wrong\nwith the first result; it was a correct upper bound. It's simply that it wasn't\nthe “tightest” possible running time.\nAsymptotic Lower Bounds  There is a complementary notation for lower\nbounds. Often when we analyze an algorithm—say we have just proven that\nits worst-case running time T(n) is O(n2)—we want to show that this upper\nbound is the best one possible.  To do this, we want to expres s the notion\nthat for arbitrari ly large input sizes n, the function T(n) is at least  a constant\nmultiple of some specific functi on f(n). (In this example, f(n) happens to be\nn2.) Thus, we say that T(n) is Ω(f(n)) (also written T(n) = Ω(f(n))) if there\nexist constants ε > 0 and n0 ≥ 0 so that for all n ≥ n0, we have T(n) ≥ ε · f(n).\nBy analogy with O(·) notat ion, we will refer to T in this case as being\nasymptotically lower -bounded by f. Again, note that the constant e must be\nfixed, independent of n.\nThis definition works just like O(·), except that we are bounding the\nfunction T(n) from below , rather than from above. For example, returning to\nthe function T(n) = pn2 + qn + r, where p, q, and r are positive constants,\nlet's claim that T(n) = Ω(n2). Whereas establishing the upper bound"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 63})","('type', 'Document')"
"('page_content', ""involved “inflating” the terms in T(n) until it looked like a constant  times\nn2, now we need to do the opposit e: we need to reduce the size of T(n) until\nit looks like a constant times n2. It is not hard to do this; for all n ≥ 0, we\nhave\nwhich meets what is required by the definition of Ω(·) with ε = p > 0.\nJust as we discussed the notion of “tighter” and “weaker” upper\nbounds, the same issue arises for lower bounds. For example, it is correct to\nsay that our function T(n) = pn2 + qn + r is Ω( n), since T(n) ≥ pn2 ≥ pn.\nAsymptotically Tight Bounds  If we can show that a running time T(n) is\nboth O(f(n)) and also Ω( f(n)), then in a natural sense we've found the “right”\nbound: T(n) grows exactly like f(n) to within a constant factor . This, for\nexample, is the conclusion we can draw from the fact that T(n) = pn2 + qn +\nr is both O(n2) and Ω( n2).\nThere is a notation to express this: if a function T(n) is both O(f(n))\nand Ω(f(n)), we say that T(n) is Θ(f(n)). In this case, we say that f(n) is an\nasymptotically tight bound  for T(n). So, for example, our analysis above\nshows that T(n) = pn2 + qn + r is Θ( n2).\nAsymptotically tight bounds on worst-case running times are nice\nthings to find, since they characterize the worst-case performance of an\nalgorithm precisely up to constant factors. And as the definit ion of Θ(·)\nshows, one can obtain such bounds by closing the gap between an upper\nbound and a lower bound. For example, sometimes you will read a (slightly\ninformally phras ed) sentence such as “An upper bound of O(n3) has been\nshown on the worst-case running time of the algorithm, but there is no\nexample known  on which the algorithm runs for more than Ω(n2) steps.”\nThis is implicitly an invitation to search for an asymptotically tight bound\non the algorithm's worst-case running time.\nSometimes one can also obtain an asymptotically tight bound directly\nby computing a limit as n goes to infinity . Essentially , if the ratio of\nfunctions f(n) and g(n) conver ges to a positive constan t as n goes to infinity ,\nthen f(n) = Θ( g(n))."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 64})","('type', 'Document')"
"('page_content', ""(2.1)  Let f and g be two functions that\nexists and is equal to some number c  > 0. Then f (n) = Θ( g(n)).\nProof. We will use the fact that the limit exists and is positive to show that f(n) = O(g(n)) and f(n) =\nΩ(g(n)), as required by the definition of Θ(·).\nSince\nit follows from the definition of a limit that there is some n0 beyond which the ratio is always\nbetween ½ c and 2c. Thus, f(n) ≤ 2cg(n) for all n ≥ n0, which implies that f(n) = O(g(n)); and f(n) ≥\n½cg(n) for all n ≥ n0, which implies that f(n) = Ω( g(n)). ▪\nProperties of Asymptotic Growth Rates\nHaving seen the definitions of O, Ω, and Θ, it is useful to explo re some of\ntheir basic properties.\nTransitivity  A first property is transitivity:  if a function f is asymptotically\nupper -bounded by a function g, and if g in turn is asym ptotically uppe r-\nbounded by a function h, then f is asym ptotically upper -bounde d by h. A\nsimilar property  holds for lower bounds. We write this more precisely as\nfollows.\n(2.2)  \n(a) If f = O(g) and g  = O(h), then f  = O(h). \n(b) If f = Ω( g) and g  = Ω( h), then f  = Ω( h).\nProof. We'll prove part (a) of this claim; the proof of part (b) is very similar .\nFor (a), we're given that for some constants c and n0, we have f(n) ≤ cg(n) for all n ≥ n0. Also,\nfor some (potentially different) constants c′ and n′0, we have g(n) ≤ c′h(n) for all n ≥ n′0. So consider\nany number n that is at least as large as both n0 and n′0. We have f(n) ≤ cg(n) ≤ cc′h(n), and so f(n) <\ncc′h(n) for all n ≥ max( n0, n′0). This latter inequalit y is exactly what is required for showing that f =\nO(h). ▪\nCombining parts (a) and (b) of (2.2), we can obtain a similar result for\nasymptotically tight bounds. Suppose we know that f = Θ(g) and that g ="")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 65})","('type', 'Document')"
"('page_content', ""Θ(h). Then since f = O(g) and g = O(h), we know from part (a) that f =\nO(h); since f = Ω(g) and g = Ω(h), we know from part (b) that f = Ω(h). It\nfollows that f = Θ( h). Thus we have shown\n(2.3)  If f = Θ( g) and g  = Θ( h), then f  = Θ( h).\nSums of Functions  It is also useful to have results that quantify the effect\nof adding two functions. First, if we have an asymptotic upper bound that\napplies to each of two functions f and g, then it applies to their sum.\n(2.4)  Suppose that f and g are two functions such that for some other function h, we have f = O(h)\nand g = O(h). Then f + g = O(h).\nProof. We're given that for some constants c and n0, we have f(n) ≤ ch(n) for all n ≥ n0. Also, for\nsome (potentially dif ferent) constants c′ and n′0, we have g(n) ≤ c′h(n) for all n ≥ n′0. So consider any\nnumber n that is at least as large as both n0 and n′0. We have f(n) + g(n) ≤ ch(n) + c′h(n). Thus f(n) +\ng(n) ≤ (c + c′)h(n) for all n ≥ max( n0, n′0), which is exactly what is required for showing that f + g =\nO(h). ▪\nThere is a generalization of this to sums of a fixed constant number of\nfunctions k, where k may be larger than two. The result can be stated\nprecisely as follows; we omit the proof, since it is essentially the same as\nthe proof of (2.4), adapted to sums consisting of k terms rather than just\ntwo.\n(2.5)  Let k be a fixed constant, and let f1, f2,…, fk and h be functions such that fi = O(h) for all i.\nThen f 1 + f2 + ··· + fk = O(h).\nThere is also a consequence of (2.4) that covers the following kind of\nsituation. It frequently happens that we're analyzing an algorith m with two\nhigh-level parts, and it is easy to show that one of the two parts is slower\nthan the other . We'd like to be able to say that the running time of the whole\nalgorithm is asymptotically comparable to the running time of the slow part.\nSince the overal l running time is a sum of two functions (the running times\nof the two parts), results on asymptotic bounds for sums of functions are\ndirectly relevant.\n(2.6)  Suppose that f and g are two functions (taking nonnegative values) such that g = O(f). Then f +\ng = Θ(f). In other wor ds, f is an asymptotically tight bound for the combined function f + g.\nProof. Clearly f + g = Ω(f), since for all n ≥ 0, we have f(n) + g(n) ≥ f(n). So to complete the proof,\nwe need to show that f + g = O(f)."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 66})","('type', 'Document')"
"('page_content', ""But this is a direct consequence of (2.4): we're given the fact that g = O(f), and also f = O(f)\nholds for any function, so by (2.4) we have f + g = O(f). ▪\nThis result also extends to the sum of any fixed, constant number of\nfunctions: the most rapidly growing among the functions is an\nasymptotically tight bound for the sum.\nAsymptotic Bounds for Some Common Functions\nThere are a number of functions that come up repeatedly in the analysis of\nalgorithms, and it is useful to consider the asymptotic properties of some of\nthe most basic of these: polynomials, logarithms, and exponentials.\nPolynomials  Recall that a polynomial is a function that can be written in the\nform f(n) = a0 + a1n + a2n2 + ··· + adnd for some intege r constant d > 0,\nwhere the final coef ficient ad is nonzero. This value d is called the degree of\nthe polynomial. For example, the functions of the form pn2 + qn + r (with p\n≠ 0) that we considered earlier are polynomials of degree 2.\nA basic fact about polynomials is that their asymptotic rate of growth\nis determined by their “high-o rder term”—the one that determines the\ndegree. We state this more formally in the following claim. Since we are\nconcerned here only with functions that take nonnegative values, we will\nrestrict our attention to polyno mials for which the high-order term has a\npositive coef ficient ad > 0.\n(2.7)  Let f be a polynomial of degr ee d, in which the coefficient a d is positive. Then f = O (nd).\nProof. We write f = a0 + a1n + a2n2 + ··· + adnd, where ad > 0. The upper bound is a direct\napplication of (2.5). First, notice that coefficients aj for j < d may be negative, but in any case we\nhave ajnj ≤ |aj|nd for all n ≥ 1. Thus  each term in the polynomial is O(nd). Since f is a sum of a\nconstant number of functions, each of which is O(nd), it follows from (2.5) that f is O(nd). ▪\nOne can also show that under the conditions of (2.7), we have f =\nΩ(nd), and hence it follows that in fact f = Θ( nd).\nThis is a good point at which to discuss the relationship between these\ntypes of asymptotic bounds and the notion of polynomial time,  which we\narrived at in the previous sectio n as a way to formalize the more elusive\nconcept of efficiency . Using O(·) notation, it's easy to formally define"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 67})","('type', 'Document')"
"('page_content', ""polynomial time: a polynomial-time algorithm  is one whose running time\nT(n) is O(nd) for some constant d, where d is independent of the input size.\nSo algorithms with running-time bounds like O(n2) and O(n3) are\npolynomial-time algorithms. But it's important to realize that an algorithm\ncan be polynom ial time even if its running time is not written as n raised to\nsome integer power . To begin with, a number of algorithms have running\ntimes of the form O(nx) for some number x that is not an integer . For\nexample, in Chapter 5 we will see an algorithm whose running time is\nO(n1.59); we will also see exponents less than 1, as in bounds like O(√n) =\nO(n1/2).\nTo take another common kind of example, we will see many\nalgorithms whos e running times have the form O(n log n). Such algorithms\nare also polynom ial time: as we will see next, log n ≤ n for all n ≥ 1, and\nhence n log n ≤ n2 for all n ≥ 1. In other words, if an algori thm has running\ntime O(n log n), then it also has running time O(n2), and so it is a\npolynomial-time algorithm.\nLogarithms  Recall that logb n is the number x such that bx = n. One way to\nget an approxim ate sense of how fast logb n grows is to note that, if we\nround it down to the nearest integer, it is one less than the number of digits\nin the base- b representation of the number n. (Thus, for example, 1 + log2 n,\nrounded down, is the number of bits needed to represent n.)\nSo logarithms are very slowly  growing functions. In particular , for\nevery base b, the function logb n is asymptotica lly bounded by every\nfunction of the form nx, even for (nonin teger) values of x arbitrary close to\n0.\n(2.8)  For every b  > 1 and every x  > 0, we have  logb n = O(nx).\nOne can directly translate betwe en logarithms of different bases using\nthe following fundamental identity:"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 68})","('type', 'Document')"
"('page_content', ""This equation explains why you'll often notice people writing bounds like\nO(log n) withou t indicating the base of the logarithm. This is not sloppy\nusage: the identi ty above says that \n  so the point is that loga n\n= Θ(logb n), and the base of the logarithm  is not important when writing\nbounds using asymptotic notation.\nExponentials  Exponential functions are functions of the form f(n) = rn for\nsome constant base r. Here we will be concerned with the case in which r >\n1, which results in a very fast-growing function.\nIn particular , where polynom ials raise n to a fixed exponent,\nexponentials raise a fixed numb er to n as a power; this leads to much faster\nrates of growth. One way to summarize the relationship between\npolynomials and exponentials is as follows.\n(2.9)  For every r  > 1 and every d  > 0, we have nd = O (rn).\nIn particular , every exponential grows faster than every polynom ial. And as\nwe saw in Table 2.1 , when you plug in actual values of n, the differences in\ngrowth rates are really quite impressive.\nJust as people write O(log n) withou t specif ying the base, you'll also\nsee people write “The running  time of this algorithm is exponential,”\nwithout specifyi ng which exponential function they have in mind. Unlike\nthe liberal use of log n, which is justified by ignoring constant factors, this\ngeneric use of the term “exponential” is somewhat sloppy . In particular , for\ndifferent bases r > s > 1, it is never  the case that rn = Θ(sn). Indeed, this\nwould require that for some constant c > 0, we would have rn ≤ csn for all\nsufficiently lar ge n. But rearranging this inequality would give (r/s)n ≤ c for\nall sufficiently large n. Since r > s, the expression (r/s)n is tending to\ninfinity with n, and so it cannot possibly remain bounded by a fixed\nconstant c.\nSo asymptotically speaking, exponential functions are all different.\nStill, it's usually clear what people intend when they inexactly  write “The\nrunning time of this algorithm is exponential”—they typically mean that the\nrunning time grows at least as fast as some  exponential function, and all\nexponentials grow so fast that we can effectively dismiss this algorithm\nwithout working out further details of the exact running time. This is not\nentirely fair. Occasionally there's more going on with an exponential"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 69})","('type', 'Document')"
"('page_content', ""algorithm than first appears, as we'll see, for example, in Chapter 10 ; but as\nwe ar gued in the first section of this chapter , it's a reasonable rule of thumb.\nTaken together , then, logarithms , polynomials, and exponential s serve\nas usefu l landmarks in the range of possible functions that you encounter\nwhen analyzing running times. Logarithms grow more slowly than\npolynomials, and polynomials grow more slowly than exponentials.\n2.3 Implementing the Stable Matching Algorithm\nUsing Lists and Arrays\nWe've now seen a general approach for expressing bounds on the running\ntime of an algorithm. In order to asymptotically analyze the running time of\nan algor ithm expressed in a high-level fashion—as we expressed the Gale-\nShapley Stable Matching algorit hm in Chapter 1 , for example—one doesn't\nhave to actually  program, compile, and execute it, but one does have to\nthink about how the data will be represented and manipulated in an\nimplementation of the algorithm, so as to bound the number of\ncomputational steps it takes.\nThe implementation of basic algorithms using data structures is\nsomething that you probably have had some experience with. In this book,\ndata structures will be covered in the context of implementing specific\nalgorithms, and so we will encounter different data structures based on the\nneeds of the algorithms we are developing. To get this process started, we\nconsider an implementation of the Gale-Shapley Stable  Matching\nalgorithm; we showed earlier that the algorithm terminates in at most n2\niterations, and our implementation here provides a corresponding worst-\ncase running time of O(n2), counting actual computational steps rather than\nsimply the total number of iterations. To get such a bound for the Stable\nMatching algori thm, we will only need to use two of the simplest data\nstructures: lists and arrays . Thus, our implementation also provides a good\nchance to review the use of these basic data structures as well.\nIn the Stable Matching Problem, each man and each woman has a\nranking of all members of the opposite gender . The very first question we\nneed to discuss is how such a ranking will be represented. Further , the\nalgorithm maintains a matching and will need to know at each step which"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 70})","('type', 'Document')"
"('page_content', ""men and women are free, and who is matched with whom. In order to\nimplement the algorithm, we need to decide which data structu res we will\nuse for all these things.\nAn important issue to note here is that the choice of data structure is up\nto the algorithm designer; for each algorithm we will choose data structures\nthat make it efficient and easy to implement. In some cases, this may\ninvolve preprocessing  the input to convert it from its given input\nrepresentation into a data structure that is more appropriate for the problem\nbeing solved.\nArrays and Lists\nTo start our discussion we will focus on a single list, such as the list of\nwomen in order of preference by a single man. Maybe the simplest way to\nkeep a list of n elements is to use an array A of lengt h n, and have A[i] be\nthe ith element of the list. Such an array is simple to impleme nt in\nessentially all standard programming languages, and it has the following\nproperties.\nWe can answer a query of the form “What is the ith elemen t on the\nlist?” in O(1) time, by a direct access to the value A[i].\nIf we want to determine whether a particular element e belongs to the\nlist (i.e., whether it is equal to A[i] for some i), we need to check the\nelements one by one in O(n) time, assuming we don't know anything\nabout the order in which the elements appear in A.\nIf the array elem ents are sorted in some clear way (either nume rically\nor alpha betically), then we can determine whether an element e\nbelongs to the list in O(log n) time using binary search; we will not\nneed to use binary search for any part of our stable matching\nimplementation, but we will have more to say about it in the next\nsection.\nAn array is less good for dynamically maintaining a list of elements\nthat changes over time, such as the list of free men in the Stable Matching\nalgorithm; since men go from being free to engaged, and potentially back\nagain, a list of free men needs to grow and shrink during the execution of\nthe algorithm. It is generally cumbersome to frequently add or delete\nelements to a list that is maintained as an array ."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 71})","('type', 'Document')"
"('page_content', 'An alternate, and often preferable, way to maintain such a dynamic set\nof elements is via a linked list. In a linked list, the elements are sequenced\ntogether by having each elemen t point to the next in the list. Thus, for each\nelement v on the list, we need to maintain a pointer to the next element; we\nset this pointer to null if i is the last element. We also have a pointer First\nthat points to the first element. By starting at First and repeatedly following\npointers to the next element until we reach null, we can thus traverse the\nentire contents of the list in time proportional to its length.\nA generic way to implement such a linked list, when the set of possible\nelements may not be fixed in advance, is to allocate a record  e for each\nelement that we want to include  in the list. Such a record would contain a\nfield e.val that contains the value of the element, and a field e.Next that\ncontains a pointer to the next element in the list. We can create a doubly\nlinked list, which is traversable in both directions, by also having a field\ne.Prev that contains a pointer to the previous element in the list. (e.Prev =\nnull if e is the first element.) We also include a pointer Last, analogous to\nFirst, that points to the last element in the list. A schematic illustration of\npart of such a list is shown in the first line of Figure 2.1 .\nA doubly linked list can be modified as follows.\nDeletion.  To delete the element e from a doubly linked list, we can just\n“splice it out” by having the previous element, referenced by e.Prev ,\nand the next element, referenc ed by e.Next, point directly to each\nother . The deletion operation is illustrated in Figure 2.1 .\nInsertion.  To insert element e between  eleme nts d and f in a list, we\n“splice it in” by updating d.Next and f.Prev to point to e, and the Next\nand Prev pointers of e to point to d and f, respectively . This operation\nis essen tially the reverse of deletion, and indeed one can see this\noperation at work by reading Figure 2.1  from bottom to top.\nFigur e 2.1 A schematic representation of a doubly linked list, showing the\ndeletion of an element e.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 72})","('type', 'Document')"
"('page_content', ""Inserting or deleting e at the beginning of the list invol ves updating the First\npointer , rather than updating the record of the element before e.\nWhile lists are good for maintai ning a dynamically changing set, they\nalso have disadvantages. Unlike arrays, we cannot find the ith element of the\nlist in O(1) time: to find the ith element, we have to follow the Next pointers\nstarting from the beginning of the list, which takes a total of O(i) time.\nGiven the relative advantages and disadvantages of arrays and lists, it\nmay happen that we receive the input to a problem in one of the two\nformats and want to convert it into the other . As discussed earlier , such\npreprocessing is often useful; and in this case, it is easy to convert between\nthe array and list representations in O(n) time. This allows us to freely\nchoose the data structure that suits the algorithm better and not be\nconstrained by the way the information is given as input.\nImplementing the Stable Matching Algorithm\nNext we will use arrays and linked lists to implement the Stable Matching\nalgorithm from Chapter 1. We have already shown that the algorithm\nterminates in at most n2 iteration s, and this provides a type of upper bound\non the running time. However , if we actually want to implement the G-S\nalgorithm so that it runs in time proportional to n2, we need to be able to\nimplement each iteration in constant time. W e discuss how to do this now .\nFor simp licity , assume that the set of men and women are both {1, …,\nn}. To ensure this, we can order the men and women (say, alphabetically),\nand associate number i with the ith man mi or ith women wi in this order .\nThis assumption (or notation) allows us to define an array indexed by all\nmen or all women. We need to have a preference list for each man and for\neach woman. To do this we will have two arrays, one for women's"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 73})","('type', 'Document')"
"('page_content', ""preference lists and one for the men's preference lists; we will use ManPref\n[m, i] to denote the ith woman on man m's preference list, and similarly\nWomanPref [ w, i] to be the ith man on the preference list of woman w. Note\nthat the amount of space needed to give the preferences for all 2n\nindividuals is O(n2), as each person has a list of length n.\nWe need to consider each step of the algorithm and understand what\ndata structure allows us to implement it efficiently . Essentially , we need to\nbe able to do each of four things in constant time.\n1. We need to be able to identify a free man.\n2. We need , for a man m, to be able to identify the highest-ranked woman\nto whom he has not yet proposed.\n3. For a woman w, we need  to decide if w is curre ntly engaged, and if she\nis, we need to identify her current partner .\n4. For a woman w and two men m and m′, we need to be able to decide,\nagain in constant time, which of m or m′ is preferred by w.\nFirst, consider selecting a free man. We will do this by maintaining the\nset of free men as a linked list. When we need to select a free man, we take\nthe first man m on this list. We delete m from the list if he becomes\nengaged, and possibly insert a different man m′, if some other man m′\nbecomes free. In this case, m′ can be inserted at the front of the list, again in\nconstant time.\nNext, consider a man m. We need to identify the highest-ranked\nwoman to whom he has not yet proposed. To do this we will need to\nmaintain an extra array Next that indicates for each man m the position of\nthe next woman he will propose to on his list. We initialize Next[ m] = 1 for\nall men m. If a man m needs to propo se to a woman, he'll propose to w =\nManPref [m,Next[ m]], and once he proposes to w, we increment the value\nof Next[ m] by one, regardless of whether or not w accepts the proposal.\nNow assume man m proposes to woman w; we need to be able to\nidentify the man m′ that w is engag ed to (if there is such a man). We can do\nthis by maintaining an array Current of length n, where Current[ w] is the\nwoman w's current partner m′. We set Current [w] to a special null symbol\nwhen we need to indicate that woman w is not currently engaged; at the\nstart of the algorithm, Current [w] is initialized to this null symbol for all\nwomen w."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 74})","('type', 'Document')"
"('page_content', ""To sum up, the data structures we have set up thus far can implement\nthe operations (1)-(3) in O(1) time each.\nMaybe the trickiest question is how to maintain women's prefe rences\nto keep step (4) efficient. Cons ider a step of the algorithm, when man m\nproposes to a woman w. Assume w is already engaged, and her current\npartner is m′ =Current[ w]. We would like to decide in O(1) time if woman w\nprefers m or m′. Keeping the women's preferences in an array WomanPref,\nanalogous to the one we used for men, does not work, as we would need to\nwalk through w's list one by one, taking O(n) time to find m and m′ on the\nlist. While O(n) is still polyno mial, we can do a lot better if we build an\nauxiliary data structure at the beginning.\nAt the start of the algorithm, we create an n × n array Ranking, where\nRanking[ w, m] contains the rank of man m in the sorted order of w's\npreferences. By a single pass through w's preference list, we can create this\narray in linear time for each woman, for a total initial time investment\nproportional to n2. Then, to decide which of m or m′ is preferred by w, we\nsimply compare the values Ranking[ w, m] and Ranking[ w, m′].\nThis allows us to execute step (4) in constant time, and hence we have\neverything we need to obtain the desired running time.\n(2.10)  The data structur es described above allow us to implement the G-S algorithm in O (n2) time.\n2.4 A Survey of Common Running Times\nWhen trying to analyze a new algorithm, it helps to have a rough sense of\nthe “landscape” of different running times. Indeed, there are styles of\nanalysis that recur frequently , and so when one sees running-t ime bounds\nlike O(n), O(n log n), and O(n2) appearing over and over, it's often for one\nof a very small  number of distinct reasons. Learning to recognize these\ncommon styles of analysis is a long-term goal. To get things under way, we\noffer the following survey of common running-time bounds and some of the\ntypical approaches that lead to them.\nEarlier we discussed the notion that most problems have a natural\n“search space”—the set of all possible solutions—and we noted that a\nunifying theme in algorithm design is the search for algorit hms whose"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 75})","('type', 'Document')"
"('page_content', ""performance is more efficient than a brute-force enumeration of this search\nspace. In approaching a new problem, then, it often helps to think about two\nkinds of bounds: one on the running time you hope to achieve, and the other\non the size of the problem's natural search space (and hence on the running\ntime of a brute-f orce algorithm for the problem). The discussion  of running\ntimes in this section will begin in many cases with an analysis of the brute-\nforce algorithm,  since it is a useful way to get one's bearings with respect to\na problem; the task of improving on such algorithms will be our goal in\nmost of the book.\nLinear Time\nAn algorithm that runs in O(n), or linear , time has a very natural property:\nits running time is at most a constant factor times the size of the input. One\nbasic way to get an algorithm with this running time is to proce ss the input\nin a single pass, spending a constant amount of time on each item of input\nencountered. Other algorithms achieve a linear time bound for more subtle\nreasons. To illustrate some of the ideas here, we consider two simple linear -\ntime algorithms as examples.\nComputing the Maximum  Computing the maximum of n numbers, for\nexample, can be performed in the basic “one-pass” style. Suppose the\nnumbers are provided as input in either a list or an array . We process the\nnumbers a1, a2, …, an in order , keeping a running estimate of the maximum\nas we go. Each time we encou nter a number ai, we check whether ai is\nlarger than our current estimate, and if so we update the estimate to ai.\nmax = a1\nFor i = 2 to n\nIf ai > max then\nset max = ai\nEndif\nEndfor\nIn this way, we do constant work per element, for a total running time of\nO(n).\nSometimes the constraints of an application force this kind of one-pass\nalgorithm on you—for example, an algorithm running on a high-speed"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 76})","('type', 'Document')"
"('page_content', ""switch on the Internet may see a stream of packets flying past it, and it can\ntry computing anything it wants to as this stream passes by, but it can only\nperform a constant amount of computational work on each packet, and it\ncan't save the stream so as to make subsequent scans through it. Two\ndifferent subareas of algorithms, online algorithms  and data stream\nalgorithms , have developed to study this model of computation.\nMerging Two Sorted Lists  Often, an algorithm has a running time of O(n),\nbut the reason is more complex. We now describe an algorithm for merging\ntwo sorted lists that stretches the one-pass style of design just a little, but\nstill has a linear running time.\nSuppose we are given two lists of n numbers each, a1, a2, …, an and\nb1, b2, …, bn, and each is already arranged in ascending order . We'd like to\nmerge these into a single list c1, c2, …, c2n that is also arranged in ascending\norder . For example, merging the lists 2, 3, 11, 19 and 4, 9, 16, 25 results in\nthe output 2, 3, 4, 9, 1 1, 16, 19, 25.\nTo do this, we could just throw  the two lists together , ignore the fact\nthat they're separately arrange d in ascending order , and run a sorting\nalgorithm. But this clearly seem s wasteful; we'd like to make  use of the\nexisting order in the input. One way to think about designing a better\nalgorithm is to imagine perform ing the merging of the two lists by hand:\nsuppose you're given two piles of numbered cards, each arranged in\nascending order , and you'd like to produce a single ordered pile containing\nall the cards. If you look at the top card on each stack, you know that the\nsmaller of these two should go first on the output pile; so you could remove\nthis card, place it on the output, and now iterate on what's left.\nIn other words, we have the following algorithm.\nTo mer ge sorted lists A = a1,…,an and B = b1,…,bn:\nMaintain a Curr ent pointer into each list, initialized to point to the front elements\nWhile both lists are nonempty:\nLet ai and bj be the elements pointed to by the Curr ent pointer\nAppend the smaller of these two to the output list\nAdvance the Curr ent pointer in the list from which the smaller element was selected\nEndWhile\nOnce one list is empty , append the remainder of the other list to the output\nSee Figure 2.2  for a picture of this process."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 77})","('type', 'Document')"
"('page_content', 'Figur e 2.2  To merge sorted  lists A and B, we repeatedly extract the smaller\nitem from the front of the two lists and append it to the output.\nNow , to show a linear -time bound, one is tempted to describe an\nargument like what worked for the maximum-finding algorith m: “We do\nconstant work per element, for a total running time of O(n).” But it is\nactually not true that we do only constant work per element. Suppose that n\nis an even number , and consider the lists A = 1, 3, 5, …, 2n - 1 and B = n, n\n+ 2, n + 4, …, 3 n - 2. The number b1 at the front of list B will sit at the front\nof the list for n/2 iterations while elements from A are repeatedly being\nselected, and hence it will be involved in Ω(n) compa risons. Now , it is true\nthat each elemen t can be involve d in at most O(n) comparisons (at worst, it\nis compared with each element in the other list), and if we sum this over all\nelements we get a running-time bound of O(n2). This is a correct bound, but\nwe can show something much stronger .\nThe better way to argue is to bound the number of iterations of the\nWhile loop by an “accounting” scheme. Suppose we charge the cost of each\niteration to the element that is selected and added to the output list. An\nelement can be charged only once, since at the moment it is first charged, it\nis added to the output and never seen again by the algorithm. But there are\nonly 2n elements total, and the cost of each iteration is accounted for by a\ncharge to some element, so there  can be at most 2n iterations. Each iteration\ninvolves a constant amount of work, so the total running time is O(n), as\ndesired.\nWhile this merging algorithm iterated through its input lists in order ,\nthe “interleaved ” way in which it processed the lists necessitate d a slightly\nsubtle running-time analysis. In Chapter 3 we will see linear -time\nalgorithms for graphs that have an even more complex flow of control: they\nspend a constant amount of time on each node and edge in the underlying')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 78})","('type', 'Document')"
"('page_content', ""graph, but the order in which they process the nodes and edges depends on\nthe structure of the graph.\nO(n log n) Time\nO(n log n) is also a very common runnin g time, and in Chapter 5 we will\nsee one of the main reasons for its prevalence: it is the running time of any\nalgorithm that splits its input into two equal-sized pieces, solves each piece\nrecursively , and then combines the two solutions in linear time.\nSorting is perhaps the most well-known example of a problem that can\nbe solved this way. Specifically , the Mergesort  algorith m divides the set of\ninput numbers into two equal-si zed pieces, sorts each half recursively , and\nthen merges the two sorted halves into a single sorted output list. We have\njust seen that the merging can be done in linear time; and Chapter 5 will\ndiscuss how to analyze the recursion so as to get a bound of O(n log n) on\nthe overall running time.\nOne also frequently encounters O(n log n) as a running time simply\nbecause there are many algorith ms whose most expensive step is to sort the\ninput. For example, suppose we are given a set of n time-stamps x1, x2, …,\nxn on which copies of a file arrived at a server , and we'd like to find the\nlargest interval of time between the first and last of these time-stamps\nduring which no copy of the file arrived. A simple solution to this problem\nis to first sort the time-stamps x1, x2, …, xn and then proces s them in sorted\norder , determining the sizes of the gaps between each number and its\nsuccessor in ascending order . The largest of these gaps is the desired\nsubinterval. Note that this algorithm requires O(n log n) time to sort the\nnumbers, and then it spends constant work on each number in ascending\norder . In other words, the remainder of the algorithm after sorting follows\nthe basic recipe for linear time that we discussed earlier .\nQuadratic Time\nHere's a basic problem: suppose you are given n points in the plane, each\nspecified by (x, y) coordinates, and you'd like to find the pair of points that\nare closest together . The natural brute-force algorithm for this problem\nwould enumerate all pairs of points, compute the distance between each\npair, and then choose the pair for which this distance is smallest."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 79})","('type', 'Document')"
"('page_content', ""What is the running time of this algorithm? The number of pairs of\npoints is \n , and since this quantity is bounded by ½n2, it is O(n2).\nMore crudely , the number of pairs is O(n2) because we multiply the number\nof ways of choo sing the first member of the pair (at most n) by the number\nof ways  of choosing the second  member of the pair (also at most n). The\ndistance between points (xi,yi) and (xj,yj) can be computed by the form ula \n in constant time, so the overall running time is O(n2).\nThis example illustrates a very common way in which a running time of\nO(n2) arises: performing a search over all pairs of input items and spending\nconstant time per pair .\nQuadratic time also arises naturally from a pair of nested loops:  An\nalgorithm consis ts of a loop with O(n) iterations, and each iteration of the\nloop launches an internal loop that takes O(n) time. Multiplying these two\nfactors of n together gives the running time.\nThe brute-force algorithm for finding the closest pair of points can be\nwritten in an equivalent way with two nested loops:\nFor each input point ( xi, yi)\nFor each other input point ( xj, yj)\nCompute distance \nIf d is less than the current minimum, update minimum to d\nEndfor\nEndfor\nNote how the “inner” loop, over (xj, yj), has O(n) iteratio ns, each taking\nconstant time; and the “outer” loop, over (xi, yi), has O(n) iterations, each\ninvoking the inner loop once.\nIt's important to notice that the algorithm we've been discussing  for the\nClosest-Pair Problem really is just the brute-force approach: the natural\nsearch space for this problem has size O(n2), and we're simply enumerating\nit. At first, one feels there is a certain inevitability about this quadratic\nalgorithm— we have to measure all the distances, don't we?—but in fact\nthis is an illusio n. In Chapter 5 we describe a very clever algorithm that\nfinds the closest  pair of points in the plane in only O(n log n) time, and in"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 80})","('type', 'Document')"
"('page_content', ""Chapter 13 we show how randomization can be used to reduce the running\ntime to O(n).\nCubic Time\nMore elaborate sets of nested loops often lead to algorithms that run in\nO(n3) time. Conside r, for example, the following problem. We are given\nsets S1, S2, …, Sn, each of which is a subset of {1, 2, …, n}, and we would\nlike to know whether some pair of these sets is disjoint—in other words,\nhas no elements in common.\nWhat is the running time needed to solve this problem? Let's suppose\nthat each set Si is repre sented in such a way that the elements of Si can be\nlisted in constant time per eleme nt, and we can also check in constant time\nwhether a given number p belongs to Si. The following  is a direct way to\napproach the problem.\nFor pair of sets Si and Sj\nDetermine whether Si and Sj have an element in common\nEndfor\nThis is a concrete algorithm, but to reason about its running time it helps to\nopen it up (at least conceptually) into three nested loops.\nFor each set Si\nFor each other set Sj\nFor each element p of Si\nDetermine whether p also belongs to Sj\nEndfor\nIf no element of Si belongs to Sj then\nReport that Si and Sj are disjoint\nEndif\nEndfor\nEndfor\nEach of the sets has maximum size O(n), so the innerm ost loop takes time\nO(n). Looping over the sets Sj involves O(n) iterati ons around this"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 81})","('type', 'Document')"
"('page_content', 'innermost loop; and looping over the sets Si involves O(n) iterations around\nthis. Multiplying these three factors of n together , we get the running time\nof O(n3).\nFor this problem, there are algorithms that improve on O(n3) running\ntime, but they are quite complicated. Furthermore, it is not clear whether the\nimproved algorithms for this problem are practical on inputs of reasonable\nsize.\nO(nk) Time\nIn the same way that we obtained a running time of O(n2) by performing\nbrute-force search over all pairs formed from a set of n items, we obtain a\nrunning time of O(nk) for any constant k when we search over all subsets of\nsize k.\nConsider , for example, the problem of finding independent sets in a\ngraph, which we discussed in Chapter 1. Recall that a set of nodes is\nindependent if no two are joined by an edge. Suppose, in particular , that for\nsome fixed constant k, we would like to know if a given n-node input graph\nG has an indepen dent set of size k. The natural brute-force algorithm for\nthis problem would enumerate all subsets of k nodes, and for each subset S\nit would  check whether there is an edge joining any two members of S. That\nis,\nFor each subset S of k nodes\nCheck whether S constitutes an independent set\nIf S is an independent set then\nStop and declare success\nEndif\nEndfor\nIf no k-node independent set was found then\nDeclare failure\nEndif\nTo unde rstand the running time of this algorithm, we need to consider\ntwo quantities. First, the total number of k-element subsets in an n-element\nset is')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 82})","('type', 'Document')"
"('page_content', ""Since we are treating fc as a constant, this quantity is O(nk). Thus, the outer\nloop in the algorithm above will run for O(nk) iterations as it tries all k-node\nsubsets of the n nodes of the graph.\nInside this loop, we need to test whether a given set S of k nodes\nconstitutes an independent set. The definition of an independent set tells us\nthat we need to check, for each pair of nodes, whether there is an edge\njoining them. Hence this is a search over pairs, like we saw earlier in the\ndiscussion of quadratic time; it requires looking at \n , that is, O(k2), pairs\nand spending constant time on each.\nThus the total running time is O(k2nk). Since we are treating k as a\nconstant here, and since constan ts can be dropped in O(·) notation, we can\nwrite this running time as O(nk).\nIndependent Set is a principal example of a problem believed to be\ncomputationally hard, and in particular it is believed that no algorithm to\nfind k-node independent sets in arbitrary graphs can avoid having some\ndependence on k in the exponent. However , as we will discuss in Chapter\n10 in the context of a related problem, even once we've conceded that brute-\nforce search over k-element subsets is necessary , there can be dif ferent ways\nof going about this that lead to significant differences in the efficiency of\nthe computation.\nBeyond Polynomial Time\nThe previous example of the Independent Set Problem starts us rapidly\ndown the path toward running times that grow faster than any polynomial.\nIn particular , two kinds of bounds that come up very frequently are 2n and\nn!, and we now discuss why this is so.\nSuppose, for example, that we are given a graph and want to find an\nindependent set of maximum  size (rather than testing for the existence of\none with a given number of nodes). Again, people don't know of algorithms\nthat improve significantly on brute-force search, which in this case would\nlook as follows."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 83})","('type', 'Document')"
"('page_content', ""For each subset S of nodes\nCheck whether S constitutes an independent set\nIf S is a lar ger independent set than the lar gest seen so far then\nRecord the size of S as the current maximum\nEndif\nEndfor\nThis is very much like the brute-force algorithm for k-node independent\nsets, except that now we are iterating over all subsets of the graph. The total\nnumber of subsets of an n-element set is 2n, and so the outer loop in this\nalgorithm will run for 2n iterations as it tries all these subsets. Inside the\nloop, we are checking all pairs from a set S that can be as large as n nodes,\nso each iteration of the loop takes at most O(n2) time. Multiplying these two\ntogether , we get a running time of O(n22n).\nThus see that 2n arises naturally as a running  time for a search\nalgorithm that must consider all subsets. In the case of Independent Set,\nsomething at least nearly this inefficient appears to be necessary; but it's\nimportant to keep in mind that 2n is the size of the search space for many\nproblems, and for many of them we will be able to find highly efficient\npolynomial-time algorithms. For example, a brute-force searc h algorithm\nfor the Interval Scheduling Problem that we saw in Chapter 1 would look\nvery similar to the algorithm above: try all subsets of intervals, and find the\nlargest subset that has no overlaps. But in the case of the Interval\nScheduling Problem, as oppose d to the Independent Set Problem, we will\nsee (in Chapter 4) how to find an optimal solution in O(n log n) time. This\nis a recurring kind of dichotomy in the study of algorithms: two algorithms\ncan have  very similar -looking search spaces, but in one case you're able to\nbypass the brute-force search algorithm, and in the other you aren't.\nThe function n! grows even more rapidly than 2n, so it's even more\nmenacing as a bound on the performance of an algorithm. Search spaces of\nsize n! tend to arise for one of two reasons. First, n! is the number of ways\nto match up n items with n other items—for example, it is the number of\npossible perfect matchings of n men with n women  in an instance of the\nStable Matching Problem. To see this, note that there are n choices for how\nwe can match up the first man; having eliminated this option, there are n - 1\nchoices for how we can match up the second man; having eliminated these\ntwo options, there are n - 2 choices for how we can match up the third man;"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 84})","('type', 'Document')"
"('page_content', ""and so forth. Multiplying all these choices out, we get n(n - 1)(n - 2) ··· (2)\n(1) = n!\nDespite this enormous set of possible solutions, we were able to solve\nthe Stable Matching Problem in O(n2) iterations of the proposal algorithm.\nIn Chapter 7, we will see a similar phenomenon for the Bipartite Matching\nProblem we discussed earlier; if there are n nodes on each side of the given\nbipartite graph, there can be up to n! ways of pairing them up. However , by\na fairly subtle search algorithm, we will be able to find the largest bipartite\nmatching in O(n3) time.\nThe function n! also arises in problems where the search space consists\nof all ways to arrange n items in order . A basic problem in this genre is the\nTraveling Salesm an Problem: given a set of n cities, with distances between\nall pairs, what is the shortest tour that visits all cities? We assume that the\nsalesman starts and ends at the first city, so the crux of the problem is the\nimplicit search over all orders of the remaining n - 1 cities, leading to a\nsearch space of size (n - 1)!. In Chapter 8, we will see that Traveling\nSalesman is another problem that, like Independent Set, belongs to the class\nof NP-complete problems and is believed to have no ef ficient solution.\nSublinear Time\nFinally , there are cases where  one encounters running times that are\nasymptotically smaller than linear . Since it takes linear time just to read the\ninput, these situations tend to arise in a model of computation  where the\ninput can be “queried” indirectly rather than read completely , and the goal\nis to minimize the amount of querying that must be done.\nPerhaps the best-known example  of this is the binary search algorithm.\nGiven a sorted array A of n numbers, we'd like to determine whether a given\nnumber p belongs to the array . We could do this by reading the entire array,\nbut we'd like to do it much more efficiently , taking advantage  of the fact\nthat the array is sorted, by caref ully probing  particular entries. In particular ,\nwe probe the middle entry of A and get its value—say it is q—and we\ncompare q to p. If q = p, we're done. If q > p, then in order for p to belong\nto the array A, it must  lie in the lower half of A; so we ignore the upper half\nof A from now on and recursively  apply this search in the lower half.\nFinally , if q < p, then we apply the analogous reasoning and recursively\nsearch in the upper half of A."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 85})","('type', 'Document')"
"('page_content', ""The point is that in each step, there's a region of A where p might\npossibly be; and we're shrinking the size of this region by a factor of two\nwith every probe. So how large is the “active” region of A after k probes? It\nstarts at size n, so after k probes it has size at most (½)kn.\nGiven this, how long will it take for the size of the active region to be\nreduced to a constant? We need k to be large enough so that (½)k = O(1/n),\nand to do this we can choose k = log2 n. Thus, when k = log2 n, the size of\nthe active region has been reduced to a constant, at which point the\nrecursion bottoms out and we can search the remainder of the array directly\nin constant time.\nSo the running time of binary search is O(log n), because of this\nsuccessive shrinking of the search region. In general, O(log n) arises as a\ntime bound whenever we're dealing with an algorithm that does a constant\namount of work in order to throw away a constant fraction  of the input. The\ncrucial fact is that O(log n) such iterations suffice to shrink the input down\nto constant size, at which point the problem can generally be solved\ndirectly .\n2.5 A More Complex Data Structure: Priority\nQueues\nOur prim ary goal in this book was expressed at the outset of the chapter: we\nseek algorithms  that improve qualitatively on brute-force search, and in\ngeneral we use polynomial-time solvability as the concrete formulation of\nthis. Typically , achieving a polynomial-time solution to a nontrivial\nproblem is not something that depends on fine-grained implementation\ndetails; rather , the difference between exponential and polynomial is based\non overcoming higher -level obstacles. Once one has an efficien t algorithm\nto solve a problem, however , it is often possible to achieve further\nimprovements in running time by being careful with the implementation\ndetails, and sometimes by using more complex data structures.\nSome complex data structures are essentially tailored for use in a\nsingle kind of algorithm, while others are more generally applicable. In this\nsection, we describe one of the most broadly useful sophisticated data\nstructures, the priority queue.  Priority  queues will be useful when we"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 86})","('type', 'Document')"
"('page_content', 'describe how to implement some of the graph algorithms develo ped later in\nthe book. For our purposes here,  it is a useful illustration of the analysis of a\ndata structure that, unlike lists and arrays, must perform some nontrivial\nprocessing each time it is invoked.\nThe Problem\nIn the implementation of the Stable Matching algorithm in Section 2.3, we\ndiscussed the need to maintain a dynamically changing set S (such as the set\nof all free men in that case). In such situations, we want to be able to add\nelements to and delete elements from the set S, and we want to be able to\nselect an element from S when the algorithm calls for it. A priority queue is\ndesigned for applications in which elements have a priority value,  or key,\nand each time we need to select an element from S, we want to take the one\nwith highest priority .\nA priori ty queue  is a data structure that maintains a set of elements S,\nwhere each element v ∊ S has an associated value key(v) that denotes the\npriority of element v; smaller keys represent higher priorities. Priority\nqueues support the addition and deletion of elements from the set, and also\nthe selection of the element with smallest key. Our implementation of\npriority queues will also support some additional operations that we\nsummarize at the end of the section.\nA motivating application for priority queues, and one that is useful to\nkeep in mind when considering  their general function, is the problem of\nmanaging real-t ime events such as the scheduling of processes on a\ncomputer . Each process has a priority , or urgency , but processes do not\narrive in order of their prioritie s. Rather , we have a current set of active\nprocesses, and we want to be able to extract the one with the currently\nhighest priority and run it. We can maintain the set of processes in a priority\nqueue, with the key of a process representing its priority value. Scheduling\nthe highest-priority process corresponds to selecting the element with\nminimum key from the priority queue; concurrent with this, we will also be\ninserting new processes as they arrive, according to their priority values.\nHow efficiently do we hope to be able to execute the operations in a\npriority queue? We will show how to implement a priority queue containing\nat most n elem ents at any time so that elements can be added and delete d,\nand the element with minimum key selected, in O(log n) time per operation.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 87})","('type', 'Document')"
"('page_content', 'Before discussing the impleme ntation, let us point out a very basic\napplication of priority queues that highlights why O(log n) time per\noperation is essentially the “right” bound to aim for .\n(2.11) A sequence of O(n) priority queue operations can be used to sort a set of n numbers.\nProof. Set up a priority queu e H, and insert each number into H with its value as a key. Then extract\nthe smallest number one by one until all numbers have been extracted; this way, the numbers will\ncome out of the priority queue in sorted order . ▪\nThus, with a priority queue that can perform insertion and the\nextraction of minima in O(log n) per operation, we can sort n numbers in\nO(n log n) time. It is known that, in a comparison-based model of\ncomputation (when each operation accesses the input only by comparing a\npair of numbers ), the time needed to sort must be at least proportional to n\nlog n, so (2.11) highlights a sense in which O(log n) time per operation is\nthe best we can hope for. We should note that the situation is a bit more\ncomplicated than this: implementations of priority queues more\nsophisticated than the one we present here can improve the running time\nneeded for certain operations, and add extra functionality . But (2.11) shows\nthat any sequenc e of priority queue operations that results in the sorting of n\nnumbers must take time at least proportional to n log n in total.\nA Data Structure for Implementing a Priority\nQueue\nWe will use a data structure called a heap  to implement a priority queue.\nBefore we discuss the structure of heaps, we should consider what happens\nwith some simpler , more natura l approaches to implementing the functions\nof a priority queue. We could just have the elements in a list, and separately\nhave a pointer labeled Min to the one with minimum key. This makes\nadding new elements easy, but extraction of the minimum hard.\nSpecifically , finding the minimum is quick—we just consult the Min\npointer—but after removing this minimum element, we need to update the\nMin pointer to be ready for the next operation, and this would require a scan\nof all elements in O(n) time to find the new minimum.\nThis complication suggests that we should perhaps maintain the\nelements in the sorted order of the keys. This makes it easy to extract the\nelement with smallest key, but now how do we add a new element to our')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 88})","('type', 'Document')"
"('page_content', ""set? Should we have the elements in an array , or a linked list? Suppose we\nwant to add s with key value key(s). If the set S is maintained as a sorted\narray , we can use binary search to find the array position where  s should be\ninserted in O(log n) time, but to insert s in the array , we would have to\nmove all later elements one position to the right. This would take O(n) time.\nOn the other hand, if we maintain the set as a sorted doubly linked list, we\ncould insert it in O(1) time into any position, but the doubly linked list\nwould not suppo rt binary search, and hence we may need up to O(n) time to\nfind the position where s should be inserted.\nThe Definition of a Heap  So in all these simple approaches, at least one of\nthe operations can take up to O(n) time— much more than the O(log n) per\noperation that we're hoping for. This is where heaps come in. The heap  data\nstructure combin es the benefits of a sorted array and list for purposes of this\napplication. Conceptually , we think of a heap as a balanced binary tree as\nshown on the left of Figure 2.3 . The tree will have a root, and each node can\nhave up to two children, a left and a right child. The keys in such a binary\ntree are said to be in heap or der if the key of any element is at least as large\nas the key of the element at its parent node in the tree. In other words,\nHeap order: For every element v, at a node i, the element w at i's parent satisfies\nkey(w) ≤ key( v).\nIn Figure 2.3 the numbers in the nodes are the keys of the corresponding\nelements.\nBefore we discuss how to work with a heap, we need to consider what\ndata structure should be used to represent it. We can use pointers: each node\nat the heap could keep the element it stores, its key, and three pointers\npointing to the two children and the parent of the heap node. We can avoid\nusing pointers, however , if a bound N is know n in advance on the total\nnumber of elements that will ever be in the heap at any one time. Such\nheaps can be maintained in an array H indexed  by i = 1, …, N. We will\nthink of the heap  nodes as corresponding to the positions in this array . H[1]\nis the root, and for any node at position i, the children are the nodes at\npositions leftChild( i) = 2i and rightChild( i) = 2i + 1. So the two children of\nthe root are at positions 2 and 3, and the parent of a node at position i is at\nposition parent( i) = [i/2|. If the heap has n < N elements at some time, we\nwill use the first n positions of the array to store the n heap elements, and\nuse length (H) to denote the number of elements in H. This representation"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 89})","('type', 'Document')"
"('page_content', 'keeps the heap balanced at all times. See the right-hand side of Figure 2.3\nfor the array representation of the heap on the left-hand side.\nFigur e 2.3 Values  in a heap shown as a binary tree on the left, and\nrepresented as an array on the right. The arrows show the children for the\ntop three nodes in the tree.\nImplementing the Heap Operations\nThe heap element with smallest key is at the root, so it takes O(1) time to\nidentify the minimal element. How do we add or delete heap elements?\nFirst consider adding a new heap element v, and assume that our heap H has\nn < N elements so far. Now it will have n + 1 elements. To start with, we\ncan add the new element v to the final position i = n + 1, by setting H[i] = v.\nUnfortunately , this does not maintain the heap property , as the key of\nelement v may be smaller than the key of its parent. So we now have\nsomething that is almost a heap, except for a small “damaged” part where v\nwas pasted on at the end.\nWe will use the procedure Heap ify-up to fix our heap. Let j = parent( i)\n= [i/2] be the parent of the node i, and assume H[j] = w. If key[v] < key[w],\nthen we will simply swap the positions of v and w. This will fix the heap\nproperty at position i, but the resulting structure will possibly fail to satisfy\nthe heap property at position j—in other words, the site of the “damage” has\nmoved upward from i to j. We thus call the process recursively from\nposition j = parent(i) to continue fixing the heap by pushing the damaged\npart upward. Figure 2.4 shows the first two steps of the process after an\ninsertion.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 90})","('type', 'Document')"
"('page_content', 'Figur e 2.4  The Heapify-up process. Key 3 (at position 16) is too small (on\nthe left). After swapping keys 3 and 11, the heap violation moves one step\ncloser to the root of the tree (on the right).\nHeapify-up(H,i):\nIf i > 1 then\nlet j = parent( i) = [i/2]\nIf key[H[i]] < key[H[j]] then\nswap the array entries H[i] and H[j]\nHeapify-up(H,j)\nEndif\nEndif\nTo see why Heapify-up works, eventually restoring the heap order , it\nhelps to understand more fully the structure of our slightly damaged heap in\nthe middle of this process. Assume that H is an array, and v is the element\nin position i. We say that H is almost a heap with the key of H[i] too small,\nif there is a value α ≥ key( v) such that raisin g the value of key(v) to α would\nmake the resulting array satisfy the heap property . (In other words, element\nv in H[i] is too small, but raising it to α would fix the problem.) One\nimportant point to note is that if H is almost a heap  with the key of the root\n(i.e., H[1]) too small, then in fact it is a heap. To see why this is true,\nconsider that if raising the value of H[1] to α would make H a heap, then\nthe value of H[1] must  also be smaller than both its children, and hence it\nalready has the heap-order property .\n(2.12)  The procedur e Heapify-up (H, i) fixes the heap property in O(log i) time, assuming that the\narray H is almost a heap with the key of H[i] too small. Using  Heapify-up  we can insert a new\nelement in a heap of n elements in O (log n) time.\nProof. We prove the statement by induction on i. If i = 1 there is nothing to prove, since we have\nalready argued that in this case H is actually a heap. Now consider the case in which i > 1: Let v =')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 91})","('type', 'Document')"
"('page_content', ""H[i], j = parent(i), w = H[j], and β = key(w). Swapping elements v and w takes O(1) time. We claim\nthat after the swap, the array H is either a heap or almost a heap with the key of H[j] (which now\nholds v) too small. This is true, as setting the key value at node j to β would make H a heap.\nSo by the induction hypothesis, applying Heapify-up (j) recursive ly will produce a heap as\nrequired. The process follows the tree-path from position i to the root, so it takes O(log i) time.\nTo insert a new element in a heap, we first add it as the last element. If the new element has a\nvery large key value, then the array is a heap. Otherwise, it is almost a heap with the key value of the\nnew element too small. W e use Heapify-up  to fix the heap property . ▪\nNow consider deleting an element. Many applications of priority\nqueues don't require the deletion of arbitrary elements, but only the\nextraction of the minimum. In a heap, this corresponds to identifying the\nkey at the root (which will be the minimum) and then deleting it; we will\nrefer to this operation as ExtractMin( H). Here we will implement a more\ngeneral operation Delete( H, i), which will delete the element in position i.\nAssume the heap currently has n elements. After deleting the element H[i],\nthe heap will have only n - 1 elements; and not only is the heap-order\nproperty violated, there is actually a “hole” at position i, since H[i] is now\nempty . So as a first step, to patch the hole in H, we move the element w in\nposition n to position i. After doing this, H at least has the property that its n\n- 1 elements are in the first n - 1 positions, as required, but we may well still\nnot have the heap-order property .\nHowever , the only place in the heap where the order might be violated\nis position i, as the key of element w may be either too small or too big for\nthe position i. If the key is too small (that is, the violation of the heap\nproperty is between node i and its parent), then we can use Heapify-up( i) to\nreestablish the heap order . On the other hand, if key[w] is too big, the heap\nproperty may be violated betwe en i and one or both of its children . In this\ncase, we will use a procedure called Heapify-down, closely analogous to\nHeapify-up, that swaps the elem ent at position i with one of its children and\nproceeds down the tree recursiv ely. Figure 2.5 shows the first steps of this\nprocess.\nFigur e 2.5  The Heapify-down process:. Key 21 (at position 3) is too big (on\nthe left).  After swapping keys 21 and 7, the heap violation moves one step\ncloser to the bottom of the tree (on the right)."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 92})","('type', 'Document')"
"('page_content', 'Heapify-down(H,i):\nLet n = length( H)\nIf 2i > n then\nTerminate with H unchanged\nElse if 2 i < n then\nLet left = 2 i, and right = 2 i + 1\nLet j be the index that minimizes key[ H[left]] and key[ H[right]]\nElse if 2 i = n then\nLet j = 2i\nEndif\nIf key[ H[j]] < key[ H[i]] then\nswap the array entries H[i] and H[j]\nHeapify-down( H, j)\nEndif\nAssume that H is an array and w is the element in position i. We say\nthat H is almost a heap with the key of H[i] too big, if there  is a value α ≤\nkey(w) such that lowering the value of key(w) to α would make the\nresulting array satisfy the heap property . Note that if H[i] corresponds to a\nleaf in the heap (i.e., it has no children), and H is almo st a heap with H[i]\ntoo big, then in fact H is a heap. Indee d, if lowering the value in H[i] would\nmake H a heap, then H[i] is already larger than its parent and hence it\nalready has the heap-order property .\n(2.13)  The pr ocedur e Heapify-down (H, i) fixes the heap property in O(log n) time, assuming that H\nis almost a heap with the key value of H[i] too big. Using  Heapify-up  or Heapify-down  we can\ndelete a new element in a heap of n elements in O (log n) time.\nProof. We prove  that the process fixes the heap by reverse induction on the value i. Let n be the\nnumber of elements in the heap. If 2i > n, then, as we just argued above, H is a heap and hence there\nis nothing to prove. Otherwise, let j be the child of i with smaller key value, and let w = H[j].\nSwapping the array elements w and v takes O(1) time. We claim that the resulting array is either a\nheap or almost a heap  with H[j] = v too big. This is true as setting key(v) = key(w) would make H a')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 93})","('type', 'Document')"
"('page_content', 'heap. Now j ≥ 2i, so by the induction hypothesis, the recursive call to Heapify-down fixes the heap\nproperty .\nThe algorithm repeatedly swaps the element originally at position i down, following a tree-path,\nso in O(log n) iterations the process results in a heap.\nTo use the process to remove an element v = H[i]from the heap, we replace H[i] with the last\nelement in the array , H[n] = w. If the resulting array is not a heap, it is almost a heap with the key\nvalue of H[i] either too small or too big. We use Heapify-down or Heapify-down to fix the heap\nproperty in O(log n) time. ▪\nImplementing Priority Queues with Heaps\nThe heap data structure with the Heapify-down and Heapify-up operations\ncan efficiently implement a priority queue that is constrained to hold at\nmost N elements at any point in time. Here we summarize the operations we\nwill use.\nStartHeap (N) returns an empty heap H that is set up to store at most N\nelements. This operation takes O(N) time, as it involves initializing the\narray that will hold the heap.\nInsert (H, v) inserts the item v into heap H. If the heap currently has n\nelements, this takes O(log n) time.\nFindMin (H) identifies the minimum element in the heap H but does\nnot remove it. This takes O(1) time.\nDelete (H, i) delete s the element in heap position i. This is\nimplemented in O(log n) time for heaps that have n elements.\nExtractMin (H) identifies and deletes an element with minimum key\nvalue from a heap. This is a combination of the precedin g two\noperations, and so it takes O(log n) time.\nThere is a second class of operations in which we want to operate on\nelements by name, rather than by their position in the heap. For example, in\na number of graph algorithms that use heaps, the heap elements are nodes\nof the graph with key values that are computed during the algorithm. At\nvarious points in these algorithms, we want to operate on a particular node,\nregardless of where it happens to be in the heap.\nTo be able to access given elem ents of the priority queue efficiently ,\nwe simply maintain an additio nal array Position that stores the current\nposition of each element (each node) in the heap. We can now implement\nthe following further operations.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 94})","('type', 'Document')"
"('page_content', ""To delete the element v, we apply Delete (H,Position [v]). Maintaining\nthis array does not increase the overall running time, and so we can\ndelete an element v from a heap with n nodes in O(log n) time.\nAn additional operation that is used by some algorithms is\nChangeKey  (H, v, α), which changes the key value of element v to\nkey(v) = α. To implement this operation in O(log n) time, we first need\nto be able to identify the position of element v in the array, which we\ndo by using the array Position. Once we have identified the position of\nelement v, we change the key and then apply Heapify-up  or Heapify-\ndown  as appropriate.\nSolved Exercises\nSolved Exercise 1\nTake the followi ng list of functi ons and arrange them in ascend ing order of\ngrowth rate. That is, if function  g(n) immediately follows function f(n) in\nyour list, then it should be the case that f(n) is O(g(n)).\nSolution  We can deal with functions f1, f2, and f4 very easily , since they\nbelong to the basic families of exponentials, polynomials, and logarithms.\nIn particular , by (2.8), we have f4(n) = O(f2(n)); and by (2.9),  we have f2(n)\n= O(f1(n)).\nNow , the functio n f3 isn't so hard to deal with. It starts out smaller than\n10n, but once n ≥ 10, then clearly 10n ≤ nn. This is exactly what we need for"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 95})","('type', 'Document')"
"('page_content', ""the definition of O(·) notation: for all n ≥ 10, we have 10n ≤ cnn, where in\nthis case c = 1, and so 10n = O(nn).\nFinally , we come to function f5, which is admittedly kind of strange-\nlooking. A useful rule of thumb in such situations is to try taking  logarithms\nto see whether this makes things clearer . In this case,  \n. What do the logarithms of the other functions\nlook like? log f4(n) = log2 log2 n, while log f2(n) = ⅓ log2 n. All of these can\nbe viewed as functions of log2 n, and so using the notation z = log2 n, we\ncan write\nNow it's easier to see what's going on. First, for z ≥ 16, we have log2z ≤ z1/2.\nBut the conditio n z ≥ 16 is the same as n ≥ 216 = 65, 536; thus once n ≥ 216\nwe have log f4(n) ≤ log f5(n), and so f4(n) ≤ f5(n). Thus we can write f4(n) =\nO(f5(n)). Similarly we have z1/2 ≤ ⅓z once z ≥ 9—in other words, once n ≥\n29 = 512. For n above this bound we have log f5(n) ≤ log f2(n) and hence\nf5(n) ≤ f2(n), and so we can write f5(n) = O(f2(n)). Essentially , we have\ndiscovered that \n  is a function whose growth rate lies somewhere\nbetween that of logarithms and polynomials.\nSince we have sandwiched f5 between f4 and f2, this finishes the task of\nputting the functions in order .\nSolved Exercise 2\nLet f and g be two functions that take nonnegative values, and suppose that f\n= O(g). Show that g = Ω( f).\nSolution  This exercise is a way to formalize the intuition that O(·) and Ω(·)\nare in a sense opposites. It is, in fact, not difficult to prove; it is just a matter\nof unwinding the definitions."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 96})","('type', 'Document')"
"('page_content', ""We're given that, for some const ants c and n0, we have f(n) ≤ cg(n) for\nall n ≥ n0. Dividing both sides by c, we can conclude that g(n) ≥ \n f(n) for all\nn ≥ n0. But this is exactly what is required to show that g = Ω(f): we have\nestablished that g(n) is at least a constant multiple of f(n) (where the\nconstant is \n ), for all suf ficiently lar ge n (at least n0).\nExercises\n1. Suppose you have algorithms with the five running times listed below .\n(Assume these are the exact running times.) How much slower do each\nof these algorithms get when you (a) double the input size, or (b)\nincrease the input size by one?  \n(a) n2 \n(b) n3 \n(c) 100n2 \n(d) n log n \n(e) 2n\n2. Suppose you have algorithms with the six running times listed below .\n(Assume these are the exact number of operations performed as a\nfunction of the input size n.) Suppose you have a compute r that can\nperform 1010 operations per second, and you need to compute a result\nin at most an hour of computation. For each of the algorithms, what is\nthe largest input size n for which you would be able to get the result\nwithin an hour?  \n(a) n2 \n(b) n3 \n(c) 100n2 \n(d) n log n \n(e) 2n \n(f) 22n\n3. Take the following list of functions and arrange them in ascending\norder of growth rate. That is, if function g(n) immediately follows\nfunction f(n) in your list, then it should be the case that f(n) is O(g(n))."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 97})","('type', 'Document')"
"('page_content', ""4. Take the following list of functions and arrange them in ascending\norder of growth rate. That is, if function g(n) immediately follows\nfunction f(n) in your list, then it should be the case that f(n) is O(g(n)). \n5. Assume you have functions f and g such that f(n) is O(g(n)). For each\nof the following statements, decide whether you think it is true or false\nand give a proof or counterexample.  \n(a) log2 f(n) is O(log2 g(n)). \n(b) 2f(n) is O(2g(n)). \n(c) f(n)2 is O(g(n)2).\n6. Consider the following basic problem. You're given an array A\nconsisting of n integers A[1], A[2], …, A[n]. You'd like to output a\ntwo-dimensional n-by-n array B in which B[i,j] (for i<j) contains the\nsum of array entries A[i] through A[j]-that is, the sum A[i] + A[i + 1]+\n··· + A[j]. (The value of array entry B[i,j] is left unspecified whenever i\n≥ j, so it doesn't matter what is output for these values.)  \nHere's a simple algorithm to solve this problem."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 98})","('type', 'Document')"
"('page_content', ""For i = 1, 2, …, n\nFor j = i + 1, i + 2, …, n\nAdd up array entries A[i] through A[j]\nStore the result in B[i, j]\nEndfor\nEndfor\n(a) For some function f that you should choose, give a bound of the\nform O(f(n)) on the running  time of this algorithm on an input of size n\n(i.e., a bound on the number of operations performed by the\nalgorithm).  \n(b) For this same  function f, show that the running time of the\nalgorithm on an input of size n is also Ω(f(n)). (This shows an\nasymptotically tight bound of Θ( f(n)) on the running time.)  \n(c) Althou gh the algorithm you analyzed in parts (a) and (b) is the\nmost natural way to solve the problem-after all, it just iterates through\nthe relevant entries of the array B, filling in a value for each—it\ncontains some highly unnecessary sources of inefficiency . Give a\ndifferent algorith m to solve this problem, with an asymptotically better\nrunning time. In other words, you should design an algorithm with\nrunning time O(g(n)), where limn→∞ g(n)/f(n) = 0.\n7. There's a class of folk songs and holiday songs in which each verse\nconsists of the previous verse, with one extra line added on. “The\nTwelve Days of Christmas” has this property; for example, when you\nget to the fifth verse, you sing about the five golden rings and then,\nreprising the lines from the fourth verse, also cover the four calling\nbirds, the three French hens, the two turtle doves, and of course the\npartridge in the pear tree. The Aramaic song “Had gadya” from the\nPassover Haggadah works like this as well, as do many other songs.  \nThese songs tend to last a long time, despite having relatively short\nscripts. In particular , you can convey the words plus instructions for\none of these songs by specifying  just the new line that is added in each\nverse, without having to write out all the previous lines each time. (So\nthe phrase “five golden rings” only has to be written once, even though\nit will appear in verses five and onward.)  \nThere's something asymptotic that can be analyzed here. Suppose, for\nconcreteness, that each line has a length that is bounded by a constant"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 99})","('type', 'Document')"
"('page_content', ""c, and suppose that the song, when sung out loud, runs for n words\ntotal. Show how to encode such a song using a script that has length\nf(n), for a function f(n) that grows as slowly as possible.\n8. You're doing some stress-testin g on various models of glass jars to\ndetermine the height from which they can be dropped and still not\nbreak. The setup  for this experiment, on a particular type of jar, is as\nfollows. You have a ladder with n rungs, and you want to find the\nhighest rung from which you can drop a copy of the jar and not have it\nbreak. W e call this the highest safe rung.  \nIt might be natural to try binary search: drop a jar from the middle\nrung, see if it breaks, and then recursively try from rung n/4 or 3n/4\ndepending on the outcome. But this has the drawback that you could\nbreak a lot of jars in finding the answer . \nIf your primary  goal were to conserve jars, on the other hand, you\ncould try the following strategy . Start by dropping a jar from the first\nrung, then the second rung, and so forth, climbing one highe r each\ntime until the jar breaks. In this way, you only need a single jar— at the\nmoment it breaks, you have the correct answer -but you may have to\ndrop it n times (rather than log n as in the binary search solution).  \nSo here is the trade-of f: it seems you can perform fewer drops if you're\nwilling to break more jars. To understand better how this tradeof f\nworks at a quantitative level, let's consider how to run this expe riment\ngiven a fixed “budget” of k ≥ 1 jars. In other words, you have to\ndetermine the correct answer -the highest safe rung-and can use at most\nk jars in doing so.  \n(a) Suppose you are given a budget of k = 2 jars. Descr ibe a strategy\nfor finding the highest safe rung that requires you to drop ajar at most\nf(n) times, for some function f(n) that grows slower than linearly . (In\nother words, it should be the case that limn→∞ f(n)/n = 0.)\n(b) Now suppose you have a budget of k > 2 jars, for some given k.\nDescribe a strategy for finding the highest safe rung using at most k\njars. If fk(n) denote s the number of times you need to drop a jar\naccording to your strategy , then the functions f1, f2, f3, … should have\nthe property that each grows asymptotically slower than the previous\none: limn→∞ fk(n)/fk-1(n) = 0 for each k."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 100})","('type', 'Document')"
"('page_content', ""Notes and Further Reading\nPolynomial-time solvability emer ged as a formal notion of efficiency by a\ngradual process, motivated by the work of a number of researchers\nincluding Cobham, Rabin, Edmonds, Hartmanis, and Stearns. The survey\nby Sipse r (1992) provides both a historical and technical perspective on\nthese developments. Similarly , the use of asymptotic order  of growth\nnotation to bound the running time of algorithms—as opposed  to working\nout exact formulas with leadin g coefficients and lower -order terms—is a\nmodeling decisio n that was quite  non-obvious at the time it was introduced;\nTarjan's Turing Award lecture (1987) offers an interesting perspective on\nthe early thinking of researcher s including Hopcroft, Tarjan, and others on\nthis issue. Further discussion of asymptotic notation and the grow th of basic\nfunctions can be found in Knuth (1997a).\nThe implementation of priority queues using heaps, and the application\nto sortin g, is generally credited to Williams (1964) and Floyd (1964). The\npriority queue is an example of a nontrivial data structure with many\napplications; in later chapters we will discuss other data structures as they\nbecome useful for the implementation of particular algorithms. We will\nconsider the Union-Find data structure in Chapter 4 for implementing an\nalgorithm to find minimum-c ost spanning trees, and we will discuss\nrandomized hashing in Chapter 13. A number of other data structures are\ndiscussed in the book by Tarjan (1983). The LEDA library (Library of\nEfficient Dataty pes and Algorithms) of Mehlhorn and Näher (1999) offers\nan extensive library of data structures useful in combinatorial and geometric\napplications.\nNotes on the Exercises  Exercise 8 is based on a problem we learned from\nSam T oueg."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 101})","('type', 'Document')"
"('page_content', 'Chapter 3')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 102})","('type', 'Document')"
"('page_content', 'Graphs\n3.1 Basic Definitions and Applications  \n3.2 Graph Connectivity and Graph T raversal  \n3.3 Implementing Graph T raversal Using Queues and Stacks  \n3.4 T esting Bipartiteness: An Application of Br eadth-First Sear ch \n3.5 Connectivity in Dir ected Graphs  \n3.6 Dir ected Acyclic Graphs and T opological Ordering  \nSolved Exer cises  \nExer cises  \nNotes and Further Reading\nOur focus in this book is on problems with a discrete flavor. Just as\ncontinuous mathematics is concerned with certain basic structu res such as\nreal numbers, vectors, and matrices, discrete mathematics has developed\nbasic combinatorial structures that lie at the heart of the subject. One of the\nmost fundamental and expressive of these is the graph.\nThe more one works with graphs, the more one tends to see them\neverywhere. Thus, we begin by introducing the basic definitions\nsurrounding graphs, and list a spectrum of different algorithmic settings\nwhere graphs arise naturally . We then discuss some basic algorithmic\nprimitives for graphs, beginning with the problem of connectivity  and\ndeveloping some fundamental graph search techniques.\n3.1 Basic Definitions and Applications\nRecall from Chapter 1  that a graph G is simply a way of encoding pairwise\nrelationships among a set of objects: it consists of a collection V of nodes\nand a collection  E of edges,  each of which “joins” two of the nodes. We\nthus represent an edge e ∊ E as a two-element subset of V: e = {u, v] for\nsome u, v ∊ V, where we call u and v the ends of e.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 103})","('type', 'Document')"
"('page_content', ""Edges in a graph indicate a symmetric relationship between their ends.\nOften we want to encode asymmetric relationships, and for this we use the\nclosely related notion of a directed graph.  A directed graph G′ consists of a\nset of nodes V and a set of directed edges E′.  Each e′ ∊ E′ is an ordered pair\n(u, v); in other word s, the roles of u and v are not interchangeable, and we\ncall u the tail of the edge and v the head.  We will also say that edge e′\nleaves node u  and enters node v .\nWhen we want to emphasize that the graph we are considering is not\ndirected, we will call it an undir ected graph;  by default, however, the term\n“graph” will mean an undirected graph. It is also worth mentioning two\nwarnings in our use of graph terminology . First, although an edge e in an\nundirected graph should properly be written as a set of nodes {u, v}, one\nwill more often  see it written (even in this book) in the notation used for\nordered pairs: e = (u, v). Second, a node  in a graph is also frequently called\na vertex;  in this context, the two words have exactly the same meaning.\nExamples of Graphs  Graphs are very simple to define: we just take a\ncollection of things and join some of them by edges. But at this level of\nabstraction, it's hard to appreciate the typical kinds of situatio ns in which\nthey arise. Thus , we propose the following list of specific contex ts in which\ngraphs serve as important models. The list covers a lot of ground, and it's\nnot important to remember everything on it; rather , it will provide us with a\nlot of useful examples against which to check the basic definitions and\nalgorithmic problems that we'll be encountering later in the chap ter. Also, in\ngoing through the list, it's useful to digest the meaning of the nodes and the\nmeaning of the edges in the context of the application. In some cases the\nnodes and edge s both correspond to physical objects in the real world, in\nothers the nodes are real objects while the edges are virtual, and in still\nothers both nodes and edges are pure abstractions.\n1. Transportation networks.  The map of routes served by an airline\ncarrier naturally forms a graph: the nodes are airports, and there is an\nedge from u to v if there is a nonstop flight that departs from u and\narrives at v. Described this way, the graph is directed; but in practice\nwhen there is an edge (u, v), there is almost always an edge (v, u), so\nwe would not lose much by treating the airline route map as an\nundirected graph with edges joining pairs of airports that have nonstop\nflights each way. Looking at such a graph (you can generally find them"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 104})","('type', 'Document')"
"('page_content', ""depicted in the backs of inflight airline magazines), we'd quickly\nnotice a few things: there are often a small number of hubs with a very\nlarge number of incident edges ; and it's possible to get between any\ntwo nodes in the graph via a very small number of intermediate stops.  \nOther transportation networks can be modeled in a similar way. For\nexample, we could take a rail network and have a node for each\nterminal, and an edge joining u and v if there's a section of railway\ntrack that goes between them without stopping at any interm ediate\nterminal. The standard depiction of the subway map in a major city is a\ndrawing of such a graph.\n2. Communication networks.  A collection of computers connected via a\ncommunication network can be naturally modeled as a graph in a few\ndifferent ways. First, we could have a node for each computer and an\nedge joining u and v if there is a direct physical link connecting them.\nAlternatively , for studying the large-scale structure of the Internet,\npeople often define a node to be the set of all machines controlled by a\nsingle Internet service provider , with an edge joining u and v if there is\na direct peering relationship  between  them—roughly , an agreement to\nexchange data under the standa rd BGP protocol that governs global\nInternet routing.  Note that this latter network is more “virtual” than the\nformer , since the links indicate a formal agreement in additio n to a\nphysical connection.  \nIn studying wireless networks, one typically defines a graph where the\nnodes are computing devices situated at locations in physical space,\nand there is an edge from u to v if v is close  enough  to u to recei ve a\nsignal from it. Note that it's often useful to view such a graph as\ndirected, since it may be the case that v can hear u's signal but u cannot\nhear v's signal  (if, for example, u has a stronger transmitter). These\ngraphs are also interesting from a geometric perspective, since they\nroughly correspond to putting down points in the plane and then\njoining pairs that are close together .\n3. Information networks.  The World Wide Web can be naturally viewed\nas a directed graph, in which nodes correspond to Web pages and there\nis an edge from u to v if u has a hyperlink  to v. The directedness of the\ngraph is crucial here; many pages, for example, link to popular news\nsites, but these sites clearly do not reciprocate all these links. The\nstructure of all these hyperlinks can be used by algorithms to try"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 105})","('type', 'Document')"
"('page_content', 'inferring the most important pages on the Web, a technique employed\nby most current search engines.  \nThe hypertextual structure of the Web is anticipated by a number of\ninformation netw orks that predate the Internet by many decades. These\ninclude the network of cross-references among articles in an\nencyclopedia or other reference work, and the network of\nbibliographic citations among scientific papers.\n4. Social networks.  Given any collection of people who interact (the\nemployees of a company , the students in a high school, or the residents\nof a small town), we can defin e a network whose nodes are people,\nwith an edge joining u and v if they are friends with one another . We\ncould have the edges mean a number of different things instead of\nfriendship: the undirected edge ( u, v) could mean that u and v have had\na roman tic relationship or a financial relationship; the directed edge (u,\nv) could mean that u seeks advice from v, or that u lists v in his or her\ne-mail address book. One can also imagine bipartite social networks\nbased on a notion of affiliation:  given a set X of peop le and a set Y of\norganizations, we could define an edge between u ∊ X and v ∊ Y if\nperson u belongs to or ganization v. \nNetworks such as this are used extensively by sociologists to study the\ndynamics of interaction among  people. They can be used to identify\nthe most “influential” people in a company or organization, to model\ntrust relationships in a financial or political setting, and to track the\nspread of fads, rumors, jokes, diseases, and e-mail viruses.\n5. Dependency networks.  It is natural to define directed graphs that\ncapture the interdependencies among a collection of objects. For\nexample, given the list of courses of fered by a college or university , we\ncould have a node for each course and an edge from u to v if u is a\nprerequisite for v. Given a list of functions or modules in a large\nsoftware system, we could have a node for each function and an edge\nfrom u to v if u invokes v by a function call. Or given a set of species\nin an ecosystem, we could define a graph—a food web—in which the\nnodes are the different species and there is an edge from u to v if u\nconsumes v.\nThis is far from a complete list, too far to even begin tabulating its\nomissions. It is meant simply to suggest some examples that are useful to')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 106})","('type', 'Document')"
"('page_content', ""keep in mind when we start thinking about graphs in an algorithmic context.\nPaths and Connectivity  One of the fundamental operations in a graph is\nthat of traversin g a sequence of nodes connected by edges. In the examples\njust listed, such a traversal could correspond to a user browsing Web pages\nby follo wing hyperlinks; a rumor passing by word of mouth from you to\nsomeone halfway around the world; or an airline passenger traveling from\nSan Francisco to Rome on a sequence of flights.\nWith this notion in mind, we define a path in an undirected graph G =\n(V, E) to be a sequence P of nodes v1, v2, …, vk-1, vk with the property that\neach consecutive pair vi, vi+1 is joine d by an edge in G. P is often called a\npath from v1 to vk, or a v1 - vk path. For examp le, the nodes 4, 2, 1, 7, 8 form\na path in Figure 3.1. A path is called simple  if all its vertice s are distinct\nfrom one another . A cycle  is a path v1, v2, …, vk-1, vk in which k > 2, the\nfirst k - 1 nodes are all distinct, and v1 = vk—in other words, the sequence of\nnodes “cycles back” to where it began. All of these definitions carry over\nnaturally to directed graphs, with the following change: in a directed path or\ncycle, each pair of consecutive nodes has the property that (vi, vi+1) is an\nedge. In other words, the sequence of nodes in the path or cycle must\nrespect the directionality of edges.\nWe say that an undirected graph is connected  if, for every pair of nodes\nu and v, there is a path from u to v. Choosing how to define connectivity of\na directed graph is a bit more subtle, since it's possible for u to have a path\nto v while v has no path to u. We say that a directed graph is strongly\nconnected  if, for every two nodes u and v, there is a path from u to v and a\npath from v to u.\nFigur e 3.1  Two drawings of the same tree. On the right, the tree is rooted at\nnode 1."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 107})","('type', 'Document')"
"('page_content', ""In additi on to simply knowing about the existence of a path between\nsome pair of nodes u and v, we may also want to know whether there is a\nshort  path. Thus we define the distance  between two nodes u and v to be the\nminimum numb er of edges in a u-v path. (We can designate some symbol\nlike ∞ to denote the distance between nodes that are not connected by a\npath.) The term distance  here comes from imagining G as representing  a\ncommunication or transportation network; if we want to get from  u to v, we\nmay well want a route with as few “hops” as possible.\nTrees We say that an undirected graph is a tree if it is connected and does\nnot contain a cycle. For example, the two graphs pictured in Figure 3.1 are\ntrees. In a strong sense, trees are the simplest kind of conne cted graph:\ndeleting any edge from a tree will disconnect it.\nFor thinking about the structure of a tree T, it is useful to root it at a\nparticular node r. Physically , this is the operation of grabbing T at the node\nr and letting the rest of it hang downward under the force of gravity, like a\nmobile. More precisely , we “orient” each edge of T away from r; for each\nother node v, we declare the parent of v to be the node u that directly\nprecedes v on its path from  r; we declare w to be a child  of v if v is the\nparent of w. More generally , we say that w is a descendant  of v (or v is an\nancestor  of w) if v lies on the path from the root to w; and we say that a\nnode x is a leaf if it has no descendants. Thus, for example, the two pictures\nin Figure 3.1 corresp ond to the same tree T—the same pairs of nodes are\njoined by edges—but the drawing on the right represents the result of\nrooting T at node 1.\nRooted trees are fundamental objects in computer science, because\nthey encode the notion of a hierar chy. For example, we can imagine the\nrooted tree in Figure 3.1 as corresponding to the organizational structure of\na tiny nine-pers on company; employees 3 and 4 report to employee 2;\nemployees 2, 5, and 7 report to employee 1; and so on. Many Web sites are\norganized accor ding to a tree-like structure, to facilitate navigation. A\ntypical computer science depart ment's Web site will have an entry page as\nthe root; the People  page is a child  of this entry page (as is the Courses\npage); pages entitled Faculty  and Students  are children of the People  page;\nindividual professors' home pages are children of the Faculty  page; and so\non.\nFor our purposes here, rooting  a tree T can make certain questions\nabout T conceptually easy to answer . For example, given a tree T on n"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 108})","('type', 'Document')"
"('page_content', ""nodes, how many edges does it have? Each node other than the root has a\nsingle edge leading “upward” to its parent; and conversely , each edge leads\nupward from precisely one non-root node. Thus we have very easily proved\nthe following fact.\n(3.1)  Every n-node tr ee has exactly n  - 1 edges.\nIn fact, the follo wing stronger statement is true, although we do not\nprove it here.\n(3.2)  Let G be an undir ected graph on n nodes. Any two of the following statements implies the thir d.\n(i) G is connected.\n(ii) G does not contain a cycle.\n(iii) G has n  - 1 edges.\nWe now turn to the role of trees in the fundamental algorithmic idea of\ngraph traversal .\n3.2 Graph Connectivity and Graph Traversal\nHaving built up some fundame ntal notions regarding graphs, we turn to a\nvery basic algorithmic question: node-to-node connectivity . Suppose we are\ngiven a graph G = (V, E) and two particu lar nodes s and t. We'd like to find\nan efficient algorithm that answ ers the question: Is there a path from s to t\nin G? We will call this the problem of determining s-t connectivity .\nFor very small graphs, this question can often be answered easily by\nvisual inspection. But for large graphs, it can take some work to search for a\npath. Indeed, the s-t Connectivity Problem could also be called the Maze-\nSolving  Problem. If we imagine G as a maze with a room corresponding to\neach node, and a hallway corresponding to each edge that joins nodes\n(rooms) together , then the problem is to start in a room s and find your way\nto another designated room t. How efficient an algorithm can we design for\nthis task?\nFigur e 3.2 In this graph, node 1 has paths  to nodes 2 through 8, but not to\nnodes 9 through 13."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 109})","('type', 'Document')"
"('page_content', 'In this section, we describe two natural algorithms for this problem at a\nhigh level: breadth-first search (BFS) and depth-first search (DFS). In the\nnext section we discuss how to implement each of these efficiently , building\non a data structure for representing a graph as the input to an algorithm.\nBreadth-First Search\nPerhaps the simplest algorithm for determining s-t connectivity is breadth-\nfirst search (BFS), in which we explore outward from s in all possible\ndirections, addin g nodes one “layer” at a time. Thus we start with s and\ninclude all nodes that are joined by an edge to s—this is the first layer of the\nsearch. We then include all additional nodes that are joined by an edge to\nany node  in the first layer—this is the second layer . We continue in this way\nuntil no new nodes are encountered.\nIn the example of Figure 3.2 , starting with node 1 as s, the first layer of\nthe search would consist of nodes 2 and 3, the second layer would consist of\nnodes 4, 5, 7, and 8, and the third layer would consist just of node 6. At this\npoint the search would stop, since there are no further nodes that could be\nadded (and in particular , note that nodes 9 through 13 are never reached by\nthe search).\nAs this example reinforces, there is a natural physical interpreta tion to\nthe algorithm. Essentially , we start at s and “flood” the graph with an\nexpanding wave  that grows to visit all nodes that it can reach. The layer\ncontaining a node represents the point in time at which the node is reached.\nWe can define the layers L1, L2, L3, … constructed by the BFS\nalgorithm more precisely as follows.\nLayer L1 consists of all nodes that are neighbors of s. (For notational\nreasons, we will sometimes use layer L0 to deno te the set consisting')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 110})","('type', 'Document')"
"('page_content', ""just of s.)\nAssuming that we have defined layers L1, …, Lj, then layer Lj+1\nconsists of all nodes that do not belong to an earlier layer and that have\nan edge to a node in layer Lj.\nRecalling our definition of the distance between two nodes as the minimum\nnumber of edges on a path joinin g them, we see that layer L1 is the set of all\nnodes at distance 1 from s, and more gene rally layer Lj is the set of all\nnodes at distance exactly j from s. A node  fails to appear in any of the\nlayers if and only if there is no path to it. Thus, BFS is not only determining\nthe nodes that s can reach, it is also computing shortest paths to them. We\nsum this up in the following fact.\n(3.3)  For each j ≥ 1, layer  Lj produced by BFS consists of all nodes at distance exactly j from s.\nThere is a path fr om s to t if and only if t appears in some layer .\nA further property of breadth-first search is that it produces, in a very\nnatural way, a tree T rooted at s on the set of nodes reachable from s.\nSpecifically , for each such node v (other than s), consider the moment when\nv is first “discovered” by the BFS algorithm; this happens when some node\nu in layer Lj is being examined, and we find that it has an edge to the\npreviously unseen node v. At this moment, we add the edge (u, v) to the tree\nT—u becomes the parent of v, represe nting the fact that u is “responsible”\nfor completing the path to v. We call the tree T that is produced in this way a\nbreadth-first sear ch tree.\nFigure 3.3 depicts the construction of a BFS tree rooted at node 1 for\nthe graph in Figure 3.2 . The solid edges are the edges of T; the dotted edge s\nare edges of G that do not belong to T. The execution of BFS that produces\nthis tree can be described as follows.\n(a) Starting from node 1, layer L1 consists of the nodes {2, 3}.\n(b) Layer L2 is then grown by considering the nodes in layer L1 in order\n(say, first 2, then 3). Thus we discover nodes 4 and 5 as soon as we look\nat 2, so 2 becomes their parent. When we consider node 2, we also\ndiscover an edge to 3, but this isn't added to the BFS tree, since we\nalready know about node 3.  \nWe first discover nodes 7 and 8 when we look at node 3. On the other\nhand, the edge from 3 to 5 is another edge of G that does not end up in"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 111})","('type', 'Document')"
"('page_content', ""the BFS tree, because by the time we look at this edge out of node 3, we\nalready know about node 5.\nFigur e 3.3  The construction of a breadth-first search tree T for the graph in\nFigure 3.2, with (a), (b), and (c) depictin g the successive layers that are\nadded. The solid edges are the edges of T; the dotted edges are in the\nconnected component of G containing node 1, but do not belong to T.\n(c) We then consider the nodes in layer L2 in order , but the only new node\ndiscovered when  we look through L2 is node 6, which is added to layer\nL3. Note that the edges (4, 5) and (7, 8) don't get added to the BFS tree,\nbecause they don't result in the discovery of new nodes.\n(d) No new nodes are discovered when node 6 is examined, so nothing is\nput in layer L4, and the algor ithm terminates . The full BFS tree is\ndepicted in Figure 3.3(c) .\nWe notice that as we ran BFS on this graph, the nontree edges all\neither connected  nodes in the same layer , or connected nodes  in adjacent\nlayers. W e now prove that this is a property of BFS trees in general.\n(3.4)  Let T be a breadth-first search tree, let x and y be nodes in T belonging to layers  Li and Lj\nrespectively , and let (x, y) be an edge of G. Then i and j differ by at most  1.\nProof. Suppose by way of contradiction that i and j differed by more than 1; in particular , suppose i <\nj - 1. Now consider the point in the BFS algorithm when the edges incident to x were being\nexamined. Since x belongs to layer Li, the only nodes disco vered from x belong to layers Li+1 and\nearlier; hence, if y is a neighbor of x, then it should have been discovered by this point at the latest\nand hence should belong to layer Li+1 or earlier . ▪\nFigur e 3.4 When growing the connected component containing s, we look\nfor nodes like v that have not yet been visited."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 112})","('type', 'Document')"
"('page_content', ""Exploring a Connected Component\nThe set of nodes discovered by the BFS algorithm is precisely those\nreachable from the starting node s. We will refer to this set R as the\nconnected component  of G containing s; and once we know the connected\ncomponent containing s, we can simply check whether t belongs  to it so as\nto answer the question of s-t connectivity .\nNow , if one thinks about it, it's clear that BFS is just one possib le way\nto produce this component. At a more general level, we can build the\ncomponent R by “exploring” G in any order , starting from s. To start of f, we\ndefine R = {s}. Then at any point in time, if we find an edge (u, v) where u\n∊ R and v ∉ R, we can add v to R. Indeed, if there is a path P from s to u,\nthen there is a path from s to v obtained by first following P and then\nfollowing the edge (u,v). Figure 3.4  illustrates this basic step in growing the\ncomponent R.\nSuppose we continue growing the set R until there are no more edges\nleading out of R; in other words, we run the following algorithm.\nR will consist of nodes to which s has a path\nInitially R = {s}\nWhile there is an edge ( u,v) where u ∊ R and v ∉ R\nAdd v to R\nEndwhile\nHere is the key property of this algorithm.\n(3.5)  The set R produced at the end of the algorithm is precisely the connected component of G\ncontaining s.\nProof. We have already ar gued that for any node v ∊ R, there is a path from s to v."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 113})","('type', 'Document')"
"('page_content', ""Now , consider a node w ∉ R, and suppose by way of contradiction, that there is an s-w path P in\nG. Since s ∊ R but w ∉ R, there must be a first node v on P that does not belong to R; and this node v\nis not equal to s. Thus there is a node u immediately preceding v on P, so ( u, v) is an edge. Moreover ,\nsince v is the first node on P that does not belong to R, we must have u ∊ R. It follows that ( u, v) is an\nedge where u ∊ R and v ∉ R; this contradicts the stopping rule for the algorithm. ▪\nFor any node t in the component R, observ e that it is easy to recov er\nthe actual path from s to t along the lines of the argument above: we simply\nrecord, for each node v, the edge (u, v) that was considered in the iteration\nin which v was added to R. Then, by tracing these edges backward from t,\nwe proceed through a sequence of nodes that were added in earlier and\nearlier iterations, eventually reaching s; this defines an s-t path.\nTo conclude, we notice that the general algorithm we have defined to\ngrow R is underspecifi ed, so how do we decide which edge to consider\nnext? The BFS algorithm arises, in particular , as a particular way of\nordering the nodes we visit—in successive layers, based on their distance\nfrom s. But there are other natural ways to grow the component, several of\nwhich lead to efficient algorithms for the connectivity problem while\nproducing search patterns with different structures. We now go on to\ndiscuss a different one of these algorithms, depth-first search, and develop\nsome of its basic properties.\nDepth-First Search\nAnother natural method to find the nodes reachable from s is the approach\nyou might take if the graph G were truly a maze of interconnected rooms\nand you were walking around in it. You'd start from s and try the first edge\nleading out of it, to a node v. You'd then follow the first edge leading out of\nv, and continue in this way until you reached a “dead end”— a node for\nwhich you had already explored all its neighbors. You'd then backtrack until\nyou got to a node with an unexplored neighbor , and resume from  there. We\ncall this algorith m depth-first sear ch (DFS), since it explores G by going as\ndeeply as possible and only retreating when necessary .\nDFS is also a particular implementation of the generic component-\ngrowing algorith m that we intro duced earlier . It is most easily described in\nrecursive form: we can invoke DFS from any starting point but maintain\nglobal knowledge of which nodes have already been explored.\nDFS( u):"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 114})","('type', 'Document')"
"('page_content', 'Mark u as ""Explored"" and add u to R\nFor each edge ( u, v) incident to u\nIf v is not marked ""Explored"" then\nRecursively invoke DFS( v)\nEndif\nEndfor\nTo apply this to s-t connect ivity, we simply declare all nodes initially to be\nnot explored, and invoke DFS(s).\nThere are some fundamental similarities and some funda mental\ndifferences betw een DFS and BFS. The similarities are based on the fact\nthat they both build the connected component containing s, and we will see\nin the next section that they achieve qualitatively similar levels of\nefficiency .\nWhile DFS ultimately visits exactly the same set of nodes as BFS, it\ntypically does so in a very different order; it probes its way down long\npaths, potentially getting very far from s, before backing up to try nearer\nunexplored node s. We can see a reflection of this difference in the fact that,\nlike BFS, the DFS algorithm yields a natural rooted tree T on the\ncomponent containing s, but the tree will generally have a very different\nstructure. W e make s the root of the tree T, and make u the parent of v when\nu is respo nsible for the discovery  of v. That is, whenever DFS(v) is invoked\ndirectly during the call to DFS(u ), we add the edge (u, v) to T. The resulting\ntree is called a depth-first sear ch tree of the component R.\nFigure 3.5 depicts the construction of a DFS tree rooted at node 1 for\nthe graph in Figure 3.2 . The solid edges are the edges of T; the dotted edge s\nare edge s of G that do not belong to T. The execution  of DFS begins  by\nbuilding a path on nodes 1, 2, 3, 5, 4. The execution reaches a dead end at 4,\nsince there are no new nodes to find, and so it “backs up” to 5, finds node 6,\nbacks up again to 3, and finds nodes 7 and 8. At this point there  are no new\nnodes to find in the connected component, so all the pending recursive DFS\ncalls terminate, one by one, and the execution comes to an end. The full\nDFS tree is depicted in Figure 3.5(g) .\nThis example suggests the characteristic way in which DFS trees look\ndifferent from BFS trees. Rather than having root-to-leaf paths that are as\nshort as possible, they tend to be quite narrow and deep. However , as in the\ncase of BFS, we can say some thing quite strong about the way in which\nnontree edges of G must be arrange d relative to the edges of a DFS tree T:')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 115})","('type', 'Document')"
"('page_content', 'as in the figure, nontree edges can only connect ancestors of T to\ndescendants.\nFigur e 3.5 The construction of a depth-first search tree T for the graph in\nFigure 3.2, with (a) through (g) depicting the nodes as they are discovere d\nin seque nce. The solid edges are the edges of T; the dotted edges are edges\nof G that do not belong to T.\nTo establish this, we first observe the following property of the DFS\nalgorithm and the tree that it produces.\n(3.6)  For a given recursi ve call DFS(u), all nodes that are marked “Explor ed” between the\ninvocation and end of this r ecursive call ar e descendants of u in T .\nUsing (3.6), we prove\n(3.7)  Let T be a depth-first search tree, let x and y be nodes in T, and let (x, y) be an edge of G that is\nnot an edge of T . Then one of x or y is an ancestor of the other .\nProof. Suppose that (x, y) is an edge of G that is not an edge of T, and supp ose withou t loss of\ngenerality that x is reached  first by the DFS algorithm. When the edge (x, y) is examined during the')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 116})","('type', 'Document')"
"('page_content', 'execution of DFS(x), it is not added to T because y is marked  “Explored .” Since y was not marked\n“Explored” when DFS(x ) was first invoked, it is a node that was discovered between the invocation\nand end of the recursive call DFS(x). It follows from (3.6) that y is a descendant of x. ▪\nThe Set of All Connected Components\nSo far we have been talking about the connected component containing a\nparticular node s. But there is a connected component associated with each\nnode in the graph. What is the relationship between these components?\nIn fact, this relationship is highly structured and is expressed  in the\nfollowing claim.\n(3.8)  For any two nodes s and t in a graph, their connected components are either identical or\ndisjoint.\nThis is a statement that is very clear intuitively , if one looks at a graph like the example in\nFigure 3.2 . The graph is divided into multiple pieces with no edges between them; the largest piece is\nthe connected component of nodes 1 through 8, the medium piece is the connecte d component of\nnodes 11, 12, and 13, and the smallest piece is the connected component of nodes 9 and 10. To prove\nthe statement in gene ral, we just need to show how to define these “pieces” precisely  for an arbitrary\ngraph.\nProof. Consider any two nodes s and t in a graph G with the property that there is a path between s\nand t. We claim that the connected components containing s and t are the same set. Indeed, for any\nnode v in the component of s, the node v must also be reachable from t by a path: we can just walk\nfrom t to s, and then on from s to v. The same  reasoning  works with the roles of s and t reversed, and\nso a node is in the component of one if and only if it is in the component of the other .\nOn the other hand, if there is no path between s and t, then there cannot be a node v that is in the\nconnected component of each. For if there were such a node v, then we could walk from s to v and\nthen on to t, constructing a path between s and t. Thus, if there is no path between s and t, then their\nconnected components are disjoint. ▪\nThis proof suggests a natural algorithm for producing all the connected\ncomponents of a graph, by grow ing them one component at a time. We start\nwith an arbitrary node s, and we use BFS (or DFS) to generate its connected\ncomponent. We then find a node v (if any) that was not visited by the search\nfrom s, and iterate, using BFS starting  from v, to generate its connected\ncomponent—which, by (3.8), will be disjoint from the component of s. We\ncontinue in this way until all nodes have been visited.\n3.3 Implementing Graph Traversal Using Queues\nand Stacks')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 117})","('type', 'Document')"
"('page_content', 'So far we have been discussing basic algorithmic primitives for working\nwith graphs without mentioning any implementation details. Here we\ndiscuss how to use lists and arrays to represent graphs, and we discuss the\ntrade-of fs between the different representations. Then we use these data\nstructures to implement the graph traversal algorithms breadth-first search\n(BFS) and depth-first search (DFS) efficiently . We will see that BFS and\nDFS differ essentially only in that one uses a queue  and the other uses a\nstack,  two simple data structures that we will describe later in this section.\nRepresenting Graphs\nThere are two basic ways to represent graphs: by an adjacency matrix  and\nby an adjacency list representation. Throughout the book we will use the\nadjacency list representation. We start, however , by reviewing both of these\nrepresentations and discussing the trade-of fs between them.\nA graph G = (V, E) has two natural input parameters, the number of\nnodes |V|, and the numbe r of edges |E|. We will use n = |V| and m = |E| to\ndenote these, respectively . Running times will be given in terms of both of\nthese two parameters. As usual,  we will aim for polynomial running times,\nand lower-degree polynomials are better . However , with two parameters in\nthe running time, the comparison is not always so clear . Is O(m2) or O(n3) a\nbetter running time? This depen ds on what the relation is between n and m.\nWith at most one edge between any pair of nodes, the number of edges m\ncan be at most \n  ≤ n2. On the other hand, in many applications the graphs\nof interest are connected, and by (3.1), connected graphs must have at least\nm ≥ n - 1 edges. But these compariso ns do not always tell us which of two\nrunning times (such as m2 and n3) are better , so we will tend to keep the\nrunning times in terms of both of these parameters. In this section we aim to\nimplement the basic graph search algorithms in time O(m + n). We will\nrefer to this as linear time,  since it takes O(m + n) time simply to read the\ninput. Note that when we work  with connected graphs, a running time of\nO(m + n) is the same as O(m), since m ≥ n - 1.\nConsider a graph G = (V, E) with n nodes, and assume the set of nodes\nis V = {1, …, n}. The simplest way to represen t a graph is by an adjacency\nmatrix,  which is an n × n matrix A where A[u, v] is equa l to 1 if the graph\ncontains the edge (u, v) and 0 otherwi se. If the graph is undirected, the\nmatrix A is symmetric, with A[u, v] = A[v, u] for all nodes u, v ∊ V. The')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 118})","('type', 'Document')"
"('page_content', ""adjacency matrix representation allows us to check in O(1) time if a given\nedge (u, v) is present in the graph. However , the representation has two\nbasic disadvantages.\nThe representation takes Θ(n2) space. When the graph has many fewer\nedges than n2, more compact representations are possible.\nMany graph algorithms need to examine all edges incident to a given\nnode v. In the adjacency matrix representation, doing this involves\nconsidering all other nodes w, and checking the matrix entry A[v, w] to\nsee whether the edge (v, w) is present—and this takes Θ(n) time. In the\nworst case, v may have Θ( n) incident edges, in which case checking all\nthese edges will take Θ(n) time regardles s of the represe ntation. But\nmany graphs in practice have significantly fewer edges incident to\nmost nodes, and so it would be good to be able to find all these\nincident edges more ef ficiently .\nThe representation of graphs  used throughout the book is the\nadjacency list, which works better for sparse graphs—that is, those with\nmany fewer than n2 edges. In the adjacency list representation there is a\nrecord for each node v, contain ing a list of the nodes to which v has edges.\nTo be precise, we have an array Adj, where Adj[v] is a record containing a\nlist of all nodes adjacent to node v. For an undirected graph G = (V, E), each\nedge e = (v, w) ∊ E occurs on two adjacency lists: node w appears on the list\nfor node v, and node v appears on the list for node w.\nLet's compare the adjacency matrix and adjacency list representations.\nFirst consider the space required  by the representation. An adjac ency matrix\nrequires O(n2) space, since it uses an n × n matrix. In contrast, we claim\nthat the adjacenc y list representation requires only O(m + n) space. Here is\nwhy. First, we need an array of pointers of length n to set up the lists in Adj,\nand then we need space for all the lists. Now , the lengths of these lists may\ndiffer from node to node, but we argued in the previous paragraph that\noverall, each edge e = (v,w) appears in exactly two of the lists: the one for v\nand the one for w. Thus the total length of all lists is 2 m = O(m).\nAnother (essentially equivalent) way to justify this bound is as follows.\nWe defin e the degree nv of a node v to be the number of incident edges it\nhas. The length of the list at Adj[v] is list is nv, so the total length over all"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 119})","('type', 'Document')"
"('page_content', ""nodes is O(Σv ∊V nv). Now, the sum of the degrees in a graph is a quantity\nthat often comes up in the analysis of graph algorithms, so it is useful to\nwork out what this sum is.\n(3.9)  Σv ∊V nv = 2m.\nProof. Each  edge  e = (v,w) contributes exactly twice to this sum: once in the quantity nv and once in\nthe quantity nw. Since the sum is the total of the contributions of each edge, it is 2 m. ▪\nWe sum up the comparison betw een adjacency matrices and adjacency\nlists as follows.\n(3.10)  The adjacency matrix representation of a graph requir es O(n2) space, while the adjacency list\nrepresentation r equir es only O (m + n) space.\nSince we have already argued that m ≤ n2, the bound O(m + n) is never\nworse than O(n2); and it is much better when the underlying graph is\nsparse,  with m much smaller than n2.\nNow we consider the ease of accessing the information stored in these\ntwo different representations. Recall that in an adjacency matrix we can\ncheck in O(1) time if a particular edge (u, v) is present in the graph. In the\nadjacency list representation, this can take time proportional to the degree\nO(nv): we have to follow the pointers on u's adjacency list to see if edge v\noccurs on the list. On the other hand, if the algorithm is currentl y looking at\na node u, it can read the list of neighbors in constant time per neighbor .\nIn view of this, the adjacency list is a natural representation for\nexploring graphs. If the algorithm is currently looking at a node u, it can\nread this list of neighbors in constant time per neighbor; move to a neighbor\nv once it encounters it on this list in constant time; and then be ready to read\nthe list associated with node v. The list representation thus corresponds to a\nphysical notion of “exploring” the graph, in which you learn the neighbors\nof a node u once you arrive  at u, and can read them off in const ant time per\nneighbor .\nQueues and Stacks\nMany algorithm s have an inner step in which they need to process a set of\nelements, such the set of all edges adjacent to a node in a graph, the set of\nvisited nodes in BFS and DFS, or the set of all free men in the Stable"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 120})","('type', 'Document')"
"('page_content', 'Matching algori thm. For this purpose, it is natural to maintai n the set of\nelements to be considered in a linked list, as we have done for maintaining\nthe set of free men in the Stable Matching algorithm.\nOne important issue that arises is the order in which to consi der the\nelements in such a list. In the Stable Matching algorithm, the order in which\nwe considered the free men did not affect the outcome, although this\nrequired a fairly subtle proof to verify . In many other algorithms, such as\nDFS and BFS, the order in which elements are considered is crucial.\nTwo of the simplest and most natural options are to maintain a set of\nelements as either a queue or a stack. A queue  is a set from which we\nextract elements in first-in, first-out  (FIFO) order: we select elements in the\nsame order in which they were added. A stack  is a set from which we\nextract elements in last-in, first-out  (LIFO) order: each time we select an\nelement, we choose the one that was added most recently . Both queues and\nstacks can be easily implemented via a doubly linked list. In both cases, we\nalways select the first element on our list; the difference is in where we\ninsert a new element. In a queue a new element is added to the end of the\nlist as the last element, while in a stack a new element is placed in the first\nposition on the list. Recall that a doubly linked list has explicit First and\nLast pointers to the beginning and end, respectively , so each of these\ninsertions can be done in constant time.\nNext we will discuss how to implement the search algorithms  of the\nprevious section  in linear time. We will see that BFS can be thought of as\nusing a queue to select which node to consider next, while DFS is\neffectively using a stack.\nImplementing Breadth-First Search\nThe adjacency list data structure is ideal for implementing breadth-first\nsearch. The algorithm examines the edges leaving a given node one by one.\nWhen we are scanning the edges leaving u and come to an edge (u, v), we\nneed to know whether or not node v has been previously discovered by the\nsearch. To make  this simple, we maintain an array Discovered of length n\nand set Discovered[ v] = true as soon as our search first sees v. The\nalgorithm, as described in the previous section, constructs layers of nodes\nL1, L2, …, where Li is the set of nodes at distance i from the source s. To\nmaintain the nodes in a layer Li, we have a list L[i] for each i = 0, 1, 2, ….')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 121})","('type', 'Document')"
"('page_content', ""BFS(s):\nSet Discovered[ s] = true and Discovered[ v] = false for all other v\nInitialize L[0] to consist of the single element s\nSet the layer counter i = 0\nSet the current BFS tree T = Ø\nWhile L[i] is not empty\nInitialize an empty list L[i + 1]\nFor each node u ∊ L[i]\nConsider each edge ( u,v) incident to u\nIf Discovered[ v] = false then\nSet Discovered[ v] = true\nAdd edge ( u, v) to the tree T\nAdd v to the list L[i + 1]\nEndif\nEndfor\nIncrement the layer counter i by one\nEndwhile\nIn this implementation it does not matter whether we manage each list\nL[i] as a queue or a stack, since the algorithm is allowed to consider the\nnodes in a layer Li in any order .\n(3.11) The above implement ation of the BFS algorithm runs in time O(m + n ) (i.e., linear in the input\nsize), if the graph is given by the adjacency list r epresentation.\nProof. As a first step, it is easy to bound the running time of the algorithm by O(n2) (a weaker bound\nthan our claimed O(m + n)). To see this, note that there are at most n lists L[i] that we need to set up,\nso this takes O(n) time. Now  we need to consider the nodes u on these lists. Each node occurs on at\nmost one list, so the For loop runs at most n times over all iterations of the While loop. When we\nconsider a node u, we need to look through all edges (u, v) incid ent to u. Ther e can be at most n such\nedges, and we spend O(1) time considering each edge. So the total time spent on one iteration of the\nFor loop is at most O(n). We've thus conclud ed that there are at most n iterations of the For loop, and\nthat each iteration takes at most O(n) time, so the total time is at most O(n2).\nTo get the improved O(m + n) time bound, we need to observe that the For loop processing a\nnode u can take less than O(n) time if u has only a few neigh bors. As before, let nu denote the degree\nof node u, the number of edges incident to u. Now, the time spent  in the For loop considering edges\nincident to node u is O(nu), so the total over all nodes is O(Σu ∊V nu). Recall from (3.9) that Σu ∊V\nnu = 2m, and so the total time spent considering edges over the whole algorithm is O(m). We need\nO(n) additiona l time to set up lists and manage the array Discovered. So the total time spent is O(m +\nn) as claimed. ▪\nWe described the algorithm using up to n separate  lists L[i] for each\nlayer Li. Instead of all these distinct lists, we can implement the algori thm\nusing a single list L that we maintai n as a queue. In this way, the algorithm\nprocesses nodes  in the order they are first discovered: each time a node is"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 122})","('type', 'Document')"
"('page_content', ""discovered, it is added to the end of the queue, and the algorithm always\nprocesses the edges out of the node that is currently first in the queue.\nIf we maintain the discovered nodes in this order , then all nodes in\nlayer Li will appear in the queue ahead of all nodes in layer Li+1, for i = 0, 1,\n2 …. Thus, all nodes in layer Li will be consid ered in a contiguous\nsequence, follow ed by all nodes in layer Li+1, and so forth. Hence this\nimplementation in terms of a single queue will produce the same result as\nthe BFS implementation above.\nImplementing Depth-First Search\nWe now consider the depth-firs t search algorithm. In the previous section\nwe presented DFS as a recursive procedure, which is a natural way to\nspecify it. Howe ver, it can also be viewed as almost identical to BFS, with\nthe difference that it maintains the nodes to be processed in a stack, rather\nthan in a queue. Essentially , the recursive structure of DFS can be viewed as\npushing nodes onto a stack for later processing, while moving  on to more\nfreshly discove red nodes. We now show how to implement DFS by\nmaintaining this stack of nodes to be processed explicitly .\nIn both BFS and DFS, there is a distinction between the act of\ndiscovering  a node v—the first time it is seen, when  the algorithm finds an\nedge leading to v—and the act of exploring  a node v, when all the incident\nedges to v are scanned, resulting in the potential discovery of further nodes.\nThe difference between BFS and DFS lies in the way in which discovery\nand exploration are interleaved.\nIn BFS, once we started to explore a node u in layer Li, we added all its\nnewly discovere d neighbors to the next layer Li+1, and we deferred actually\nexploring these neighbors until we got to the processing of layer Li+1. In\ncontrast, DFS is more impulsiv e: when it explores a node u, it scans the\nneighbors of u until it finds the first not-yet-explored node v (if any), and\nthen it immediately shifts attention to exploring v.\nTo implement the exploration strategy of DFS, we first add all of the\nnodes adjacent to u to our list of nodes to be considered, but after doing this\nwe proceed to explore a new neighbor v of u. As we explore v, in turn, we\nadd the neighbors of v to the list we're  maintaining, but we do so in stack\norder , so that these neighbors will be explored before we return to explore"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 123})","('type', 'Document')"
"('page_content', ""the other neighbors of u. We only come  back to other nodes adjacent to u\nwhen there are no other nodes left.\nIn addit ion, we use an array Explored analogous to the Discovered\narray we used for BFS. The difference is that we only set Explored[ v] to be\ntrue when we scan v's incident edges (when the DFS search is at v), while\nBFS sets Discovered[ v] to true as soon as v is first discovered. The\nimplementation in full looks as follows.\nDFS(s):\nInitialize S to be a stack with one element s\nWhile S is not empty\nTake a node u from S\nIf Explored[ u] = false then\nSet Explored[ u] = true\nFor each edge ( u, v) incident to u\nAdd v to the stack S\nEndfor\nEndif\nEndwhile\nThere is one final wrinkle to mention. Depth-first search is\nunderspecified, since the adjace ncy list of a node being explored can be\nprocessed in any order . Note that the above algorithm, because it pushes all\nadjacent nodes onto the stack before considering any of them, in fact\nprocesses each adjacency list in the reverse order relative to the recursive\nversion of DFS in the previous section.\n(3.12)  The above algorithm implements DFS, in the sense that it visits the nodes in exactly the same\norder as the recursiv e DFS procedur e in the previous section (except that each adjacency list is\nprocessed in r everse or der).\nIf we want the algorithm to also find the DFS tree, we need to have\neach node u on the stack S maintain the node that “caused” u to get added to\nthe stack. This can be easily done by using an array parent and setting\nparent[ v]= u when we add node v to the stack due to edge (u, v). When we\nmark a node u ≠ s as Explored, we also can add the edge (u, parent[ u]) to\nthe tree T. Note that a node v may be in the stack S multiple times, as it can\nbe adjac ent to multiple nodes u that we explore , and each such node adds a\ncopy of v to the stack S. However , we will only use one of these copies to\nexplore node v, the copy that we add last. As a result, it suffices to maintain"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 124})","('type', 'Document')"
"('page_content', 'one value parent[ v] for each node v by simply overwriting the value\nparent[ v] every time we add a new copy of v to the stack S.\nThe main step in the algorithm is to add and delete nodes to and from\nthe stack S, which takes O(1) time. Thus, to bound the running time, we\nneed to bound the number of these operations. To count the number of stack\noperations, it suf fices to count the number of nodes added to S, as each node\nneeds to be added once for every time it can be deleted from S.\nHow many elements ever get added to S? As before, let nv denote the\ndegree of node v. Node v will be added to the stack S every time one of its\nnv adjacen t nodes is explored, so the total number of nodes added to S is at\nmost Σunv = 2m. This proves the desired O(m + n) bound on the running\ntime of DFS.\n(3.13)  The above implementation of the DFS algorithm runs in time O(m + n) (i.e., linear in the input\nsize), if the graph is given by the adjacency list r epresentation.\nFinding the Set of All Connected Components\nIn the previous section we talked about how one can use BFS (or DFS) to\nfind all connected components of a graph. We start with an arbitrary node s,\nand we use BFS (or DFS) to generate its connected compone nt. We then\nfind a node v (if any) that was not visited by the search from s and iterate,\nusing BFS (or DFS) starting from v to generate its connected component—\nwhich, by (3.8), will be disjoint from the component of s. We continue in\nthis way until all nodes have been visited.\nAlthough we earlier expressed the running time of BFS and DFS as\nO(m + n), where m and n are the total number of edges and nodes in the\ngraph, both BFS and DFS in fact spend work only on edges and nodes in\nthe conn ected component contai ning the starting node. (They never see any\nof the other nodes or edges.) Thus the above algorithm, although it may run\nBFS or DFS a number of times, only spends a constant amount of work on\na given edge or node in the iteration when the connected component it\nbelongs to is under consideration. Hence the overall running time of this\nalgorithm is still O(m + n).')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 125})","('type', 'Document')"
"('page_content', ""3.4 Testing Bipartiteness: An Application of\nBreadth-First Search\nRecall the definition of a bipartite graph: it is one where the node set V can\nbe partitioned into sets X and Y in such a way that every edge has one end in\nX and the other end in Y. To make the discussion a little smoother , we can\nimagine that the nodes in the set X are colored red, and the nodes in the set\nY are colored blue. With this imagery , we can say a graph is bipartite if it is\npossible to color its nodes red and blue so that every edge has one red end\nand one blue end.\nThe Problem\nIn the earlier chapters, we saw examples of bipartite graphs. Here we start\nby asking: What are some natural examples of a nonbipartite graph, one\nwhere no such partition of V is possible?\nClearly a triangle is not bipartite, since we can color one node red,\nanother one blue, and then we can't do anything with the third node. More\ngenerally , consider a cycle C of odd length, with nodes numbered 1, 2, 3,\n…, 2 k, 2k + 1. If we color node 1 red, then we must color node 2 blue, and\nthen we must color node 3 red, and so on—coloring odd-numbered nodes\nred and even-nu mbered nodes blue. But then we must color node 2k + 1\nred, and it has an edge to node 1, which is also red. This demonstrates that\nthere's no way to partition C into red and blue nodes as required. More\ngenerally , if a graph G simply contains  an odd cycle, then we can apply the\nsame ar gument; thus we have established the following.\n(3.14)  If a graph G is bipartite, then it cannot contain an odd cycle.\nIt is easy to recognize that a graph is bipartite when appropriate  sets X\nand Y (i.e., red and blue nodes) have actually been identified for us; and in\nmany settings where bipartite graphs arise, this is natural. But suppose we\nencounter a graph G with no annota tion provided for us, and we'd like to\ndetermine for ourselves whether  it is bipartite—that is, whether there exists\na partition into red and blue nodes, as required. How difficult is this? We\nsee from  (3.14) that an odd cycle  is one simple “obstacle” to a graph's being\nbipartite. Are there other , more complex obstacles to bipartitness?"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 126})","('type', 'Document')"
"('page_content', ""Designing the Algorithm\nIn fact, there is a very simple procedure to test for bipartiten ess, and its\nanalysis can be used to show that odd cycles are the only obstacle. First we\nassume the graph G is conn ected, since otherwise we can first compute its\nconnected components and analyze each of them separately . Next we pick\nany node s ∊ V and color it red; there is no loss in doing this, since s must\nreceive some color . It follows that all the neighbors of s must be colored\nblue, so we do this. It then follows that all the neighbors of these  nodes\nmust be colored  red, their neighbors must be colored blue, and so on, until\nthe whole graph is colored. At this point, either we have a valid red/blue\ncoloring of G, in whic h every  edge has ends of opposite colors, or there is\nsome edge with ends of the same color . In this latter case, it seems clear that\nthere's nothing we could have done: G simply is not bipartite. We now want\nto argue this point precisely and also work out an efficient way to perform\nthe coloring.\nThe first thing to notice is that the coloring procedure we have just\ndescribed is essentially identic al to the description of BFS: we move\noutward from s, coloring nodes as soon as we first encounter them. Indeed,\nanother way to describe the coloring algorithm is as follows: we perform\nBFS, coloring s red, all of layer L1 blue, all of layer L2 red, and so on,\ncoloring odd-numbered layers blue and even-numbered layers red.\nWe can implement this on top of BFS, by simply taking the\nimplementation of BFS and adding an extra array Color over the nodes.\nWhenever we get to a step in BFS where we are adding a node v to a list L[i\n+ 1], we assign Color[ v]= red if i + 1 is an even number , and Color[ v]= blue\nif i + 1 is an odd number . At the end of this procedure, we simply scan all\nthe edge s and determine wheth er there is any edge for which both ends\nreceived the same color . Thus, the total running time for the coloring\nalgorithm is O(m + n), just as it is for BFS.\nFigur e 3.6 If two nodes x and y in the same layer are joined by an edge,\nthen the cycle through x, y, and their lowest common ancestor z has odd\nlength, demonstrating that the graph cannot be bipartite."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 127})","('type', 'Document')"
"('page_content', 'Analyzing the Algorithm\nWe now prove a claim that shows this algorithm correctly determines\nwhether G is bipar tite, and it also shows that we can find an odd cycle in G\nwhenever it is not bipartite.\n(3.15)  Let G be a connected graph, and let L1,L2,… be the layers produced by BFS starting at node\ns. Then exactly one of the following two things must hold.\n(i) There is no edge of G joining two nodes of the same layer . In this case G is a bipartite graph in\nwhich the nodes in even-number ed layers can be color ed red, and the nodes in odd-number ed\nlayers can be color ed blue.\n(ii) There is an edge of G joining two nodes of the same layer . In this case, G contain s an odd-length\ncycle, and so it cannot be bipartite.\nProof. First consider case (i), where we suppose that there is no edge joining two nodes of the same\nlayer . By (3.4), we know that every edge of G joins nodes either in the same layer or in adjacent\nlayers. Our assumption for case (i) is precisely that the first of these two alternatives never happens,\nso this means that every  edge joins  two nodes in adjacent layers. But our coloring procedure gives\nnodes in adjacent layers the opposite colors, and so every edge has ends with opposite colors. Thus\nthis coloring establishes that G is bipartite.\nNow suppo se we are in case (ii); why must G contain an odd cycle? We are told that G contains\nan edge joining two nodes of the same layer . Suppose this is the edge e = (x,y), with x,y ∊ Lj. Also,\nfor notational reasons, recall that L0 (“lay er 0”) is the set consisting of just s. Now consider the BFS\ntree T produced by our algorithm, and let z be the node whose layer number is as large as possible,\nsubject to the conditio n that z is an ancestor of both x and y in T; for obvious reasons, we can call z\nthe lowest common ancestor  of x and y. Suppose z ∊ Li, where i < j. We now have the situation\npictured in Figure 3.6 . We consid er the cycle C defined by following  the z-x path in T, then the edge\ne, and then the y-z path in T. The length of this cycle is (j - i) + 1 + (j - i), adding the length of its\nthree parts separately; this is equal to 2( j - i) + 1, which is an odd number . ▪')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 128})","('type', 'Document')"
"('page_content', ""3.5 Connectivity in Directed Graphs\nThus far, we have been looking at problems on undirected graphs; we now\nconsider the extent to which these ideas carry over to the case of directed\ngraphs.\nRecall that in a directed graph, the edge (u, v) has a direction : it goes\nfrom u to v. In this way , the relationship between u and v is asym metric, and\nthis has qualitati ve effects on the structure of the resulting graph . In Section\n3.1, for example, we discussed the World Wide Web as an insta nce of a\nlarge, complex directed graph whose nodes are pages and whos e edges are\nhyperlinks. The act of browsing  the Web is based on following a sequence\nof edges  in this directed graph; and the directionality is crucial, since it's not\ngenerally possible to browse “backwards” by following hyper links in the\nreverse direction.\nAt the same time, a number of basic definitions and algorithm s have\nnatural analogues in the directed case. This includes the adjacency list\nrepresentation and graph search algorithms such as BFS and DFS. We now\ndiscuss these in turn.\nRepresenting Directed Graphs\nIn order to repre sent a directed graph for purposes of designing  algorithms,\nwe use a version of the adjacency list representation that we employed for\nundirected graphs. Now , instead of each node having a single list of\nneighbors, each node has two lists associated with it: one list consists of\nnodes to which  it has edges, and a second list consists of nodes from which\nit has edges. Thus an algorithm  that is currently looking at a node u can\nread off the nodes reachable by going one step forward on a directed edge,\nas well as the nodes that would be reachable if one went one step in the\nreverse direction on an edge from u.\nThe Graph Search Algorithms\nBreadth-first search and depth-first search are almost the same in directed\ngraphs as they are in undirecte d graphs. We will focus here on BFS. We\nstart at a node s, define a first layer of nodes to consist of all those to which\ns has an edge, define a second layer to consist of all additiona l nodes to"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 129})","('type', 'Document')"
"('page_content', ""which these first-layer nodes have an edge, and so forth. In this way, we\ndiscover nodes layer by layer as they are reached in this outw ard search\nfrom s, and the nodes in layer j are precisely those for which the shortest\npath from s has exactly j edges. As in the undirected case, this algorithm\nperforms at most constant work for each node and edge, resulting in a\nrunning time of O(m + n).\nIt is important to understand what this directed version of BFS is\ncomputing. In directed graphs, it is possible for a node s to have  a path to a\nnode t even though t has no path to s; and what directed BFS is computing\nis the set of all nodes t with the proper ty that s has a path to t. Such nodes\nmay or may not have paths back to s.\nThere is a natur al analogue of depth-first search as well, which also\nruns in linear time and computes the same set of nodes. It is again a\nrecursive procedure that tries to explore as deeply as possible, in this case\nonly following edges according to their inherent direction. Thus , when DFS\nis at a node u, it recursively launches a depth-first search, in order , for each\nnode to which u has an edge.\nSuppose that, for a given node s, we wanted the set of nodes with paths\nto s, rather than the set of nodes to which s has paths. An easy way to do\nthis would be to define a new directed graph, Grev, that we obtain  from G\nsimply by reversing the direction of every edge. We could then run BFS or\nDFS in Grev; a node has a path from s in Grev if and only if it has a path to s\nin G.\nStrong Connectivity\nRecall that a directed graph is strongly connected  if, for every two nodes u\nand v, there is a path from u to v and a path from v to u. It's worth also\nformulating some terminology for the property at the heart of this\ndefinition; let's say that two nodes u and v in a directed graph are mutually\nreachable  if there is a path from u to v and also a path from v to u. (So a\ngraph is strongly connected if every pair of nodes is mutually reachable.)\nMutual reachability has a number of nice properties, many of them\nstemming from the following simple fact.\n(3.16)  If u and v are mutually reachable, and v and w are mutually reachable, then u and w are\nmutually r eachable."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 130})","('type', 'Document')"
"('page_content', 'Proof. To construct a path from u to w, we first go from u to v (along the path guaranteed by the\nmutual reachability of u and v), and then on from v to w (alon g the path guaranteed by the mutual\nreachability of v and w). To const ruct a path from w to u, we just reverse this reasoning: we first go\nfrom w to v (along the path guaranteed by the mutual reachability of v and w), and then on from v to\nu (along the path guaranteed by the mutual reachability of u and v).\nThere is a simple linear -time algorithm to test if a directed graph is\nstrongly connected, implicitly based on (3.16). We pick any node s and run\nBFS in G starting  from s. We then also run BFS starting from s in Grev.\nNow , if one of these two searches fails to reach every node, then clearly G\nis not strongly connected. But suppose we find that s has a path to every\nnode, and that every node has a path to s. Then s and v are mutually\nreachable for every v, and so it follows that every  two nodes u and v are\nmutually reachable: s and u are mutually reachable, and s and v are\nmutually reachable, so by (3.16) we also have that u and v are mutually\nreachable.\nBy analogy with connected components in an undirected graph, we can\ndefine the strong component  containing a node s in a directed graph to be\nthe set of all v such that s and v are mutually reachable. If one thinks about\nit, the algorithm  in the previou s paragraph is really computing the strong\ncomponent containing s: we run BFS starting from s both in G and in Grev;\nthe set of nodes reached by both searches is the set of nodes with paths to\nand from s, and hence this set is the strong component containing s.\nThere are further similarities between the notion of connected\ncomponents in undirected graphs and strong components in directed graphs.\nRecall that connected componen ts naturally partitioned the graph, since any\ntwo were either identical or disjoint. Strong components have this property\nas well, and for essentially the same reason, based on (3.16).\n(3.17)  For any two nodes s and t in a directed graph, their strong components are either identical or\ndisjoint.\nProof. Consider any two nodes s and t that are mutually reachable; we claim that the strong\ncomponents containing s and t are identical. Indeed, for any node v, if s and v are mutual ly reachab le,\nthen by (3.16), t and v are mutually reachable as well. Similarly , if t and v are mutua lly reachab le,\nthen again by (3.16), s and v are mutually reachable.\nOn the other hand, if s and t are not mutually reachable, then there cannot be a node v that is in\nthe strong componen t of each. For if there were such a node v, then s and v would be mutually\nreachable, and v and t woul d be mutually reachable, so from (3.16) it would follow that s and t were\nmutually reachable. ▪')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 131})","('type', 'Document')"
"('page_content', 'In fact, although we will not discuss the details of this here, with more\nwork it is possib le to compute the strong components for all nodes in a total\ntime of O(m + n).\n3.6 Directed Acyclic Graphs and Topological\nOrdering\nIf an undirected graph has no cycles, then it has an extrem ely simple\nstructure: each of its connected components is a tree. But it is possible for a\ndirected graph to have no (directed) cycles and still have a very rich\nstructure. For example, such graphs can have a large number of edges: if we\nstart with the node set {1, 2, …, n} and include an edge (i,j) whenever i < j,\nthen the resulting directed graph has \n  edges but no cycles.\nFigur e 3.7 (a) A directed acyclic graph . (b) The same DAG with a\ntopological ordering, specified by the labels on each node. (c) A different\ndrawing of the same DAG, arranged so as to emphasize the topological\nordering.\nIf a directed graph has no cycles, we call it—naturally enou gh—a\ndirected acyclic graph,  or a DAG  for short. (The  term DAG  is typically\npronounced as a word, not spelled out as an acronym.) In Figure 3.7(a)  we\nsee an example of a DAG, although it may take some checking to convince\noneself that it really has no directed cycles.\nThe Problem\nDAGs are a very common structure in computer science, because many\nkinds of dependency networks of the type we discussed in Section 3.1 are')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 132})","('type', 'Document')"
"('page_content', ""acyclic. Thus DAGs can be used to encode precedence relations  or\ndependencies  in a natural way. Suppose we have a set of tasks labeled\n{1,2,…, n] that need to be performed, and there are dependencies among\nthem stipulating, for certain pairs i and j, that i must be performed before j.\nFor example, the tasks may be courses, with prerequisite requirements\nstating that certa in courses must be taken before others. Or the tasks may\ncorrespond to a pipeline of computing jobs, with assertions that the output\nof job i is used in determining the input to job j, and hence job i must be\ndone before job j.\nWe can represent such an interdependent set of tasks by introducing a\nnode for each task, and a directed edge (i,j) whenever i must be done before\nj. If the precedenc e relation is to be at all meaningful, the resultin g graph G\nmust be a DAG. Indeed, if it contained a cycle C, there would be no way to\ndo any of the tasks in C: since each task in C cannot begin until some other\none completes, no task in C could ever be done, since none could be done\nfirst.\nLet's continue a little further with this picture of DAGs as precedence\nrelations. Given a set of tasks with dependencies, it would be natural to seek\na valid order in which the tasks could be performed, so that all\ndependencies are respected. Specifically , for a directed graph G, we say that\na topological ordering  of G is an ordering of its nodes as v1, v2, …, vn so\nthat for every edge (vi, vj), we have i < j. In other words, all edges point\n“forward” in the ordering. A topological ordering on tasks provides an\norder in which they can be safely performed; when we come to the task vj,\nall the tasks that are required to precede it have already been done. In\nFigure 3.7(b)  we've labeled the nodes of the DAG from part (a) with a\ntopological ordering; note that each edge indeed goes from a lower -indexed\nnode to a higher -indexed node.\nIn fact, we can view a topological ordering of G as providing an\nimmediate “proof” that G has no cycles, via the following.\n(3.18)  If G has a topological or dering, then G is a DAG.\nProof. Suppose, by way of contradiction, that G has a topological ordering v1, v2, …, vn, and also\nhas a cycle C. Let vi be the lowest-indexed node on C, and let vj be the node on C just before  vi—\nthus (vj, vi) is an edge. But by our choice of i, we have j > i, which contradicts the assumption that\nv1, v2, …, vn was a topological ordering. ▪"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 133})","('type', 'Document')"
"('page_content', 'The proof of acyclicity that a topological ordering provides can be\nvery useful, even visually . In Figure 3.7(c) , we have drawn  the same graph\nas in (a) and (b), but with the nodes laid out in the topological ordering. It is\nimmediately clear that the graph in (c) is a DAG since each edge goes from\nleft to right.\nComputing a Topological Ordering  The main question we consider here is\nthe converse of (3.18): Does every DAG have a topological ordering, and if\nso, how do we find one efficiently? A method to do this for every DAG\nwould be very useful: it would show that for any precedence relation on a\nset of tasks without cycles, there is an efficiently computable order in which\nto perform the tasks.\nDesigning and Analyzing the Algorithm\nIn fact, the converse of (3.18)  does hold, and we establish this via an\nefficient algorith m to compute a topological ordering. The key to this lies in\nfinding a way to get started: which node do we put at the begin ning of the\ntopological ordering? Such a node v1 would need to have no incoming\nedges, since any such incoming edge would violate the defining  property of\nthe topological ordering, that all edges point forward. Thus, we need to\nprove the following fact.\n(3.19)  In every DAG G, ther e is a node v with no incoming edges.\nProof. Let G be a directed graph in which every node has at least one incoming edge. We show how\nto find a cycle in G; this will prove the claim. We pick any node v, and begin following edges\nbackward from v: since v has at least one incoming edge (u, v), we can walk backw ard to u; then,\nsince u has at least one incoming edge (x, u), we can walk backward to x; and so on. We can continue\nthis process indefinitely , since every node we encounter has an incoming edge. But after n + 1 steps,\nwe will have visited some node w twice. If we let C denote the sequence of nodes encounter ed\nbetween successive visits to w, then clearly C forms a cycle. ▪\nIn fact, the existence of such a node v is all we need  to produce a\ntopological ordering of G by induction. Specifically , let us claim by\ninduction that every DAG has a topological ordering. This is clearly true for\nDAGs on one or two nodes. Now suppose it is true for DAGs with up to\nsome number of nodes n. Then, given a DAG G on n + 1 nodes, we find a\nnode v with no incoming edges, as guaranteed by (3.19). We place v first in\nthe topological ordering; this is safe, since all edges out of v will point\nforward. Now G-{v} is a DAG, since deleting v cannot create any cycles')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 134})","('type', 'Document')"
"('page_content', ""that weren't there previously . Also, G-{v} has n nodes, so we can apply the\ninduction hypothesis to obtain a topological ordering of G-{v}. We append\nthe nodes of G-{v} in this order after v; this is an order ing of G in whic h all\nedges point forward, and hence it is a topological ordering.\nThus we have proved the desired converse of (3.18).\n(3.20)  If G is a DAG, then G has a topological or dering.\nThe inductive proof contains the following algorithm to compute a\ntopological ordering of G.\nTo compute a topological ordering of G:\nFind a node v with no incoming edges and order it first\nDelete v from G\nRecursively compute a topological ordering of G-{v} and append this order after v\nIn Figure 3.8  we show  the sequence of node deletions that occurs when this\nalgorithm is applied to the graph in Figure 3.7. The shaded nodes in each\niteration are those with no incoming edges; the crucial point, which is what\n(3.19) guarantees, is that when we apply this algorithm to a DAG, there will\nalways be at least one such node available to delete.\nFigur e 3.8 Starting from the graph in Figure 3.7, nodes are deleted one by\none so as to be added to a topolo gical ordering. The shaded nodes are those\nwith no incomin g edges; note that there is always at least one such edge at\nevery stage of the algorithm's execution."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 135})","('type', 'Document')"
"('page_content', 'To bound the running time of this algorithm, we note that identi fying a\nnode v with no incomin g edges, and deleting it from G, can be done in O(n)\ntime. Since the algorithm runs for n iteratio ns, the total running time is\nO(n2).\nThis is not a bad running time; and if G is very dense, containing Θ( n2)\nedges, then it is linear in the size of the input. But we may well want\nsomething better when the number of edges m is much  less than n2. In such\na case, a running  time of O(m + n) could be a significant improvement over\nΘ(n2).\nIn fact, we can achieve a running time of O(m + n) using the same\nhigh-level algor ithm—iteratively deleting nodes with no incoming edges.\nWe simp ly have to be more efficient in finding these nodes, and we do this\nas follows.\nWe declare a node to be “active” if it has not yet been deleted by the\nalgorithm, and we explicitly maintain two things:\n(a) for each node w, the number of incoming edges  that w has from  active\nnodes; and\n(b) the set S of all active nodes in G that have no incoming edges from other\nactive nodes.\nAt the start, all nodes are active, so we can initialize (a) and (b) with a\nsingle pass through the nodes and edges. Then, each iteration consists of\nselecting a node v from the set S and deleting it. After deleting v, we go\nthrough all nodes w to which v had an edge, and subtract one from the\nnumber of active incoming edges that we are maintaining for w. If this\ncauses the number of active incoming edges to w to drop to zero, then we\nadd w to the set S. Procee ding in this way, we keep track of nodes that are\neligible for deletion at all times, while spending constant work per edge\nover the course of the whole algorithm.\nFigur e 3.9  How many topological orderings does this graph have?')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 136})","('type', 'Document')"
"('page_content', 'Solved Exercises\nSolved Exercise 1\nConsider the directed acyclic graph G in Figure 3.9 . How many topological\norderings does it have?\nSolution  Recall that a topological orderin g of G is an ordering of the nodes\nas v1, v2, …, vn so that all edge s point “forward”: for every edge (vi, vj), we\nhave i < j.\nSo one way to answer this question would be to write down all 5 · 4 · 3\n· 2 · 1 = 120 possible ordering s and check whether each is a topological\nordering. But this would take a while.\nInstead, we think about this as follows. As we saw in the text (or\nreasoning direc tly from the definition), the first node in a topological\nordering must be one that has no edge coming into it. Analogou sly, the last\nnode must be one that has no edge leaving it. Thus, in every  topological\nordering of G, the node a must come first and the node e must come last.\nNow we have to figure how the nodes b, c, and d can be arranged in\nthe middle of the ordering. The edge (c, d) enforces the requirement that c\nmust come before d; but b can be placed anywhere relative to these two:\nbefore both, between c and d, or after both. This exhausts all the\npossibilities, and so we conclude that there are three possible topological\norderings:\nSolved Exercise 2')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 137})","('type', 'Document')"
"('page_content', ""Some friends of yours are working on techniques for coordinatin g groups of\nmobile robots. Each robot has a radio transmitter that it uses to\ncommunicate with a base station, and your friends find that if the robots get\ntoo close to one another , then there are problems with interference among\nthe transmitters.  So a natural problem arises: how to plan the motion of the\nrobots in such a way that each robot gets to its intended destina tion, but in\nthe process the robots don't come close enough together to cause\ninterference problems.\nWe can model this problem abstractly as follows. Suppose that we\nhave an undirected graph G = (V, E), representing the floor plan of a\nbuilding, and there are two robots initially located at nodes a and b in the\ngraph. The robot at node a wants to travel to node c along a path in G, and\nthe robot at node b wants to travel to node d. This is accomplished by\nmeans of a schedule:  at each time step, the schedule specifies that one of\nthe robots move s across a single edge, from one node to a neighboring\nnode; at the end of the schedule , the robot from node a should be sitting on\nc, and the robot from b should be sitting on d.\nA sched ule is interfer ence-fr ee if there is no point at which the two\nrobots occupy nodes that are at a distance ≤ r from one anothe r in the graph,\nfor a given parameter r. We'll assume that the two starting nodes a and b are\nat a distance greater than r, and so are the two ending nodes c and d.\nGive a polynom ial-time algorithm that decides whether there exists an\ninterference-free schedule by which each robot can get to its destination.\nSolution  This is a problem  of the following general flavor . We have a set of\npossible configurations  for the robots, where we defin e a configuration to\nbe a choice of location for each one. We are trying to get from a given\nstarting configuration (a, b) to a given ending configuratio n (c, d), subject\nto constraints on how we can move between configurations (we can only\nchange one robot's location to a neighboring node), and also subject to\nconstraints on which configurations are “legal.”\nThis problem can be tricky to think about if we view things at the level\nof the underlying graph G: for a given configuration of the robots—that is,\nthe current location of each one— it's not clear what rule we should be using\nto decide how to move one of the robots next. So instead we apply an idea\nthat can be very useful for situations in which we're trying to perform this\ntype of search. We observe that our problem looks a lot like a path-finding"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 138})","('type', 'Document')"
"('page_content', ""problem, not in the original graph G but in the space of all possible\nconfigurations.\nLet us define the following (larger) graph H. The node set of H is the\nset of all possible configurations of the robots; that is, H consist s of all\npossible pairs of nodes in G. We join two nodes of H by an edge if they\nrepresent config urations that could be consecutive in a schedule; that is, (u,\nv) and (u′, v′) will be joined by an edge in H if one of the pairs u, u′ or v, v′\nare equal, and the other pair corresponds to an edge in G.\nWe can already observe that paths in H from ( a, b) to (c, d) correspond\nto schedules for the robots: such a path consists precisely of a sequence of\nconfigurations in which, at each step, one robot crosses a single edge in G.\nHowever , we have not yet encoded the notion that the schedule should be\ninterference-free.\nTo do this, we simply delete from H all nodes that correspond to\nconfigurations in which there would be interference. Thus we define H′ to\nbe the graph obtained from H by deleting all nodes (u, v) for which the\ndistance between u and v in G is at most r.\nThe full algorithm is then as follows. We construct the graph H′, and\nthen run the connectivity algorithm from the text to determine whether there\nis a path from (a, b) to ( c, d). The correctness of the algorith m follows from\nthe fact that paths in H′ correspond to schedules, and the nodes in H′\ncorrespond precisely to the configurations in which there is no interference.\nFinally , we need to consider the running time. Let n denote the number\nof nodes in G, and m denote the number of edges in G. We'll analyze the\nrunning time by doing three things: (1) bounding the size of H′ (which will\nin gener al be larger than G), (2) bounding the time it takes  to construct H′,\nand (3) bounding  the time it takes to search for a path from (a, b) to ( c, d) in\nH.\n1. First, then, let's consider the size of H′.H′  has at most n2 nodes, since\nits nodes correspond to pairs of nodes in G. Now , how many edges\ndoes H′ have? A node ( u, v) will have edges to ( u′, v) for each neighbor\nu′ of u in G, and to (u, v′) for each neighbor v′ of v in G. A simple\nupper bound says that there can be at most n choices for (u′, v), and at\nmost n choices  for (u, v′), so there are at most 2n edges incident to\neach node of H′. Summing over the (at most) n2 nodes of H′, we have\nO(n3) edges."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 139})","('type', 'Document')"
"('page_content', ""(We can actually give a better bound of O(mn) on the number  of edges\nin H′, by using the bound (3.9) we proved in Section 3.3  on the sum of\nthe degrees in a graph. W e'll leave this as a further exercise.)\n2. Now we bound the time needed to construct H′. We first build H by\nenumerating all pairs of nodes in G in time O(n2), and constructing\nedges using the definition abov e in time O(n) per node, for a total of\nO(n3). Now we need to figure out which nodes to delete from H so as\nto produce H′. We can do this as follows. For each node u in G, we run\na breadth-first search from u and identify all nodes v within distance r\nof u. We list all these pairs (u, v) and delete them from H. Each\nbreadth-first search in G takes time O(m + n), and we're doing one\nfrom each node, so the total time for this part is O(mn + n2).\n3. Now we have H′, and so we just need to decide whether there is a path\nfrom ( a, b) to ( c, d). This can be done using the connectivity algorithm\nfrom the text in time that is linear in the number of nodes and edges of\nH′. Since H′ has O(n2) nodes and O(n3) edges, this final step takes\npolynomial time as well.\nFigur e 3.10  How many topological orderings does this graph have?\nExercises\n1. Consider the directed acyclic graph G in Figure 3.10. How many\ntopological orderings does it have?\n2. Give an algorith m to detect whether a given undirected graph contains\na cycle.  If the graph contains a cycle, then your algorithm should\noutput one. (It should not output all cycles in the graph, just one of"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 140})","('type', 'Document')"
"('page_content', ""them.) The running time of your algorithm should be O(m + n) for a\ngraph with n nodes and m edges.\n3. The algorithm described in Section 3.6 for computing a topological\nordering of a DAG repeatedly finds a node with no incoming  edges\nand deletes it. This will eventually produce a topological ordering,\nprovided that the input graph really is a DAG.  \nBut suppose that we're given an arbitrary graph that may or may not be\na DAG. Extend the topological ordering algorithm so that, given an\ninput directed graph G, it outputs one of two things: (a) a topological\nordering, thus establishing that G is a DAG; or (b) a cycle in G, thus\nestablishing that G is not a DAG. The running time of your algorithm\nshould be O(m + n) for a directed graph with n nodes and m edges.\n4. Inspired by the example of that great Cornellian, Vladimir Nabokov ,\nsome of your friends have become amateur lepidopterists (they study\nbutterflies). Often when they return from a trip with specimens of\nbutterflies, it is very dif ficult for them to tell how many distinct species\nthey've caught— thanks to the fact that many species look very similar\nto one another . \nOne day they return with n butterflies, and they believe that each\nbelongs to one of two different  species, which we'll call A and B for\npurposes of this discussion. They'd like to divide the n specimens into\ntwo groups—those that belong to A and those that belong to B—but it's\nvery hard for them to directly label any one specimen. So they decide\nto adopt the following approach.  \nFor each pair of specimens i and j, they study them carefully side by\nside. If they're confident enough in their judgment, then they label the\npair ( i,j) either “same” (meaning they believe them both to come from\nthe same species) or “different”  (meaning they believe them to come\nfrom different species). They also have the option of render ing no\njudgment on a given pair , in which case we'll call the pair ambiguous.  \nSo now they have the collection of n specimens, as well as a collectio n\nof m judgme nts (either “same” or “different”) for the pairs that were\nnot declared to be ambiguous. They'd like to know if this data is\nconsistent with the idea that each butterfly is from one of speci es A or\nB. So more concretely , we'll decla re the m judgments to be consistent\nif it is possible to label each specimen either A or B in such a way that\nfor each pair (i,j) labeled “same,” it is the case that i and; have the"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 141})","('type', 'Document')"
"('page_content', ""same label; and for each pair (i,j) labeled “different,” it is the case that\ni and; have different labels. They 're in the middle of tediously working\nout whether their judgments are consistent, when one of them realizes\nthat you probably have an algorithm that would answer this question\nright away . \nGive an algorithm with running time O(m + n) that determines whether\nthe m judgments are consistent.\n5. A binar y tree is a rooted tree in which each node has at most two\nchildren. Show by induction that in any binary tree the number of\nnodes with two children is exactly one less than the number of leaves.\n6. We have  a connected graph G = (V,E), and a specific vertex u ∊ V.\nSuppose we compute a depth-fir st search tree rooted at u, and obtain a\ntree T that includes all nodes of G. Suppose we then compute a\nbreadth-first search tree rooted at u, and obtain the same tree T. Prove\nthat G = T. (In other words , if T is both a depth-first search tree and a\nbreadth-first search tree rooted at u, then G cannot contain any edges\nthat do not belong to T.)\n7. Some friends of yours work on wireless networks, and they're\ncurrently studying the properties of a network of n mobile devices. As\nthe devices move around (actually , as their human owners move\naround), they define a graph at any point in time as follows: there is a\nnode representing each of the n devices , and there is an edge between\ndevice i and device j if the physical locations of i and; are no more\nthan 500 meters apart. (If so, we say that i and; are “in range” of each\nother .) \nThey'd like it to be the case that the network of devices is connected at\nall times, and so they've constrained the motion of the devices to\nsatisfy the following property: at all times, each device i is within 500\nmeters of at least n/2 of the other devices. (We'll assume n is an even\nnumber .) What they'd like to know is: Does this property by itself\nguarantee that the network will remain connected?  \nHere's a concrete way to formulate the question as a claim about\ngraphs.  \nClaim: Let Gbea graph on n nodes, wher e n is an even number . If every node of\nG has degr ee at least n/2, then G is connected."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 142})","('type', 'Document')"
"('page_content', ""Decide whether you think the claim is true or false, and give a proof of\neither the claim or its negation.\n8. A number of stories in the press about the structure of the Intern et and\nthe Web have focused on some version of the following question : How\nfar apart are typical nodes in these networks? If you read these  stories\ncarefully , you find that many of them are confused about the difference\nbetween the diameter  of a network and the average distance  in a\nnetwork; they often jump back and forth between these concepts as\nthough they're the same thing.  \nAs in the text, we say that the distance  between two nodes u and v in a\ngraph G = (V, E) is the minimum number of edges in a path joining\nthem; we'll denote this by dist(u,v). We say that the diameter  of G is\nthe maximum distance between any pair of nodes; and we'll denote this\nquantity by diam (G). \nLet's define a related quantity , which we'll call the average pairwise\ndistance  in G (denoted apd(G)). We define apd(G) to be the average,\nover all \n  sets of two distinct nodes u and v, of the distance between u\nand v. That is,  \n \nHere's a simple example to convince yourself that there are graphs G\nfor which diam (G) ≠ apd(G). Let G be a graph with three nodes u,v,w,\nand with the two edges { u, v} and { v, w}. Then\n \nwhile"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 143})","('type', 'Document')"
"('page_content', ""Of course, these two numbers aren't all that far apart in the case of this\nthree-node graph, and so it's natural to ask whether there's always a\nclose relation between them. Here's a claim that tries to make this\nprecise.  \nClaim: There exists a positive natural number c so that for all connected graphs\nG, it is the case that\n \nDecide whether you think the claim is true or false, and give a proof of\neither the claim or its negation.\n9. There's a natural intuition that two nodes that are far apart in a\ncommunication network-separat ed by many hops-have a more tenuous\nconnection than two nodes that are close together . There are a number\nof algor ithmic results that are based to some extent on different ways\nof making this notion precise. Here's one that involv es the\nsusceptibility of paths to the deletion of nodes.  \nSuppose that an n-node undirected graph G = (V,E) contains two nodes\ns and t such that the distance between s and t is strictly greater than\nn/2. Show that there must exist some node v, not equal to either s or t,\nsuch that deleting v from G destroys all s-t paths. (In other  words, the\ngraph obtained from G by deleting v contains no path from s to t.) Give\nan algorithm with running time O(m + n) to find such a node v.\n10. A numb er of art museums around the country have been featuring\nwork by an artist named Mark Lombardi (1951–2000), consisting of a\nset of intricately  rendered graphs. Building on a great deal of research,\nthese graphs encode the relationships among people involved in major\npolitical scandals over the past several decades: the nodes correspond\nto participants, and each edge indicates some type of relationship\nbetween a pair of participants. And so, if you peer closely enough at\nthe drawings, you can trace out ominous-looking paths from a high-"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 144})","('type', 'Document')"
"('page_content', ""ranking U.S. government official, to a former business partne r, to a\nbank in Switzerland, to a shadowy arms dealer . \nSuch pictures form striking examples of social networks,  which, as we\ndiscussed in Section 3.1, have nodes representing people and\norganizations, and edges representing relationships of various  kinds.\nAnd the short paths that abou nd in these networks have attracted\nconsiderable attention recently , as people ponder what they mean. In\nthe case of Mark  Lombardi's graphs, they hint at the short set of steps\nthat can carry you from the reputable to the disreputable.  \nOf course, a single, spurious short path between nodes v and w in such\na network may be more coincidental than anything else; a large\nnumber of short paths between v and w can be much more convincing.\nSo in addition to the problem of computing a single shortest v-w path\nin a graph G, social networks researchers have looked at the problem\nof determining the number  of shortest v-w paths.  \nThis turns out to be a problem that can be solved efficiently . Suppose\nwe are given an undirected graph G = (V, E), and we identify two\nnodes v and w in G. Give an algorithm that computes the number of\nshortest v-w paths in G. (The algorithm should not list all the paths;\njust the number suffices.) The running time of your algorithm should\nbe O(m + n) for a graph with n nodes and m edges.\n11. You're helping some security analysts monitor a collection of\nnetworked comp uters, tracking the spread of an online virus. There are\nn computers in the system, labeled C1,C2,…,Cn, and as input you're\ngiven a collection of trace data indicating the times at which pairs of\ncomputers communicated. Thus the data is a sequence of ordered\ntriples ( Ci, Cj, tk); such a triple indicates that Ci and Cj exchanged bits\nat time tk. There are m triples total.  \nWe'll assume that the triples are presented to you in sorted order of\ntime. For purposes of simplic ity, we'll assume that each pair of\ncomputers communicates at most once during the interval you're\nobserving.  \nThe security analysts you're working with would like to be able to\nanswer questions of the following form: If the virus was inserted into\ncomputer Ca at time x, could it possibly have infected computer Cb by\ntime y? The mechanics of infection are simple: if an infected compute r"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 145})","('type', 'Document')"
"('page_content', 'Ci commu nicates with an uninfected computer Cj at time tk (in other\nwords, if one of the triples (Ci, Cj, tk) or (Cj, Ci, tk) appears in the trace\ndata), then computer Cj becomes infected as well, starting at time tk.\nInfection can thus spread from one machine to another across a\nsequence  of communications, provided that no step in this sequence\ninvolves a move backward in time. Thus, for example, if Ci is infected\nby time tk, and the trace data contains triples (Ci, Cj, tk) and (Cj, Cq, tr),\nwhere tk ≤ tr, then Cq will become infected via Cj. (Note that it is okay\nfor tk to be equal to tr; this would mean that Cj had open connections to\nboth Ci and Cq at the same time, and so a virus could move from Ci to\nCq.) \nFor example, suppose n = 4, the trace data consists of the triples  \nand the virus was inserted into computer C1 at time 2. Then C3 would\nbe infec ted at time 8 by a sequence of three steps: first C2 becomes\ninfected at time 4, then C4 gets the virus from C2 at time 8, and then C3\ngets the virus from C4 at time 8. On the other hand, if the trace data\nwere  \nand again the virus was inserted into computer C1 at time 2, then C3\nwould not become infected during the period of observation: although\nC2 become s infected at time 14, we see that C3 only communicates\nwith C2 befor e C2 was infected. There is no sequence of\ncommunications moving forward in time by which the virus could get\nfrom C1 to C3 in this second example.  \nDesign an algorithm that answers questions of this type: given a\ncollection of trace data, the algorithm should decide whether a virus')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 146})","('type', 'Document')"
"('page_content', ""introduced at computer Ca at time x could have infected computer Cb\nby time y. The algorithm should run in time O(m + n).\n12. You're helping a group of ethnographers analyze some oral history data\nthey've collected by interviewin g members of a village to learn about\nthe lives of people who've lived there over the past two hundred years.  \nFrom these interviews, they've learned about a set of n people (all of\nthem now decea sed), whom we'll denote P1, P2, …, Pn. They've also\ncollected facts about when these people lived relative to one another .\nEach fact has one of the following two forms:  \nFor some i and j, person Pi died before person Pj was born; or\nfor some i and j, the life spans of Pi and Pj overlap ped at least\npartially .\nNaturally , they're not sure that all these facts are correct; memor ies are\nnot so good, and a lot of this was passed down by word of mouth. So\nwhat they'd like you to determine is whether the data they've collected\nis at least internally consistent, in the sense that there could have\nexisted a set of people for which all the facts they've learned\nsimultaneously hold.  \nGive an efficient algorithm to do this: either it should produce\nproposed dates of birth and death for each of the n people so that all\nthe facts  hold true, or it should report (correctly) that no such dates can\nexist—that is, the facts collected by the ethnographers are not\ninternally consistent.\nNotes and Further Reading\nThe theory of graphs is a large topic, encompassing both algorithmic and\nnon-algorithmic issues. It is generally considered to have begun with a\npaper by Euler (1736), grown through interest in graph representations of\nmaps and chemical compounds in the nineteenth century , and emerged as a\nsystematic area of study in the twentieth century , first as a branch of\nmathematics and later also through its applications to computer science.\nThe books by Berge (1976), Bollobas (1998), and Diestel (2000) provide\nsubstantial further coverage of graph theory . Recently , extensi ve data has\nbecome availab le for studying large networks that arise in the physical,"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 147})","('type', 'Document')"
"('page_content', 'biological, and social sciences, and there has been interest in understanding\nproperties of networks that span all these different domains. The books by\nBarabasi (2002)  and Watts (2002) discuss this emer ging area of research,\nwith presentations aimed at a general audience.\nThe basic graph traversal techniques covered in this chapter have\nnumerous applications. We will see a number of these in subsequent\nchapters, and we refer the reade r to the book by Tarjan (1983) for further\nresults.\nNotes on the Exercises  Exercise 12 is based on a result of Martin Golumbic\nand Ron Shamir .')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 148})","('type', 'Document')"
"('page_content', 'Chapter 4')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 149})","('type', 'Document')"
"('page_content', ""Greedy Algorithms\n4.1 Interval Scheduling: The Gr eedy Algorithm Stays Ahead  \n4.2 Scheduling to Minimize Lateness: An Exchange Argument  \n4.3 Optimal Caching: A Mor e Complex Exchange Argument  \n4.4 Shortest Paths in a Graph  \n4.5 The Minimum Spanning T ree Pr oblem  \n4.6 Implementing Kruskal's Algorithm: The Union-Find Data\nStructur e \n4.7 Clustering  \n4.8 Huffman Codes and Data Compr ession  \n* 4.9 Minimum-Cost Arbor escences: A Multi-Phase Gr eedy Algorithm  \nSolved Exer cises  \nExer cises  \nNotes and Further Reading\nIn Wall Street, that iconic movie of the 1980s, Michael Douglas gets up in\nfront of a room  full of stockh olders and proclaims, “Greed … is good.\nGreed is right. Greed works.” In this chapter , we'll be taking a much more\nunderstated perspective as we investigate the pros and cons of short-sighted\ngreed in the design of algorithms. Indeed, our aim is to approach a number\nof different computational problems with a recurring set of questions: Is\ngreed good? Does greed work?\nIt is hard, if not impossible, to define precisely what is mean t by a\ngreedy algorithm . An algorithm is greedy if it builds up a solution in small\nsteps, choosing  a decision at each step myopically to optimize some\nunderlying criterion. One can often design many different greedy\nalgorithms for the same problem, each one locally , incrementally\noptimizing some dif ferent measure on its way to a solution.\nWhen a greedy algorithm succeeds in solving a nontrivial problem\noptimally , it typically implies something interesting and usefu l about the\nstructure of the problem itself; there is a local decision rule that one can use\nto construct optimal solutions. And as we'll see later, in Chapter 11, the"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 150})","('type', 'Document')"
"('page_content', ""same is true of problems in which a greedy algorithm can produce a\nsolution that is guaranteed to be close  to optimal, even if it does not achieve\nthe precise optim um. These are the kinds of issues we'll be dealing with in\nthis chap ter. It's easy to invent greedy algorithms for almost any problem;\nfinding cases in which they work well, and proving that they work well, is\nthe interesting challenge.\nThe first two sections of this chapter will develop two basic methods\nfor proving that a greedy algorithm produces an optimal solution to a\nproblem. One can view the first approach as establishing that the greedy\nalgorithm stays ahead . By this we mean that if one measures the greedy\nalgorithm's progress in a step-by-step fashion, one sees that it does better\nthan any other algorithm at each step; it then follows that it produces an\noptimal solution. The second approach is known as an exchange argument ,\nand it is more general: one considers any possible solution to the problem\nand gradually transforms it into the solution found by the greedy algorithm\nwithout hurting its quality . Again, it will follow that the greedy algorithm\nmust have found a solution that is at least as good as any other solution.\nFollowing our introduction of these two styles of analysis, we focus on\nseveral of the most well-known applications of greedy algorithm s: shortest\npaths in a graph , the Minimum Spanning Tree Problem , and the\nconstruction of Huffman codes  for performing data compressio n. They each\nprovide nice examples of our analysis techniques. We also explore an\ninteresting relationship between minimum spanning trees and the long-\nstudied problem  of clustering . Finally , we consider a more complex\napplication, the Minimum-Cost Arbor escence Problem , which further\nextends our notion of what a greedy algorithm is.\n4.1 Interval Scheduling: The Greedy Algorithm\nStays Ahead\nLet's recall the Interval Schedul ing Problem, which was the first of the five\nrepresentative problems we considered in Chapter 1. We have a set of\nrequests {1, 2, …, n}; the ith request corresponds to an interval of time\nstarting at s(i) and finishing at f(i). (Note that we are slightly changing the\nnotation from Section 1.2, where we used si rather than s(i) and fi rather"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 151})","('type', 'Document')"
"('page_content', ""than f(i). This change of notation will make things easier to talk about in the\nproofs.) We'll say that a subset  of the requests is compatible  if no two of\nthem overlap in time, and our goal is to accept as large a compatible subset\nas possible. Compatible sets of maximum size will be called optimal .\nDesigning a Greedy Algorithm\nUsing the Interval Scheduling Problem, we can make our discussion of\ngreedy algorithms much more  concrete. The basic idea in a greedy\nalgorithm for interval scheduling is to use a simple rule to select a first\nrequest i1. Once a request i1 is accep ted, we reject all requests that are not\ncompatible with i1. We then select  the next reque st i2 to be accepted, and\nagain reject all requests that are not compatible with i2. We continue in this\nfashion until we run out of requests. The challenge in designing a good\ngreedy algorithm is in deciding which simple rule to use for the selection—\nand there are many natural rules for this problem that do not give good\nsolutions.\nLet's try to think of some of the most natural rules and see how they\nwork.\nThe most obvious rule might be to always select the available request\nthat starts earliest—that is, the one with minimal start time s(i). This\nway our resource starts being used as quickly as possible.  \nThis method does not yield an optimal solution. If the earliest request i\nis for a very long interval, then by accepting request i we may have to\nreject a lot of requests for shorter time intervals. Since our goal is to\nsatisfy as many requests as possible, we will end up with a suboptimal\nsolution. In a really bad case— say, when the finish time f(i) is the\nmaximum amon g all requests—the accepted request i keeps our\nresource occupied for the whole time. In this case our greedy method\nwould accept a single request, while the optimal solution could accept\nmany . Such a situation is depicted in Figure 4.1(a) .\nThis might suggest that we should start out by accepting the request\nthat requires the smallest interval of time—namely , the request for\nwhich f(i) - s(i) is as small as possible. As it turns out, this is a\nsomewhat better  rule than the previous one, but it still can produce a\nsuboptimal schedule. For example, in Figure 4.1(b) , accepting the"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 152})","('type', 'Document')"
"('page_content', ""short interval in the middle would prevent us from accepting the other\ntwo, which form an optimal solution.\nIn the previous greedy rule, our problem was that the second request\ncompetes with both the first and the third—that is, accepting this\nrequest made us reject two other requests. We could design a greedy\nalgorithm that is based on this idea: for each request, we count the\nnumber of other requests that are not compatible, and accept the\nrequest that has the fewest number of noncompatible requests. (In\nother words, we select the interval with the fewest “conflicts.”) This\ngreedy choice would lead to the optimum solution in the previous\nexample. In fact, it is quite a bit harder to design a bad example for this\nrule; but it can be done, and we've drawn an example in Figure 4.1(c) .\nThe unique optimal solution in this example is to accept the four\nrequests in the top row. The greedy method suggested here accepts the\nmiddle request in the second row and thereby ensures a solution of size\nno greater than three.\nFigur e 4.1 Some instances of the Interval Scheduling Problem on which\nnatural greedy algorithms fail to find the optimal solution. In (a), it does not\nwork to select the interval that starts earliest; in (b), it does not work to\nselect the shorte st interval; and in (c), it does not work to select the interval\nwith the fewest conflicts.\nA greedy rule that does lead to the optimal solution is based on a\nfourth idea: we should accept first the request that finishes first, that is, the"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 153})","('type', 'Document')"
"('page_content', 'request i for which f(i) is as small as possible. This is also quite a natural\nidea: we ensure  that our resour ce becomes free as soon as possible while\nstill satisfying one request. In this way we can maximize the time left to\nsatisfy other requests.\nLet us state the algorithm a bit more formally . We will use R to denote\nthe set of requests that we have neither accepted nor rejected yet, and use A\nto denote the set of accepted requests. For an example of how the algorithm\nruns, see Figure 4.2 .\nInitially let R be the set of all requests, and let A be empty\nWhile R is not yet empty\nChoose a request i ∊ R that has the smallest finishing time\nAdd request i to A\nDelete all requests from R that are not compatible with request i\nEndWhile\nReturn the set A as the set of accepted requests\nAnalyzing the Algorithm\nWhile this greedy method is quite natural, it is certainly not obvious that it\nreturns an optimal set of intervals. Indeed, it would only be sensible to\nreserve judgment on its optimality: the ideas that led to the previous\nnonoptimal versions of the greedy method also seemed promising at first.\nAs a start, we can immediately declare that the intervals in the set A\nreturned by the algorithm are all compatible.\n(4.1)  A is a compatible set of r equests.\nFigur e 4.2 Sample run of the Interval Scheduling Algorithm. At each step\nthe selected intervals are darker lines, and the intervals deleted at the\ncorresponding step are indicated with dashed lines.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 154})","('type', 'Document')"
"('page_content', 'What we need to show is that this solution is optimal. So, for purposes of\ncomparison, let \n be an optimal set of intervals. Ideally one might want to\nshow that A = \n, but this is too much to ask: there may be many optimal\nsolutions, and at best A is equal  to a single one of them . So instead we will\nsimply show that |A| = |\n|, that is, that A contains the same number of\nintervals as \n  and hence is also an optimal solution.\nThe idea underly ing the proof, as we suggested initially , will be to find\na sense in which  our greedy algorithm “stays ahead” of this solution \n . We\nwill compare the partial solutio ns that the greedy algorithm constructs to\ninitial segments of the solution \n , and show that the greedy algorithm is\ndoing better in a step-by-step fashion.\nWe intro duce some notation to help with this proof. Let i1, …, ik be the\nset of requests in A in the order they were added to A. Note that |A| = k.\nSimilarly , let the set of requests in \n be denoted by j1, …, jm. Our goal is to\nprove that k = m. Assume that the requests in \n are also ordere d in the\nnatural left-to-right order of the corresponding intervals, that is, in the order\nof the start and finish points. Note that the requests in \n are compatible,\nwhich implies that the start points have the same order as the finish points.\nFigur e 4.3 The inductive step in the proof that the greedy algorithm stays\nahead.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 155})","('type', 'Document')"
"('page_content', ""Our intuition for the greedy method came from wanting our resource\nto becom e free again as soon as possible after satisfying the first request.\nAnd indeed, our greedy rule guarantees that f(i1) ≤ f(j1). This is the sense in\nwhich we want to show that our greedy rule “stays ahead”—that each of its\nintervals finishe s at least as soon as the corresponding interval in the set \n .\nThus we now prove that for each r ≥ 1, the rth accepted request in the\nalgorithm's schedule finishes no later than the rth request in the optimal\nschedule.\n(4.2)  For all indices r ≤ k we have f (ir) ≤ f(jr).\nProof. We will prove this statement by induction. For r = 1 the statement is clearly true: the\nalgorithm starts by selecting the request i1 with minimum finish time.\nNow let r > 1. We will assume as our induction hypothesis that the statement is true for r - 1,\nand we will try to prove it for r. As shown in Figure 4.3 , the induct ion hypothesis lets us assume that\nf(ir-1) ≤ f(jr-1). In order for the algorithm's rth interval not to finish  earlier as well, it would need to\n“fall behin d” as shown. But there's a simp le reason why this could not happen: rathe r than choose a\nlater-finishing interva l, the greedy algorith m always has the option (at worst) of choosing jr and thus\nfulfilling the induction step.\nWe can make this argument precise as follows. We know (since \n  consists of compatible\nintervals) that f(jr-1) ≤ s(jr). Combining this with the induction hypo thesis f(ir-1) ≤ f(jr-1), we get\nf(ir-1) ≤ s(jr). Thus the interval jr is in the set R of availab le intervals  at the time when the greedy\nalgorithm selects ir. The greedy algorith m selects the available interval with smallest  finish time;\nsince interval jr is one of these availa ble intervals, we have f(ir) ≤ f(jr). This completes the induction\nstep. ▪\nThus we have formalized the sense in which the greedy algorithm is\nremaining ahead of \n : for each r, the rth interval it selects finishes at least as\nsoon as the rth interval in \n. We now see why this implies the optimality of\nthe greedy algorithm's set A.\n(4.3)  The gr eedy algorithm r eturns an optimal set A.\nProof. We will prove the statement by contradict ion. If A is not optimal, then an optimal set \n  must\nhave more requests, that is, we must have m > k. Applying (4.2) with r = k, we get that f(ik) ≤ f(jk).\nSince m > k, there is a request jk+1 in \n. This request starts after request jk ends, and hence after ik"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 156})","('type', 'Document')"
"('page_content', ""ends. So after deleting all requests that are not compatible with requests i1, …, ik, the set of possible\nrequests R still contai ns jk+1. But the greedy algorithm stops with request ik, and it is only suppo sed\nto stop when R is empty—a contradiction. ▪\nImplementation and Running Time We can make our algorithm run in\ntime O(n log n) as follows. We begin by sorting the n requests in order of\nfinishing time and labeling them in this order; that is, we will assume that\nf(i) ≤ f(j) when i < j. This takes time O(n log n). In an additional O(n) time,\nwe construct an array S[1 … n] with the property that S[i] contains the\nvalue s(i).\nWe now select requests by processing the intervals in order of\nincreasing f(i). We always select the first interval; we then iterate through\nthe intervals in order until reaching the first interval j for which s(j) ≥ f(1);\nwe then select this one as well. More generally , if the most recent interval\nwe've selected ends at time f, we continue iterating through subsequent\nintervals until we reach the first j for which s(j) ≥ f. In this way, we\nimplement the greedy algorithm  analyzed above in one pass through the\nintervals, spend ing constant time per interval. Thus this part of the\nalgorithm takes time O(n).\nExtensions\nThe Interval Scheduling Probl em we considered here is a quite simple\nscheduling problem. There are many further complications that could arise\nin practi cal settings. The following point out issues that we will see later in\nthe book in various forms.\nIn defining the problem, we assumed that all requests were known to\nthe scheduling algorithm when it was choosing the compatible subset.\nIt would also be natural, of course, to think about the version of the\nproblem in which the schedu ler needs to make decisions about\naccepting or rejecting certain requests before knowing about the full\nset of requests. Customers (requestors) may well be impatient, and\nthey may give up and leave if the scheduler waits too long to gather\ninformation about all other requests. An active area of research is\nconcerned with such online  algorithms, which must make decisions as\ntime proceeds, without knowledge of future input."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 157})","('type', 'Document')"
"('page_content', 'Our goal was to maximize the number of satisfied requests. But we\ncould picture a situation in which each request has a different value to\nus. For example , each request i could also have  a value vi (the amount\ngained by satisfying request i), and the goal would be to maximize our\nincome: the sum of the values of all satisfied requests. This leads to the\nWeighted Inter val Schedulin g Problem , the second of the\nrepresentative problems we described in Chapter 1 .\nThere are many other variants and combinations that can arise. We\nnow discuss one of these further variants in more detail, since it forms\nanother case in which a greedy algorithm can be used to produce an optimal\nsolution.\nA Related Problem: Scheduling All Intervals\nThe Problem  In the Interval Scheduling Problem, there is a single resource\nand many requests in the form of time intervals, so we must choose which\nrequests to accept and which to reject. A related problem arises if we have\nmany identical resources availab le and we wish to schedule all the requests\nusing as few resources as possib le. Because the goal here is to partition all\nintervals across multiple resou rces, we will refer to this as the Interval\nPartitioning  Problem.1\nFor example, suppose that each request corresponds to a lecture that\nneeds to be scheduled in a classroom for a particular interval of time. We\nwish to satisfy all these requests, using as few classrooms as possible. The\nclassrooms at our disposal are thus the multiple resources, and the basic\nconstraint is that any two lectures that overlap in time must be scheduled in\ndifferent classrooms. Equivalently , the interval requests could be jobs that\nneed to be processed for a specific period of time, and the resources are\nmachines capabl e of handling these jobs. Much later in the book, in Chapter\n10, we will see a different application of this problem in which the intervals\nare routing requests that need to be allocated bandwidth on a fiber-optic\ncable.\nAs an illustration of the problem, consider the sample instance in\nFigure 4.4(a) . The requests in this example can all be scheduled using three\nresources; this is indicated in Figure 4.4(b) , where the requests are\nrearranged into three rows, each containing a set of nonoverlapping')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 158})","('type', 'Document')"
"('page_content', 'intervals. In general, one can imagine a solution using k resources as a\nrearrangement of the requests into k rows of nonove rlapping interva ls: the\nfirst row contain s all the interva ls assigned to the first resource , the second\nrow contains all those assigned to the second resource, and so forth.\nFigur e 4.4 (a) An instanc e of the Interva l Partitioning Problem with ten\nintervals (a through j). (b) A solution  in which all intervals are scheduled\nusing three resources: each row represents a set of intervals that can all be\nscheduled on a single resource.\nNow , is there any hope of using just two resources in this sample\ninstance? Clearly the answer is no. We need at least three resources since,\nfor example, intervals a, b, and c all pass over a common point on the time-\nline, and hence they all need to be scheduled on different resour ces. In fact,\none can make this last argument in general for any instance of Interval\nPartitioning. Suppose we defin e the depth  of a set of intervals to be the\nmaximum numb er that pass over any single point on the time-line. Then we\nclaim\n(4.4)  In any instance of Interval Partitioning, the number of resour ces needed is at least the depth of\nthe set of intervals.\nProof. Suppose a set of intervals has depth d, and let I1, …, Id all pass over a common point on the\ntime-line. Then each of these intervals must be scheduled on a different resource , so the whole\ninstance needs at least d resources. ▪\nWe now consider two questions , which turn out to be closely related.\nFirst, can we design an efficient algorithm that schedules all intervals using')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 159})","('type', 'Document')"
"('page_content', ""the minimum possible number  of resources? Second, is there always a\nschedule using a number of resources that is equal  to the depth? In effect, a\npositive answer to this second question would say that the only obstacles to\npartitioning intervals are purely local—a set of intervals all piled over the\nsame point. It's not immediately clear that there couldn't exist other , “long-\nrange” obstacles that push the number of required resources even higher .\nWe now design a simple greedy  algorithm that schedules all intervals\nusing a number of resources equal to the depth. This immedia tely implies\nthe optimality of the algorithm: in view of (4.4), no solution could use a\nnumber of resources that is smaller than the depth. The analysis of our\nalgorithm will therefore illustrate another general approach to proving\noptimality: one finds a simple, “structural” bound asserting  that every\npossible solution must have at least a certain value, and then one shows that\nthe algorithm under consideration always achieves this bound.\nDesigning the Algorithm  Let d be the depth of the set of intervals; we show\nhow to assign a label  to each interval , where the labels come from the set of\nnumbers {1, 2, …, d}, and the assignment has the property that overlapping\nintervals are labeled with different numbers. This gives the desired solution,\nsince we can interpret each number as the name of a resource, and the label\nof each interval as the name of the resource to which it is assigned.\nThe algorithm we use for this is a simple one-pass greedy strategy that\norders intervals by their starting times. We go through the intervals in this\norder , and try to assign to each interval we encounter a label that hasn't\nalready been assigned to any previous interval that overlaps it. Specifically ,\nwe have the following description.\nSort the intervals by their start times, breaking ties arbitrarily\nLet I1,I2,…,In denote the intervals in this order\nFor j = 1,2,3, …, n\nFor each interval Ii that precedes Ij in sorted order and overlaps it\nExclude the label of Ii from consideration for Ij\nEndfor\nIf there is any label from {1,2, …, d} that has not been excluded then\nAssign a nonexcluded label to Ij\nElse\nLeave Ij unlabeled\nEndif\nEndfor"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 160})","('type', 'Document')"
"('page_content', ""Analyzing the Algorithm  We claim the following.\n(4.5)  If we use the greedy algorithm above, every interval will be assigned a label, and no two\noverlapping intervals will r eceive the same label.\nProof. First let's argue that no interval ends up unlabeled. Consider one of the intervals Ij, and\nsuppose there are t intervals earlier in the sorted order that overlap it. These t interv als, together with\nIj, form a set of t + 1 intervals that all pass over a common point on the time-line (namely , the start\ntime of Ij), and so t + 1 ≤ d. Thus t ≤ d - 1. It follows that at least one of the d labels is not excluded\nby this set of t intervals, and so there is a label that can be assigned to Ij.\nNext we claim that no two overlapping intervals are assigned the same label. Indeed, consider\nany two intervals I and I′ that overlap, and suppose I precedes I′ in the sorted order . Then when I′ is\nconsidered by the algorithm, I is in the set of intervals whose labels are excluded from consideration;\nconsequently , the algorithm will not assign to I′ the label that it used for I. ▪\nThe algorithm and its analysis are very simple. Essentially , if you have\nd labels at your disposal, then as you sweep through the intervals from left\nto right, assigning an available label to each interval you encounter , you can\nnever reach a point where all the labels are currently in use.\nSince our algorithm is using d labels, we can use (4.4) to conclude that\nit is, in fact, always using the minimum possible number of labels. We sum\nthis up as follows.\n(4.6)  The greedy algorithm  above schedules every interval on a resour ce, using a number of\nresour ces equal to the depth of the set of intervals. This is the optimal number of r esour ces needed.\n4.2 Scheduling to Minimize Lateness: An\nExchange Argument\nWe now discuss a scheduling problem related to the one with which we\nbegan the chapter . Despite the similarities in the problem formulation and in\nthe greedy algorithm to solve it, the proof that this algorithm is optimal will\nrequire a more sophisticated kind of analysis.\nThe Problem\nConsider again a situation in which we have a single resource and a set of n\nrequests to use the resource for an interval of time. Assume that the\nresource is available starting at time s. In contrast to the previous problem,"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 161})","('type', 'Document')"
"('page_content', 'however , each request is now more flexible. Instead of a start time and\nfinish time, the request i has a deadline di, and it requires a contiguous time\ninterval of length ti, but it is willing  to be schedule d at any time before the\ndeadline. Each accepted reques t must be assigned an interval  of time of\nlength ti, and dif ferent requests must be assigned nonoverlapping intervals.\nThere are many objective functions we might seek to optimize when\nfaced with this situation, and some are computationally much more difficult\nthan others. Here we consider a very natural goal that can be optimized by a\ngreedy algorithm. Suppose that we plan to satisfy each request , but we are\nallowed to let certain requests run late. Thus, beginning at our overall start\ntime s, we will assign each request i an interval of time of length ti; let us\ndenote this interval by [s(i), f(i)], with f(i) = s(i) + ti. Unlike  the previous\nproblem, then, the algorithm must actually determine a start time (and\nhence a finish time) for each interval.\nFigur e 4.5  A sample instance of scheduling to minimize lateness.\nWe say that a request i is late if it misses the deadline, that is, if f(i) >\ndi. The lateness  of such a request i is defin ed to be li = f(i) - di. We will say\nthat li = 0 if request i is not late. The goal in our new optimization problem\nwill be to sched ule all requests, using nonoverlapping intervals, so as to\nminimize the maximum lateness, L = maxi li. This problem arises naturally\nwhen schedulin g jobs that need to use a single machine, and so we will\nrefer to our requests as jobs.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 162})","('type', 'Document')"
"('page_content', ""Figure 4.5  shows a sample  instance of this problem, consisting of three\njobs: the first has length t1 = 1 and deadline d1 = 2; the second  has t2 = 2\nand d2 = 4; and the third has t3 = 3 and d3 = 6. It is not hard to check that\nscheduling the jobs in the order 1, 2, 3 incurs a maximum lateness of 0.\nDesigning the Algorithm\nWhat would a greedy algorith m for this problem look like? There are\nseveral natural greedy approach es in which we look at the data (ti, di) about\nthe jobs and use this to order them according to some simple rule.\nOne approach would be to schedule the jobs in order of increasing\nlength ti, so as to get the short jobs out of the way quickly . This\nimmediately looks too simplistic, since it completely ignores the\ndeadlines of the jobs. And indeed, consider a two-job instance where\nthe first job has t1 = 1 and d1 = 100, while the second job has t2 = 10\nand d2 = 10. Then the second job has to be started right away if we\nwant to achieve lateness L = 0, and schedu ling the second job first is\nindeed the optimal solution.\nThe previous example suggests  that we should be concerned about\njobs whose available slack time di - ti is very small—they're the ones\nthat need to be started with minimal delay . So a more natural greedy\nalgorithm would be to sort jobs in order of increasing slack di - ti. \nUnfortunately , this greedy rule fails as well. Consider a two-job\ninstance where the first job has t1 = 1 and d1 = 2, while the second job\nhas t2 = 10 and d2 = 10. Sorting by increasing slack would place the\nsecond job first in the schedule, and the first job would incur a lateness\nof 9. (It finishes at time 11, nine units beyond its deadline.) On the\nother hand, if we schedule the first job first, then it finishes on time\nand the second job incurs a lateness of only 1.\nThere is, however , an equally  basic greedy algorithm that always\nproduces an optimal solution. We simply sort the jobs in increasing order of\ntheir deadlines di, and schedule them in this order . (This rule is often called\nEarliest Deadline First. ) There is an intuitive basis to this rule: we should\nmake sure that jobs with earlier deadlines get completed earlier . At the same"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 163})","('type', 'Document')"
"('page_content', ""time, it's a little hard to believe that this algorithm always produces optimal\nsolutions— specifically because it never looks at the lengths of the jobs.\nEarlier we were skeptical of the approach that sorted by length on the\ngrounds that it threw away half the input data (i.e., the deadlines); but now\nwe're considering a solution that throws away the other half of the data.\nNevertheless, Earliest Deadline First does produce optimal solutions, and\nwe will now prove this.\nFirst we specify  some notation that will be useful in talking about the\nalgorithm. By renaming the jobs if necessary , we can assume that the jobs\nare labeled in the order of their deadlines, that is, we have\nWe will simply schedule all jobs in this order . Again, let s be the start time\nfor all jobs. Job 1 will start at time s = s(1) and end at time f(1) = s(1) + t1;\nJob 2 will start at time s(2) = f(1) and end at time f(2) = s(2) + t2; and so\nforth. We will use f to denote the finishing time of the last scheduled job.\nWe write this algorithm here.\nOrder the jobs in order of their deadlines\nAssume for simplicity of notation that d1≤…≤ dn\nInitially , f = s\nConsider the jobs i = 1, …, n in this order\nAssign job i to the time interval from s(i) = f to f(i) = f + ti\nLet f = f + ti\nEnd\nReturn the set of scheduled intervals [ s(i), f(i)] for i = 1, …, n\nAnalyzing the Algorithm\nTo reason about the optimality of the algorithm, we first observe that the\nschedule it produces has no “gaps”—times when the machine is not\nworking yet there are jobs left. The time that passes during a gap will be\ncalled idle time:  there is work to be done, yet for some reason the machine\nis sitting idle. Not only does the schedule A produced by our algorithm have"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 164})","('type', 'Document')"
"('page_content', 'no idle time; it is also very easy to see that there is an optimal schedule with\nthis property . We do not write down a proof for this.\n(4.7)  There is an optimal schedule with no idle time.\nNow , how can we prove that our schedule A is optim al, that is, its\nmaximum lateness L is as small as possible? As in previous analyses, we\nwill start by considering an optimal schedule \n . Our plan here is to\ngradually modify \n , preserving its optimality at each step, but eventually\ntransforming it into a schedule that is identical to the schedule A found by\nthe greedy algorithm. We refer to this type of analysis as an exchange\nargument,  and we will see that it is a powerful way to think about greed y\nalgorithms in general.\nWe first try characterizing schedules in the following way. We say that\na schedule A′ has an inversion  if a job i with deadline di is sched uled before\nanother job j with earlier deadline dj < di. Notice that, by definition, the\nschedule A produced by our algorithm has no inversions. If there are jobs\nwith identical deadlines then there can be many different schedu les with no\ninversions. How ever, we can show that all these schedules have the same\nmaximum lateness L.\n(4.8)  All schedules with no inversions and no idle time have the same maximum lateness.\nProof. If two different schedules have neither inversions nor idle time, then they might not produce\nexactly the same order of jobs, but they can only differ in the order in which jobs with identical\ndeadlines are schedul ed. Consider such a deadline d. In both schedules, the jobs with deadline d are\nall scheduled consecutively (after all jobs with earlier deadlines and before all jobs with later\ndeadlines). Among the jobs with deadline d, the last one has the greatest lateness, and this lateness\ndoes not depend on the order of the jobs. ▪\nThe main step in showing the optimality of our algorithm is to\nestablish that there is an optimal  schedule that has no inversions and no idle\ntime. To do this, we will start with any optimal schedule having no idle\ntime; we will then convert it into a schedule with no inversi ons without\nincreasing its maximum lateness. Thus the resulting schedulin g after this\nconversion will be optimal as well.\n(4.9)  There is an optimal schedule that has no inversions and no idle time.\nProof. By (4.7), there is an optimal schedule \n  with no idle time. The proof will consist of a\nsequence of statements. The first of these is simple to establish.\n(a) If \n has an inversion, then there is a pair of jobs i and j such that j is scheduled immediat ely after\ni and has d j < di.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 165})","('type', 'Document')"
"('page_content', 'Indeed, consider an inversion in which a job a is schedul ed sometime before a job b, and da > db. If\nwe advance in the scheduled order of jobs from a to b one at a time, there has to come a point at\nwhich the deadline we see decreases for the first time. This corresponds to a pair of consecutive jobs\nthat form an inversion.\nNow suppose \n  has at least one inversion, and by (a), let i and j be a pair of inverted  requests\nthat are consecutive in the scheduled order. We will decrease the number of inversions in \n  by\nswapping the requests i and j in the schedule \n . The pair (i,j) formed an inversion  in \n, this inversion\nis eliminated by the swap, and no new inversions are created. Thus we have\n(b) After swapping i and j we get a schedule with one less inversion.\nThe hardest part of this proof is to ar gue that the inverted schedule is also optimal.\n(c) The new swapped schedule has a maximum lateness no lar ger than that of  \n.\nIt is clear that if we can prove (c), then we are done. The initial schedule \n  can have at most \ninversions (if all pairs are inverted), and hence after at most \n  swaps we get an optimal schedule\nwith no inversions.\nSo we now conclude by proving (c), showing that by swapping a pair of consecutive, inverted\njobs, we do not increase the maximum lateness L of the schedule. ▪\nProof of (c). We inven t some notation to describe the schedule \n : assume that each request r is\nscheduled for the time interval [s(r),f(r)] and has lateness l′r. Let L′ = maxr l′r denote the maximum\nlateness of this sched ule. Let \n  denote the swapped schedule; we will use \n (r), \n(r), \nr, and \n  to\ndenote the corresponding quantities in the swapped schedule.\nFigur e 4.6  The ef fect of swapping two consecutive, inverted jobs.\nNow recall our two adjacent, inverted jobs i and j. The situation is roughly as pictured in Figure\n4.6. The finish ing time of j before the swap is exactly equal to the finishing time of i after the swap.\nThus all jobs other than jobs i and j finish  at the same time in the two schedule s. Moreover , job j will\nget finished earlier in the new schedule, and hence the swap does not increase the lateness of job j.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 166})","('type', 'Document')"
"('page_content', 'Thus the only thing to worry about is job i: its latenes s may have been increased, and what if\nthis actually raises the maximum lateness of the whole schedule? After the swap, job i finishes at\ntime f(j), when job j was finished in the schedule \n . If job i is late in this new schedule, its lateness is \ni = \n(i) - di = f(j) - di. But the crucial point  is that i cannot be more late  in the schedule \n  than j was\nin the schedule \n . Specifically , our assumption di > dj implies that\nSince the lateness of the schedule \n  was L′ ≥ l′j > \ni, this shows that the swap does not increase the\nmaximum lateness of the schedule. ▪\nThe optimality of our greedy algorithm now follows immediately .\n(4.10)  The schedule A pr oduced by the gr eedy algorithm has optimal maximum lateness L.\nProof. Statement (4.9) proves that an optimal schedule with no inversions exists. Now by (4.8) all\nschedules with no inversions have the same maximum lateness, and so the schedule obtained by the\ngreedy algorithm is optimal. ▪\nExtensions\nThere are many possible generalizations of this scheduling problem. For\nexample, we assumed that all jobs were available to start at the common\nstart time s. A natural, but harder , version of this problem would contain\nrequests i that, in addition to the deadline di and the requeste d time ti, would\nalso have an earliest possible starting time ri. This earliest possible starting\ntime is usually referred to as the release time. Problems with release times\narise naturally in scheduling problems where requests can take the form:\nCan I reserve the room for a two-hour lecture, sometime betw een 1 P.M.\nand 5 P.M.? Our proof that the greedy algorithm finds an optimal solution\nrelied crucially on the fact that all jobs were available at the common start\ntime s. (Do you see where?) Unfortunately , as we will see later in the book,\nin Chapter 8, this more general version of the problem is much more\ndifficult to solve optimally .\n4.3 Optimal Caching: A More Complex Exchange\nArgument')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 167})","('type', 'Document')"
"('page_content', ""We now conside r a problem that involves processing a sequence of requests\nof a different form, and we deve lop an algorithm whose analysis requires a\nmore subtle use of the exchang e argument. The problem is that of cache\nmaintenance .\nThe Problem\nTo motivate caching, consider the following situation. You're working on a\nlong research paper, and your draconian library will only allow you to have\neight books checked out at once . You know that you'll probably  need more\nthan this over the course of working on the paper , but at any point in time,\nyou'd like to have ready access to the eight books that are most relevant at\nthat time. How should you decide which books to check out, and when\nshould you return some in exchange for others, to minimize the number of\ntimes you have to exchange a book at the library?\nThis is precisely the problem that arises when dealing with a memory\nhierar chy: There is a small amount of data that can be accessed very\nquickly , and a large amount of data that requires more time to access; and\nyou must decide which pieces of data to have close at hand.\nMemory hierarc hies have been a ubiquitous feature of computers since\nvery early in their history . To begin with, data in the main memory of a\nprocessor can be accessed much more quickly than the data on its hard disk;\nbut the disk has much more storage capacity . Thus, it is impor tant to keep\nthe most regularly used pieces of data in main memory , and go to disk as\ninfrequently as possible. The same phenomenon, qualitatively , occurs with\non-chip caches in modern processors. These can be accessed in a few\ncycles, and so data can be retrieved from cache much more quickly than it\ncan be retrieved  from main memory . This is another level of hierarchy:\nsmall caches have faster access time than main memory , which in turn is\nsmaller and faster to access than disk. And one can see extensions of this\nhierarchy in many other setting s. When one uses a Web browser , the disk\noften acts as a cache for frequently visited Web pages, since going to disk is\nstill much faster than downloading something over the Internet.\nCaching  is a general term for the process of storing a small amount of\ndata in a fast memory so as to reduce the amount of time spent interacting\nwith a slow mem ory. In the previous examples, the on-chip cache reduces\nthe need to fetch data from main memory , the main memory acts as a cache"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 168})","('type', 'Document')"
"('page_content', ""for the disk, and the disk acts as a cache for the Internet. (Much as your\ndesk acts as a cache for the campus library , and the assorted facts you're\nable to remembe r without looking them up constitute a cache for the books\non your desk.)\nFor caching to be as effective as possible, it should generally be the\ncase that when you go to access a piece of data, it is already in the cache. T o\nachieve this, a cache maintenance  algorithm determines what to keep in the\ncache and what to evict from the cache when new data needs to be brought\nin.\nOf course, as the caching problem arises in different settings, it\ninvolves various different considerations based on the underlying\ntechnology . For our purposes here, though, we take an abstract view of the\nproblem that underlies most of these settings. We consider a set U of n\npieces of data stored in main memory . We also have a faster memory , the\ncache , that can hold k < n pieces of data at any one time.  We will assume\nthat the cache initially holds some set of k items. A sequence of data items\nD = d1, d2, …, dm draw n from U is presented to us—this is the sequence of\nmemory references we must process— and in processing them we must\ndecide at all times which k items to keep in the cache. When item di is\npresented, we can access it very quickly if it is already in the cache;\notherwise, we are required to bring it from main memory into the cache\nand, if the cache  is full, to evict  some other piece of data that is currently in\nthe cache to make room for di. This is called a cache miss, and we want to\nhave as few of these as possible.\nThus, on a particular sequence of memory references, a cache\nmaintenance algorithm determines an eviction schedule —specifying which\nitems should be evicted from the cache at which points in the sequence—\nand this determines the contents  of the cache and the number of misses over\ntime. Let's consider an example of this process.\nSuppose we have three items {a,b,c }, the cache size is k = 2, and we\nare presented with the sequence  \na, b, c, b, c, a, b.  \nSuppose that the cache initially contains the items a and b. Then on the\nthird item in the sequence, we could evict a so as to bring in c; and on\nthe sixth  item we could evict c so as to bring in a; we thereby incur\ntwo cache misses over the whole sequence. After thinking about  it, one"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 169})","('type', 'Document')"
"('page_content', ""concludes that any eviction schedule for this sequence must include at\nleast two cache misses.\nUnder real operating conditions, cache maintenance algorithms must\nprocess memory references d1, d2, … without knowledge of what's coming\nin the future; but for purposes of evaluating the quality of these algorithms,\nsystems researchers very early on sought to understand the nature of the\noptimal solution  to the caching problem. Given a full sequence S of\nmemory referen ces, what is the eviction schedule that incurs as few cache\nmisses as possible?\nDesigning and Analyzing the Algorithm\nIn the 1960s, Les Belady showed that the following simple rule will always\nincur the minimum number of misses:\nWhen di needs to be brought into the cache, evict the item that is needed the farthest into the future\nWe will call this the Farthest-in-Futur e Algorithm . When it is time to evict\nsomething, we look at the next time that each item in the cache will be\nreferenced, and choose the one for which this is as late as possible.\nThis is a very natural algorithm . At the same time, the fact that it is\noptimal on all sequences is somewhat more subtle than it first appears. Why\nevict the item that is needed farthest in the future, as opposed, for example,\nto the one that will be used least frequently in the future? Moreover ,\nconsider a sequence like\na, b, c, d, a, d, e, a, d, b, c\nwith k = 3 and items {a,b,c } initiall y in the cache. The Farthest-in-Future\nrule will produce a schedule S that evicts c on the fourth step and b on the\nseventh step. But there are other eviction schedules that are just as good.\nConsider the schedule S′ that evicts b on the fourth step and c on the\nseventh step, incurring the same number of misses. So in fact it's easy to\nfind cases where schedules produced by rules other than Farthe st-in-Future\nare also optimal; and given this flexibility , why might a deviation from\nFarthest-in-Future early on not yield an actual savings farther along in the\nsequence? For example, on the seventh step in our example, the schedule S′"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 170})","('type', 'Document')"
"('page_content', ""is actual ly evicting an item (c) that is needed farther  into the future than the\nitem evicted at this point by Farthest-in-Future, since Farthest-in-Future\ngave up c earlier on.\nThese are some of the kinds of things one should worry about before\nconcluding that Farthest-in-Futu re really is optimal. In thinkin g about the\nexample above, we quickly appreciate that it doesn't really matte r whether b\nor c is evicted at the fourth step, since the other one should be evicte d at the\nseventh step; so given a schedu le where b is evicted first, we can swap the\nchoices of b and c without changing the cost. This reasoning—swapping\none decision for another—form s the first outline of an exchange argument\nthat proves the optimality of Farthest-in-Future.\nBefore delving into this analysis, let's clear up one important issue. All\nthe cache maintenance algorithms we've been considering so far produce\nschedules that only bring an item d into the cache in a step i if there is a\nrequest to d in step i, and d is not already in the cache. Let us call such a\nschedule reduced —it does the minimal amount of work necessary in a\ngiven step. But in general one could imagine an algorithm that produced\nschedules that are not reduced, by bringing in items in steps when they are\nnot requested. We now show that for every nonreduced schedule , there is an\nequally good reduced schedule.\nLet S be a schedule that may not be reduced. W e define a new schedule\n—the reduction  of S—as follows. In any step i where S brings in an item d\nthat has not been requested, our construction of \n “pretends” to do this but\nactually leaves d in main memory . It only really brings d into the cache in\nthe next step j after this in which d is requested. In this way, the cache miss\nincurred by \n  in step j can be charged to the earlier cache operation\nperformed by S in step i, when it brought  in d. Hence we have the following\nfact.\n(4.11) S is a r educed schedule that brings in at most as many items as the schedule S.\nNote that for any reduced schedule, the number of items that are\nbrought in is exactly the number of misses.\nProving the Optimalthy of Farthest-in-Future  We now proceed with the\nexchange argument showing that Farthest-in-Future is optimal. Consider an\narbitrary sequence D of mem ory references; let SFF denote the schedule\nproduced by Farthest-in-Future, and let S* denote a schedu le that incurs the"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 171})","('type', 'Document')"
"('page_content', ""minimum possible number of misses. We will now gradually “transform”\nthe schedule S* into the schedule SFF, one eviction decision at a time,\nwithout increasing the number of misses.\nHere is the basic fact we use to perform one step in the transformation.\n(4.12)  Let S be a reduced schedule that makes the same eviction decisions as SFF through the first j\nitems in the sequence, for a number j. Then there is a reduced schedule S′ that makes the same\neviction decisions as S FF through the first j  + 1 items, and incurs no mor e misses than S does.\nProof. Cons ider the (j + 1)st request, to item d = dj+1. Since S and SFF have agreed up to this point,\nthey have the same cache contents. If d is in the cache for both, then no eviction decision is necessary\n(both sched ules are reduced), and so S in fact agrees with SFF through step j + 1, and we can set S′ =\nS. Simi larly, if d need s to be brought into the cache, but S and SFF both evict  the same item to make\nroom for d, then we can again set S′ = S.\nSo the interesting case arises when d needs to be brought into the cache, and to do this S evicts\nitem f while SFF evicts item e ≠ f. Here S and SFF do not already agree through step j + 1 since S has\ne in cache while SFF has f in cache. Hence we must actually do something nontrivial to construct S′.\nAs a first step, we should have S′ evict e rather than f. Now we need to further ensure that S′\nincurs no more misse s than S. An easy way to do this would be to have S′ agree with S for the\nremainder of the sequence; but this is no longer possible, since S and S′ have slightly different caches\nfrom this point onward. So instead we'll have S′ try to get its cache back to the same state as S as\nquickly as possible, while not incurring unnecessary misses. Once the caches are the same, we can\nfinish the construction of S′ by just having it behave like S.\nSpecifically , from request j + 2 onward, S′ behaves exactly like S until one of the following\nthings happens for the first time.\n(i) There is a request to an item g ≠ e,f that is not in the cache of S, and S evicts e to make room for it.\nSince S′ and S only differ on e and f, it must be that g is not in the cache of S′ either; so we can\nhave S′ evict f, and now the caches of S and S′ are the same. We can then have S′ behave exactly\nlike S for the rest of the sequence.\n(ii) There is a request to f, and S evicts an item e′. If e′ = e, then we're all set: S′ can simply access f\nfrom the cache, and after this step the caches of S and S′ will be the same. If e′ ≠ e, then we have S′\nevict e′ as well, and bring in e from main memory; this too results in S and S′ having the same\ncaches. However , we must be careful here, since S′ is no longe r a reduced schedule: it brough t in e\nwhen it wasn't immed iately needed. So to finish this part of the construction, we further transform\nS′ to its reduction \n ′ using (4.11); this doesn't increase the number of items brought in by S′, and it\nstill agrees with SFF through step j + 1.\nHence, in both these cases, we have a new reduced schedule S′ that agrees with SFF through the first\nj + 1 items and incurs no more misses than S does. And crucially— here is where we use the defining\nproperty of the Farthest-in-Future Algorithm—one of these two cases will arise befor e there is a\nreference to e. This is because in step j + 1, Farth est-in-Future evicted the item (e) that would be\nneeded farthest in the future; so before there could be a request to e, there would have to be a request\nto f, and then case (ii) above would apply . ▪\nUsing this result, it is easy to complete the proof of optimality . We\nbegin with an optimal schedule S*, and use (4.12) to construct a schedule S1"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 172})","('type', 'Document')"
"('page_content', ""that agrees with SFF through the first step. We continue applying (4.12)\ninductively for j = 1,2,3,…, m, produc ing schedules Sj that agree with SFF\nthrough the first j steps. Each schedule incurs no more misses than the\nprevious one; and by definition Sm = SFF, since it agrees with it through the\nwhole sequence. Thus we have\n(4.13)  SFF incurs no mor e misses than any other schedule S* and hence is optimal.\nExtensions: Caching under Real Operating\nConditions\nAs mentioned in the previous subsection, Belady's optimal algorithm\nprovides a benchmark for caching performance; but in applications, one\ngenerally must make eviction decisions on the fly without knowledge of\nfuture requests. Experimentally , the best caching algorithms under this\nrequirement seem to be variants of the Least-Recently-Used  (LRU)\nPrinciple, which  proposes evicting the item from the cache that was\nreferenced longest ago.\nIf one thinks about it, this is just Belady's Algorithm with the direction\nof time reversed —longest in the past rather than farthest in the future. It is\neffective becaus e applications generally exhibit locality of reference:  a\nrunning program will generally  keep accessing the things it has just been\naccessing. (It is easy to invent pathological exceptions to this principle, but\nthese are relatively rare in practice.) Thus one wants to keep the more\nrecently referenced items in the cache.\nLong after the adoption of LRU in practice, Sleator and Tarjan showed\nthat one could actually provide some theoretical analy sis of the\nperformance of LRU, bounding  the number of misses it incurs relative to\nFarthest-in-Future. We will discuss this analysis, as well as the analysis of a\nrandomized variant on LRU, when we return to the caching problem in\nChapter 13 .\n4.4 Shortest Paths in a Graph"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 173})","('type', 'Document')"
"('page_content', ""Some of the basic algorithms for graphs are based on greedy design\nprinciples. Here we apply a greedy algorithm to the problem  of finding\nshortest paths, and in the next section we look at the construction of\nminimum-cost spanning trees.\nThe Problem\nAs we've seen, graphs are often used to model networks in which one\ntravels from one point to another—traversing a sequence of highways\nthrough interchanges, or traversing a sequence of communication links\nthrough interme diate routers. As a result, a basic algorithmic problem is to\ndetermine the shortest path betw een nodes in a graph. We may ask this as a\npoint-to-point question: Given nodes u and v, what is the shortest u-v path?\nOr we may ask for more infor mation: Given a start node s, what is the\nshortest path from s to each other node?\nThe concrete setup of the shorte st paths problem is as follows. We are\ngiven a directed graph G = (V, E), with a designated start node s. We assume\nthat s has a path to every other node in G. Each edge e has a length ℓe ≥ 0,\nindicating the time (or distance,  or cost) it takes to traverse e. For a path P,\nthe length of P—denoted ℓ(P)—is the sum of the lengths of all edges in P.\nOur goal is to determine the shortest path from s to every  other node in the\ngraph. We should mention that although the problem is specified for a\ndirected graph, we can handle the case of an undirected graph by simply\nreplacing each undirected edge e = (u,v) of length ℓe by two directed edges\n(u, v) and ( v, u), each of length ℓe.\nDesigning the Algorithm\nIn 1959, Edsger Dijkstra propos ed a very simple greedy algorithm to solve\nthe single-source shortest-paths problem. We begin by describing an\nalgorithm that just determines the length  of the shortest path from s to each\nother node in the graph; it is then easy to produce the paths as well. The\nalgorithm maintains a set S of vertices u for which we have determined  a\nshortest-path distance d(u) from s; this is the “explored” part of the graph.\nInitially S = {s}, and d(s) = 0. Now , for each node v ∊ V - S, we determine\nthe shortest path that can be constructed by traveling along a path through\nthe explored part S to some u ∊ S, followed by the single edge (u, v). That"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 174})","('type', 'Document')"
"('page_content', ""is, we consider the quantity d′(v) = mine=(u,v):u ∊S d(u) + ℓe. We choose the\nnode v ∊ V-S for which this quantity is minimized, add v to S, and define\nd(v) to be the value d′(v).\nDijkstra's Algorithm ( G, ℓ)\nLet S be the set of explored nodes\nFor each u ∊ S, we store a distance d(u)\nInitially S = {s} and d(s) = 0\nWhile S ≠ V\nSelect a node v ∉ S with at least one edge from S for which d′(v) = min e=(u, v):u ∊S d(u) + ℓe is\nas small as possible\nAdd v to S and define d(v) = d′(v)\nEndWhile\nIt is simple to produce the s-u paths corresponding to the distances\nfound by Dijkst ra's Algorithm. As each node v is added to the set S, we\nsimply record the edge (u, v) on which it achieved the value mine=(u,v):u ∊S\nd(u) + ℓe. The path Pv is implicitly represented by these edges: if (u, v) is\nthe edge we have stored for v, then Pv is just (recursively) the path Pu\nfollowed by the single edge (u, v). In other words, to construct Pv, we\nsimply start at v; follow the edge we have stored for v in the reverse\ndirection to u; then follow the edge we have stored for u in the reverse\ndirection to its predecessor; and so on until we reach s. Note that s must be\nreached, since our backward walk from v visits nodes that were added to S\nearlier and earlier .\nTo get a better sense of what the algorithm is doing, consid er the\nsnapshot of its execution depict ed in Figure 4.7. At the point the picture is\ndrawn, two iterations have been performed: the first added node u, and the\nsecond added node v. In the iteration that is about to be performed, the node\nx will be added because it achieves the smallest value of d′(x); thanks to the\nedge ( u, x), we have d′(x) = d(u) + lux = 2. Note that attempting to add y or z\nto the set S at this point would lead to an incorrect value for their shortest-\npath distances; ultimately , they will be added because of their edges from x.\nAnalyzing the Algorithm"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 175})","('type', 'Document')"
"('page_content', ""We see in this example that Dijkstra's Algorithm is doing the right thing and\navoiding recurring pitfalls: growing the set S by the wrong node can lead to\nan overestimate  of the shortest-path distance to that node. The question\nbecomes: Is it always true that when Dijkstra's Algorithm adds a node v, we\nget the true shortest-path distance to v?\nWe now answer this by provi ng the correctness of the algorithm,\nshowing that the paths Pu really are short est paths. Dijkstra's Algorithm is\ngreedy in the sense that we always form the shortest new s-v path we can\nmake from a path in S followed by a single edge. We prove its correctness\nusing a variant of our first style of analysis: we show that it “stays ahead” of\nall other  solutions by establishing, inductively , that each time it selects a\npath to a node v, that path is shorter than every other possible path to v.\nFigur e 4.7 A snapshot of the execution of Dijkstra's Algorithm. The next\nnode that will be added to the set S is x, due to the path through u.\n(4.14)  Consider the set S at any point in the algorithm's execution. For each u ∊  S, the path Pu is a\nshortest s-u path.\nNote that this fact immediately establishes the correctness of Dijkstra's Algorithm, since we can\napply it when the algorithm terminates, at which point S includes all nodes.\nProof. We prove this by induction on the size of S. The case |S| = 1 is easy, since then we have S =\n{s} and d(s) = 0. Suppose the claim holds when |S| = k for some value of k ≥ 1; we now grow S to\nsize k + 1 by adding the node v. Let ( u, v) be the final edge on our s-v path Pv.\nBy induction hypothesis, Pu is the shortest s-u path for each u ∊ S. Now consider any other s-v\npath P; we wish to show that it is at least as long as Pv. In order to reach v, this path P must  leave  the"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 176})","('type', 'Document')"
"('page_content', ""set S somewher e; let y be the first node on P that is not in S, and let x ∊ S be the node just before y.\nThe situation is now as depicted in Figure 4.8 , and the crux of the proof is very simple: P cannot\nbe shorter than Pv because it is already at least as long as Pv by the time it has left the set S. Indeed,\nin iteration k + 1, Dijkstra's Algor ithm must have consi dered adding node y to the set S via the edge\n(x, y) and rejected this option in favor of adding v. This means that there is no path from s to y\nthrough x that is shorter than Pv. But the subpath of P up to y is such a path, and so this subpath is at\nleast as long as Pv. Since edge lengths are nonnegative, the full path P is at least as long as Pv as\nwell.\nFigur e 4.8  The shortest path Pv and an alternate s-v path P through the node y.\nThis is a complete proof; one can also spell out the ar gument in the previous paragraph using the\nfollowing inequalities. Let P′ be the subpath of P from s to x. Since x ∊ S, we know by the induction\nhypothesis that Px is a shortest s-x path (of length d(x)), and so ℓ(P′) ≥ ℓ(Px) = d(x). Thus the subpath\nof P out to node y has length  ℓ(P′) + ℓ(x, y) ≥ d(x) + ℓ(x, y) ≥ d′(y), and the full path P is at least as\nlong as this subpath. Finally , since Dijkstra's Algorithm selected v in this iteration, we know that d′(y)\n≥ d′(v) = ℓ(Pv). Combining these inequalities shows that ℓ(P) ≥ ℓ(P′) + ℓ( x, y) ≥ ℓ(Pv). ▪\nHere are two observations about Dijkstra's Algorithm and its analysis.\nFirst, the algorithm does not always find shortest paths if some of the edges\ncan have negative lengths. (Do you see where the proof breaks?) Many\nshortest-path applications involve negative edge lengths, and a more\ncomplex algorithm—due to Bellman and Ford—is required for this case.\nWe will see this algorithm when we consider the topic of dynamic\nprogramming.\nThe second observation is that Dijkstra's Algorithm is, in a sense, even\nsimpler than we've described here. Dijkstra's Algorithm is really a\n“continuous” version of the standard breadth-first search algorithm for\ntraversing a graph, and it can be motivated by the followi ng physical\nintuition. Suppose the edges of G formed a syste m of pipes filled with\nwater , joined together at the nodes; each edge e has length ℓe and a fixed\ncross-sectional area. Now suppose an extra droplet of water falls at node s\nand starts a wave from s. As the wave expands out of node s at a constant"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 177})","('type', 'Document')"
"('page_content', ""speed, the expanding sphere of wavefront reaches nodes in increasing order\nof their distance from s. It is easy to believe (and also true) that the path\ntaken by the wavefront to get to any node v is a shortest path. Indeed, it is\neasy to see that this is exactly the path to v found by Dijkstra's Algorithm,\nand that the nodes are discovere d by the expanding water in the same order\nthat they are discovered by Dijkstra's Algorithm.\nImplementation and Running Time To conclude our discussion of\nDijkstra's Algorithm, we consider its running time. There are n - 1 iterations\nof the While loop for a graph with n nodes, as each iteration adds a new\nnode v to S. Selecting the correct node v efficiently is a more subtle issue.\nOne's first impression is that each iteration would have to consider each\nnode v ∊ S, and go through all the edges between S and v to deter mine the\nminimum mine=(u,v):u ∊S d(u) + ℓe, so that we can select the node v for which\nthis minimum is smallest. For a graph with m edges, computing all these\nminima can take O(m) time, so this would lead to an implementation that\nruns in O(mn) time.\nWe can do considerably better if we use the right data structures. First,\nwe will explicit ly maintain the values of the minima d′(v) = mine=(u,v):u ∊S\nd(u) + ℓe for each node v ∊ V - S, rather than recomputing them in each\niteration. We can further improv e the efficiency by keeping the nodes V - S\nin a priority queue with d′(v) as their keys. Priority queues were discussed\nin Chapter 2; they are data structures designed to maintain a set of n\nelements, each with a key. A priority queue can efficiently insert elements,\ndelete elements, change an element's key, and extract the element with the\nminimum key. We will need the third and fourth of the above operations:\nChangeKey  and ExtractMin .\nHow do we implement Dijkstra's Algorithm using a priority queue?\nWe put the nodes V in a priority queue with d′(v) as the key for v ∊ V. To\nselect the node v that should be added to the set S, we need the ExtractMin\noperation. To see how to update the keys, consider an iteration in which\nnode v is added to S, and let w ∉ S be a node that remains in the priority\nqueue. What do we have to do to update the value of d′(w)? If (v, w) is not\nan edge, then we don't have to do anything: the set of edges considered in\nthe minimum mine=(u,w):u ∊S d(u) + ℓe is exactly the same before and after\nadding v to S. If e′ = (v, w) ∊ E, on the other hand, then the new value for\nthe key is min( d′(w), d(v) + ℓe′). If d′(w) > d(v) + ℓe′ then we need to use the"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 178})","('type', 'Document')"
"('page_content', ""ChangeKey operation to decrease the key of node w appropriately . This\nChangeKey operation can occur  at most once per edge, when the tail of the\nedge e′ is added to S. In summary , we have the following result.\n(4.15)  Using a priority queue, Dijkstra's Algorithm can be implemented on a graph with n nodes and\nm edges to run in O (m) time, plus the time for n  ExtractMin and m  ChangeKey operations.\nUsing the heap-based priority queue implementation discussed in\nChapter 2, each priority queue operation can be made to run in O(log n)\ntime. Thus the overall time for the implementation is O(m log n).\n4.5 The Minimum Spanning Tree Problem\nWe now apply an exchange  argument in the context of a second\nfundamental problem on graphs: the Minimum Spanning T ree Problem.\nThe Problem\nSuppose we have a set of locations V = {v1, v2, …, vn}, and we want to\nbuild a communication network  on top of them. The network should be\nconnected— there should be a path between every pair of nodes—but\nsubject to this requirement, we wish to build it as cheaply as possible.\nFor certain pairs  (vi, vj), we may build a direct link between vi and vj\nfor a certain cost c(vi, vj) > 0. Thus we can represent the set of possible links\nthat may be built using a graph G = (V, E), with a positive cost ce associated\nwith each edge e = (vi, vj). The problem is to find a subse t of the edges T ⊆\nE so that the graph (V, T) is connected, and the total cost Σe ∊T ce is as small\nas possible. (We will assume that the full graph G is conn ected; otherwise,\nno solution is possible.)\nHere is a basic observation.\n(4.16)  Let T be a minimum-c ost solution to the network design problem defined above. Then  (V, T) is\na tree.\nProof. By definition, (V, T) must be connected; we show that it also will contain no cycles. Indeed,\nsuppose it contained  a cycle C, and let e be any edge on C. We claim that (V, T - {e}) is still\nconnected, since any path that previously used the edge e can now go “the long way” around the\nremainder of the cycle C instead. It follows that (V, T - {e}) is also a valid solution to the problem,\nand it is cheaper—a contradiction. ▪"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 179})","('type', 'Document')"
"('page_content', ""If we allow some edges to have 0 cost (that is, we assume only that the\ncosts ce are nonnegativ e), then a minimum-cost solution to the netw ork\ndesign problem may have extra  edges—edges that have 0 cost and could\noptionally be deleted. But even in this case, there is always a minimum-cost\nsolution that is a tree. Starting from any optimal solution, we could keep\ndeleting edges on cycles until we had a tree; with nonnegative edges, the\ncost would not increase during this process.\nWe will call a subset T ⊆ E a spanning tree of G if (V, T) is a tree.\nStatement (4.16) says that the goal of our network design problem can be\nrephrased as that of finding the cheapest spanning tree of the graph; for this\nreason, it is generally called the Minimum Spann ing Tree Problem.  Unless\nG is a very simple graph, it will have exponentially many dif ferent spanning\ntrees, whose structures may look very different from one another . So it is\nnot at all clear how to ef ficiently find the cheapest tree from among all these\noptions.\nDesigning Algorithms\nAs with the previous problems  we've seen, it is easy to come up with a\nnumber of natural greedy algorithms for the problem. But curiously , and\nfortunately , this is a case where many  of the first greedy algorithms one\ntries turn out to be correct: they each solve the problem optimally . We will\nreview a few of these algorithm s now and then discover , via a nice pair of\nexchange arguments, some of the underlying reasons for this plethora of\nsimple, optimal algorithms.\nHere are three greedy algorithms, each of which correctly finds a\nminimum spanning tree.\nOne simple algorithm starts without any edges at all and builds a\nspanning tree by successively inserting edges from E in order of\nincreasing cost. As we move through the edges in this order , we insert\neach edge e as long as it does not create a cycle when added to the\nedges we've already inserted. If, on the other hand, inserting e would\nresult in a cycle, then we simply discard e and continue. This approach\nis called Kruskal's Algorithm.\nAnother simple  greedy algorithm can be designed by analogy with\nDijkstra's Algorithm for paths, although, in fact, it is even simpler to"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 180})","('type', 'Document')"
"('page_content', ""specify than Dijkstra's Algorithm . We start with a root node s and try\nto greedily grow a tree from s outward. At each step, we simply add\nthe node that can be attached as cheaply as possibly to the partial tree\nwe already have.  \nMore concretely , we maintain a set S ⊆ V on which a spanning tree has\nbeen constructed so far. Initially , S = {s}. In each iteration, we grow S\nby one node, adding the node v that minimizes the “attachment  cost”\nmine=(u,v):u ∊S ce, and including the edge e = (u, v) that achieves this\nminimum in the spanning tree. This approach is called Prim's\nAlgorithm.\nFinally , we can design a greedy algorithm by running sort of a\n“backward” version of Kruskal's Algorithm. Specifically , we start with\nthe full graph (V, E) and begin deleting edges in order of decreasing\ncost. As we get to each edge e (starting from the most expensive), we\ndelete it as long as doing so would not actually disconnect the graph\nwe currently have. For want of a better name, this appro ach is\ngenerally called  the Reverse-Delete Algorithm  (as far as we can tell,\nit's never been named after a specific person).\nFigur e 4.9 Sample  run of the Minimum Spanning Tree Algorithms of (a)\nPrim and (b) Kruskal, on the same input. The first 4 edges added to the\nspanning tree are indicated by solid lines; the next edge to be added is a\ndashed line."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 181})","('type', 'Document')"
"('page_content', ""For example, Figure 4.9 shows the first four edges added by Prim's and\nKruskal's Algorithms respectively , on a geometric instance of the Minimum\nSpanning Tree Problem in which  the cost of each edge is propor tional to the\ngeometric distance in the plane.\nThe fact that each of these algorithms is guaranteed to produce an\noptimal solution  suggests a certain “robustness” to the Minimum Spanning\nTree Problem—there are many ways to get to the answer . Next we explore\nsome of the underlying reasons why so many different algorithms produce\nminimum-cost spanning trees.\nAnalyzing the Algorithms\nAll these algorithms work by repeatedly inserting or deleting edges from a\npartial solution. So, to analyze them, it would be useful to have in hand\nsome basic facts saying when it is “safe” to include an edge in the minimum\nspanning tree, and, correspondingly , when it is safe to eliminate an edge on\nthe grounds that it couldn't possibly be in the minimum spanning tree. For\npurposes of the analysis, we will make the simplifying assumption that all\nedge costs are distinct from one another (i.e., no two are equal). This\nassumption makes it easier to express the arguments that follow, and we\nwill show later in this section how this assumption can be easily eliminated.\nWhen Is It Safe to Include an Edge in the Minimum Spanning Tree? The\ncrucial fact abou t edge insertion is the following statement, which we will\nrefer to as the Cut Pr operty .\n(4.17)  Assume that all edge costs are distinct. Let S be any subset of nodes that is neither empty nor\nequal to all of V, and let edge e = (v, w) be the minimum-cost edge with one end in S and the other in\nV - S. Then every minimum spanning tr ee contains the edge e.\nProof. Let T be a spanning tree that does not contain e; we need to show that T does not have the\nminimum possible cost. We'll do this using an exchange argument: we'll identify an edge e′ in T that\nis more expensive than e, and with the propert y exchanging e for e′ results in another spanning tree.\nThis resulting spanning tree will then be cheaper than T, as desired.\nThe crux is therefore to find an edge that can be successfully exchanged with e. Reca ll that the\nends of e are v and w. T is a spanning tree, so there must be a path P in T from v to w. Starting at v,\nsuppose we follow the nodes of P in sequence; there is a first node w′ on P that is in V - S. Let v′ ∊ S\nbe the node just befor e w′ on P, and let e′ = (v′, w′ ) be the edge joining them. Thus, e′ is an edge  of T\nwith one end in S and the other in V - S.  See Figure 4.10  for the situation at this stage in the proof.\nIf we exchange e for e′, we get a set of edges T′ = T - {e′} ∪ {e}. We claim that T′ is a spanning\ntree. Clearly ( V, T′) is connected, since ( V, T) is connected, and any path in (V, T) that used the edge e′\n= (v′, w′) can now be “reroute d” in (V, T′) to follow  the portion of P from v′ to v, then the edge e, and\nthen the portion of P from w to w′. To see that (V, T′) is also acyclic, note that the only cycle in (V, T′"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 182})","('type', 'Document')"
"('page_content', ""∪ {e′}) is the one compos ed of e and the path P, and this cycle is not present in (V, T′) due to the\ndeletion of e′.\nWe noted above that the edge e′ has one end in S and the other in V - S. But e is the cheapest\nedge with this property , and so ce < ce′. (The inequality is strict since no two edges have the same\ncost.) Thus the total cost of T′ is less than that of T, as desired. ▪\nThe proof of (4.17) is a bit more subtle than it may first appear. To\nappreciate this subtlety , consider the following shorter but incorrect\nargument for (4.17). Let T be a spanning tree that does not contain e. Since\nT is a spanning tree, it must contain an edge f with one end in S and the\nother in V - S. Since e is the cheapest edge with this property , we have ce <\ncf, and hence T - [f} ∪ {e} is a spanning tree that is cheaper than T.\nFigur e 4.10 Swapping the edge e for the edge e′ in the spanning tree T, as\ndescribed in the proof of (4.17).\nThe problem with this argument is not in the claim that f exists, or that\nT - [f} ∪ {e} is cheaper than T. The difficulty is that T - [f} ∪ {e} may not\nbe a spanning tree, as shown by the example of the edge f in Figure 4.10.\nThe point is that we can't prove (4.17) by simply picking any edge in T that\ncrosses from S to V - S; some care must be taken to find the right one.\nThe Optimality of Kruskal's and Prim's Algorithms  We can now easily\nprove the optimality of both Kruskal's Algorithm and Prim's Algorithm."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 183})","('type', 'Document')"
"('page_content', ""The point is that both algorithms only include an edge when it is justified\nby the Cut Property (4.17).\n(4.18)  Kruskal's Algorithm pr oduces a minimum spanning tr ee of G.\nProof. Consider any edge e = (v,w) adde d by Kruskal's Algorithm, and let S be the set of all node s to\nwhich v has a path at the moment just before e is added. Clearly v ∊ S, but w ∉ S, since adding e\ndoes not create a cycle. Moreover , no edge  from S to V - S has been encountered  yet, since any such\nedge could have been added without creating a cycle, and hence would have been added by Kruskal's\nAlgorithm. Thus e is the cheapest edge with one end in S and the other in V - S, and so by (4.17) it\nbelongs to every minimum spanning tree.\nSo if we can show that the output (V, T) of Kruskal's Algorit hm is in fact a spanning tree of G,\nthen we will be done. Clearly (V, T) contains no cycles, since the algorithm is explicitly designed to\navoid creat ing cycles. Further , if (V, T) were not connected,  then there would exist a nonempty subset\nof nodes S (not equal  to all of V) such that there is no edge from S to V - S. But this contradicts the\nbehavior of the algorithm: we know that since G is connected, there is at least one edge between S\nand V - S, and the algorithm will add the first of these that it encounters. ▪\n(4.19)  Prim's Algorithm pr oduces a minimum spanning tr ee of G.\nProof. For Prim's  Algorithm , it is also very easy to show that it only adds edges belonging to every\nminimum spanning tree. Indeed, in each iteration of the algorithm, there is a set S ⊆ V on which a\npartial spanning tree has been constructed , and a node v and edge e are added  that minimize the\nquantity min e=(u,v):u ∊S ce. By definition, e is the cheapest edge with one end in S and the other end\nin V - S, and so by the Cut Property (4.17) it is in every minimum spanning tree.\nIt is also straightforw ard to show that Prim's Algorithm produces a spanning tree of G, and\nhence it produces a minimum spanning tree. ▪\nWhen Can We Guarantee an Edge Is Not in the Minimum Spanning\nTree? The crucial fact about edge deletion is the following statement, which\nwe will refer to as the Cycle Pr operty .\n(4.20)  Assume that all edge costs are distinct. Let C be any cycle in G, and let edge e = (v,w) be the\nmost expensive edge belonging to C. Then e does not belong to any minimum spanning tr ee of G.\nProof. Let T be a spanning tree that contains e; we need to show that T does not have the minimum\npossible cost. By analogy with the proof of the Cut Property (4.17), we'll do this with an exchange\nargument, swapping e for a cheaper edge in such a way that we still have a spanning tree.\nSo again the question  is: How do we find a cheaper edge that can be exchanged in this way with\ne? Let's begin by deleting e from T; this partitions the nodes into two components: S, containing node\nv; and V - S, containing node w. Now , the edge we use in place of e should have one end in S and the\nother in V - S, so as to stitch the tree back together .\nWe can find such an edge by following the cycle C. The edges of C other than e form, by\ndefinition, a path P with one end at v and the other at w. If we follow P from v to w, we begin in S and\nend up in V - S, so there is some edge e′ on P that crosses from S to V - S. See Figure 4.11 for an\nillustration of this.\nNow consi der the set of edges T′ = T - {e} ∪ {e′}. Arguing just as in the proof of the Cut\nProperty (4.17), the graph (V, T′) is connected and has no cycles, so T′ is a spann ing tree of G."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 184})","('type', 'Document')"
"('page_content', 'Moreover , since e is the most expensive edge on the cycle C, and e′ belongs to C, it must be that e′ is\ncheaper than e, and hence T′ is cheaper than T, as desired. ▪\nFigur e 4.11 Swapping the edge e′ for the edge e in the spanning tree T, as\ndescribed in the proof of (4.20).\nThe Optimality of the Reverse -Delete Algorithm  Now that we have the\nCycle Property (4.20), it is easy to prove that the Reverse-Delet e Algorithm\nproduces a minimum spanning  tree. The basic idea is analogous to the\noptimality proofs for the previous two algorithms: Reverse-Delete only\nadds an edge when it is justified by (4.20).\n(4.21)  The Reverse-Delete Algorithm pr oduces a minimum spanning tr ee of G.\nProof. Consider any edge e = (v,w) removed by Reverse-Delete. At the time that e is removed, it lies\non a cycle C; and since it is the first edge encountered by the algorithm in decreasing order of edge\ncosts, it must be the most expensive edge on C. Thus by (4.20), e does not belong to any minimum\nspanning tree.\nSo if we show that the output (V, T) of Reverse-Delete is a spanning tree of G, we will be done.\nClearly ( V, T) is connec ted, since the algorithm never removes an edge when this will disconnect the\ngraph. Now , suppose by way of contradiction that (V, T) contains a cycle C. Consider the most\nexpensive edge e on C, whic h would be the first one encountered  by the algorithm. This edge should\nhave been removed, since its removal would not have disconnected the graph, and this contradicts the\nbehavior of Reverse-Delete. ▪\nWhile we will not explore this further here, the combination of the Cut\nProperty (4.17) and the Cycle Property (4.20) implies that something even\nmore general is going on. Any algorithm that builds a spanning tree by\nrepeatedly inclu ding edges when justified by the Cut Property and deleting\nedges when justified by the Cycle Property—in any order at all—will end')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 185})","('type', 'Document')"
"('page_content', ""up with a minimum spanning tree. This principle allows one to design\nnatural greedy algorithms for this problem beyond the three we have\nconsidered here, and it provides an explanation for why so many greedy\nalgorithms produce optimal solutions for this problem.\nEliminating the Assumption that All Edge Costs Are Distinct  Thus far, we\nhave assumed that all edge costs are distinct, and this assumption has made\nthe analysis cleaner in a number of places. Now , suppose we are given an\ninstance of the Minimum Spanning Tree Problem in which certain edges\nhave the same cost how can we conclude that the algorithms we have been\ndiscussing still provide optimal solutions?\nThere turns out to be an easy way to do this: we simply take the\ninstance and perturb all edge costs by different, extremely small numbers,\nso that they all become distinct.  Now , any two costs that differed originally\nwill still have the same relative order , since the perturbations are so small;\nand since all of our algorithms are based on just comparing edge costs, the\nperturbations effectively serve simply as “tie-breakers” to resolve\ncomparisons among costs that used to be equal.\nMoreover , we claim that any minimum spanning tree T for the new,\nperturbed instan ce must have also been a minimum spanning tree for the\noriginal instance . To see this, we note that if T cost more than some tree T*\nin the original instance, then for small enough perturbations, the change in\nthe cost of T cannot be enough to make it better than T* under the new\ncosts. Thus, if we run any of our minimum spanning tree algorithms, using\nthe perturbed costs for compa ring edges, we will produce a minimum\nspanning tree T that is also optimal for the original instance.\nImplementing Prim's Algorithm\nWe next discuss how to implement the algorithms we have been\nconsidering so as to obtain good running-time bounds. We will see that both\nPrim's and Kruskal's Algorithms  can be implemented, with the right choice\nof data structures, to run in O(m log n) time. We will see how to do this for\nPrim's Algorithm here, and defer discussing the implementation of\nKruskal's Algor ithm to the next section. Obtaining a running time close to\nthis for the Reverse-Delete Algorithm is difficult, so we do not focus on\nReverse-Delete in this discussion."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 186})","('type', 'Document')"
"('page_content', ""For Prim's Algorithm, while the proof of correctness was quite\ndifferent from the proof for Dijkstra's Algorithm for the Shortest-Path\nAlgorithm, the implementations of Prim and Dijkstra are almost identical.\nBy analogy with Dijkstra's Algorithm, we need to be able to decide which\nnode v to add next to the growing set S, by maintaining  the attachment costs\na(v) = mine=(u,v):u ∊S ce for each node v ∊ V - S. As before, we keep the\nnodes in a prior ity queue with these attachment costs a(v) as the keys; we\nselect a node with an ExtractMin operation, and update the attac hment costs\nusing ChangeKey operations. There are n - 1 iterations in which we perform\nExtractMin, and we perform ChangeKey at most once for each edge. Thus\nwe have\n(4.22)  Using a priority queue, Prim's Algorithm can be implemented on a graph with n nodes and m\nedges to run in O (m) time, plus the time for n  ExtractMin, and m  ChangeKey operations.\nAs with Dijkstra 's Algorithm, if we use a heap-based priority queue we\ncan implement both ExtractMin and ChangeKey in O(log n) time, and so\nget an overall running time of O(m log n).\nExtensions\nThe minimum spanning tree problem emer ged as a particular formulation of\na broader network design  goal—f inding a good way to connect a set of sites\nby insta lling edges between them. A minimum spanning tree optimizes a\nparticular goal, achieving connectedness with minimum total edge cost. But\nthere are a range of further goals one might consider as well.\nWe may, for example, be concerned about point-to-point distances in\nthe spanning tree we build, and be willing to reduce these even if we pay\nmore for the set of edges. This raises new issues, since it is not hard to\nconstruct examp les where the minimum spanning tree does not minimize\npoint-to-point distances, suggesting some tension between these goals.\nAlternately , we may care more about the congestion  on the edges.\nGiven traffic that needs to be routed between pairs of nodes, one could seek\na spanni ng tree in which no single edge carries more than a certain amount\nof this traffic. Here too, it is easy to find cases in which the minimum\nspanning tree ends up concentrating a lot of traf fic on a single edge.\nMore generally , it is reasonable to ask whether a spanning tree is even\nthe right kind of solution to our network design problem. A tree has the"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 187})","('type', 'Document')"
"('page_content', 'property that destroying any one edge disconnects it, which means that trees\nare not at all robust against failures. One could instead make resilience an\nexplicit goal, for example seeki ng the cheapest connected network on the\nset of sites that remains connected after the deletion of any one edge.\nAll of these extensions lead to problems that are computationally much\nharder than the basic Minimum Spanning Tree problem, though due to their\nimportance in practice there has been research on good heuristics for them.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 188})","('type', 'Document')"
"('page_content', ""4.6 Implementing Kruskal's Algorithm: The\nUnion-Find Data Structure\nOne of the most basic graph problems is to find the set of connected\ncomponents. In Chapter 3  we discussed linear -time algorithms using BFS or\nDFS for finding the connected components of a graph.\nIn this section, we consider the scenario in which a graph evolves\nthrough the addition of edges. That is, the graph has a fixed population of\nnodes, but it grows over time by having edges appear between certain pairs\nof nodes. Our goal is to maintain  the set of connected components of such a\ngraph throughou t this evolution process. When an edge is added to the\ngraph, we don't want to have to recompute the connected comp onents from\nscratch. Rather , we will develop  a data structure that we call the Union-Find\nstructure, which will store a representation of the components in a way that\nsupports rapid searching and updating.\nThis is exactly the data struc ture needed to implement Kruskal's\nAlgorithm efficiently . As each edge e = (v, w) is considered, we need to\nefficiently find the identities of the connected components conta ining v and\nw. If these  compo nents are different, then there is no path from v and w, and\nhence edge e should be included; but if the components are the same, then\nthere is a v-w path on the edges already included, and so e should be\nomitted. In the event that e is included, the data structure should also\nsupport the efficient merging of the components of v and w into a single\nnew component.\nThe Problem\nThe Union-Find data structure allows us to maintain disjoint sets (such as\nthe components of a graph) in the following sense. Given a node u, the\noperation Find (u) will return the name of the set containing u. This\noperation can be used to test if two nodes u and v are in the same set, by\nsimply checkin g if Find( u) = Find( v). The data structure will also\nimplement an operation Union( A, B) to take two sets A and B and merge\nthem to a single set."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 189})","('type', 'Document')"
"('page_content', ""These operations can be used to maintain connected components of an\nevolving graph G = (V, E) as edges are added. The sets will be the\nconnected components of the graph. For a node u, the operation Find( u)\nwill return the name of the component containing u. If we add an edge ( u, v)\nto the graph, then we first test if u and v are already in the same connected\ncomponent (by testing if Find( u) = Find( v)). If they are not, then\nUnion(Find( u),Find( v)) can be used to merge the two components into one.\nIt is important to note that the Union-Find data structure can only be used to\nmaintain components of a graph as we add edges; it is not designed to\nhandle the effects of edge deleti on, which may result in a single component\nbeing “split” into two.\nTo summarize, the Union-Find data structure will support three\noperations.\nMakeUnionFind( S) for a set S will return a Union-Find data structure\non set S where all elements are in separate sets. This corresponds, for\nexample, to the connected components of a graph with no edges. Our\ngoal will be to implement MakeUnionFind in time O(n) where n = |S|.\nFor an element u ∊ S, the operation Find(u) will return the name of the\nset containing u. Our goal will be to implemen t Find( u) in O(log n)\ntime. Some implementations that we discuss will in fact take only O(1)\ntime for this operation.\nFor two sets A and B, the operation Union( A, B) will change the data\nstructure by mer ging the sets A and B into a single set. Our goal will be\nto implement Union in O(log n) time.\nLet's briefly discuss what we mean by the name  of a set—for example,\nas returned by the Find operation. There is a fair amount of flexibility in\ndefining the names of the sets; they should simply be consistent in the sense\nthat Find( v) and Find( w) should  return the same name if v and w belong to\nthe same set, and different names otherwise. In our implementations, we\nwill name each set using one of the elements it contains.\nA Simple Data Structure for Union-Find\nMaybe the simplest possible way to implement a Union-Find data structure\nis to maintain an array Component that contains the name  of the set\ncurrently containing each elem ent. Let S be a set, and assume it has n"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 190})","('type', 'Document')"
"('page_content', ""elements denote d {1,…, n}. We will set up an array Com ponent of size n,\nwhere Component[ s] is the name of the set containing s. To implement\nMakeUnionFind( S), we set up the array and initial ize it to Component [s] =\ns for all s ∊ S. This implementation makes Find( v) easy: it is a simple\nlookup and takes only O(1) time. However , Union( A, B) for two sets A and\nB can take as long as O(n) time, as we have to update the values of\nComponent[ s] for all elements in sets A and B.\nTo improve this bound, we will do a few simple optimizations. First, it\nis useful to explicitly maintain the list of elements in each set, so we don't\nhave to look through the whole array to find the elements that need\nupdating. Furthe r, we save some time by choosing the name for the union to\nbe the name of one of the sets, say, set A: this way we only have to update\nthe values Component[ s] for s ∊ B, but not for any s ∊ A. Of course, if set B\nis large, this idea by itself doesn 't help very much. Thus we add one further\noptimization. When set B is big, we may want to keep its name and change\nComponent[ s] for all s ∊ A instead. More generally , we can maintain an\nadditional array  size of length n, where size[ A] is the size of set A, and\nwhen a Union( A, B) operation is performed, we use the name of the larger\nset for the union . This way, fewer elements need to have their Component\nvalues updated.\nEven with these optimizations, the worst case for a Union operation is\nstill O(n) time; this happ ens if we take the union of two large sets A and B,\neach containing a constant fraction of all the elements. Howeve r, such bad\ncases for Union cannot happen very often, as the resulting set A ∪ B is even\nbigger . How can we make this statement more precise? Instead of bounding\nthe worst-case running time of a single Union operation, we can bound the\ntotal (or average) running time of a sequence of k Union operations.\n(4.23)  Consider the array implementation of the Union-Find data structur e for some set S of size n,\nwher e unions keep the name of the larger set. The Find operation takes O(1) time,\nMakeUnionFind( S) takes O (n) time, and any sequence of k  Union operations takes at most O(k log k)\ntime.\nProof. The claims about the MakeUnionFind and Find operations are easy to verify . Now consider a\nsequence of k Union operations. The only part of a Unio n operation that takes more than O(1) time is\nupdating the array Component. Instead of bounding the time spent on one Union operation, we will\nbound the total time spent updating Component[ v] for an element v throughout the sequence of k\noperations.\nRecall that we start the data structure from a state when all n elements are in their own separate\nsets. A single Union operation can consider at most two of these original one-element sets, so after\nany sequence of k Union operations, all but at most 2k elements of S have  been completely"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 191})","('type', 'Document')"
"('page_content', ""untouched. Now consider a particular element v. As v's set is involved in a sequence of Union\noperations, its size grows. It may be that in some of these Unions, the value of Component [v] is\nupdated, and in others it is not. But our convention is that the union uses the name of the lar ger set, so\nin every update to Component[ v] the size of the set containing v at least doubles. The size of v's set\nstarts out at 1, and the maximum possible size it can reach is 2k (since we argued above that all but at\nmost 2k elements are untouched by Union operations). Thus Component[ v] gets updated at most\nlog2(2k) times throughout the process. Moreover , at most 2k elements are involved in any Union\noperations at all, so we get a bound of O(k log k) for the time spent updating Component values in a\nsequence of k Union operations. ▪\nWhile this boun d on the avera ge running time for a sequenc e of k\noperations is good enough in many applications, including implementing\nKruskal's Algorithm, we will try to do better and reduce the worst-case  time\nrequired. We'll do this at the expense of raising the time required for the\nFind operation to O(log n).\nA Better Data Structure for Union-Find\nThe data structure for this alternate implementation uses pointers. Each\nnode v ∊ S will be contained in a record with an associated pointer to the\nname of the set that contains v. As before, we will use the elements of the\nset S as possible set names, naming each set after one of its elemen ts. For\nthe MakeUnionFind( S) operation, we initialize a recor d for each element v\n∊ S with a pointer that points to itself (or is defined as a null pointer), to\nindicate that v is in its own set.\nConsider a Union operation for two sets A and B, and assume that the\nname we used for set A is a node v ∊ A, while set B is name d after node u ∊\nB. The idea is to have either u or v be the name of the combined set; assume\nwe select v as the name. To indicate that we took the union of the two sets,\nand that the name of the union set is v, we simply update u's pointer to point\nto v. We do not update the pointers at the other nodes of set B.\nAs a result, for elements w ∊ B other than u, the name of the set they\nbelong to must be computed by following a sequence of pointers, first\nleading them to the “old name” u and then via the pointer from u to the\n“new name” v. See Figure 4.12 for what such a representation  looks like.\nFor example, the two sets in Figure 4.12 could be the outcome of the\nfollowing seque nce of Union operations: Union( w, u), Union( s, u), Union( t,\nv), Union( z, v), Union( i, x), Union( y, j), Union( x, j), and Union( u, v).\nThis pointer -based data structure implements Union in O(1) time: all\nwe have  to do is to update one pointer . But a Find operation is no longer"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 192})","('type', 'Document')"
"('page_content', 'constant time, as we have to follow a sequence of pointers through a history\nof old names the set had, in order to get to the current name. How long can\na Find( u) operation take? The number of steps needed is exactly the number\nof times the set containing node u had to change its name, that is, the\nnumber of times the Component[ u] array position would have been updated\nin our previous array representa tion. This can be as large as O(n) if we are\nnot careful with choosing set names. To reduce the time required for a Find\noperation, we will use the same optimization we used before: keep the name\nof the larger set as the name of the union. The sequence of Unions that\nproduced the data structure in Figure 4.12 followed this convention. To\nimplement this choice efficientl y, we will maintain an additional field with\nthe nodes: the size of the corresponding set.\nFigur e 4.12 A Union-Find data structure using pointers. The data structure\nhas only two sets at the moment, named after nodes v and j. The dashed\narrow from u to v is the result of the last Union operation. To answer a Find\nquery , we follow the arrows until we get to a node that has no outgoing\narrow . For example, answering the query Find( i) would involve  following\nthe arrows i to x, and then x to j.\n(4.24)  Consider the above pointer -based impleme ntation of the Union-Find data struct ure for some\nset S of size n, wher e unions keep the name of the larger set. A Union operation takes O(1) time,\nMakeUnionFind( S) takes O (n) time, and a  Find operation takes O (log n) time.\nProof. The statements about Union and MakeU nionFind are easy to verify . The time to evaluate\nFind( v) for a node v is the number of times the set containing node v changes its name during the\nprocess. By the convention that the union keeps the name of the larger set, it follows  that every time\nthe name of the set containing node v changes, the size of this set at least doubles. Since the set\ncontaining v starts  at size 1and is never larger than n, its size can double at most log2n times , and so\nthere can be at most log 2n name changes. ▪')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 193})","('type', 'Document')"
"('page_content', 'Further Improvements\nNext we will briefly discuss a natural optimization in the pointer-based\nUnion-Find data structure that has the effect of speeding up the Find\noperations. Stric tly speaking, this improvement will not be necessary for\nour purposes in this book: for all the applications of Unio n-Find data\nstructures that we consider , the O(log n) time per operation is good enough\nin the sense that further improvement in the time for operations would not\ntranslate to improvements in the overall running time of the algorithms\nwhere we use them. (The Union-Find operations will not be the only\ncomputational bottleneck in the running time of these algorithms.)\nTo motivate the improved version of the data structure, let us first\ndiscuss a bad case for the running time of the pointer -based Union-Find\ndata structure. First we build  up a structure where one of the Find\noperations takes about log n time. T o do this, we can repeatedly take Unions\nof equal-sized sets. Assume v is a node for which the Find( v) operation\ntakes about log n time. Now we can issue Find( v) repeatedly , and it takes\nlog n for each such call. Having to follow the same sequence of log n\npointers every time for finding  the name of the set containing v is quite\nredundant: after the first request  for Find( v), we already “know” the name x\nof the set containing v, and we also know that all other nodes that we\ntouched during our path from v to the current name also are all contained in\nthe set x. So in the improved implementation, we will compr ess the path we\nfollowed after every Find opera tion by resetting all pointers along the path\nto point to the current name of the set. No information is lost by doing this,\nand it makes subsequent Find operations run more quickly . See Figure 4.13\nfor a Union-Fi nd data structure and the result of Find( v) using path\ncompression.\nNow consider the running time of the operations in the resulting\nimplementation. As before, a Union operation takes O(1) time and\nMakeUnion-Find( S) takes O(n) time to set up a data structure for a set of\nsize n. How did the time required for a Find( v) operation change? Some\nFind operations can still take up to log n time; and for some Find operations\nwe actually increase the time, since after finding the name x of the set\ncontaining v, we have to go back through the same path of pointers from v\nto x, and reset each of these pointers to point to x directly . But this')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 194})","('type', 'Document')"
"('page_content', ""additional work  can at most double the time required, and so does not\nchange the fact that a Find takes at most O(log n) time. The real gain from\ncompression is in making subsequent calls to Find cheaper , and this can be\nmade precise by the same type of argument we used in (4.23): bounding the\ntotal time for a sequence of n Find operations , rather than the worst-case\ntime for any one of them. Although we do not go into the details here, a\nsequence of n Find operations employing compression requires an amount\nof time that is extremely close  to linear in n; the actual uppe r bound is\nO(nα(n)), where α(n) is an extremely  slow-growing function of n called the\ninverse Ackermann function.  (In particular , α(n) ≤ 4 for any value of n that\ncould be encountered in practice.)\nFigur e 4.13 (a) An instanc e of a Union-F ind data structure; and (b) the\nresult of the operation Find( v) on this structure, using path compression.\nImplementing Kruskal's Algorithm\nNow we'll use the Union-Fin d data structure to implement Kruskal's\nAlgorithm. First we need to sort the edges by cost. This takes time O(m log\nm). Since we have at most one edge between any pair of nodes, we have m\n≤ n2 and hence this running time is also O(m log n).\nAfter the sorting operation, we use the Union-Find data struc ture to\nmaintain the connected components of (V, T) as edges are added. As each\nedge e = (v,w) is considered, we compute Find(u) and Find( v) and test if\nthey are equal to see if v and w belong to different components. We use\nUnion(Find( u),Find( v)) to merge the two components, if the algorithm\ndecides to include edge e in the tree T."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 195})","('type', 'Document')"
"('page_content', ""We are doing a total of at most 2m Find and n - 1 Union operations\nover the course of Kruskal's Algorithm. We can use either (4.23) for the\narray-based implementation of Union-Find, or (4.24) for the pointer -based\nimplementation, to conclude that this is a total of O(m log n) time. (While\nmore efficient implementations of the Union-Find data structure are\npossible, this would not help the running time of Kruskal's Algorithm,\nwhich has an unavoidable O(m log n) term due to the initial sorting of the\nedges by cost.)\nTo sum up, we have\n(4.25)  Kruskal's Algorithm can be implemented on a graph with n nodes and m edges to run in O(m\nlog n) time.\n4.7 Clustering\nWe motivated the construction of minimum spanning trees through the\nproblem of finding a low-cost network connecting a set of sites. But\nminimum spann ing trees arise in a range of different settings, several of\nwhich appear on the surface to be quite different from one another . An\nappealing examp le is the role that minimum spanning trees play in the area\nof clustering .\nThe Problem\nClustering arises whenever one has a collection of objects—say , a set of\nphotographs, documents, or microor ganisms—that one is trying to classify\nor organize into coherent groups . Faced with such a situation, it is natural to\nlook first for measures of how similar or dissimilar each pair of objects is.\nOne common approach is to define a distance function  on the objects, with\nthe interpretatio n that objects at a larger distance from one another are less\nsimilar to each other . For points in the physical world, distance may\nactually be related to their physical distance; but in many applications,\ndistance takes on a much more abstract meaning. For exampl e, we could\ndefine the distance between two species to be the number of years since\nthey diverged in the course of evolution; we could define the distance"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 196})","('type', 'Document')"
"('page_content', ""between two images in a video stream as the number of corresponding\npixels at which their intensity values dif fer by at least some threshold.\nNow , given a distance function on the objects, the clustering problem\nseeks to divide them into groups so that, intuitively , objects within the same\ngroup are “close,” and objects in different groups are “far apart.” Starting\nfrom this vague set of goals, the field of clustering branches into a vast\nnumber of technically different approaches, each seeking to formalize this\ngeneral notion of what a good set of groups might look like.\nClusterings of Maximum Spacing  Minimum spann ing trees play a role in\none of the most basic formalizations, which we describe here. Suppose we\nare given a set U of n objects, labeled p1, p2, …, pn. For each pair, pi and pj,\nwe have  a numerical distance d(pi, pj). We require only that d(pi, pi) = 0;\nthat d(pi, pj) > 0 for distinct pi and pj; and that distances are symmetric: d(pi,\npj) = d(pj, pi).\nSuppose we are seeking to divide the objects in U into k groups, for a\ngiven parameter k. We say that a k-clustering  of U is a partition of U into k\nnonempty sets C1, C2, …, Ck. We define the spacing  of a k-clustering to be\nthe minimum distance between any pair of points lying in different clusters.\nGiven that we want points in different clusters to be far apart from one\nanother , a natural goal is to seek the k-clustering with the maximum\npossible spacing.\nThe question now becomes the following. There are exponentially\nmany different k-clusterings of a set U; how can we efficiently find the one\nthat has maximum spacing?\nDesigning the Algorithm\nTo find a cluster ing of maximum spacing, we consider growing  a graph on\nthe verte x set U. The connected components will be the clusters, and we\nwill try to bring nearby points together into the same cluster as rapidly as\npossible. (This way, they don't end up as points in different clusters that are\nvery close together .) Thus we start by drawing an edge between the closest\npair of points. W e then draw an edge between the next closest pair of points.\nWe continue adding edges between pairs of points, in order of increasing\ndistance d(pi, pj). In this way, we are growing a graph H on U edge by edge,\nwith connected components corresponding to clusters. Notice that we are"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 197})","('type', 'Document')"
"('page_content', ""only interested in the connected components of the graph H, not the full set\nof edges; so if we are about to add the edge (pi, pj) and find that pi and pj\nalready belong to the same cluster , we will refrain from adding the edge—\nit's not necessary , because it won't change the set of components. In this\nway, our graph-growing process  will never create a cycle; so H will actually\nbe a union of trees. Each time we add an edge that spans two distinct\ncomponents, it is as though we have merged the two corresponding clusters.\nIn the clustering  literature, the iterative merging of clusters in this way is\noften termed single-link clustering , a special case of hierar chical\nagglomerative clustering . (Agglomerative  here means that we combine\nclusters; single-link  means that we do so as soon as a single link joins them\ntogether .) See Figure 4.14  for an example of an instance with k = 3 clusters\nwhere this algorithm partitions the points into an intuitively natural\ngrouping.\nWhat is the connection to minimum spanning trees? It's very simple:\nalthough our graph-growing procedure was motivated by this cluster -\nmerging idea, our procedure is precisely Kruskal's Minimum Spanning Tree\nAlgorithm. We are doing exactly what Kruskal's Algorithm would do if\ngiven a graph G on U in which there was an edge of cost d(pi, pj) between\neach pair of nodes ( pi, pj). The only dif ference is that we seek a k-clustering,\nso we stop the procedure once we obtain k connected components.\nIn other words, we are running Kruskal's Algorithm but stopping  it just\nbefore it adds its last k - 1 edges. This is equivalent to taking the full\nminimum spanning tree T (as Kruskal's Algorithm would have produced it),\ndeleting the k - 1 most expensive edges (the ones that we never actually\nadded), and defining the k-clustering to be the resulting connected\ncomponents C1, C2, …, Ck. Thus, iteratively merging clust ers is equivalent\nto computing a minimum spanning tree and deleting the most expensive\nedges.\nAnalyzing the Algorithm\nHave we achieved our goal of producing clusters that are as spaced apart as\npossible? The following claim shows that we have.\nFigur e 4.14 An example of single-linkage clustering with k = 3 clusters.\nThe clusters are formed by adding edges between points in order of"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 198})","('type', 'Document')"
"('page_content', ""increasing distance.\n(4.26)  The components C1,C2,…,Ck formed by deleting the k - 1 most expensive edges of the\nminimum spanning tr ee T constitute a k-clustering of maximum spacing.\nProof. Let \n  denote the clustering C1, C2, …, Ck. The spacing of \n is precisely the lengt h d* of the\n(k - 1)st most expensive edge in the minimum spanning tree; this is the length of the edge that\nKruskal's Algorithm would have added next, at the moment we stopped it.\nNow consider some other k-clustering \n ′, which partitions U into nonempty sets C1′, C2′, …,\nC′k. We must show that the spacing of \n ′ is at most d*.\nSince the two clusterings \n  and \n ′ are not the same, it must be that one of our clusters Cr is not\na subset of any of the k sets C′s in \n′. Hence there are points pi,pj ∊ Cr that belong to different\nclusters in \n ′—say , pi ∊ C′s and pj ∊ Ct′ ≠ C′s.\nNow consi der the picture in Figure 4.15. Since pi and pj belong to the same component Cr, it\nmust be that Kruskal's Algorithm added all the edges of a pi-pj path P before we stopped it. In\nparticular , this means that each edge on P has length  at most d*. Now , we know that pi ∊ C′s but pj\n∉ C′s; so let p′ be the first node on P that does not belong  to C′s, and let p be the node on P that\ncomes just before p′. We have just argued that d(p,p′) ≤ d*, since the edge (p,p′) was added by\nKruskal's Algorithm. But p and p′ belong to different sets in the clustering \n ′, and hence the spacing\nof \n′ is at most d(p,p′) ≤ d*. This completes the proof. ▪\nFigur e 4.15  An illustration of the proof of (4.26), showing that the spacing\nof any other clustering can be no larger than that of the clustering found by\nthe single-linkage algorithm."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 199})","('type', 'Document')"
"('page_content', ""4.8 Huffman Codes and Data Compression\nIn the Shortest-Path and Minim um Spanning Tree Problems, we've seen\nhow greedy algorithms can be used to commit to certain parts of a solution\n(edges in a graph, in these cases), based entirely on relatively short-sighted\nconsiderations. We now consider a problem in which this style of\n“committing” is carried out in an even looser sense: a greedy rule is used,\nessentially , to shrink the size of the problem instance, so that an equivalent\nsmaller problem  can then be solved by recursion. The greedy operation here\nis prove d to be “safe,” in the sense that solving the smaller instance still\nleads to an optimal solution for the original instance, but the global\nconsequences of the initial greedy decision do not become fully apparent\nuntil the full recursion is complete.\nThe problem itself is one of the basic questions in the area of data\ncompr ession,  an area that forms part of the foundations for digital\ncommunication.\nThe Problem\nEncoding Symb ols Using Bits Since computers ultimately operate on\nsequences of bits (i.e., sequences  consisting only of the symbols 0 and 1),\none needs encoding schemes that take text written in richer alphabets (such\nas the alphabets underpinning human languages) and converts this text into\nlong strings of bits."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 200})","('type', 'Document')"
"('page_content', ""The simplest way to do this would be to use a fixed number of bits for\neach symbol in the alphabet, and then just concatenate the bit strings for\neach symbol to form the text. To take a basic example, suppose we wanted\nto encod e the 26 letters of Engl ish, plus the space (to separate words) and\nfive punctuation characters: comma, period, question mark, exclamation\npoint, and apostrophe. This would give us 32 symbols in total to be\nencoded. Now , you can form 2b differen t sequences out of b bits, and so if\nwe use 5 bits per symbol, then we can encode 25 = 32 symbols—just\nenough for our purposes. So, for example, we could let the bit string 00000\nrepresent a, the bit string 00001 represent b, and so forth up to 11111, which\ncould represent the apostrophe . Note that the mapping of bit strings to\nsymbols is arbitrary; the point is simply that five bits per symbol is\nsufficient. In fact, encoding schemes like ASCII work precisely this way,\nexcept that they use a larger number of bits per symbol so as to handle\nlarger character  sets, including capital letters, parentheses, and all those\nother special symbols you see on a typewriter or computer keyboard.\nLet's think about our bare-bon es example with just 32 symb ols. Is\nthere anything more we could ask for from an encoding scheme? We\ncouldn't ask to encode each symbol using just four bits, since 24 is only 16\n—not enough for the number of symbols we have. Neverthel ess, it's not\nclear that over large stretches of text, we really need to be spending an\naverage  of five bits per symbol. If we think about it, the letters in most\nhuman alphabets do not get used equally frequently . In English, for\nexample, the letters e, t, a, o, i, and n get used much more frequently than q,\nj, x, and z (by more than an order of magnitude). So it's really a tremendous\nwaste to translat e them all into the same number of bits; instead we could\nuse a small number of bits for the frequent letters, and a larger number of\nbits for the less frequent ones, and hope to end up using fewer than five bits\nper letter when we average over a long string of typical text.\nThis issue of reducing the average number of bits per letter is a\nfundamental problem in the area of data compr ession . When large files\nneed to be shipp ed across communication networks, or stored on hard disks,\nit's important to represent them  as compactly as possible, subject to the\nrequirement that a subsequent reader of the file should be able to correctly\nreconstruct it. A huge amount of research is devoted to the design of\ncompr ession algorithms  that can take files as input and reduce their space\nthrough ef ficient encoding schemes."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 201})","('type', 'Document')"
"('page_content', ""We now describe one of the fundamental ways of formulati ng this\nissue, building up to the questi on of how we might construct the optimal\nway to take advantage of the nonuniform frequencies of the letters. In one\nsense, such an optimal solution is a very appealing answer to the problem of\ncompressing data: it squeezes all the available gains out of nonuniformities\nin the frequencies. At the end of the section, we will discuss how one can\nmake further progress in compression, taking advantage of features other\nthan nonuniform frequencies.\nVariable-Length Encoding Schemes  Before the Internet, before the digital\ncomputer , before the radio and telephone, there was the telegraph.\nCommunicating by telegraph was a lot faster than the contemporary\nalternatives of hand-delivering messages by railroad or on horseback. But\ntelegraphs were only capable of transmitting pulses down a wire, and so if\nyou wanted to send a message, you needed a way to encode the text of your\nmessage as a sequence of pulses.\nTo deal with this issue, the pioneer of telegraphic communi cation,\nSamuel Morse,  developed Morse code , translating each letter into a\nsequence of dots (short pulses) and dashes  (long pulses). For our purposes,\nwe can think of dots and dashes as zeros and ones, and so this is simply a\nmapping of symbols into bit strings, just as in ASCII. Morse understood the\npoint that one could communic ate more efficiently by encoding frequent\nletters with short strings, and so this is the approach he took. (He consulted\nlocal printing presses to get frequency estimates for the letters in English.)\nThus, Morse code maps e to 0 (a single dot), t to 1 (a single dash), a to 01\n(dot-dash), and in general maps more frequent letters to shorter bit strings.\nIn fact, Morse code uses such short strings for the letters that the\nencoding of words becomes ambiguous. For example, just using what we\nknow about the encoding of e, t, and a, we see that the string 0101 could\ncorrespond to any of the sequences of letters eta, aa, etet, or aet. (There are\nother possibiliti es as well, involving other letters.) To deal with this\nambiguity , Morse code transmissions involve short pauses between letters\n(so the encoding of aa would actually be dot-dash-pause-dot-dash-pause).\nThis is a reaso nable solution—using very short bit string s and then\nintroducing pauses—but it means that we haven't actually encoded the\nletters using just 0 and 1; we've actually encoded it using a three-letter\nalphabet of 0, 1, and “pause.” Thus, if we really needed to encode"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 202})","('type', 'Document')"
"('page_content', ""everything using  only the bits 0 and 1, there would need to be some further\nencoding in which the pause got mapped to bits.\nPrefix Codes  The ambiguity problem in Morse code arises because there\nexist pairs of letters where the bit string that encodes one letter is a prefix of\nthe bit string that encodes another . To eliminate this problem, and hence to\nobtain an encoding scheme that has a well-defined interpretation for every\nsequence of bits, it is enough to map letters to bit strings in such a way that\nno encoding is a prefix of any other .\nConcretely , we say that a prefix code  for a set S of letters is a function γ\nthat maps each letter x ∊ S to some sequen ce of zeros and ones, in such a\nway that for distinct x,y ∊ S, the sequence γ(x) is not a prefix of the\nsequence γ(y).\nNow suppose we have a text consisting of a sequence of letters x1x2x3\n··· xn. We can convert this to a sequence of bits by simply encoding each\nletter as a bit sequence using  γ and then conc atenating all these bit\nsequences together: γ(x1)γ(x2) ··· γ(xn). If we then hand this message to a\nrecipient who knows the functio n γ, they will be able to reconstruct the text\naccording to the following rule.\nScan the bit sequence from left to right.\nAs soon  as you've seen enough bits to match the encoding of some\nletter , output this as the first letter of the text. This must be the correct\nfirst letter , since no shorter or longer prefix of the bit sequence could\nencode any other letter .\nNow delete the corresponding set of bits from the front of the message\nand iterate.\nIn this way, the recipient can produce the correct set of letters without our\nhaving to resort to artificial devices like pauses to separate the letters.\nFor exam ple, suppose we are trying to encode the set of five letters S =\n{a,b,c,d, e }. The encoding γ1 specified by"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 203})","('type', 'Document')"
"('page_content', ""is a prefix code, since we can check that no encoding is a prefix of any\nother . Now, for example, the string cecab  would be encoded as\n001000001 1101. A recipient of this message, knowing γ1, would begin\nreading from left to right. Neithe r 0 nor 00 encodes a letter , but 001 does, so\nthe recipient concludes that the first letter is c. This is a safe decision, since\nno longer sequence of bits beginning with 001 could encode  a different\nletter . The recipient now iterates on the rest of the message, 000001 1101;\nnext they will conclude that the second letter is e, encoded as 000.\nOptimal Prefix Codes  We've been doing all this because some letters are\nmore frequent than others, and we want to take advantage of the fact that\nmore frequent letters can have shorter encodings. To make this objective\nprecise, we now introduce some notation to express the frequencies of\nletters.\nSuppose that for each letter x ∊ S, there is a freque ncy fx, representing\nthe fraction of letters in the text that are equal to x. In other words,\nassuming there are n letters total, nfx of these letters are equal to x. We\nnotice that the frequencies sum to 1; that is, Σx ∊S fx = 1.\nNow , if we use a prefix code γ to encode the given text, what is the\ntotal length of our encoding? This is simply the sum, over all letters x ∊ S,\nof the number of times x occurs times the length of the bit string γ(x) used\nto encode x. Using | γ(x)| to denote the length γ(x), we can write this as\nDropping the leading coefficien t of n from the final expression gives us\nΣx ∊s fx|γ(x)|, the average  number of bits required per letter . We denote this"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 204})","('type', 'Document')"
"('page_content', 'quantity by ABL( γ).\nTo continue the earlier examp le, suppose we have a text with the\nletters S = {a, b, c, d, e }, and their frequencies are as follows:\nThen the averag e number of bits per letter using the prefix code γ1 defined\npreviously is\nIt is interesting to compare this to the average number of bits per letter\nusing a fixed-length encoding. (Note that a fixed-length encoding is a prefix\ncode: if all letters have encodings of the same length, then clearly no\nencoding can be a prefix of any other .) With a set S of five letters, we would\nneed three bits per letter for a fixed-length encoding, since two bits could\nonly encode four letters. Thus, using the code γ1 reduces the bits per letter\nfrom 3 to 2.25, a savings of 25 percent.\nAnd, in fact, γ1 is not the best we can do in this example. Consider the\nprefix code γ2 given by\nThe average number of bits per letter using γ2 is')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 205})","('type', 'Document')"
"('page_content', ""So now it is natural to state the underlying question. Given an alphabet\nand a set of frequencies for the letters, we would like to produ ce a prefix\ncode that is as efficient as possible—namely , a prefix code that minimizes\nthe average number of bits per letter ABL( γ) = Σx ∊S fx|γ(x)|. We will call\nsuch a prefix code optimal.\nDesigning the Algorithm\nThe search space for this problem is fairly complicated; it includes all\npossible ways of mapping letters to bit strings, subject to the defining\nproperty of prefix codes. For alphabets consisting of an extremely small\nnumber of letters, it is feasible to search this space by brute force, but this\nrapidly becomes infeasible.\nWe now describe a greedy method to construct an optimal prefix code\nvery efficiently . As a first step, it is useful to develop a tree-bas ed means of\nrepresenting prefix codes that exposes their structure more clearly than\nsimply the lists of function values we used in our previous examples.\nRepresenting Prefix Codes Using Binary Trees Suppose we take a rooted\ntree T in which each node that is not a leaf has at most two children; we call\nsuch a tree a binary tr ee. Further suppose that the numbe r of leaves is equal\nto the size of the alphabet S, and we label each leaf with a distinct letter in\nS.\nSuch a labeled binary tree T naturally describes a prefix code, as\nfollows. For each letter x ∊ S, we follow the path from the root to the leaf\nlabeled x; each time the path goes from a node to its left child, we write\ndown a 0, and each time the path goes from a node to its right child, we\nwrite down a 1. W e take the resulting string of bits as the encoding of x.\nNow we observe\n(4.27)  The encoding of S constructed fr om T is a pr efix code.\nProof. In order for the encoding of x to be a prefix of the encoding of y, the path from the root to x\nwould have to be a prefix of the path from the root to y. But this is the same as saying that x would lie\non the path from the root to y, which isn't possible if x is a leaf. ▪\nThis relationship  between binary trees and prefix codes works in the\nother direction as well. Given a prefix code γ, we can build a binary tree\nrecursively as follows. We start with a root; all letters x ∊ S whose"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 206})","('type', 'Document')"
"('page_content', 'encodings begin  with a 0 will be leaves in the left subtree of the root, and\nall letters y ∊ S whose encodings begin with a 1 will be leaves in the right\nsubtree of the root. We now build these two subtrees recursively using this\nrule.\nFor example, the labeled tree in Figure 4.16(a)  corresponds to the\nprefix code γ0 specified by\nTo see this, note that the leaf labeled a is obtained by simply taking the\nright-hand edge out of the root (resulting in an encoding of 1); the leaf\nlabeled e is obtained by taking three successive left-hand edges starting\nfrom the root; and analogous explanations apply for b, c, and d. By similar\nreasoning, one can see that the labeled tree in Figure 4.16(b)  corresponds to\nthe prefix code γ1 defined earlier , and the labeled tree in Figure 4.16(c)\ncorresponds to the prefix code γ2 defined earlier . Note also that the binary\ntrees for the two prefix codes γ1 and γ2 are identical in structure; only the\nlabeling of the leaves is differen t. The tree for γ0, on the other hand, has a\ndifferent structure.\nThus the search for an optimal prefix code can be viewed as the search\nfor a binary tree T, together with a labeling of the leaves of T, that\nminimizes the average number  of bits per letter . Moreover , this average\nquantity has a natural interpreta tion in the terms of the structure of T: the\nlength of the encoding of a letter  x ∊ S is simply the length of the path from\nthe root to the leaf labeled x. We will refer to the length of this path as the\ndepth  of the leaf, and we will denote the depth of a leaf v in T simply by\ndepthT(v). (As two bits of notational convenience, we will drop the\nsubscript T when it is clear  from context, and we will often use a letter x ∊\nS to also denote the leaf that is labeled by it.) Thus we are seeking the\nlabeled tree that minimizes the weighted average of the depths of all leaves,')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 207})","('type', 'Document')"
"('page_content', ""where the averag e is weighted by the frequencies of the letters that label the\nleaves: Σx ∊S fx · depthT(x). We will use ABL( T) to denote this quantity .\nFigur e 4.16 Parts (a), (b), and (c) of the figure depict three different prefix\ncodes for the alphabet S = {a, b, c, d, e }.\nAs a first step in considering algorithms for this problem, let's note a\nsimple fact abou t the optimal tree. For this fact, we need a definition: we\nsay that a binary tree is full if each node that is not a leaf has two children.\n(In other words, there are no nodes with exactly one child.) Note that all\nthree binary trees in Figure 4.16  are full.\n(4.28)  The binary tr ee corr esponding to the optimal pr efix code is full.\nProof. This is easy to prove  using an exchange argument. Let T denote the binary tree corresponding\nto the optimal prefix code, and suppose it contains a node u with exact ly one child v. Now  conv ert T\ninto a tree T′ by replacing node u with v.\nTo be precise, we need to distinguish two cases. If u was the root of the tree, we simply delete\nnode u and use v as the root. If u is not the root, let w be the parent of u in T. Now we delete node  u\nand make v be a child of w in place of u. This change decreases the number of bits needed to encode\nany leaf in the subtree rooted at node u, and it does not affect other leaves. So the prefix code\ncorresponding to T′ has a smaller average number of bits per letter than the prefix code for T,\ncontradicting the optimality of T. ▪"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 208})","('type', 'Document')"
"('page_content', ""A First  Attempt: The Top-Down Approach  Intuitively , our goal is to\nproduce a labeled binary tree in which the leaves are as close to the root as\npossible. This is what will give us a small average leaf depth.\nA natura l way to do this would be to try building a tree from the top\ndown by “packi ng” the leaves as tightly as possible. So suppose we try to\nsplit the alphabet S into two sets S1 and S2, such that the total frequency of\nthe letters in each set is exactly  ½. If such a perfect split is not possible,\nthen we can try for a split that is as nearly balanced as possib le. We then\nrecursively construct prefix codes for S1 and S2 independently , and make\nthese the two subtrees of the root. (In terms of bit strings, this would mean\nsticking a 0 in front of the encod ings we produce for S1, and sticking a 1 in\nfront of the encodings we produce for S2.)\nIt is not entirely  clear how we should concretely define this “nearly\nbalanced” split of the alphabet, but there are ways to make this precise. The\nresulting encodi ng schemes are called Shannon-Fano  codes, named after\nClaude Shannon and Robert Fano, two of the major early figures in the area\nof information theory , which deals with representing and encoding digital\ninformation. These types of prefix codes can be fairly good in practice, but\nfor our present purposes they represent a kind of dead end: no version of\nthis top-down splitting strategy is guaranteed to always produce  an optimal\nprefix code. Consider again our example with the five-letter alphabet S =\n{a,b,c,d,e } and frequencies\nThere is a unique way to split the alphabet into two sets of equal frequency:\n{a,d} and {b,c,e }. For {a,d}, we can use a single bit to encode each. For\n{b,c, e ], we need to continue recursively , and again there is a unique way to\nsplit the set into two subsets  of equal frequency . The resulting code\ncorresponds to the code γ1, given by the labeled tree in Figure 4.16(b) ; and\nwe've already seen that γ1 is not as efficient as the prefix code γ2\ncorresponding to the labeled tree in Figure 4.16(c) .\nShannon and Fano knew that their approach did not always yield the\noptimal prefix code, but they didn't see how to compute the optimal code"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 209})","('type', 'Document')"
"('page_content', ""without brute-force search. The problem was solved a few years later by\nDavid Huffman , at the time a graduate student who learned about the\nquestion in a class taught by Fano.\nWe now describe the ideas leading up to the greedy approach that\nHuffman discovered for producing optimal prefix codes.\nWhat If We Knew the Tree Structure of the Optimal Prefi x Code?  A\ntechnique that is often helpful in searching for an efficient algorithm is to\nassume, as a thought experiment, that one knows something partial about\nthe optimal solution, and then to see how one would make use of this partial\nknowledge in finding the complete solution. (Later , in Chapter 6, we will\nsee in fact that this technique is a main underpinning of the dynamic\nprogramming  approach to designing algorithms.)\nFor the current problem, it is useful to ask: What if someone gave us\nthe binary tree T* that corresponded to an optimal prefix code, but not the\nlabeling of the leaves? To complete the solution, we would need to figure\nout which letter should label which leaf of T*, and then we'd have our code.\nHow hard is this?\nIn fact, this is quite easy. We begin by formulating the following basic\nfact.\n(4.29)  Suppose that u and v are leaves of T*, such that depth (u) < depth (v). Further , suppose that in a\nlabeling of T* corresponding to an optim al prefix code, leaf u is labeled with y ∊ S and leaf v is\nlabeled with z  ∊ S. Then f y ≥ fz.\nProof. This has a quick proof using an exchange argument. If fy < fz, then consider the code obtained\nby exchang ing the labels at the nodes u and v. In the expression for the average number of bits per\nletter , ABL( T*) = Σx ∊S fx depth( x), the effect of this exchange is as follows: the multiplier on fy\nincreases (from depth( u) to depth( v)), and the multiplier on fz decreases by the same amount (from\ndepth( v) to depth(u)).\nThus the change to the overall sum is (depth( v) - depth( u))(fy - fz). If fy < fz, this change is a\nnegative number , contradicting the supposed optimality of the prefix code that we had before the\nexchange. ▪\nWe can see the idea behind (4.29) in Figure 4.16(b) : a quick way to see\nthat the code here is not optimal is to notice that it can be improved by\nexchanging the positions of the labels c and d. Having  a lower -frequency\nletter at a strictly smaller depth than some other higher -frequency letter is\nprecisely what (4.29) rules out for an optimal solution.\nStatement (4.29) gives us the following intuitively natural, and\noptimal, way to label the tree T* if someone should give it to us. We first"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 210})","('type', 'Document')"
"('page_content', ""take all leaves of depth 1 (if there are any) and label them with the highest-\nfrequency letters in any order . We then take all leaves of depth 2 (if there\nare any) and label them with the next-highest-frequency letters in any order .\nWe continue through the leaves in order of increasing depth, assigning\nletters in order of decreasing frequency . The point is that this can't lead to a\nsuboptimal labeling of T*, since any supposedly better labeling would be\nsusceptible to the exchange in (4.29). It is also crucial to note that, among\nthe labels we assign to a block of leaves all at the same depth, it doesn't\nmatter which label we assign to which leaf. Since the depths are all the\nsame, the corresponding multip liers in the expression Σx ∊S fx|γ(x)| are the\nsame, and so the choice of assignment among leaves of the same depth\ndoesn't af fect the average number of bits per letter .\nBut how is all this helping us? We don't have the structure of the\noptimal tree T*, and since there are exponentially many possible trees (in\nthe size of the alphabet), we aren't going to be able to perform a brute-force\nsearch over all of them.\nIn fact, our reasoning about T* becomes very useful if we think not\nabout the very beginning of this labeling process, with the leaves of\nminimum depth,  but about the very end, with the leaves of maximum depth\n—the ones that receive the letters with lowest frequency . Specifically ,\nconsider a leaf v in T* whose  depth is as large as possible. Leaf v has a\nparent u, and by (4.28) T* is a full binary  tree, so u has another child w. We\nrefer to v and w as siblings,  since they have a common parent. Now , we\nhave\n(4.30)  w is a leaf of T*.\nProof. If w were not a leaf, there would be some leaf w′ in the subtree below it. But then w′ would\nhave a depth greater than that of v, contradicti ng our assumption that v is a leaf of maximum depth in\nT*. ▪\nSo v and w are sibling leaves that are as deep as possible in T*. Thus\nour level-by-lev el process of labeling T*, as justified by (4.29), will get to\nthe level containing v and w last. The leaves  at this level will get the lowest-\nfrequency letters . Since we have  already argued that the order in which we\nassign these letters to the leaves within this level doesn't matter , there is an\noptimal labeling in which v and w get the two lowest-frequency letters of\nall.\nWe sum this up in the following claim."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 211})","('type', 'Document')"
"('page_content', '(4.31)  There is an optimal prefix code, with corresponding tree T*, in which the two lowest-f requency\nletters ar e assigned to leaves that ar e siblings in T*.\nFigur e 4.17  There is an optimal solution in which the two lowest-frequency\nletters label sibling leaves; deleting them and labeling their parent with a\nnew letter having the combined frequency yields an instance with a smaller\nalphabet.\nAn Algorithm to Construct an Optimal Prefix Code  Suppose that y* and z*\nare the two lowest-frequency letters in S. (We can break ties in the\nfrequencies arbitrarily .) Statement (4.31) is important because it tells us\nsomething about where y* and z* go in the optimal solution; it says that it is\nsafe to “lock them together” in thinking about the solution, because we\nknow they end up as sibling leaves below a common parent. In effect, this\ncommon parent acts like a “meta-letter” whose frequency is the sum of the\nfrequencies of y* and z*.\nThis directly suggests an algorithm: we replace y* and z* with this\nmeta-letter , obtaining an alphabet that is one letter smaller . We recursively\nfind a prefix code for the small er alphabet, and then “open up” the meta-\nletter back into y* and z* to obtain a prefix code for S. This recursive\nstrategy is depicted in Figure 4.17 .\nA concrete description of the algorithm is as follows.\nTo construct a prefix code for an alphabet S, with given frequencies:\nIf S has two letters then\nEncode one letter using 0 and the other letter using 1\nElse\nLet y* and z* be the two lowest-frequency letters')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 212})","('type', 'Document')"
"('page_content', ""Form a new alphabet S′ by deleting y* and z* and replacing them  with a new letter ω of\nfrequency fy* + fz*\nRecursively construct a prefix code γ′ for S′, with tree T′\nDefine a prefix code for S as follows:\nStart with T′\nTake the leaf labeled ω and add two children below it labeled y* and z*\nEndif\nWe refer to this as Huffman's Algorithm,  and the prefix code that it\nproduces for a given alphabet is accordingly referred to as a Huffman code.\nIn general, it is clear that this algorithm always terminates, since it simply\ninvokes a recursive call on an alphabet that is one letter smaller . Moreover ,\nusing (4.31), it will not be difficult to prove that the algorithm in fact\nproduces an optimal prefix code. Before doing this, however , we pause to\nnote some further observations about the algorithm.\nFirst let's consider the behavior of the algorithm on our sample\ninstance with S = {a, b, c, d, e } and frequencies\nThe algorithm would first merge d and e into a single letter—let's\ndenote it (de)—of frequency .18 + .05 = .23. We now have an instance of\nthe problem on the four letters S′ = {a, b, c, (de)}. The two lowest-\nfrequency letters in S′ are c and ( de), so in the next step we merge these into\nthe single letter (cde) of frequency .20 + .23 = .43. This gives us the three-\nletter alphabet {a, b, (cde)}. Next we merge a and b, and this gives us a\ntwo-letter alphabet, at which point we invoke the base case of the recursion.\nIf we unfold the result back through the recursive calls, we get the tree\npictured in Figure 4.16(c) .\nIt is interesting to note how the greedy rule underlying Huffman's\nAlgorithm—the merging of the two lowest-frequency letters—fits into the\nstructure of the algorithm as a whole. Essentially , at the time we merge\nthese two letters, we don't know  exactly how they will fit into the overall\ncode. Rather, we simply commit to having them be children of the same\nparent, and this is enough to produce a new, equivalent problem with one\nless letter ."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 213})","('type', 'Document')"
"('page_content', ""Moreover , the algorithm forms a natural contrast with the earlier\napproach that led to suboptima l Shannon-Fano codes. That approach was\nbased on a top-down strategy that worried first and foremost about the top-\nlevel split in the binary tree—namely , the two subtrees directl y below the\nroot. Huffman's Algorithm, on the other hand, follows a bottom-up\napproach: it focuses on the leaves representing the two lowest-frequency\nletters, and then continues by recursion.\nAnalyzing the Algorithm\nThe Optimality of the Algorithm  We first prove the optimality of\nHuffman's Algorithm. Since the algorithm operates recursively , invoking\nitself on smaller and smaller alphabets, it is natural to try establishing\noptimality by induction on the size of the alphabet. Clearly it is optimal for\nall two-letter alphabets (since it uses only one bit per letter). So suppose by\ninduction that it is optimal for all alphabets of size k - 1, and consider an\ninput instance consisting of an alphabet S of size k.\nLet's quickly recap the behavior of the algorithm on this instance. The\nalgorithm merges the two lowe st-frequency letters y*,z*  ∊ S into a single\nletter ω, calls itself recursively on the smaller alphabet S′ (in which y* and\nz* are replaced by ω), and by inducti on produces an optimal prefix code for\nS′, represen ted by a labeled binary  tree T′. It then extends this into a tree T\nfor S, by attac hing leaves labeled y* and z* as child ren of the node in T′\nlabeled ω.\nThere is a close relationship between ABL( T) and ABL( T′). (Note that\nthe former quantity is the averag e number of bits used to encode letters in S,\nwhile the latter quantity is the average number of bits used to encode letters\nin S′.)\n(4.32)  ABL( T′) = ABL( T) - fω.\nProof. The depth  of each letter x other than y*,z*  is the same in both T and T′. Also , the depths of y*\nand z* in T are each one greater than the depth of ω in T′. Using this, plus the fact that fω = fy* +\nfz**, we have"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 214})","('type', 'Document')"
"('page_content', ""Using this, we now prove optimality as follows.\n(4.33)  The Huffman code for a given alphabet achieves the minimum average number of bits per\nletter of any pr efix code.\nProof. Suppose by way of contradiction that the tree T produced by our greedy algorithm is not\noptimal. This means that there is some labeled binary tree Z such that ABL( Z) < ABL( T); and by\n(4.31), there is such a tree Z in which the leaves representing y* and z* are siblings.\nIt is now easy to get a contradiction, as follows. If we delete the leaves labeled y* and z* from Z,\nand label their forme r parent with ω, we get a tree Z′ that define s a prefix code for S′. In the same\nway that T is obtained from T′, the tree Z is obtained from Z′ by adding leaves for y* and z* below ω;\nthus the identity in (4.32) applies to Z and Z′ as well: ABL( Z′) = ABL( Z) - fω.\nBut we have assumed  that ABL( Z) < ABL( T); subtracting fω from both sides of this inequality\nwe get ABL( Z′) < ABL( T′), which contradicts the optimality of T′ as a prefix code for S′. ▪\nImplementation and Running Time It is clear that Huffman's Algorithm\ncan be made to run in polynom ial time in k, the number of letters in the\nalphabet. The recursive calls of the algorithm define a sequen ce of k - 1\niterations over smaller and smal ler alphabets, and each iteration except the\nlast consists simply of identifying the two lowest-frequency  letters and\nmerging them into a single letter that has the combined frequency . Even\nwithout being careful about the implementation, identifying the lowest-\nfrequency letters  can be done in a single scan of the alphabet, in time O(k),\nand so summing this over the k - 1 iterations gives O(k2) time.\nBut in fact Huffman's Algorithm is an ideal setting in which to use a\npriority queue. Recall that a priority queue maintains a set of k elements,"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 215})","('type', 'Document')"
"('page_content', ""each with a numerical key, and it allows for the insertion of new elements\nand the extraction of the element with the minimum key. Thus we can\nmaintain the alphabet S in a priority queue, using each letter's frequency as\nits key. In each iteration we just extract the minimum twice (this gives us\nthe two lowest-frequency letters), and then we insert a new letter whose key\nis the sum of these two minim um frequencies. Our priority queue now\ncontains a representation of the alphabet that we need for the next iteration.\nUsing an implementation of priority queues via heaps, as in Chapter 2 ,\nwe can make each insertion and extraction of the minimum run in time\nO(log k); hence, each iteration—which performs just three of these\noperations—takes time O(log k). Summing over all k iterations, we get a\ntotal running time of O(k log k).\nExtensions\nThe structure of optimal prefix codes, which has been our focus here,\nstands as a fundamental result in the area of data compression. But it is\nimportant to understand that this optimality result does not by any means\nimply that we have found the best way to compress data under all\ncircumstances.\nWhat more could we want beyond an optimal prefix code? First,\nconsider an application in which we are transmitting black-and-white\nimages: each image is a 1,000-by-1,000 array of pixels, and each pixel takes\none of the two values black  or white . Further, suppose that a typical image\nis almost entirely white: roughly  1,000 of the million pixels are black, and\nthe rest are white. Now , if we wanted to compress such an imag e, the whole\napproach of prefix codes has very little to say: we have a text of length one\nmillion over the two-letter alphabet {black , white }. As a result, the text is\nalready encoded using one bit per letter—the lowest possible in our\nframework.\nIt is clear , though, that such images should be highly compre ssible.\nIntuitively , one ought to be able to use a “fraction of a bit” for each white\npixel, since they are so overw helmingly frequent, at the cost of using\nmultiple bits for each black pixel. (In an extreme version, sending a list of\n(x, y) coordinates for each black pixel would be an improvement over\nsending the image as a text with a million bits.) The challenge here is to\ndefine an encod ing scheme where the notion of using fraction s of bits is"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 216})","('type', 'Document')"
"('page_content', ""well-defined. There are results in the area of data compression, however ,\nthat do just this; arithmetic coding  and a range of other techniqu es have\nbeen developed to handle settings like this.\nA second drawback of prefix codes, as defined here, is that they cannot\nadapt  to changes in the text. Again let's consider a simple example.\nSuppose we are trying to encod e the output of a program that produces a\nlong sequence of letters from the set {a, b, c, d}. Further suppose that for\nthe first half of this sequence, the letters a and b occur equally frequently ,\nwhile c and d do not occur at all; but in the second half of this sequence, the\nletters c and d occur equally frequently , while a and b do not occur at all. In\nthe framework developed in this section, we are trying to compress a text\nover the four-letter alphabet {a, b, c, d}, and all letters  are equally frequent.\nThus each would be encoded with two bits.\nBut what's really happening in this example is that the frequency\nremains stable for half the text, and then it changes radically . So one could\nget away with just one bit per letter , plus a bit of extra overhead, as follows.\nBegin with an encoding in which the bit 0 represents a and the bit 1\nrepresents b.\nHalfway into the sequence, insert some kind of instruction that says,\n“We're changing the encoding now. From now on, the bit 0 represents\nc and the bit 1 represents d.”\nUse this new encoding for the rest of the sequence.\nThe point is that investing a small amount of space to describe a new\nencoding can pay off many times over if it reduces the average number of\nbits per letter over a long run of text that follows. Such approaches, which\nchange the encoding in midstream, are called adaptive  compression\nschemes, and for many kinds of data they lead to significant improvements\nover the static method we've considered here.\nThese issues suggest some of the directions in which work on data\ncompression has proceeded. In many of these cases, there is a trade-of f\nbetween the power of the compression technique and its computational cost.\nIn particular , many of the impr ovements to Huffman codes just described\ncome with a corresponding increase in the computational effort needed both\nto produce the compressed version of the data and also to decompress it and"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 217})","('type', 'Document')"
"('page_content', ""restore the origin al text. Finding the right balance among these trade-of fs is\na topic of active research.\n* 4.9 Minimum-Cost Arborescences: A Multi-\nPhase Greedy Algorithm\nAs we've seen more and more examples of greedy algorithms, we've come\nto appre ciate that there can be considerable diversity in the way they\noperate. Many greedy algorithm s make some sort of an initial “ordering”\ndecision on the input, and then process everything in a one-pass fashion.\nOthers make more incremental decisions—still local and opportunistic, but\nwithout a global “plan” in advance. In this section, we consider a problem\nthat stresses our intuitive view of greedy algorithms still further .\nThe Problem\nThe problem is to compute a minimum-cost arbor escence  of a directed\ngraph. This is essentially an analogue of the Minimum Spanning Tree\nProblem for directed, rather than undirected, graphs; we will see that the\nmove to directed graphs introd uces significant new complications. At the\nsame time, the style of the algorithm has a strongly greedy flavor , since it\nstill constructs a solution according to a local, myopic rule.\nWe begin with the basic definitions. Let G = (V, E) be a directed graph\nin which  we've distinguished one node r ∊ V as a root. An arbor escence\n(with respect to r) is essentially a directed spanning tree rooted at r.\nSpecifically , it is a subgraph T = (V, F) such that T is a spanning tree of G if\nwe ignore the direction of edges; and there is a path in T from r to each\nother node v ∊ V if we take the direction of edges into account. Figure 4.18\ngives an example of two dif ferent arborescences in the same directed graph.\nThere is a useful equivalent way to characterize arborescences, and\nthis is as follows.\nFigur e 4.18  A directed graph can have many different arborescences. Parts\n(b) and (c) depic t two different aborescences, both rooted at node r, for the\ngraph in part (a)."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 218})","('type', 'Document')"
"('page_content', ""(4.34)  A subgraph T = (V, F) of G is an arbor escence with respect to root r if and only if T has no\ncycles, and for each node v  ≠ r, ther e is exactly one edge in F that enters v .\nProof. If T is an arborescence with root r, then indeed every other node v has exactly one edge\nentering it: this is simply the last edge on the unique r-v path.\nConversely , suppose T has no cycles, and each node v ≠ r has exactly one entering edge. In\norder to establish that T is an arborescence, we need only show that there is a directed path from r to\neach other node v. Here is how to construct such a path. We start at v and repeat edly follow  edges in\nthe backward direction. Since T has no cycles, we can never return to a node we've previously\nvisited, and thus this process must terminate. But r is the only node without incoming edges, and so\nthe process must in fact terminate by reaching r; the sequence of nodes thus visited yields  a path (in\nthe reverse direction) from r to v. ▪\nIt is easy to see that, just as every connected graph has a spannin g tree,\na directed graph has an arborescence rooted at r provided that r can reach\nevery node. Indeed, in this case, the edges in a breadth-first search tree\nrooted at r will form an arborescence.\n(4.35)  A directed graph G has an arbor escence rooted at r if and only if there is a directed path from\nr to each other node.\nThe basic problem we consider here is the following. We are given a\ndirected graph G = (V, E), with a distinguished root node r and with a non-\nnegative cost ce ≥ 0 on each edge, and we wish to compute an arborescence\nrooted at r of minimum total cost. (We will refer to this as an optimal\narborescence.) We will assum e throughout that G at least has an\narborescence rooted at r; by (4.35), this can be easily checked at the outset.\nDesigning the Algorithm"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 219})","('type', 'Document')"
"('page_content', ""Given the relationship between arborescences and trees, the minimum-cost\narborescence problem certainly has a strong initial resemblance to the\nMinimum Spann ing Tree Problem for undirected graphs. Thus it's natural to\nstart by asking whether the ideas we developed for that problem can be\ncarried over directly to this setting. For example, must the minimum-cost\narborescence contain the cheapest edge in the whole graph? Can we safely\ndelete the most expensive edge on a cycle, confident that it cannot be in the\noptimal arborescence?\nClearly the cheapest edge e in G will not belon g to the optim al\narborescence if e enters the root, since the arbore scence we're seeking is not\nsupposed to have any edges entering the root. But even if the cheapest edge\nin G belongs  to some  arborescence rooted at r, it need not belong to the\noptimal one, as the example of Figure 4.19 shows. Indeed, including the\nedge of cost 1 in Figure 4.19 would prevent us from including the edge of\ncost 2 out of the root r (since there can only be one entering edge per node);\nand this in turn would force us to incur an unacceptable cost of 10 when we\nincluded one of the other edges out of r. This kind of argument never\nclouded our thinking in the Minimum Spanning Tree Problem, where it was\nalways safe to plunge ahead and include the cheapest edge; it suggests that\nfinding the optimal arborescence may be a significantly more complicated\ntask. (It's worth noticing that the optimal arborescence in Figure 4.19 also\nincludes the most expensive edge on a cycle; with a different construction,\none can even cause the optimal arborescence to include the most expensive\nedge in the whole graph.)\nFigur e 4.19  (a) A directed graph with costs on its edges, and (b) an optimal\narborescence rooted at r for this graph."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 220})","('type', 'Document')"
"('page_content', ""Despite this, it is possible to design a greedy type of algorithm for this\nproblem; it's just that our myopic rule for choosing edges has to be a little\nmore sophistica ted. First let's consider a little more carefully what goes\nwrong with the general strategy of including the cheapest edges. Here's a\nparticular version of this strategy: for each node v ≠ r, select the cheapest\nedge entering v (breaki ng ties arbitrarily), and let F* be this set of n - 1\nedges. Now consider the subgraph (V, F*). Since we know that the optimal\narborescence needs to have exactly one edge entering each node v ≠ r, and\n(V, F*) represents the cheapest possib le way of making these choice s, we\nhave the following fact.\n(4.36)  If (V, F*) is an arbor escence, then it is a minimum-cost arbor escence.\nSo the difficulty is that (V, F*) may not be an arborescence. In this\ncase, (4.34) implies that (V, F*) must contain a cycle C, which does not\ninclude the root. W e now must decide how to proceed in this situation.\nTo make matters somewhat clearer , we begin with the following\nobservation. Every arborescence contains exactly one edge entering each\nnode v ≠ r; so if we pick some node v and subtract a uniform quantity  from\nthe cost of every edge entering v, then the total cost of every arborescence\nchanges by exactly the same amount. This means, essentially , that the actual\ncost of the cheapest edge entering v is not importan t; what matters is the\ncost of all other edges entering v relative  to this. Thus let yv denote the\nminimum cost of any edge entering v. For each edge e = (u, v), with cost ce\n≥ 0, we define its modified cost c′e to be ce - yv. Note that since ce ≥ yv, all\nthe modified costs are still nonnegative. More crucially , our discussion\nmotivates the following fact.\n(4.37)  T is an optimal arborescence in G subject to costs  {ce} if and only if it is an optimal\narbor escence subject to the modified costs  {c′e}.\nProof. Consider an arbitrar y arborescence T. The difference between its cost with costs {ce} and\n{c′e} is exactly Σ v≠r yv—that is,"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 221})","('type', 'Document')"
"('page_content', ""This is because an arborescence has exactly one edge entering each node v in the sum. Since the\ndifference between the two costs is independent of the choice of the arborescence T, we see that T\nhas minimum cost subject to { ce} if and only if it has minimum cost subject to { c′e}. ▪\nWe now consider the problem in terms of the costs {c′e}. All the edges\nin our set F* have cost 0 under these modi fied costs; and so if (V, F*)\ncontains a cycle C, we know that all edges in C have cost 0. This suggests\nthat we can afford to use as many edges from C as we want (consistent with\nproducing an arborescence), since including edges from C doesn't raise the\ncost.\nThus our algorithm continues as follows. We contract C into a single\nsupernode,  obtainin g a smaller graph G′ = (V′, E′). Here, V′ contains the\nnodes of V - C, plus a single node c* representing C. We transform each\nedge e ∊ E to an edge e′ ∊ E′ by replacing each end of e that belongs to C\nwith the new node c*. This can result in G′ having parallel edges (i.e., edges\nwith the same ends), which is fine; however , we delete self-loops from E′—\nedges that have both ends equal to c*. We recursively find an optimal\narborescence in this smaller graph G′, subject to the costs {c′e}. The\narborescence returned by this recursive call can be converted into an\narborescence of G by including all but one edge on the cycle C.\nIn summary , here is the full algorithm.\nFor each node v ≠ r\nLet yv be the minimum cost of an edge entering node v\nModify the costs of all edges e entering v to c′e = ce - yv\nChoose one 0-cost edge entering each v ≠ r, obtaining a set F*\nIf F* forms an arborescence, then return it\nElse there is a directed cycle C ⊆ F*\nContract C to a single supernode, yielding a graph G′ = (V′,E′ )\nRecursively find an optimal arborescence ( V′,F′ ) in G′ with costs { c′e}\nExtend ( V′,F′ ) to an arborescence ( V,F) in G by adding all but one edge of C\nAnalyzing the Algorithm\nIt is easy to implement this algorithm so that it runs in polynomi al time. But\ndoes it lead to an optimal arborescence? Before concluding that it does, we\nneed to worry about the follo wing point: not every arborescence in G"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 222})","('type', 'Document')"
"('page_content', 'corresponds to an arborescence in the contracted graph G′. Could we\nperhaps “miss” the true optimal arborescence in G by focusing on G′? What\nis true is the following. The arborescences of G′ are in one-to-one\ncorrespondence with arborescences of G that have exactly one edge\nentering the cycle C; and these corresponding arborescences have the same\ncost with respect to {c′e}, since C consists of 0-cost edges. (We say that an\nedge e = (u, v) enters C if v belongs to C but u does not.) So to prove that\nour algorithm finds an optimal arborescence in G, we must prove  that G has\nan optimal arborescence with exactly one edge entering C. We do this now .\n(4.38)  Let C be a cycle in G consisting of edges of cost 0, such that r ∉  C. Then there is an optimal\narbor escence r ooted at r that has exactly one edge entering C.\nProof. Cons ider an optimal  arborescence T in G. Since r has a path in T to every node, there  is at\nleast one edge of T that enters C. If T enters C exactly once, then we are done. Otherwise, suppose\nthat T enters C more than once. We show how to modify it to obtain an arborescence of no greater\ncost that enters C exactly once.\nLet e = (a, b) be an edge entering C that lies on as short a path as possible from r; this mean s in\nparticular that no edges on the path from r to a can enter C. We delete all edges of T that enter C,\nexcept for the edge e. We add in all edges of C except for the one edge that enters b, the head of edge\ne. Let T′ denote the resulting subgraph of G.\nWe claim that T′ is also an arborescen ce. This will establish the result, since the cost of T′ is\nclearly no greater than that of T: the only edges of T′ that do not also belong to T have cost 0. So why\nis T′ an arbores cence? Observe that T′ has exactly one edge entering each node v ≠ r, and no edge\nentering r. So T′ has exactly n - 1 edges; hence if we can show there is an r-v path in T′ for each v,\nthen T′ must be connected in an undirected sense , and hence a tree. Thus it would satisfy our initial\ndefinition of an arborescence.\nSo consider any node v ≠ r; we must show there is an r-v path in T′. If v ∊ C, we can use the fact\nthat the path in T from r to e has been preserved in the construction of T′; thus we can reach v by first\nreaching e and then following the edges of the cycle C. Now suppose that v ∉ C, and let P denote the\nr-v path in T. If P did not touch C, then it still exists in T′. Othe rwise, let w be the last node in P ∩ C,\nand let P′ be the subpath of P from w to v. Observe that all the edges in P′ still exist in T′. We have\nalready argued that w is reachable from r in T′, since it belongs to C. Concatenating this path to w\nwith the subpath P′ gives us a path to v as well. ▪\nWe can now put all the pieces together to argue that our algor ithm is\ncorrect.\n(4.39)  The algorithm finds an optimal arbor escence r ooted at r in G\nProof. The proof is by induction on the number of nodes in G. If the edges of F form an\narborescence, then the algorithm returns an optimal arborescence by (4.36). Otherwise, we consider\nthe problem with the modified costs {c′e}, which is equivalent by (4.37). After contracting a 0-cost\ncycle C to obtain a smaller graph G′, the algorithm produces an optimal arborescence in G′ by the\ninductive hypothesis. Finally , by (4.38), there is an optimal arborescence in G that corresponds to the\noptimal arborescence computed for G′. ▪')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 223})","('type', 'Document')"
"('page_content', ""Solved Exercises\nSolved Exercise 1\nSuppose that three of your friends, inspired by repeated viewings of the\nhorror -movie phenomenon The Blair Witch Project,  have decided to hike\nthe Appalachian  Trail this summ er. They want to hike as much as possible\nper day but, for obvious reasons, not after dark. On a map they've identified\na large set of good stopping points  for camping, and they're considering the\nfollowing system for deciding when to stop for the day. Each time they\ncome to a potential stopping point, they determine whether they can make it\nto the next one before nightfall.  If they can make it, then they keep hiking;\notherwise, they stop.\nDespite many significant drawb acks, they claim this system does have\none good  feature . “Given that we're only hiking in the daylight,”  they claim,\n“it minimizes the number of camping stops we have to make.”\nIs this true? The proposed system is a greedy algorithm, and we wish\nto determine whether it minimizes the number of stops needed.\nTo make this question precise, let's make the following set of\nsimplifying assumptions. We'll model the Appalachian Trail as a long line\nsegment of length L, and assume that your friends can hike d miles per day\n(independent of terrain, weather  conditions, and so forth). We'll assume that\nthe potential stopping points are located at distances x1, x2, …, xn from the\nstart of the trail. We'll also assume (very generously) that your friends are\nalways correct when they estimate whether they can make it to the next\nstopping point before nightfall.\nWe'll say that a set of stopping points is valid  if the distance between\neach adjacent pair is at most d, the first is at distance at most d from the\nstart of the trail, and the last is at distance at most d from the end of the\ntrail. Thus a set of stopping points is valid if one could camp only at these\nplaces and still make it across the whole trail. We'll assume, naturally , that\nthe full set of n stoppin g points is valid; otherw ise, there would be no way\nto make it the whole way .\nWe can now state the question as follows. Is your friends' greedy\nalgorithm—hiking as long as possible each day— optimal,  in the sense that"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 224})","('type', 'Document')"
"('page_content', ""it finds a valid set whose size is as small as possible?\nSolution  Often a greedy algorithm looks correct when you first encounter\nit, so before succumbing too deeply to its intuitive appeal, it's useful to ask:\nwhy might it not work? What should we be worried about?\nThere's a natura l concern with this algorithm: Might it not help to stop\nearly on some day, so as to get better synchronized with camping\nopportunities on future days? But if you think about it, you start to wonder\nwhether this could really happen . Could there really be an alternate solution\nthat intentionally lags behind the greedy solution, and then puts on a burst\nof speed  and passes the greedy solution? How could it pass it, given that the\ngreedy solution travels as far as possible each day?\nThis last consideration starts to look like the outline of an argument\nbased on the “staying ahead” principle from Section 4.1. Perhaps we can\nshow that as long as the greedy camping strategy is ahead on a given day,\nno other solution can catch up and overtake it the next day .\nWe now turn this into a proof showing the algorithm is indeed optimal,\nidentifying a natural sense in which the stopping points it chooses “stay\nahead” of any other legal set of stopping points. Although we are following\nthe style of proof from Section 4.1, it's worth noting an interesting contrast\nwith the Interval Scheduling Problem: there we needed to prove that a\ngreedy algorithm maximized a quantity of interest, whereas here we seek to\nminimize a certain quantity .\nLet R = {xp1, …, xpk} denote the set of stopping points chosen by the\ngreedy algorithm , and suppose by way of contradiction that there is a\nsmaller valid set of stopping points; let's call this smaller set S = {xq1, …,\nxqm}, with m < k.\nTo obtai n a contradiction, we first show that the stopping point reached\nby the greedy algorithm on each day j is farther than the stopping point\nreached under the alternate solution. That is,\n(4.40)  For each j  = 1, 2, …, m, we have x pj ≥ xqj.\nProof. We prove this by induction on j. The case j = 1 follow s directly  from the definition of the\ngreedy algorithm: your friends travel as long as possible on the first day before stopp ing. Now let j >\n1 and assume that the claim is true for all i < j. Then"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 225})","('type', 'Document')"
"('page_content', 'since S is a valid set of stopping points, and\nsince xpj-1 ≥ xqj-1 by the induction hypothesis. Combining these two inequalities, we have\nThis means that your friends have the option of hiking all the way from xpj-1 to xqj in one day;\nand hence the location xpj at which they finally stop can only be farther along than xqj. (Note the\nsimilarity with the corresponding proof for the Interval Scheduling Problem: here too the greedy\nalgorithm is staying ahead because, at each step, the choice made by the alternate solution is one of\nits valid options.) ▪\nStatement (4.40 ) implies in particular that xqm ≤ xpm. Now , if m < k,\nthen we must have xpm < L - d, for otherwise your friends woul d never have\nneeded to stop at the location xpm+1. Combi ning these two inequalities, we\nhave concluded that xqm < L - d; but this contradicts the assumpt ion that S is\na valid set of stopping points.\nConsequently , we cannot have m < k, and so we have proved that the\ngreedy algorithm  produces a valid set of stopping points of minimum\npossible size.\nSolved Exercise 2\nYour friends are starting a security company that needs to obtain licenses\nfor n different pieces of cryptographic software. Due to regulations, they\ncan only obtain these licenses at the rate of at most one per month.\nEach license is currently selling for a price of $100. However , they are\nall beco ming more expensive according to exponential growth  curves: in\nparticular , the cost of license j increases by a factor of rj > 1 each month,\nwhere rj is a given parameter . This means that if license j is purchased t\nmonths from now, it will cost 100 · rt\nj. We will assume that all the price\ngrowth rates are distinct; that is, ri ≠ rj for licenses i ≠ j (even though they\nstart at the same price of $100).')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 226})","('type', 'Document')"
"('page_content', ""The question is: Given that the company can only buy at most one\nlicense a month , in which order should it buy the licenses so that the total\namount of money it spends is as small as possible?\nGive an algorithm that takes the n rates of price growth r1, r2, …, rn,\nand computes an order in which  to buy the licenses so that the total amount\nof money spent is minimized. The running time of your algorithm should be\npolynomial in n.\nSolution  Two natural guesses for a good sequence would be to sort the ri in\ndecreasing order , or to sort them in increasing order . Faced with alternatives\nlike this, it's perfectly reasonable  to work out a small example and see if the\nexample elimina tes at least one of them. Here we could try r1 = 2, r2 = 3,\nand r3 = 4. Buying the licenses in increasing order results in a total cost of\nwhile buying them in decreasing order results in a total cost of\nThis tells us that increasing order is not the way to go. (On the other hand, it\ndoesn't tell us immediately that decreasing order is the right answer , but our\ngoal was just to eliminate one of the two options.)\nLet's try proving  that sorting the ri in decre asing order in fact always\ngives the optimal solution. When a greedy algorithm works for problems\nlike this, in which we put a set of things in an optimal order , we've seen in\nthe text that it's often effective to try proving correctness using an exchange\nargument.\nTo do this here, let's suppose that there is an optimal solution O that\ndiffers from our solution S. (In other words, S consists  of the licenses sorted\nin decreasing order .) So this optimal solution O must contain an inversion—\nthat is, there must exist two neighboring months t and t + 1 such that the\nprice increase rate of the license  bought in month t (let us denote it by rt) is"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 227})","('type', 'Document')"
"('page_content', ""less than that bought in month t + 1 (similarly , we use rt+1 to deno te this).\nThat is, we have rt < rt+1.\nWe claim that by exchanging these two purchases, we can strictly\nimprove our optimal solution, which contradicts the assumption  that O was\noptimal. Therefore if we succeed in showing this, we will successfully show\nthat our algorithm is indeed the correct one.\nNotice that if we swap these two purchases, the rest of the purchases\nare identically priced. In O, the amount paid during the two months\ninvolved in the swap is 100(rtt + rt+1t+1). On the other hand, if we swapped\nthese two purcha ses, we would pay 100(rt+1t + rtt+1). Since the constant 100\nis common to both expressions , we want to show that the second term is\nless than the first one. So we want to show that\nBut this last inequality is true simply because ri > 1 for all i and since rt <\nrt+1.\nThis concludes the proof of correctness. The running time of the\nalgorithm is O(n log n), since the sorting takes that much time and the rest\n(outputting) is linear . So the overall running time is O(n log n).\nNote:  It's interestin g to note that things become much less\nstraightforward if we vary this question even a little. Suppose that instead of\nbuying licenses whose prices increase, you're trying to sell off equipment\nwhose cost is depreciating. Item i depreciates at a factor of rt < 1 per month,\nstarting from $100, so if you sell it t months from now you will receive 100\n· rt\ni. (In other words, the exponential rates are now less than 1, instead of\ngreater than 1.) If you can only sell one item per month, what is the optimal\norder in which to sell them? Here, it turns out that there are cases in which\nthe optimal solution doesn't put the rates in either increasing or decreasing\norder (as in the input ¾, ½, \n )."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 228})","('type', 'Document')"
"('page_content', ""Solved Exercise 3\nSuppose you are given a connec ted graph G, with edge costs that you may\nassume are all distinct. G has n vertices and m edges. A particu lar edge e of\nG is specified. Give an algorithm  with running time O(m + n) to decide\nwhether e is contained in a minimum spanning tree of G.\nSolution  From the text, we know of two rules by which we can conclude\nwhether an edge e belongs to a minimum spanning tree: the Cut Property\n(4.17) says that e is in every minimum spanning tree when it is the cheapest\nedge crossing from some set S to the complement V - S; and the Cycle\nProperty (4.20) says that e is in no minimum spanning tree if it is the most\nexpensive edge on some cycle C. Let's see if we can make use of these two\nrules as part of an algorithm that solves this problem in linear time.\nBoth the Cut and Cycle Properties are essentially talking about  how e\nrelates to the set of edges that are cheaper  than e. The Cut Proper ty can be\nviewed as asking : Is there some set S ⊆ V so that in order to get from S to V\n- S without using e, we need to use an edge that is more expensive than e?\nAnd if we think about the cycle C in the statement of the Cycle Property ,\ngoing the “long way” around C (avoiding e) can be viewed as an alternate\nroute between the endpoints of e that only uses cheaper edges.\nPutting these two observations together suggests that we should try\nproving the following statement.\n(4.41)  Edge e = (v, w) does not belong to a minim um spanning tree of G if and only if v and w can be\njoined by a path consisting entir ely of edges that ar e cheaper than e.\nProof. First suppose that P is a v-w path consisting entirely of edges cheaper than e. If we add e to P,\nwe get a cycle on which e is the most expensive  edge. Thus, by the Cycle Property , e does not belong\nto a minimum spanning tree of G.\nOn the other hand, suppose that v and w cannot be joined by a path consisting entirely of edges\ncheaper than e. We will now identif y a set S for which e is the cheapest edge with one end in S and\nthe other in V - S; if we can do this, the Cut Property will imply that e belongs to every minimum\nspanning tree. Our set S will be the set of all nodes that are reacha ble from v using a path consisting\nonly of edges that are cheaper than e. By our assumption, we have w ∊ V - S. Also, by the definition\nof S, there cannot be an edge f = (x, y) that is cheaper than e, and for which one end x lies in S and the\nother end y lies in V - S. Indeed, if there were such an edge f, then since  the node x is reachab le from\nv using only edges cheaper than e, the node y woul d be reachable as well. Hence e is the cheapest\nedge with one end in S and the other in V - S, as desired, and so we are done. ▪\nGiven this fact, our algorithm is now simply the following. We form a\ngraph G′ by deleting from G all edges of weight greater than ce (as well as"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 229})","('type', 'Document')"
"('page_content', 'deleting e itself). We then use one of the connectivity algorithms from\nChapter 3  to deter mine whether there is a path from v to w in G′. Statement\n(4.41) says that e belongs to a minimum spanning  tree if and only if there is\nno such path.\nThe running time of this algorith m is O(m + n) to build G′, and O(m +\nn) to test for a path from v to w.\nExercises\n1. Decide whether you think the following statement is true or false. If it\nis true, give a short explanation. If it is false, give a counterexample.  \nLet G be an arbitrar y connected, undir ected graph with a distinct cost c(e) on\nevery edge e. Suppose e* is the cheapest edge in G; that is, c(e*) < c(e) for every\nedge e  ≠ e*. Then there is a minimum spanning tree T of G that contains the edge\ne*.\n2. For each of the following two statements, decide whether it is true or\nfalse. If it is true, give a short explanation. If it is false, give a\ncounterexample.  \n(a) Suppose we are given an instance of the Minimum Spanning Tree\nProblem on a graph G, with edge costs that are all positive and distinct.\nLet T be a minimum spanning tree for this instance. Now suppose we\nreplace each edge cost ce by its square, ce2, thereby creating a new\ninstance of the problem with the same graph but dif ferent costs.  \nTrue or false? T must still be a minimum spanning tree for this new\ninstance.  \n(b) Suppose we are given an instance of the Shortest s-t Path Problem\non a directed graph G. We assume that all edge costs are positive and\ndistinct. Let P be a minimum-cost s-t path for this instance. Now\nsuppose we replace each edge  cost ce by its square, ce2, thereby\ncreating a new instance of the problem with the same graph but\ndifferent costs.  \nTrue or false? P must still be a minimum-cost s-t path for this new\ninstance.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 230})","('type', 'Document')"
"('page_content', ""3. You are consulting for a trucking company that does a large amount of\nbusiness shipping packages between New York and Boston. The\nvolume is high enough that they have to send a number of truck s each\nday between the two locations. Trucks have a fixed limit W on the\nmaximum amou nt of weight they are allowed to carry . Boxes arrive at\nthe New York station one by one, and each package i has a weight wi.\nThe trucking station is quite small, so at most one truck can be at the\nstation at any time. Company policy requires that boxes are shipped in\nthe order they arrive; otherwis e, a customer might get upset upon\nseeing a box that arrived after his make it to Boston faster . At the\nmoment, the company is using a simple greedy algorithm for packing:\nthey pack boxes  in the order they arrive, and whenever the next box\ndoes not fit, they send the truck on its way . \nBut they wonder if they might be using too many trucks, and they want\nyour opinion on whether the situation can be improved. Here is how\nthey are thinking. Maybe one could decrease the number of trucks\nneeded by sometimes sending off a truck that was less full, and in this\nway allow the next few trucks to be better packed.  \nProve that, for a given set of boxes with specified weights, the greedy\nalgorithm currently in use actually minimizes the number of trucks that\nare needed. Your proof should follow the type of analysis we used for\nthe Interval Scheduling Problem: it should establish the optimality of\nthis greedy packing algorithm by identifying a measure under which it\n“stays ahead” of all other solutions.\n4. Some of your friends have gotten into the burgeoning field of time-\nseries data mining,  in which one looks for patterns in sequences of\nevents that occur over time. Purchases at stock exchanges-what's being\nbought-are one source of data with a natural ordering in time. Given a\nlong sequence S of such events, your friends want an efficient way to\ndetect certain “patterns” in them -for example, they may want to know\nif the four events  \n \nbuy Y ahoo, buy eBay , buy Y ahoo, buy Oracle  \n \noccur in this sequence S, in order but not necessarily consecutively . \nThey begin with a collection of possible events  (e.g., the possible\ntransactions) and a sequence S of n of these  events. A given event may"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 231})","('type', 'Document')"
"('page_content', ""occur multiple times in S (e.g., Y ahoo stock may be bought many times\nin a single sequence S). We will say that a seque nce S′ is a\nsubsequence  of S if there is a way to delete certai n of the events from S\nso that the rema ining events, in order , are equal to the sequence  S′. So,\nfor example, the sequence of four events above is a subsequence of the\nsequence  \n \nbuy Amazon, buy Yahoo, buy eBay , buy Yahoo, buy Yahoo, buy\nOracle  \n \nTheir goal is to be able to dream up short sequences and quickly  detect\nwhether they are subsequences of S. So this is the problem they pose to\nyou: Give an algorithm that takes two sequences of events- S′ of length\nm and S of length n, each possibly containing an event more than once-\nand decides in time O(m + n) whether S′ is a subsequence of S.\n5. Let's consider a long, quiet country road with houses scattered very\nsparsely along it. (We can picture the road as a long line segment, with\nan eastern endpoint and a wester n endpoint.) Further , let's suppose that\ndespite the bucolic setting, the residents of all these houses are avid\ncell phone users . You want to place cell phone base stations at certain\npoints along the road, so that every house is within four miles of one of\nthe base stations.  \nGive an efficient algorithm that achieves this goal, using as few base\nstations as possible.\n6. Your friend is working as a camp counselor , and he is in charge of\norganizing activities for a set of junior -high-school-age campers. One\nof his plans is the following mini-triathalon exercise: each contestant\nmust swim 20 laps of a pool, then bike 10 miles, then run 3 miles. The\nplan is to send the contestants out in a staggered fashion, via the\nfollowing rule: the contestants must use the pool one at a time. In other\nwords, first one contestant swims the 20 laps, gets out, and starts\nbiking. As soon as this first person is out of the pool, a second\ncontestant begin s swimming the 20 laps; as soon as he or she is out\nand starts biking, a third contestant begins swimming … and so on.)  \nEach contestant  has a projected swimming time (the expected time it\nwill take him or her to complete the 20 laps), a projected biking time\n(the expected time it will take him or her to complete the 10 miles of"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 232})","('type', 'Document')"
"('page_content', ""bicycling), and a projected running time (the time it will take him or\nher to complete the 3 miles of running). Your friend wants to decide on\na schedule  for the triathalo n: an order in which to sequence the starts\nof the contestants. Let's say that the completion time of a schedule is\nthe earliest time at which all contestants will be finished with all three\nlegs of the triath alon, assuming they each spend exactly their projected\nswimming, biking, and running  times on the three parts. (Again, note\nthat participants can bike and run simultaneously , but at most one\nperson can be in the pool at any time.) What's the best order for\nsending people out, if one wants the whole competition to be over as\nearly as possible? More precis ely, give an efficient algorithm that\nproduces a schedule whose completion time is as small as possible.\n7. The wildly popu lar Spanish-lan guage search engine El Goog needs to\ndo a serious amount of computa tion every time it recompiles its index.\nFortunately , the company has at its disposal a single large\nsupercomputer , together with an essentially unlimited supply of high-\nend PCs.  \nThey've broken the overall comp utation into n distinct jobs, labeled J1,\nJ2, …, Jn, which can be performed completely independently of one\nanother . Each job consists of two stages: first it needs to be\npreprocessed  on the supercomputer , and then it needs to be finished  on\none of the PCs. Let's say that job Ji needs pi seconds of time on the\nsupercomputer , followed by fi seconds of time on a PC.  \nSince there are at least n PCs available on the premises, the finishing\nof the jobs can be performed fully in parallel—all the jobs can be\nprocessed at the same time. However , the supercomputer can only\nwork on a singl e job at a time, so the system managers need to work\nout an order in which to feed the jobs to the supercomputer . As soon as\nthe first job in order is done on the supercomputer , it can be handed off\nto a PC for finishing; at that point in time a second job can be fed to\nthe supercomputer; when the second job is done on the supercomputer ,\nit can proceed to a PC regardles s of whether or not the first job is done\n(since the PCs work in parallel); and so on.  \nLet's say that a schedule  is an ordering of the jobs for the\nsupercomputer , and the completion time of the schedule is the earliest\ntime at which all jobs will have finished processing on the PCs. This is"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 233})","('type', 'Document')"
"('page_content', 'an impo rtant quantity to minimize, since it determines how rapidly El\nGoog can generate a new index.  \nGive a polynomial-time algorithm that finds a schedule with as small a\ncompletion time as possible.\n8. Suppose you are given a connected graph G, with edge costs that are\nall distinct. Prove that G has a unique minimum spanning tree.\n9. One of the basic motivations behind the Minimum Spanning Tree\nProblem is the goal of designing a spanning network for a set of nodes\nwith minimum total cost. Here we explore another type of objective:\ndesigning a spanning network for which the most expensive  edge is as\ncheap as possible.  \nSpecifically , let G = (V,E) be a connected graph with n vertices, m\nedges, and posit ive edge costs that you may assume are all distinct. Let\nT = (V,E′) be a spanning tree of G; we define the bottleneck edge  of T\nto be the edge of T with the greatest cost.  \nA spanning tree T of G is a minimum-bottleneck spanning tree if there\nis no spanning tree T′ of G with a cheaper bottleneck edge.  \n(a) Is every minimum-bottleneck tree of G a minimum spanning tree of\nG? Prove or give a counterexample.  \n(b) Is every minimum spanning tree of G a minimum-bottleneck tree\nof G? Prove or give a counterexample.\n10. Let G = (V, E) be an (undirected) graph with costs ce ≥ 0 on the edge s e\n∊ E. Assume you are given a minimum-cost spanning tree T in G.\nNow assume that a new edge is added to G, connecting two nodes v, w\n∊ V with cost c. \n(a) Give an efficien t algorithm to test if T remains the minimum-cost\nspanning tree with the new edge added to G (but not to the tree T).\nMake your algorithm run in time O(|E|). Can you do it in O(|V|) time?\nPlease note any assumptions you make about what data struc ture is\nused to represent the tree T and the graph G. \n(b) Suppose T is no longer the minimum-cost spanning tree. Give a\nlinear -time algorithm (time O(|E|)) to update the tree T to the new\nminimum-cost spanning tree.\n11. Suppose you are given a connected graph G = (V,E), with a cost ce on\neach edge e. In an earlier problem, we saw that when all edge costs are\ndistinct, G has a unique minimum spanning tree. However , G may\nhave many minimum spanning trees when the edge costs are not all')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 234})","('type', 'Document')"
"('page_content', ""distinct. Here we formulate the question: Can Kruskal's Algorithm be\nmade to find all the minimum spanning trees of G? \nRecall that Kruskal's Algorithm sorted the edges in order of increasing\ncost, then greedily processed edges one by one, adding an edge e as\nlong as it did not form a cycle. When some edges have the same cost,\nthe phrase “in order of increasing cost” has to be specified a little more\ncarefully: we'll say that an ordering of the edges is valid  if the\ncorresponding sequence of edge costs is nondecreasing. We'll say that\na valid execution  of Krus kal's Algorithm is one that begins with a valid\nordering of the edges of G. \nFor any graph G, and any minimum spanning tree T of G, is there a\nvalid execution  of Kruskal's Algorithm on G that produces T as\noutput? Give a proof or a counterexample.\n12. Suppose you have n video streams that need to be sent, one after\nanother , over a communication link. Stream i consists of a total of bi\nbits that need to be sent, at a constant rate, over a period of ti seconds.\nYou cannot send two streams at the same time, so you need to\ndetermine a schedule  for the streams:  an order in which to send them.\nWhichever order you choose, there cannot be any delays between the\nend of one stream and the start of the next. Suppose your schedule\nstarts at time 0 (and therefore ends at time Σni=1 ti, whichever order\nyou choose). We assume that all the values bi and ti are positive\nintegers.  \nNow , because you're just one user, the link does not want you taking\nup too much bandwidth, so it imposes the following constraint, using a\nfixed parameter r: \n(*) For each natural  number t > 0, the total number of bits you send over the\ntime interval fr om 0 to t cannot exceed rt.\nNote that this constraint is only imposed for time intervals that start at\n0, not for time intervals that start at any other value.  \nWe say that a schedule is valid  if it satisfies the constraint (*) imposed\nby the link.  \nThe Problem.  Given a set of n streams, each specified by its number\nof bits bi and its time duration ti, as well as the link parameter r,"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 235})","('type', 'Document')"
"('page_content', ""determine whether there exists a valid schedule.  \nExample.  Suppose we have n = 3 streams, with  \nand supp ose the link's parameter is r = 5000. Then the schedule that\nruns the streams in the order 1,2,3, is valid, since the constraint (*) is\nsatisfied:  \nt = 1: the whole first str eam has been sent, and  2000 < 5000 · 1  \nt = 2: half of the second stream has also been sent, and 2000 + 3000 <\n5000 · 2  \nSimilar calculations hold for t  = 3 and t  = 4. \n(a) Consider the following claim:  \nClaim: There exists a valid schedule if and only if each stream i satisfies bi ≤ rti.\n \nDecide whether you think the claim is true or false, and give a proof of\neither the claim or its negation.  \n(b) Give an algorithm that takes a set of n streams, each specified by\nits number of bits bi and its time duration ti, as well as the link\nparameter r, and determines whether there exists a valid schedule. The\nrunning time of your algorithm should be polynomial in n.\n13. A small  business-say , a photocopying service with a single large\nmachine-faces the following scheduling problem. Each mornin g they\nget a set of jobs from customers. They want to do the jobs on their\nsingle machine in an order that keeps their customers happiest.\nCustomer i's job will take ti time to complete. Given a schedule (i.e.,\nan ordering of the jobs), let Ci denote the finishing time of job i. For\nexample, if job j is the first to be done, we would have Cj = tj; and if\njob j is done right after job i, we would have Cj = Ci + tj. Each\ncustomer i also has a given weight wi that represents his or her\nimportance to the business. The happiness of customer i is expec ted to\nbe dependent on the finishing time of i's job. So the company decides\nthat they want to order the jobs to minimize the weighted sum of the"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 236})","('type', 'Document')"
"('page_content', ""completion times, Σn\ni=1 wiCi. \nDesign an efficient algorithm to solve this problem. That is, you are\ngiven a set of n jobs with a processing time ti and a weight wi for each\njob. You want to order the jobs so as to minimize the weighted sum of\nthe completion times, Σn\ni=1 wiCi. \nExample.  Suppose there are two jobs: the first takes time t1 = 1 and\nhas weight w1 = 10, while the second job takes time t2 = 3 and has\nweight w2 = 2. Then doing job 1 first would yield a weighted\ncompletion time of 10 · 1 + 2 · 4 = 18, while doing the second job first\nwould yield the lar ger weighted completion time of 10 · 4 + 2 · 3 = 46.\n14. You're working with a group of security consultants who are helping to\nmonitor a large computer system. There's particular interest in keeping\ntrack of processes that are labele d “sensitive.” Each such process has a\ndesignated start time and finish time, and it runs continuously between\nthese times; the consultants have a list of the planned start and finish\ntimes of all sensitive processes that will be run that day . \nAs a simple first step, they've written a program called status _check\nthat, when invoked, runs for a few seconds and records various pieces\nof logging information about all the sensitive processes running on the\nsystem at that moment. (We'll model each invocation of status _check\nas lasting for only this single point in time.) What they'd like to do is to\nrun statu s_check as few times as possible during the day, but enough\nthat for each sensitive process P, status_check is invoked at least once\nduring the execution of process P. \n(a) Give an efficient algorithm that, given the start and finish times of\nall the sensitive processes, finds as small a set of times as possible at\nwhich to invoke status_check, subject to the requirement that\nstatus_check is invoked at least once during each sensitive process P. \n(b) While you were designing your algorithm, the security consultants\nwere engaging in a little back-of-the-envelope reasoning. “Suppose we\ncan find a set of k sensitive processes with the property that no two are\never running at the same time. Then clearly your algorithm will need\nto invoke status_check at least k times: no one invocation of\nstatus_check can handle more than one of these processes.”  \nThis is true, of course, and after some further discussion, you all begin\nwondering whether something stronger is true as well, a kind of"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 237})","('type', 'Document')"
"('page_content', ""converse to the above argument.  Suppose that k* is the largest value of\nk such that one can find a set of k sensitive processes with no two ever\nrunning at the same time. Is it the case that there must be a set of k*\ntimes at which you can run status_check so that some invocation\noccurs during the execution of each sensitive process? (In other words,\nthe kind of argument in the previous paragraph is really the only thing\nforcing you to need a lot of invocations of status_check.) Decide\nwhether you think this claim is true or false, and give a proof or a\ncounterexample.\n15. The manager of a large student  union on campus comes to you with\nthe follo wing problem. She's in charge of a group of n students, each\nof whom  is scheduled to work one shift during the week. There are\ndifferent jobs associated with these shifts (tending the main  desk,\nhelping with package delivery , rebooting cranky information kiosks,\netc.), but we can view each shift as a single contiguous interval of\ntime. There can be multiple shifts going on at once.  \nShe's trying to choose a subset of these n students to form a\nsupervising committee  that she can meet with once a week. She\nconsiders such a committee to be complete  if, for every student not on\nthe committee, that student's shift overlaps (at least partially) the shift\nof some student who is on the committee. In this way, each student's\nperformance can be observed by at least one person who's serving on\nthe committee.  \nGive an efficient algorithm that takes the schedule of n shifts and\nproduces a complete supervising committee containing as few students\nas possible.  \nExample.  Suppose n = 3, and the shifts are  \nMonday 4 P .M.-Monday 8 P .M.,\nMonday 6 P .M.-Monday 10 P .M.,\nMonday 9 P .M.-Monday 1 1 P.M..\n \nThen the smallest complete supervising committee would consist of\njust the second student, since the second shift overlaps both the first\nand the third.\n16. Some security consultants working in the financial domain are\ncurrently advising a client who is investigating a potential money-"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 238})","('type', 'Document')"
"('page_content', ""laundering scheme. The investigation thus far has indicated that n\nsuspicious transactions took place in recent days, each involving\nmoney transferred into a single account. Unfortunately , the sketchy\nnature of the evidence to date means that they don't know the identity\nof the account, the amounts of the transactions, or the exact times at\nwhich the transactions took place. What they do have is an\napproximate time-stamp  for each transaction; the evidence indicates\nthat transaction i took place at time ti ± ei, for some “mar gin of error”\nei. (In other words, it took place sometime between tt - ei and ti + ei.)\nNote that dif ferent transactions may have dif ferent mar gins of error . \nIn the last day or so, they've come across a bank account that (for other\nreasons we don't need to go into here) they suspect might be the one\ninvolved in the crime. There are n recent events  involving the account,\nwhich took place at times x1, x2, …, xn. To see whether it's plausible\nthat this really is the account they're looking for, they're wondering\nwhether it's possible to associate each of the account's n events with a\ndistinct one of the n suspicious transactions in such a way that, if the\naccount event at time xi is associated with the suspicious transaction\nthat occurred approximately at time tj, then | tj - xi| ≤ ej. (In other words ,\nthey want to know if the activity on the account lines up with the\nsuspicious trans actions to within the margin of error; the tricky part\nhere is that they don't know which account event to associat e with\nwhich suspicious transaction.)  \nGive an efficient algorithm that takes the given data and decides\nwhether such an association exists. If possible, you should make the\nrunning time be at most O(n2).\n17. Consider the following variation on the Interval Scheduling Problem.\nYou have a processor that can operate 24 hours a day, every day.\nPeople submit requests to run daily jobs on the processor . Each such\njob comes with a start time and an end time;  if the job is accepted to\nrun on the processor , it must run continuously , every day, for the\nperiod between its start and end times. (Note that certain jobs can\nbegin before midnight and end after midnight; this makes for a type of\nsituation different from what we saw in the Interval Scheduling\nProblem.)  \nGiven a list of n such jobs, your goal is to accept as many jobs as"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 239})","('type', 'Document')"
"('page_content', ""possible (regardless of their length), subject to the constraint that the\nprocessor can run at most one job at any given point in time. Provide\nan algorithm to do this with a running time that is polynomial in n.\nYou may assume for simplicity that no two jobs have the same start or\nend times.  \nExample.  Consider the following four jobs, specified by (start-time,\nend-time ) pairs.  \n(6 P.M., 6 A.M.), (9 P .M., 4 A.M.), (3 A.M., 2 P .M.), (1 P .M., 7 P .M.).\n \nThe optimal solution would be to pick the two jobs (9 P.M., 4 A.M.)\nand (1 P .M., 7 P .M.), which can be scheduled without overlapping.\n18. Your friends are planning an expedition to a small town deep  in the\nCanadian north next winter break. They've researched all the travel\noptions and have drawn up a directed graph whose nodes represent\nintermediate destinations and edges represent the roads between them.  \nIn the course of this, they've also learned that extreme weather causes\nroads in this part of the world to become quite slow in the winter and\nmay cause large travel delays. They've found an excellent travel Web\nsite that can accurately predict how fast they'll be able to trave l along\nthe roads; howe ver, the speed of travel depends on the time of year.\nMore precisely , the Web site answers queries of the following form:\ngiven an edge e=(v,w) connecting two sites v and w, and given a\nproposed starting time t from location v, the site will return a value\nfe(t), the predicted arrival time at w. The Web site guarantees that fe(t)\n≥ t for all edges e and all times t (you can't trave l backward in time),\nand that fe(t) is a monotone increasing function of t (that is, you do not\narrive earlier by starting later). Other than that, the functions fe(t) may\nbe arbitrary . For example, in areas where the travel time does not vary\nwith the season , we would have fe(t) = t + ℓe, where ℓe is the time\nneeded to travel from the beginning to the end of edge e. \nYour friends want to use the Web site to determine the fastest way to\ntravel through the directed graph from their starting point to their\nintended destination. (You should assume that they start at time 0, and\nthat all predictions made by the Web site are completely correct .) Give\na polynomial-time algorithm to do this, where we treat a single query"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 240})","('type', 'Document')"
"('page_content', ""to the Web site (based on a specific edge e and a time t) as taking a\nsingle computational step.\n19. A group of network designers at the communications company CluNet\nfind them selves facing the following problem. They have a connected\ngraph G = (V, E), in which the nodes represen t sites that want to\ncommunicate. Each edge e is a communication link, with a given\navailable bandwidth be. \nFor each pair of nodes u, v ∊ V, they want to select a single u-v path P\non which this pair will commun icate. The bottleneck rate b(P) of this\npath P is the minimum bandwidth of any edge it contains; that is, b(P)\n= mine ∊P be. The best achievable bottleneck rate for the pair u, v in G\nis simply the maximum, over all u-v paths P in G, of the value b(P). \nIt's getting to be very complicat ed to keep track of a path for each pair\nof nodes, and so one of the network designers makes a bold\nsuggestion: Maybe one can find a spanning tree T of G so that for\nevery  pair of nodes u, v, the unique u-v path in the tree actually attains\nthe best achievable bottleneck rate for u, v in G. (In other words, even\nif you could choose any u-v path in the whole graph, you couldn't do\nbetter than the u-v path in T.) \nThis idea is roundly heckled in the offices of CluNet for a few days,\nand there's a natural reason for the skepticism: each pair of nodes\nmight want a very different-looking path to maximize its bottleneck\nrate; why should there be a single tree that simultaneously makes\neverybody happy? But after some failed attempts to rule out the idea,\npeople begin to suspect it could be possible.  \nShow that such a tree exists, and give an efficient algorithm to find\none. That is, give an algorithm constructing a spanning tree T in which,\nfor each u,v ∊ V, the bottleneck rate of the u-v path in T is equal to the\nbest achievable bottleneck rate for the pair u, v in G.\n20. Every September , somewhere in a far-away mountainous part of the\nworld, the county highway crew s get together and decide which  roads\nto keep clear through the coming winter . There are n towns in this\ncounty , and the road system can be viewed as a (connected) graph G =\n(V,E) on this set of towns, each edge  representing a road joining two of\nthem. In the winter , people are high enough up in the mountai ns that\nthey stop worrying about the length  of roads and start worrying about\ntheir altitude -this is really what determines how difficult the trip will"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 241})","('type', 'Document')"
"('page_content', ""be. \nSo each road-each edge e in the graph-is annotated with a number ae\nthat gives the altitude of the highest point on the road. We'll assume\nthat no two edges have exactly the same altitude value ae. The height\nof a path P in the graph is then the maximu m of ae over all edges e on\nP. Finally , a path between towns i and j is declared to be winter -\noptimal  if it achieves the minimum possible height over all paths from\ni to j. \nThe highway crews are going to select a set E′ ⊆ E of the roads to\nkeep clear through the winter; the rest will be left unmaintained and\nkept off limits to travelers. They all agree that whichever subset of\nroads E′ they decide to keep clear , it should have the property that (V,\nE′) is a connected subgraph; and more strongly , for every pair of towns\ni and j, the height of the winter -optimal path in (V, E′) should  be no\ngreater than it is in the full graph G = (V, E). We'll say that (V, E′) is a\nminimum-altitude connected subgraph  if it has this property . \nGiven that they're going to maintain this key property , however , they\notherwise want to keep as few roads clear as possible. One year, they\nhit upon the following conjecture:  \nThe minim um spann ing tree of G, with respect to the edge weights ae, is a\nminimum-altitude connected subgraph.\n \n(In an earlier problem, we claimed that there is a unique minimum\nspanning tree when the edge weights are distinct. Thus, thanks to the\nassumption that all ae are distinct, it is okay for us to speak of the\nminimum spanning tree.)  \nInitially , this conjecture is somewhat counterintuitive, since the\nminimum spanning tree is trying to minimize the sum of the values ae,\nwhile the goal of minimizing altitude seems to be asking for a fairly\ndifferent thing. But lacking an argument to the contrary , they begin\nconsidering an even bolder second conjecture:  \nA subgrap h (V,E′) is a minimum-altitude connected subgraph if and only if it\ncontains the edges of the minimum spanning tr ee."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 242})","('type', 'Document')"
"('page_content', ""Note that this second conjecture would immediately imply the first\none, since a minimum spanning tree contains its own edges.\nSo here's the question.  \n(a) Is the first conje cture true, for all choices of G and distinct altitudes\nae? Give a proof or a counterexample with explanation.  \n(b) Is the second conjecture true, for all choices of G and distinct\naltitudes ae? Give a proof or a counterexample with explanation.\n21. Let us say that a graph G = (V,E) is a near-tree if it is connected and\nhas at most n + 8 edges, where n = |V|. Give an algori thm with running\ntime O(n) that takes a near-tree G with costs on its edges, and returns a\nminimum spanning tree of G. You may assume that all the edge costs\nare distinct.\n22. Consider the Minimum Spanning T ree Problem on an undirected graph\nG = (V, E), with a cost ce ≥ 0 on each edge, where the costs may not all\nbe different. If the costs are not all distinct, there can in general be\nmany distinct minimum-cost solutions. Suppose we are given a\nspanning tree T ⊆ E with the guarantee that for every e ∊ T, e belongs\nto some  minimu m-cost spanning tree in G. Can we concl ude that T\nitself must be a minimum-cost spanning tree in G? Give a proof or a\ncounterexample with explanation.\n23. Recall the problem of computing a minimum-cost arborescenc e in a\ndirected graph G = (V,E), with a cost ce ≥ 0 on each edge. Here we will\nconsider the case in which G is a directed acyclic graph-th at is, it\ncontains no directed cycles.  \nAs in general directed graphs, there can be many distinct minimum-\ncost solutions. Suppose we are given a directed acyclic graph G =\n(V,E), and an arborescence A ⊆ E with the guaran tee that for every e ∊\nA, e belongs to some  minimum-cost arborescence in G. Can we\nconclude that A itself must be a minimum-cost arborescence in G?\nGive a proof or a counterexample with explanation.\n24. Timing circuits are a crucial component of VLSI chips. Here's a simple\nmodel of such a timing circuit.  Consider a complete balanced binary\ntree with n leaves, where n is a power of two. Each edge e of the tree\nhas an associated length ℓe, which is a positive number . The distance\nfrom the root to a given leaf is the sum of the lengths of all the edges\non the path from the root to the leaf."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 243})","('type', 'Document')"
"('page_content', ""Figur e 4.20 An instance of the zero-skew problem, described in\nExercise 23.\nThe root generates a clock signal  which is propagated along the edges\nto the leaves. We'll assume that the time it takes for the signal to reach\na given leaf is proportional to the distance from the root to the leaf.  \nNow , if all leaves do not have the same distance from the root, then the\nsignal will not reach the leaves at the same time, and this is a big\nproblem. We want the leaves to be completely synchronized, and all to\nreceive the signal at the same time. To make this happen, we will have\nto increase the lengths of certain edges, so that all root-to-leaf paths\nhave the same length (we're not able to shrink edge lengths). If we\nachieve this, then the tree (with  its new edge lengths) will be said to\nhave zero skew. Our goal is to achieve zero skew in a way that keeps\nthe sum of all the edge lengths as small as possible.  \nGive an algorithm that increases the lengths of certain edges so that the\nresulting tree has zero skew and the total edge length is as small as\npossible.  \nExample.  Consider the tree in Figure 4.20, in which letters name the\nnodes and numbers indicate the edge lengths.  \nThe unique optimal solution for this instance would be to take the\nthree length-1 edges and increase each of their lengths to 2. The\nresulting tree has zero skew , and the total edge length is 12, the\nsmallest possible.\n25. Suppose we are given a set of points P = {p1,p2,…,pn}, together with a\ndistance function d on the set P; d is simply a function on pairs of\npoints in P with the proper ties that d(pi,pj) = d(pj,pi) > 0 if i ≠ j, and\nthat d(pi,pi) = 0 for each i. \nWe define a hierar chical metric  on P to be any distance function τ that"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 244})","('type', 'Document')"
"('page_content', ""can be construct ed as follows. We build a rooted tree T with n leaves,\nand we associate with each node v of T (both leaves and internal\nnodes) a height hv. These heights must satisfy the properties that h(v) =\n0 for each leaf v, and if u is the parent of v in T, then h(u) ≥ h(v). We\nplace each point in P at a distinct leaf in T. Now , for any pair of points\npi and pj their distance τ(pi,pj) is defined as follows. We determine the\nleast common ancestor v in T of the leaves containing pi and pj, and\ndefine τ( pi,pj) = hv. \nWe say that a hierarchical metric τ is consistent  with our distance\nfunction d if, for all pairs i,j, we have τ( pi,pj) ≤ d(pi,pj). \nGive a polynomial-time algorit hm that takes the distance function d\nand produces a hierarchical metric τ with the following properties.  \n(i) τ is consistent with d, and \n(ii) if τ′ is any other hierarchical  metric consistent with d, then τ′(pi,pj)\n≤ τ(pi,pj) for each pair of points pi and pj.\n26. One of the first things you learn in calculus is how to minimize a\ndifferentiable function such as y = ax2 + bx + c, where a > 0. The\nMinimum Spanning Tree Problem, on the other hand,  is a\nminimization problem of a very different flavor: there are now just a\nfinite number of possibilities for how the minimum might be achieved-\nrather than a continuum of possibilities-and we are interested in how to\nperform the computation without having to exhaust this (huge ) finite\nnumber of possibilities.  \nOne can ask what happens when these two minimization issues are\nbrought togethe r, and the following question is an example of this.\nSuppose we have a connected graph G = (V,E). Each edge e now has a\ntime-varying edge cost given by a function fe:R→R. Thus, at time t, it\nhas cost fe(t). We'll assume that all these functions are positive over\ntheir entire range. Observe that the set of edges constituti ng the\nminimum spanning tree of G may change over time. Also, of course,\nthe cost of the minimum spanning tree of G become s a function of the\ntime t; we'll denote this function cG(t). A natural problem then\nbecomes: find a value of t at which cG(t) is minimized.  \nSuppose each function fe is a polynomial of degree 2: fe(t) = aet2 + bet\n+ ce, where ae > 0. Give an algorithm that takes the graph G and the"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 245})","('type', 'Document')"
"('page_content', ""values {( ae,be,ce) : e ∊ E} and returns a value of the time t at which the\nminimum spann ing tree has minimum cost. Your algorithm should run\nin time polynomial in the number of nodes and edges of the graph G.\nYou may assume that arithmetic operations on the numbers {( ae,be,ce)}\ncan be done in constant time per operation.\n27. In trying to understand the combinatorial structure of spanning  trees,\nwe can conside r the space of all possibl e spann ing trees of a given\ngraph and study  the properties of this space. This is a strategy that has\nbeen applied to many similar problems as well.  \nHere is one way to do this. Let G be a connected graph, and T and T′\ntwo dif ferent spanning trees of G. We say that T and T′ are neighbors  if\nT contains exactly one edge that is not in T′, and T′ contains exactly\none edge that is not in T. \nNow , from any graph G, we can build a (large) graph ℋ  as follows.\nThe nodes of ℋ  are the spann ing trees of G, and there is an edge\nbetween two nodes of ℋ  if the corresponding spanning trees are\nneighbors.  \nIs it true that, for any connected graph G, the resulting graph ℋ  is\nconnected? Give a proof that ℋ  is always connected, or provide an\nexample (with explanation) of a connected graph G for which ℋ  is not\nconnected.\n28. Suppose you're a consultant for the networking company CluNet, and\nthey have the following problem. The network that they're currently\nworking on is modeled by a connected graph G = (V,E) with n nodes.\nEach edge e is a fiber-optic cable that is owned by one of two\ncompanies—creatively named X and Y—and leased to CluNet.  \nTheir plan is to choose a spanning tree T of G and upgrade the links\ncorresponding to the edges of T. Their business relations people  have\nalready concluded an agreement with companies X and Y stipulating a\nnumber k so that in the tree T that is chosen, k of the edges will be\nowned by X and n - k - 1 of the edges will be owned by Y. \nCluNet managem ent now faces the following problem. It is not at all\nclear to them whether there even exists  a spanning tree T meeting these\nconditions, or how to find one if it exists. So this is the problem they\nput to you: Give a polynomial-t ime algorithm that takes G, with each"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 246})","('type', 'Document')"
"('page_content', ""edge labeled X or Y, and either (i) returns a spanning tree with exactly\nk edges labeled X, or (ii) reports correctly that no such tree exists.\n29. Given a list of n natural numbers d1,d2,…,dn, show how to decide in\npolynomial time whether there exists an undirected graph G = (V,E)\nwhose node degrees are precise ly the numbers d1,d2,…,dn. (That is, if\nV = {v1,v2,…,vn}, then the degre e of vi should be exactly di.) G should\nnot contain multiple edges between the same pair of nodes, or “loop”\nedges with both endpoints equal to the same node.\n30. Let G = (V,E) be a graph with n nodes in which each pair of nodes is\njoined by an edge. There is a positive weight wtj on each edge (i,j); and\nwe will assume these weights satisfy the triangle inequality wlk ≤ wtj +\nwjk. For a subset V′ ⊆ V, we will use G[V′] to denote the subgraph\n(with edge weights) induced on the nodes in V′. \nWe are given a set X ⊆ V of k terminals  that must be connected by\nedges. We say that a Steiner tree on X is a set Z so that X ⊆ Z ⊆ V,\ntogether with a spanning subtre e T of G[Z]. The weight  of the Steiner\ntree is the weight of the tree T.\nShow that the problem of finding a minimum-weight Steiner tree on X\ncan be solved in time O(nO(k)).\n31. Let's go back to the original motivation for the Minimum Spanning\nTree Problem. We are given a connected, undirected graph G = (V, E)\nwith positive edge lengths {ℓe}, and we want to find a spanning\nsubgraph of it. Now suppose we are willing to settle for a subg raph H\n= (V, F) that is “dens er” than a tree, and we are interested in\nguaranteeing that, for each pair of vertices u, v ∊ V, the length of the\nshortest u-v path in H is not much longer than the length of the shortest\nu-v path in G. By the length  of a path P here, we mean the sum of ℓe\nover all edges e in P. \nHere's a variant of Kruskal's Algorithm designed to produce such a\nsubgraph.  \nFirst we sort all the edges in order of increasing length. (You may\nassume all edge lengths are distinct.)\nWe then construct a subgraph H = (V, F) by considering each edge\nin order ."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 247})","('type', 'Document')"
"('page_content', ""When we come to edge e = (u, v), we add e to the subgraph H if\nthere is currently no u-v path in H. (This is what Kruskal's\nAlgorithm woul d do as well.) On the other hand, if there is a u-v\npath in H, we let duv denote the length of the shortest such path;\nagain, length is with respect to the values {ℓe}. We add e to H if\n3ℓe < duv.\n \nIn other words, we add an edge even when u and v are already in the\nsame connected  component, provided that the addition of the edge\nreduces their shortest-path distance by a suf ficient amount.  \nLet H = (V, F) be the subgraph of G returned by the algorithm.  \n(a) Prove that for every pair of nodes u,v ∊V, the length of the shortest\nu-v path in H is at most three  times the length of the shortest u-v path\nin G. \n(b) Despite its ability to approximately preserve shortest-path\ndistances, the subgraph H produced by the algorithm cannot be too\ndense. Let f(n) denote the maximum number of edges that can possibly\nbe produced as the output of this algorithm, over all n-node input\ngraphs with edge lengths. Prove that  \n32. Consider a directed graph G = (V, E) with a root r ∊ V and nonnegative\ncosts on the edges. In this problem we consider variants of the\nminimum-cost arborescence algorithm.  \n(a) The algorithm discussed in Section 4.9 works as follows. We\nmodify the costs, consider the subgraph of zero-cost edges, look for a\ndirected cycle in this subgraph, and contract it (if one exists). Argue\nbriefly that instead of looking for cycles, we can instead identify and\ncontract strong components of this subgraph.  \n(b) In the course of the algorithm, we defined yv to be the minimum\ncost of an edge  entering v, and we modified the costs of all edges e\nentering node v to be c′e = ce - yv. Suppose we instead use the\nfollowing modif ied cost: c″e = max(0, ce - 2yv). This new change is"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 248})","('type', 'Document')"
"('page_content', 'likely to turn more edges to 0 cost. Suppose now we find an\narborescence T of 0 cost. Prove that this T has cost at most twice the\ncost of the minimum-cost arborescence in the original graph.  \n(c) Assume you do not find an arborescence of 0 cost. Contract all 0-\ncost strong components and recursively apply the same procedure on\nthe resulting graph until an arborescence is found. Prove that this T has\ncost at most twice the cost of the minimum-cost arborescence in the\noriginal graph.\n33. Suppose you are given a directed graph G = (V, E) in which each edge\nhas a cost of either 0 or 1. Also suppose that G has a node r such that\nthere is a path from r to every  other node in G. You are also given an\ninteger k. Give a polynomial-time algorithm that either constructs an\narborescence rooted at r of cost exactly k,  or reports (corr ectly) that no\nsuch arborescence exists.\nNotes and Further Reading\nDue to their conceptual cleanne ss and intuitive appeal, greedy algorithms\nhave a long history and many applications throughout computer  science. In\nthis chapter we focused on cases in which greedy algorithms find the\noptimal solution . Greedy algorithms are also often used as simp le heuristics\neven when they are not guaranteed to find the optimal solution. In Chapter\n11 we will discuss greedy algorithms that find near-optimal approximate\nsolutions.\nAs discu ssed in Chapter 1, Interval Scheduling can be viewed as a\nspecial case of the Independent Set Problem on a graph that represents the\noverlaps among a collection of intervals. Graphs arising this way are called\ninterval graphs , and they have been extensivel y studied; see, for example,\nthe book by Golumbic (1980). Not just Independent Set but many hard\ncomputational problems become much more tractable when restricted to the\nspecial case of interval graphs.\nInterval Schedu ling and the problem of scheduling to minimize the\nmaximum lateness are two of a range of basic scheduling problems for\nwhich a simple greedy algorit hm can be shown to produce an optimal\nsolution. A wealth of related problems can be found in the survey by\nLawler , Lenstra, Rinnooy Kan, and Shmoys (1993).')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 249})","('type', 'Document')"
"('page_content', ""The optimal algorithm for caching and its analysis are due to Belady\n(1966). As we mentioned in the text, under real operating conditions\ncaching algorithms must make eviction decisions in real time without\nknowledge of future requests. We will discuss such caching strategies in\nChapter 13 .\nThe algorithm for shortest paths in a graph with nonnegative edge\nlengths is due to Dijkstra (1959 ). Surveys of approaches to the Minimum\nSpanning Tree Problem, togethe r with historical background, can be found\nin the reviews by Graham and Hell (1985) and Nesetril (1997).\nThe single-link algorithm is one of the most widely used approaches to\nthe general problem of clustering; the books by Anderber g (1973), Duda,\nHart, and Stork (2001), and Jain and Dubes (1981) survey a variety of\nclustering techniques.\nThe algorithm for optimal prefix codes is due to Huffman (1952); the\nearlier approaches mentioned in the text appear in the books by Fano (1949)\nand Shannon and Weaver (1949). General overviews of the area of data\ncompression can be found in the book by Bell, Cleary , and Witten (1990)\nand the survey by Lelewer and Hirschber g (1987). More generally , this\ntopic belongs to the area of information theory , which is conce rned with the\nrepresentation and encoding of digital information. One of the founding\nworks in this field is the book by Shannon and W eaver (1949), and the more\nrecent textbook by Cover and Thomas (1991) provides detailed coverage of\nthe subject.\nThe algorithm for finding minimum-cost arborescences is generally\ncredited to Chu and Liu (1965) and to Edmonds (1967) independently . As\ndiscussed in the chapter , this multi-phase approach stretches our notion of\nwhat constitute s a greedy algorithm. It is also important from the\nperspective of linear programming, since in that context it can be viewed as\na fundamental application of the pricing method , or the primal-dual\ntechnique, for designing algorit hms. The book by Nemhauser and Wolsey\n(1988) develops these connectio ns to linear programming. We will discuss\nthis method in Chapter 1 1 in the context of approximation algorithms.\nMore generally , as we discussed at the outset of the chapter , it is hard\nto find a precise definition of what constitutes a greedy algorithm. In the\nsearch for such a definition, it is not even clear that one can apply the\nanalogue of U.S. Supreme Court Justice Potter Stewart's famous test for\nobscenity—“I know it when I see it”—since one finds disagreem ents within"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 250})","('type', 'Document')"
"('page_content', 'the research community on what constitutes the boundary , even intuitively ,\nbetween greedy and nongreedy algorithms. There has been research aimed\nat formalizing classes of greedy  algorithms: the theory of matroids is one\nvery influential example (Edmo nds 1971; Lawler 2001); and the paper of\nBorodin, Nielse n, and Rackof f (2002) formalizes notions of greedy and\n“greedy-type” algorithms, as well as providing a comparison to other\nformal work on this question.\nNotes on the Exercises  Exercise 24 is based on results  of M. Edahiro, T.\nChao, Y. Hsu, J. Ho, K. Boese,  and A. Kahng; Exercise 31 is based on a\nresult of Ingo Althofer , Gautam Das, David Dobkin, and Deborah Joseph.\n1 The problem is also referred to as the Interval Coloring Problem ; the\nterminology arises from thinking of the different resources as having\ndistinct colors—all the intervals  assigned to a particular resource are given\nthe corresponding color .')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 251})","('type', 'Document')"
"('page_content', 'Chapter 5')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 252})","('type', 'Document')"
"('page_content', 'Divide and Conquer\n5.1 A First Recurr ence: The Mergesort Algorithm  \n5.2 Further Recurr ence Relations  \n5.3 Counting Inversions  \n5.4 Finding the Closest Pair of Points  \n5.5 Integer Multiplication  \n5.6 Convolutions and the Fast Fourier T ransform  \nSolved Exer cises  \nExer cises  \nNotes and Further Reading\nDivide and conquer  refers to a class of algorithmic techniques in which one\nbreaks the input into several parts, solves the problem in each part\nrecursively , and then combines the solutions to these subproblems into an\noverall solution. In many cases, it can be a simple and powerful method.\nAnalyzing the running time of a divide and conquer algorithm\ngenerally involves solving a recurr ence relation  that bounds the running\ntime recursively in terms of the running time on smaller instances. We\nbegin the chapter with a general discussion of recurrence relations,\nillustrating how they arise in the analysis and describing methods for\nworking out upper bounds from them.\nWe then illustrate the use of divide and conquer with applications to a\nnumber of different domains: computing a distance function on different\nrankings of a set of objects; finding the closest pair of points in the plane;\nmultiplying two integers; and smoothing a noisy signal. Divide and conquer\nwill also come up in subsequen t chapters, since it is a method that often\nworks well when combined with other algorithm design techniques. For\nexample, in Chapter 6 we will see it combined with dynamic programming\nto produce a space-ef ficient solution to a fundamental sequence comparison\nproblem, and in Chapter 13 we will see it combined with randomization to\nyield a simple and efficient algorithm for computing the median  of a set of\nnumbers.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 253})","('type', 'Document')"
"('page_content', ""One thing to note about many settings in which divide and conquer is\napplied, including these, is that the natural brute-force algorithm may\nalready be polynomial time, and the divide and conquer strateg y is serving\nto reduce the running time to a lower polynomial. This is in contrast to most\nof the problems  in the previous chapters, for example, where  brute force\nwas exponential and the goal in designing a more sophisticated algorithm\nwas to achieve any kind of polynomial running time. For example, we\ndiscussed in Chapter 2  that the natural brute-force algorithm for finding the\nclosest pair among n points in the plane would simply measure all Θ(n2)\ndistances, for a (polynomial) running time of Θ(n2). Using divide and\nconquer , we will improve the running time to O(n log n). At a high level,\nthen, the overal l theme of this chapter is the same as what we've been\nseeing earlier: that improving on brute-force search is a fundamental\nconceptual hurdle in solving a problem efficiently , and the design of\nsophisticated algorithms can achieve this. The difference is simply that the\ndistinction betw een brute-force search and an improved solution here will\nnot always be the distinction between exponential and polynomial.\n5.1 A First Recurrence: The Mergesort Algorithm\nTo motivate the general approach to analyzing divide-a nd-conquer\nalgorithms, we begin with the Mergesort  Algorithm. We discussed the\nMergesort Algorithm briefly in Chapter 2, when we surveyed common\nrunning times for algorithms. Mergesort sorts a given list of numbers by\nfirst dividing them into two equal halves, sorting each half separately by\nrecursion, and then combining the results of these recursive calls—in the\nform of the two sorted halves—using the linear -time algorithm for merging\nsorted lists that we saw in Chapter 2 .\nTo analyze the running time of Mergesort, we will abstract its behavior\ninto the following template, which describes many common divide-and-\nconquer algorithms.\n(†) Divide the input into two pieces of equal size; solve the two subpr oblems on these\npieces separately by recursion; and then combine the two results into an overall\nsolution, spending only linear time for the initial division and final r ecombining."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 254})","('type', 'Document')"
"('page_content', ""In Mergesort, as in any algorithm that fits this style, we also need a base\ncase for the recursion, typically  having it “bottom out” on inputs of some\nconstant size. In the case of Mergesort, we will assume that once the input\nhas been reduced to size 2, we stop the recursion and sort the two elements\nby simply comparing them to each other .\nConsider any algorithm that fits the pattern in (†), and let T(n) denote\nits worst-case running time on input instances of size n. Supposing that n is\neven, the algorithm spends O(n) time to divide the input into two pieces of\nsize n/2 each; it then spends time T(n/2) to solve each one (since T(n/2) is\nthe worst-case running time for an input of size n/2); and finally it spends\nO(n) time to combi ne the solutions from the two recursive calls. Thus the\nrunning time T(n) satisfies the following recurr ence r elation.\n(5.1)  For some constant c,\nwhen n > 2, and\nThe structure of (5.1) is typical of what recurrences will look like: there's an\ninequality or equation that bounds T(n) in terms of an expression involving\nT(k) for smaller values k; and there is a base case that generally says that\nT(n) is equal to a constant when n is a constant. Note that one can also write\n(5.1) more informally as T(n) ≤ 2T(n/2) + O(n), suppressing the constant c.\nHowever , it is generally useful to make c explicit when analyzing the\nrecurrence.\nTo keep the exposition simpler , we will generally assume that\nparameters like n are even when needed. This is somewhat imprecise usage;\nwithout this assumption, the two recursive calls would be on problems of\nsize [ n/2] and [ n/2], and the recurrence relation would say that"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 255})","('type', 'Document')"
"('page_content', 'for n≥2. Nevertheless, for all the recurrences we consider here (and for\nmost that arise in practice), the asymptotic bounds are not affected by the\ndecision to ignore all the floors and ceilings, and it makes the symbolic\nmanipulation much cleaner .\nNow (5.1) does not explicitly provide an asymptotic bound on the\ngrowth rate of the function T; rather , it specifies T(n) implicitly in terms of\nits values on smaller inputs. To obtain an explicit bound, we need to solve\nthe recurrence relation so that T appears only on the left-hand side of the\ninequality , not the right-hand side as well.\nRecurrence solving is a task that has been incorporated into a number\nof stand ard computer algebra systems, and the solution to many standard\nrecurrences can now be found by automated means. It is still useful,\nhowever , to understand the process of solving recurrences and to recognize\nwhich recurrences lead to good running times, since the design of an\nefficient divide -and-conquer algorithm is heavily intertwine d with an\nunderstanding of how a recurrence relation determines a running time.\nApproaches to Solving Recurrences\nThere are two basic ways one can go about solving a recurren ce, each of\nwhich we describe in more detail below .\nThe most intuitively natural way to search for a solution  to a\nrecurrence is to “unroll” the recursion, accounting for the running time\nacross the first few levels, and identify a pattern that can be continued\nas the recursion expands. One then sums the running times over all\nlevels of the recursion (i.e., until it “bottoms out” on subproblems of\nconstant size) and thereby arrives at a total running time.\nA secon d way is to start with a guess for the solution, substitute  it into\nthe recurrence relation, and check that it works. Formally , one justifies\nthis plugging-in using an argument by induction on n. There is a useful\nvariant of this method in which one has a general form for the solution,\nbut does not have exact values for all the parameters. By leavin g these\nparameters unspecified in the substitution, one can often work them\nout as needed.\nWe now discuss  each of these approaches, using the recurrence in (5.1) as\nan example.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 256})","('type', 'Document')"
"('page_content', ""Unrolling the Mergesort Recurrence\nLet's start with the first approach to solving the recurrence in (5.1). The\nbasic ar gument is depicted in Figure 5.1 .\nAnalyzing the first few levels:  At the first level of recursion, we have a\nsingle problem of size n, which takes time at most cn plus the time\nspent in all subsequent recursive calls. At the next level, we have two\nproblems each of size n/2. Each of these takes time at most cn/2, for a\ntotal of at most cn, again plus the time in subsequent recursive calls. At\nthe third  level, we have four problems each of size n/4, each taking\ntime at most cn/4, for a total of at most cn.\nIdentifying a pattern:  What's going on in general? At level j of the\nrecursion, the number of subproblems has doubled j times, so there are\nnow a total of 2j. Each has corre spondingly shrunk in size by a factor\nof two j times, and so each has size n/2j, and hence each takes time at\nmost cn/2j. Thus level j contributes a total of at most 2j(cn/2j) = cn to\nthe total running time.\nSumming over all levels of recursion:  We've found that the recurrence\nin (5.1) has the property that the same upper bound of cn applies to\ntotal amount of work performed  at each level. The number of times the\ninput must be halved in order to reduce its size from n to 2 is log2 n.\nSo summing the cn work over log n levels of recursion, we get a total\nrunning time of O(n log n).\nFigur e 5.1  Unrolling the recurrence T(n) ≤ 2 T(n/2) + O(n).\nWe summarize this in the following claim."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 257})","('type', 'Document')"
"('page_content', ""(5.2)  Any function T (·) satisfying (5.1) is bounded by O (n log n), when n  > 1.\nSubstituting a Solution into the Mergesort\nRecurrence\nThe argument establishing (5.2)  can be used to determine that the function\nT(n) is bounded by O(n log n). If, on the other hand, we have a guess for the\nrunning time that we want to verify , we can do so by plugging it into the\nrecurrence as follows.\nSuppose we believe that T(n) ≤ cn log2 n for all n≥2, and we want to\ncheck whether this is indeed true. This clearly holds for n = 2, since in this\ncase cn log2 n = 2c, and (5.1) explicitly tells us that T(2) ≤ c. Now suppose,\nby induction, that T(m) ≤ cm log2 m for all values of m less than n, and we\nwant to establish  this for T(n). We do this by writing the recurrence for T(n)\nand plugging in the inequality T(n/2) ≤ c(n/2) log2(n/2). We then simplify\nthe resulting expression by noticing that log2(n/2) = (log2 n) - 1. Here is the\nfull calculation.\nThis establishes  the bound we want for T(n), assuming it holds for smaller\nvalues m < n, and thus it completes the induction ar gument.\nAn Approach Using Partial Substitution\nThere is a somewhat weaker kind of substitution one can do, in which one\nguesses the overall form of the solution without pinning down the exact\nvalues of all the constants and other parameters at the outset.\nSpecifically , suppose we believe that T(n) = O(n log n), but we're not\nsure of the constant inside the O(·) notat ion. We can use the substitution"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 258})","('type', 'Document')"
"('page_content', ""method even without being sure of this constant, as follows. We first write\nT(n) ≤ kn logb n for some constant k and base b that we'll determine later.\n(Actually , the base and the constant we'll end up needing are related to each\nother , since we saw in Chapter 2 that one can change the base of the\nlogarithm by simply changing the multiplicative constant in front.)\nNow we'd like to know whether there is any choice of k and b that will\nwork in an inductive argument. So we try out one level of the induction as\nfollows.\nIt's now very tempting to choose the base b = 2 for the logarithm, since we\nsee that this will let us apply the simplification log2(n/2) = (log2 n) - 1.\nProceeding with this choice, we have\nFinally , we ask: Is there a choice of k that will cause this last expression to\nbe bounded by kn log2 n? The answer is clearly yes; we just need to choose\nany k that is at least as lar ge as c, and we get\nwhich completes the induction.\nThus the substitution method can actually be useful in working out the\nexact constants when one has some guess of the general form of the\nsolution."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 259})","('type', 'Document')"
"('page_content', ""5.2 Further Recurrence Relations\nWe've just work ed out the solut ion to a recurrence relation, (5.1), that will\ncome up in the design of several divide-and-conquer algorithms later in this\nchapter . As a way to explore this issue further , we now consider a class of\nrecurrence relations that generalizes (5.1), and show how to solve the\nrecurrences in this class. Other members of this class will arise in the design\nof algorithms both in this and in later chapters.\nThis more general class of algorithms is obtained by considering\ndivide-and-conquer algorithms that create recursive calls on q subproblems\nof size n/2 each and then combine the results in O(n) time. This corresponds\nto the Mergesort recurrence (5.1) when q = 2 recursive calls are used, but\nother algorithms find it useful to spawn q > 2 recursive calls, or just a single\n(q = 1) recursive call. In fact, we will see the case q > 2 later in this chapter\nwhen we design algorithms for integer multiplication; and we will see a\nvariant on the case q = 1 much later in the book, when we design a\nrandomized algorithm for median finding in Chapter 13 .\nIf T(n) denotes the running time of an algorithm designed in this style ,\nthen T(n) obeys the following recurrence relation, which direct ly\ngeneralizes (5.1) by replacing 2 with q:\n(5.3)  For some constant c,\nwhen n > 2, and\nWe now describe how to solve (5.3) by the methods we've seen above:\nunrolling, substitution, and partial substitution. We treat the cases q > 2 and\nq = 1 separately , since they are qualitatively different from each other—and\ndifferent from the case q = 2 as well.\nThe Case of q > 2 Subproblems"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 260})","('type', 'Document')"
"('page_content', ""We begin by unrolling (5.3) in the case q > 2, following the style we used\nearlier for (5.1). We will see that the punch line ends up being quite\ndifferent.\nAnalyzing the first few levels:  We show an example of this for the case\nq = 3 in Figure 5.2. At the first level of recursion, we have a single\nproblem of size n, which takes time at most cn plus the time spent in\nall subsequent recursive calls. At the next level, we have q problems,\neach of size n/2. Each of these takes time at most cn/2, for a total of at\nmost (q/2)cn, again plus the time in subseq uent recursive calls. The\nnext level yields q2 problems of size n/4 each, for a total time of\n(q2/4)cn. Since q > 2, we see that the total work per level is increasing\nas we proceed through the recursion.\nIdentifying a pattern:  At an arbitrar y level j, we have qj distinct\ninstances, each of size n/2j. Thus the total work performed at level j is\nqj(cn/2j) = (q/2)jcn.\nSumming over all levels of recursion:  As before, there  are log2 n levels\nof recursion, and the total amount of work performed is the sum over\nall these:  \n \nThis is a geometric sum, consis ting of powers of r = q/2. We can use\nthe formula for a geometric sum when r > 1, which gives us the\nformula  \n \nSince we're aiming for an asymp totic upper bound, it is useful to figure"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 261})","('type', 'Document')"
"('page_content', ""out what's simp ly a constant; we can pull out the factor of r - 1 from\nthe denominator , and write the last expression as  \n \nFinally , we need to figure out what rlog2n is. Here we use a very handy\nidentity , which says that, for any a > 1 and b > 1, we have alogb = bloga.\nThus  \n \nThus we have  \nFigur e 5.2  Unrolling the recurrence T(n) ≤ 3 T(n/2) + O(n).\nWe sum this up as follows.\n(5.4)  Any function T (·) satisfying (5.3) with q  > 2 is bounded by O (nlog2q)."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 262})","('type', 'Document')"
"('page_content', ""So we find that the running time is more than linear , since log2 q > 1,\nbut still polynomial in n. Plugging in specific values of q, the running time\nis O(nlog23) = O(n1.59) when q = 3; and the running time is O(nlog24) = O(n2)\nwhen q = 4. This increase in running time as q increases makes sense, of\ncourse, since the recursive calls generate more work for lar ger values of q.\nApplying Partial Substitution  The appearance of log2 q in the exponent\nfollowed naturally from our solution to (5.3), but it's not necessarily an\nexpression one would have guessed at the outset. We now consider how an\napproach based on partial substitution into the recurrence yields a different\nway of discovering this exponent.\nSuppose we guess that the solut ion to (5.3), when q > 2, has the form\nT(n) ≤ knd for some constants k > 0 and d > 1. This is quite a general guess,\nsince we haven't even tried specifying the exponent d of the polynomial.\nNow let's try starting the inductive ar gument and seeing what constraints we\nneed on k and d. We have\nand applying the inductive hypothesis to T(n/2), this expands to\nThis is remarkably close to something that works: if we choo se d so that\nq/2d = 1, then we have T(n) ≤ knd + cn, which is almos t right except for the\nextra term cn. So let's deal with these two issues: first, how to choose d so\nwe get q/2d = 1; and second, how to get rid of the cn term.\nChoosing d is easy: we want 2d = q, and so d = log2 q. Thus we see\nthat the exponent log2 q appears very naturally once we decide to discover\nwhich value of d works when substituted into the recurrence."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 263})","('type', 'Document')"
"('page_content', ""But we still have to get rid of the cn term. To do this, we change the\nform of our guess for T(n) so as to explicitly subtract it off. Suppose we try\nthe form T(n) ≤ knd - ℓn, where we've now decided that d = log2 q but we\nhaven't fixed the constants k or ℓ. Applying the new formula to T(n/2), this\nexpands to\nThis now works completely , if we simply choose ℓ so that \n : in\nother words, ℓ = 2c/(q - 2). This comp letes the inductive step for n. We also\nneed to handle the base case n = 2, and this we do using the fact that the\nvalue of k has not yet been fixed: we choose k large enough so that the\nformula is a valid upper bound for the case n = 2.\nThe Case of One Subproblem\nWe now consid er the case of q = 1 in (5.3), since this illustrates an\noutcome of yet another flavor . While we won't see a direct application of\nthe recurrence for q = 1 in this chapter , a variation on it comes up in\nChapter 13 , as we mentioned earlier .\nWe begin by unrolling the recurrence to try constructing a solution.\nAnalyzing the first few levels:  We show the first few levels of the\nrecursion in Figure 5.3 . At the first level of recursion, we have a single\nproblem of size n, which takes time at most cn plus the time spent in\nall subsequent recursive calls. The next level has one problem of size\nn/2, which contributes cn/2, and the level after that has one problem of\nsize n/4, whic h contri butes cn/4. So we see that, unlike the previous"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 264})","('type', 'Document')"
"('page_content', 'case, the total work per level when q = 1 is actually decreasing  as we\nproceed through the recursion.\nIdentifying a pattern:  At an arbitrary level j, we still have just one\ninstance; it has size n/2j and contributes cn/2j to the running time.\nSumming over all levels of recursion:  There are log2 n levels of\nrecursion, and the total amount of work performed is the sum over all\nthese:  \n \nThis geometric sum is very easy to work out; even if we continued it to\ninfinity , it would conver ge to 2. Thus we have  \nFigur e 5.3  Unrolling the recurrence T(n) ≤ T(n/2) + O(n).\nWe sum this up as follows.\n(5.5)  Any function T (·) satisfying (5.3) with q  = 1 is bounded by O (n).\nThis is counterintuitive when you first see it. The algorithm is\nperforming log n levels of recursion, but the overall running time is still')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 265})","('type', 'Document')"
"('page_content', ""linear in n. The point is that a geometric series with a decaying exponent is\na power ful thing : fully half the work performed by the algorit hm is being\ndone at the top level of the recursion.\nIt is also useful to see how partial substitution into the recurrence\nworks very well in this case. Suppose we guess, as before, that the form of\nthe solution is T(n) ≤ knd. We now try to establish this by induction using\n(5.3), assuming that the solution holds for the smaller value n/2:\nIf we now simply choose d = 1 and k = 2c, we have\nwhich completes the induction.\nThe Effect of the Parameter q. It is worth reflecting briefly on the role of\nthe parameter q in the class of recurrences T(n) ≤ qT(n/2) + O(n) defined by\n(5.3). When q = 1, the resulting running time is linear; when q = 2, it's O(n\nlog n); and when q > 2, it's a polynomial bound with an exponent larger\nthan 1 that grow s with q. The reason for this range of different running\ntimes lies in where most of the work is spent in the recursion: when q = 1,\nthe total running time is dominated by the top level, whereas when q > 2 it's\ndominated by the work done on constant-size subproblems at the bottom of\nthe recursion. Viewed this way, we can appreciate that the recurrence for q\n= 2 really repre sents a “knife-edge”—the amount of work done at each\nlevel is exactly the same,  which is what yields the O(n log n) running time.\nA Related Recurrence: T(n) ≤ 2T(n/2) + O(n2)"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 266})","('type', 'Document')"
"('page_content', ""We conclude our discussion with one final recurrence relation; it is\nillustrative both as another application of a decaying geometric sum and as\nan interesting contrast with the recurrence (5.1) that characterized\nMergesort. Moreover , we will see a close variant of it in Chapter 6, when\nwe analyze a divide-and-conquer algorithm for solving the Sequence\nAlignment Problem using a small amount of working memory .\nThe recurrence is based on the following divide-and-conquer structure.\nDivide the input into two pieces of equal size; solve the two subpr oblems on these pieces\nseparately by recursion; and then combine the two results into an overall solution,\nspending quadratic time for the initial division and final r ecombining.\nFor our purpose s here, we note that this style of algorithm has a running\ntime T(n) that satisfies the following recurrence.\n(5.6)  For some constant c,\nwhen n > 2, and\nOne's first reaction is to guess that the solution will be T(n) = O(n2 log\nn), since it looks  almost identical to (5.1) except that the amount of work\nper level is larger by a factor equal to the input size. In fact, this upper\nbound is correct (it would need a more careful argument than what's in the\nprevious sentence), but it will turn out that we can also show  a stronger\nupper bound.\nWe'll do this by unrolling the recurrence, following the standard\ntemplate for doing this.\nAnalyzing the first few levels:  At the first level of recursion, we have a\nsingle problem of size n, which takes time at most cn2 plus the time\nspent in all subsequent recursive calls. At the next level, we have two\nproblems, each of size n/2. Each of these takes time at most c(n/2)2 =\ncn2/4, for a total of at most cn2/2, again  plus the time in subse quent"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 267})","('type', 'Document')"
"('page_content', ""recursive calls. At the third level, we have four problems each of size\nn/4, each taking time at most c(n/4)2 = cn2/16, for a total of at most\ncn2/4. Already we see that something is different from our solution to\nthe analogous recurrence (5.1); whereas the total amount of work per\nlevel remained the same in that case, here it's decreasing.\nIdentifying a pattern:  At an arbitrary level j of the recursion, there are\n2j subproblems, each of size n/2j, and hence the total work at this level\nis bounded by \n .\nSumming over all levels of recursion:  Having  gotten this far in the\ncalculation, we've arrived at almost exactly the same sum that we had\nfor the case q = 1 in the previous recurrence. W e have  \n \nwhere the second inequality follows from the fact that we have a\nconver gent geometric sum.\nIn retros pect, our initial guess of T(n) = O(n2 log n), based on the\nanalogy to (5.1), was an overest imate because of how quickly n2 decreases\nas we replace it with \n2, (\n)2, (\n)2, and so forth in the unrolling of the\nrecurrence. This means that we get a geometric sum, rather than one that\ngrows by a fixed amount over all n levels (as in the solution to (5.1)).\n5.3 Counting Inversions\nWe've spent some time discussing approaches to solving a number of\ncommon recurr ences. The remainder of the chapter will illustrate the\napplication of divide-and-conquer to problems from a number of different\ndomains; we will use what we've seen in the previous sections to bound the\nrunning times of these algorithm s. We begin by showing how a variant of"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 268})","('type', 'Document')"
"('page_content', ""the Mergesort technique can be used to solve a problem that is not directly\nrelated to sorting numbers.\nThe Problem\nWe will consider a problem that arises in the analysis of rankings,  which are\nbecoming impo rtant to a number of current applications. For example, a\nnumber of sites on the W eb make use of a technique known as collaborative\nfiltering,  in which they try to match your preferences (for books, movies,\nrestaurants) with those of other  people out on the Internet. Once the Web\nsite has identified people with “similar” tastes to yours—based on a\ncomparison of how you and they rate various things—it can recommend\nnew things that these other peop le have liked. Another application arises in\nmeta-sear ch tools  on the Web, which execute the same query on many\ndifferent search engines and then try to synthesize the results by looking for\nsimilarities and differences among the various rankings that the search\nengines return.\nA core issue in applications like this is the problem of comparing two\nrankings. You rank a set of n movies, and then a collaborative filtering\nsystem consults  its database to look for other people who had “similar”\nrankings. But what's a good way to measure, numerically , how similar two\npeople's rankings are? Clearly an identical ranking is very similar, and a\ncompletely reversed ranking is very different; we want something that\ninterpolates through the middle region.\nLet's consider comparing your ranking and a stranger's ranking of the\nsame set of n movies. A natural method would be to label the movies from\n1 to n according to your ranking, then order these labels according to the\nstranger's ranking, and see how many pairs are “out of order .” More\nconcretely , we will consider the following problem. We are given a\nsequence of n numbers a1, …, an; we will assume that all the numbers are\ndistinct. We want to define a measure that tells us how far this list is from\nbeing in ascending order; the value of the measure should be 0 if a1 < a2 <\n… < an, and should increase as the numbers become more scrambled.\nA natural way to quantify this notion is by counting the number of\ninversions.  We say that two indices i < j form an inversi on if ai > aj, that is,"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 269})","('type', 'Document')"
"('page_content', ""if the two elements ai and aj are “out of order .” We will seek to determine\nthe number of inversions in the sequence a1,…,an.\nJust to pin down this definition, consider an example in which the\nsequence is 2,4,1,3,5. There are three inversions in this sequence: (2,1),\n(4,1), and (4, 3). There is also an appealing geometric way to visualize the\ninversions, pictu red in Figure 5.4: we draw the sequence of input numbers\nin the order they're provided, and below that in ascending order . We then\ndraw a line segm ent between each number in the top list and its copy in the\nlower list. Each crossing pair of line segments corresponds to one pair that\nis in the opposite order in the two lists—in other words, an inversion.\nFigur e 5.4 Counting the number of inversions in the sequence 2,4,1,3,5 .\nEach crossing pair of line segments corresponds to one pair that is in the\nopposite order in the input list and the ascending list—in other words, an\ninversion.\nNote how the number of inversions is a measure that smoothly\ninterpolates between complete agreement (when the sequence is in\nascending order , then there are no inversions) and complete disagreement\n(if the sequence is in descending order , then every pair forms an inversion,\nand so there are \n  of them).\nDesigning and Analyzing the Algorithm\nWhat is the simplest algorithm to count inversions? Clearly , we could look\nat every pair of numbers (ai, aj) and determine whether they constitute an\ninversion; this would take O(n2) time.\nWe now show how to count the number of inversions much  more\nquickly , in O(n log n) time. Note that since there can be a quadratic number\nof inversions, such an algorithm  must be able to compute the total number\nwithout ever looking at each inversion individually . The basic idea is to\nfollow the strategy (†) defined in Section 5.1. We set m = [n/2] and divide\nthe list into the two pieces a1,…,am and am+1,…,an. We first count the"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 270})","('type', 'Document')"
"('page_content', 'number of inversions in each of these two halves separately . Then we count\nthe number of inversions (ai, aj), where the two numbers belong  to different\nhalves; the trick is that we must do this part in O(n) time, if we want to\napply (5.2). Note that these first-half/second-half inversions have a\nparticularly nice form: they are precisely the pairs (ai, aj), where ai is in the\nfirst half, aj is in the second half, and ai > aj.\nTo help with counting the number of inversions between the two\nhalves, we will make the algorithm recursively sort the numbers in the two\nhalves as well. Having the recursive step do a bit more work (sorting as\nwell as counting inversions) will make the “combining” portion of the\nalgorithm easier .\nSo the crucial routine in this process is Merge-and-Count . Suppose\nwe have recursively sorted the first and second halves of the list and\ncounted the inversions in each. We now have two sorted lists A and B,\ncontaining the first and second halves, respectively . We want to produce a\nsingle sorted list C from their union, while also counting the number of\npairs ( a, b) with a ∊ A, b ∊ B, and a > b. By our previous discussion, this is\nprecisely what we will need for the “combining” step that computes the\nnumber of first-half/second-half inversions.\nThis is closely related to the simpler problem we discussed in Chapter\n2, which formed the correspondi ng “combining” step for Mergesort: there\nwe had two sorte d lists A and B, and we wanted to merge them into a single\nsorted list in O(n) time. The difference here is that we want to do something\nextra: not only should we produce a single sorted list from A and B, but we\nshould also count the number of “inverted pairs” (a, b) where a ∊ A, b ∊ B,\nand a > b.\nIt turns out that we will be able to do this in very much the same style\nthat we used for merging. Our Merge-and-Count routine will walk through\nthe sorted lists A and B, removing elements from the front and appending\nthem to the sorted list C. In a given step, we have a Curr ent pointer into\neach list, showing our current position. Suppose that these pointers are\ncurrently at elements ai and bj. In one step, we compare the elements ai and\nbj being pointed to in each list, remove the smaller one from its list, and\nappend it to the end of list C.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 271})","('type', 'Document')"
"('page_content', 'Figur e 5.5 Merging two sorted lists while also counting the number of\ninversions between them.\nThis takes care of merging. How do we also count the number of\ninversions? Because A and B are sorted, it is actually very easy to keep\ntrack of the number of inversions we encounter . Every time the element ai is\nappended to C, no new inversi ons are encountered, since ai is small er than\neverything left in list B, and it comes before all of them . On the other hand,\nif bj is appended to list C, then it is small er than all the remaining items in\nA, and it comes after all of them, so we increase our count of the number of\ninversions by the number of elements remaining in A. This is the crucial\nidea: in constant  time, we have accounted for a potentially large number of\ninversions. See Figure 5.5  for an illustration of this process.\nTo summarize, we have the following algorithm.\nMerge-and-Count ( A,B)\nMaintain a Curr ent pointer into each list, initialized to point to the front elements\nMaintain a variable Count  for the number of inversions, initialized to 0\nWhile both lists are nonempty:\nLet ai and bj be the elements pointed to by the Curr ent pointer\nAppend the smaller of these two to the output list\nIf bj is the smaller element then\nIncrement Count  by the number of elements remaining in A\nEndif\nAdvance the Curr ent pointer in the list from which the smaller element was selected.\nEndWhile\nOnce one list is empty , append the remainder of the other list to the output\nReturn Count  and the mer ged list\nThe running time of Mer ge-and-Count can be bounded by the analogue\nof the argument we used for the original merging algorithm at the heart of\nMergesort: each iteration of the While loop takes constant time,  and in each')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 272})","('type', 'Document')"
"('page_content', ""iteration we add some element to the output that will never be seen again.\nThus the number of iterations can be at most the sum of the initial lengths\nof A and B, and so the total running time is O(n).\nWe use this Merge-and-Count routine in a recursive procedure that\nsimultaneously sorts and counts the number of inversions in a list L.\nSort-and-Count( L)\nIf the list has one element then\nthere are no inversions\nElse\nDivide the list into two halves:\nA contains the first [ n/2] elements\nB contains the remaining [ n/2] elements\n(rA, A) = Sort-and-Count( A)\n(rB, B) = Sort-and-Count( B)\n(r,L) = Mer ge-and-Count( A, B)\nEndif\nReturn r = rA + rB + r, and the sorted list L\nSince our Merge-and-Count procedure takes O(n) time, the running\ntime T(n) of the full Sort-and-Count procedure satisfies the recurrence (5.1).\nBy (5.2), we have\n(5.7)  The Sort-and-Count algorithm corr ectly sorts the input list and counts the number of inversions;\nit runs in O (n log n) time for a list with n elements.\n5.4 Finding the Closest Pair of Points\nWe now describe another proble m that can be solved by an algorithm in the\nstyle we've been discussing; but finding the right way to “mer ge” the\nsolutions to the two subproblems it generates requires quite a bit of\ningenuity .\nThe Problem\nThe problem we consider is very simple to state: Given n points in the\nplane, find the pair that is closest together ."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 273})","('type', 'Document')"
"('page_content', ""The problem was considered by M. I. Shamos and D. Hoey in the early\n1970s, as part of their project to work out efficient algorithms for basic\ncomputational primitives in geometry . These algorithms formed the\nfoundations of the then-fledgling field of computational geometry , and they\nhave found their way into areas such as graphics, computer vision,\ngeographic information systems, and molecular modeling. And although the\nclosest-pair problem is one of the most natural algorithmic problems in\ngeometry , it is surprisingly hard to find an efficient algorithm for it. It is\nimmediately clear that there is an O(n2) solution—compute the distance\nbetween each pair of points and take the minimum—and so Shamos and\nHoey asked whether an algorithm asymptotically faster than quadratic could\nbe found . It took quite a long time before they resolved this question, and\nthe O(n log n) algorithm we give below is essentially the one they\ndiscovered. In fact, when we return to this problem in Chapter 13, we will\nsee that it is possible to further improve the running time to O(n) using\nrandomization.\nDesigning the Algorithm\nWe begin with a bit of notation. Let us denote the set of points by P = {p1,\n…, pn}, where pi has coordinates ( xi,yi); and for two points pi,pj ∊ P, we use\nd(pi, pj) to deno te the standard Euclidean distance between them. Our goal\nis to find a pair of points pi,pj that minimizes d(pi,pj).\nWe will assume that no two points in P have the same x-coordinate or\nthe same y-coordinate. This makes the discussion cleaner; and it's easy to\neliminate this assumption either by initially applying a rotation to the points\nthat makes it true, or by slightly extending the algorithm we develop here.\nIt's instructive to consider the one-dimensional version of this problem\nfor a minute, since it is much simpler and the contrasts are revealing. How\nwould we find the closest pair of points on a line? We'd first sort them, in\nO(n log n) time, and then we'd walk through the sorted list, computing the\ndistance from each point to the one that comes after it. It is easy to see that\none of these distances must be the minimum one.\nIn two dimens ions, we could try sorting the points by their y-\ncoordinate (or x-coordinate) and hoping that the two closest points were\nnear one another in the order of this sorted list. But it is easy to construct"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 274})","('type', 'Document')"
"('page_content', ""examples in which they are very far apart, preventing us from adapting our\none-dimensional approach.\nInstead, our plan will be to apply the style of divide and conquer used\nin Mergesort: we find the closest pair among the points in the “left half” of\nP and the closest pair among the points in the “right half” of P; and then we\nuse this information to get the overall solution in linear time. If we develop\nan algorithm with this structure, then the solution of our basic recurrence\nfrom (5.1) will give us an O(n log n) running time.\nIt is the last, “combining” phase of the algorithm that's tricky: the\ndistances that have not been considered by either of our recursive calls are\nprecisely those that occur between a point in the left half and a point in the\nright half; there are Ω(n2) such distances, yet we need to find the smallest\none in O(n) time after the recursive calls return. If we can do this, our\nsolution will be complete: it will be the smallest of the values computed in\nthe recursive calls and this minimum “left-to-right” distance.\nSetting Up the Recursion  Let's get a few easy things out of the way first. It\nwill be very useful if every recursive call, on a set P′ ⊆ P, begins with two\nlists: a list P′x in which all the points in P′ have been sorte d by increasing x-\ncoordinate, and a list P′y in which all the points in P′ have been sorted by\nincreasing y-coordinate. We can ensure that this remains true throughout the\nalgorithm as follows.\nFirst, before any of the recursio n begins, we sort all the points in P by\nx-coordinate and again by y-coordinate, producing lists Px and Py. Attached\nto each entry in each list is a record of the position of that point in both lists.\nThe first level of recursion will work as follows, with all further levels\nworking in a completely analogous way. We define Q to be the set of points\nin the first [ n/2] positions of the list Px (the “left half”) and R to be the set of\npoints in the final [n/2] positions of the list Px (the “right half” ). See Figure\n5.6. By a single pass through each of Px and Py, in O(n) time, we can create\nthe following four lists: Qx, consisting of the points in Q sorted by\nincreasing x-coordinate; Qy, consisting of the points in Q sorted by\nincreasing y-coordinate; and analogous lists Rx and Ry. For each entry of\neach of these lists, as before, we record the position of the point in both lists\nit belongs to."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 275})","('type', 'Document')"
"('page_content', 'Figur e 5.6 The first level of recursion: The point set P is divided evenly\ninto Q and R by the line L, and the closest pair is found  on each side\nrecursively .\nWe now recursively determine  a closest pair of points in Q (with\naccess to the lists Qx and Qy). Suppo se that q0* and q1* are (correctly)\nreturned as a closest pair of points in Q. Simila rly, we determine a closest\npair of points in R, obtaining r0* and r1*.\nCombining the Solutions  The general machinery of divide and conquer has\ngotten us this far, without our really having delved into the structure of the\nclosest-pair problem. But it still leaves us with the problem that we saw\nlooming originally: How do we use the solutions to the two subproblems as\npart of a linear -time “combining” operation?\nLet δ be the minimum of d(q0*,q1*) and d(r0*,r1*). The real question\nis: Are there points q ∊ Q and r ∊ R for which d(q, r) < δ? If not, then we\nhave already found the closest pair in one of our recursive calls. But if there\nare, then the closest such q and r form the closest pair in P.\nLet x* denote the x-coordinate of the rightmost point in Q, and let L\ndenote the vertical line described by the equation x = x*. This line L\n“separates” Q from R. Here is a simple fact.\n(5.8)  If there exists q ∊ Q and r  ∊ R for which  d(q, r) < δ, then each of q and r lies within a distance\nδ of L.\nProof. Supp ose such q and r exist; we write q = (qx, qy) and r = (rx, ry). By the definition of x*, we\nknow that qx ≤ x* ≤ rx. Then we have')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 276})","('type', 'Document')"
"('page_content', ""and\nso each of q and r has an x-coordinate within δ of x* and hence lies within distance δ of the line L. ▪\nSo if we want to find a close q and r, we can restrict our search to the\nnarrow band consisting only of points in P within δ of L. Let S ⊆ P denote\nthis set, and let Sy denote the list consisting of the points in S sorted by\nincreasing y-coordinate. By a single pass through the list Py, we can\nconstruct Sy in O(n) time.\nWe can restate (5.8) as follows, in terms of the set S.\n(5.9)  There exist q ∊  Q and r ∊  R for which d(q, r) < δ if and only if there exist s,s′ ∊  S for which\nd(s,s′) < δ.\nIt's worth noticing at this point that S might in fact be the whole set P,\nin which case (5.8) and (5.9) really seem to buy us nothing. But this is\nactually far from true, as the following amazing fact shows.\n(5.10)  If s, s′ ∊  S have the pr operty that d (s, s′) < δ, then s and s′ ar e within  15 positions of each other\nin the sorted list S y.\nProof. Consider the subset Z of the plane consistin g of all points within distance δ of L. We partition\nZ into boxes:  squares with horizon tal and vertical sides  of length δ/2. One row of Z will consi st of\nfour boxes whose horizontal sides have the same y-coordinates. This collection of boxes is depicted\nin Figure 5.7 .\nSuppose two points of S lie in the same box. Since all points in this box lie on the same side of\nL, these two points either both belong to Q or both belong to R. But any two points in the same box\nare within distance δ · √2/2 < δ, which contradicts our definition of δ as the minimum distance\nbetween any pair of points in Q or in R. Thus each box contains at most one point of S.\nNow suppo se that s,s′ ∊ S have the property that d(s,s′) < δ, and that they are at least 16\npositions apart in Sy. Assume without loss of generality that s has the smaller y-coordinate. Then,\nsince there  can be at most one point per box, there are at least three rows of Z lying betw een s and s′.\nBut any two points in Z separated by at least three rows must be a distance of at least 3δ/2 apart—a\ncontradiction. ▪\nFigur e 5.7  The portion of the plane close to the dividing line L, as analyzed\nin the proof of (5.10)."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 277})","('type', 'Document')"
"('page_content', ""We note that the value of 15 can be reduced; but for our purposes at\nthe moment, the important thing is that it is an absolute constant.\nIn view of (5.10 ), we can conclu de the algorithm as follows. We make\none pass through  Sy, and for each s ∊ Sy, we compute its distance to each of\nthe next 15 points in Sy. Statement (5.10) implies that in doing so, we will\nhave computed the distance of each pair of points in S (if any) that are at\ndistance less than δ from each other. So having done this, we can compare\nthe smal lest such distance to δ, and we can report one of two things: (i) the\nclosest pair of points in S, if their distance is less than δ; or (ii) the (correct)\nconclusion that no pairs of points in S are within δ of each other . In case (i),\nthis pair is the closest pair in P; in case (ii), the closest pair found by our\nrecursive calls is the closest pair in P.\nNote the resemblance between this procedure and the algorithm we\nrejected at the very beginning, which tried to make one pass through P in\norder of y-coordinate. The reason such an approach works now is due to the\nextra knowledge (the value of δ) we've gained from the recursive calls, and\nthe special structure of the set S.\nThis concludes the description of the “combining” part of the\nalgorithm, since  by (5.9) we have now determined whether the minimum\ndistance between a point in Q and a point in R is less than δ, and if so, we\nhave found the closest such pair ."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 278})","('type', 'Document')"
"('page_content', 'A comp lete description of the algorithm and its proof of correctness\nare implicitly contained in the discussion so far, but for the sake of\nconcreteness, we now summarize both.\nSummary of the Algorithm  A high-level description of the algorithm is the\nfollowing, using the notation we have developed above.\nClosest-Pair( P)\nConstruct Px and Py (O(n log n) time)\n(P*0, p*1) = Closest-Pair -Rec( Px,Py)\n \nClosest-Pair -Rec( Px,Py)\nIf |P| ≤ 3 then\nfind closest pair by measuring all pairwise distances\nEndif\n \nConstruct Qx, Qy, Rx, Ry (O(n) time)\n(q0*,q1*) = Closest-Pair -Rec( Qx, Qy)\n(r0*,r1*) = Closest-Pair -Rec( Rx, Ry)\n \nδ = min( d(q0*,q1*), d(r*0,r*1))\nx* = maximum x-coordinate of a point in set Q\nL = {( x,y) : x = x*}\nS = points in P within distance δ of L.\n \nConstruct Sy (O(n) time)\nFor each point s ∊ Sy, compute distance from s\nto each of next 15 points in Sy\nLet s, s′ be pair achieving minimum of these distances\n(O(n) time)\n \nIf d(s,s′) < δ then\nReturn ( s,s′)\nElse if d(q0*,q1*) < d(r0*,r1*) then\nReturn ( q*0, q1*)\nElse\nReturn ( r0*,r1*)\nEndif\nAnalyzing the Algorithm')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 279})","('type', 'Document')"
"('page_content', ""We first prove that the algorithm produces a correct answer , using the facts\nwe've established in the process of designing it.\n(5.11) The algorithm corr ectly outputs a closest pair of points in P .\nProof. As we've noted, all the components of the proof have already been worked out, so here we\njust summarize how they fit together .\nWe prove the correct ness by induction on the size of P, the case of |P| ≤ 3 being clear . For a\ngiven P, the closest pair in the recursive calls is computed correctly by induction. By (5.10) and (5.9),\nthe remainder of the algorithm correctly determines whether any pair of points in S is at distance less\nthan δ, and if so returns the closest such pair. Now the closest pair in P either has both elem ents in\none of Q or R, or it has one elemen t in each. In the form er case, the closest pair is correctly found by\nthe recursive call; in the latter case, this pair is at distance less than δ, and it is correctly found by the\nremainder of the algorithm. ▪\nWe now bound the running time as well, using (5.2).\n(5.12)  The running time of the algorithm is O (n log n).\nProof. The initial  sorting of P by x- and y-coordinate takes time O(n log n). The running time of the\nremainder of the algorithm satisfies the recurrence (5.1), and hence is O(n log n) by (5.2). ▪\n5.5 Integer Multiplication\nWe now discuss  a different application of divide and conquer , in which the\n“default” quadratic algorithm is improved by means of a different\nrecurrence. The analysis of the faster algorithm will exploit one of the\nrecurrences considered in Section 5.2, in which more than two recursive\ncalls are spawned at each level.\nThe Problem\nThe problem we consider is an extremely basic one: the multiplication of\ntwo integers. In a sense, this problem is so basic that one may not initially\nthink of it even as an algorithmic question. But, in fact, elementary\nschoolers are taught a concrete  (and quite efficient) algorithm to multiply\ntwo n-digit numbers x and y. You first compute a “partial product” by\nmultiplying each digit of y separat ely by x, and then you add up all the\npartial products. (Figure 5.8 should  help you recall this algorithm. In\nelementary school we always see this done in base-10, but it works exactly\nthe same way in base-2 as well.) Counting a single operation on a pair of"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 280})","('type', 'Document')"
"('page_content', ""bits as one prim itive step in this computation, it takes O(n) time to compu te\neach partial product, and O(n) time to combin e it in with the running sum of\nall partial products so far. Since there are n partial products, this is a total\nrunning time of O(n2).\nFigur e 5.8 The elementary -school algorithm for multiplying two integers ,\nin (a) decimal and (b) binary representation.\nIf you haven't thought about this much since elementary school, there's\nsomething initially striking about the prospect of improvi ng on this\nalgorithm. Aren't all those partial products “necessary” in some way? But,\nin fact, it is possible to improve on O(n2) time using a different, recursi ve\nway of performing the multiplication.\nDesigning the Algorithm\nThe improved algorithm is based on a more clever way to break up the\nproduct into partial sums. Let's assume we're in base-2 (it doesn't really\nmatter), and start by writing x as x1 · 2n/2 + x0. In other words, x1\ncorresponds to the “high-order” n/2 bits, and x0 corresponds to the “low-\norder” n/2 bits. Similarly , we write y = y1 · 2n/2 + y0. Thus, we have\nEquation (5.1)  reduces the problem of solving a single n-bit instance\n(multiplying the two n-bit numbers x and y) to the problem of solving four"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 281})","('type', 'Document')"
"('page_content', 'n/2-bit instances (computing the products x1y1, x1y0, x0y1, and x0y0). So we\nhave a first candidate for a divide-and-conquer solution: recursively\ncompute the results for these four n/2-bit instances, and then combine them\nusing Equation (5.1) . The combining of the solution requires a constant\nnumber of additions of O(n)-bit numbers, so it takes time O(n); thus, the\nrunning time T(n) is bounded by the recurrence\nfor a constant c. Is this good enough to give us a subquadratic running time?\nWe can work out the answer by observing that this is just the case q =\n4 of the class of recurrences in (5.3). As we saw earlier in the chapter , the\nsolution to this is T(n) < O(nlog2q) = O(n2).\nSo, in fact, our divide-and-conquer algorithm with four-way branching\nwas just a complicated way to get back to quadratic time! If we want to do\nbetter using a strategy that reduces the problem to instances on n/2 bits, we\nshould try to get away with only three recursiv e calls. This will lead to the\ncase q = 3 of (5.3), which we saw had the solution T(n) ≤ O(nlog2q) =\nO(n1.59).\nRecall that our goal is to comp ute the expression x1y1 · 2n + (x1y0 +\nx0y1) · 2n/2 + x0y0 in Equation (5.1) . It turns  out there is a simple trick that\nlets us determine all of the terms in this expression using just three\nrecursive calls. The trick is to consider the result of the single multiplication\n(x1 + x0)(y1 + y0) = x1y1 + x1y0 + x0y1 + x0y0. This has the four products\nabove added together , at the cost of a single recursive multiplic ation. If we\nnow also determ ine x1y1 and x0y0 by recursion, then we get the outermost\nterms explicitly , and we get the middle term by subtracting x1y1 and x0y0\naway from ( x1 + x0)(y1 + y0).\nThus, in full, our algorithm is\nRecursive-Multiply(x,y):\nWrite x = x1 · 2n/2 + x0 \ny = y1 · 2n/2 + y0\nCompute x1 + x0 and y1 + y0')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 282})","('type', 'Document')"
"('page_content', 'p = Recursive-Multiply( x1 + x0, y1 + y0)\nx1y1 = Recursive-Multiply( x1,y1)\nx0y0 = Recursive-Multiply( x0,y0)\nReturn x1y1 · 2n + (p - x1y1 - x0y0) · 2n/2 + x0y0\nAnalyzing the Algorithm\nWe can determine the running time of this algorithm as follows. Given two\nn-bit numbers, it performs a constant number of additions on O(n)-bit\nnumbers, in addition to the three recursive calls. Ignoring for now the issue\nthat x1 + x0 and y1 + y0 may have n/2 + 1 bits (rather than just n/2), which\nturns out not to affect the asymptotic results, each of these recursive calls is\non an instance of size n/2. Thus , in place of our four-way branching\nrecursion, we now have a three-way branching one, with a running time that\nsatisfies\nfor a constant c.\nThis is the case q = 3 of (5.3) that we were aiming for. Using the\nsolution to that recurrence from earlier in the chapter , we have\n(5.13)  The running time of  Recursive-Multiply on two n-bit factors is O (nlog23) = O(n1.59).\n5.6 Convolutions and the Fast Fourier Transform\nAs a final topic in this chapter , we show how our basic recurrence from\n(5.1) is used in the design of the Fast Fourier Transform , an algorithm with\na wide range of applications.\nThe Problem')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 283})","('type', 'Document')"
"('page_content', ""Given two vecto rs a = (a0, a1, …, an-1) and b = (b0, b1, …, bn-1), there are a\nnumber of common ways of combining them. For example, one can\ncompute the sum, producing the vector a + b = (a0 + b0, a1 + b1, …, an-1 +\nbn-1); or one can compute the inner product, producing the real number a · b\n= a0b0 + a1b1 + ··· + an-1bn-1. (For reasons that will emer ge shortly , it is\nuseful to write vectors in this section with coordinates that are indexed\nstarting from 0 rather than 1.)\nA means of combining vectors that is very important in applic ations,\neven if it doesn't always show up in introductory linear algebra courses, is\nthe convolution a*b.  The convolution of two vectors of length n (as a and b\nare) is a vector with 2 n - 1 coordinates, where coordinate k is equal to\nIn other words,\nThis definition is a bit hard to absorb when you first see it. Another way to\nthink about the convolution is to picture an n × n table whose (i,j) entry is\naibj, like this,\nand then to compute the coordinates in the convolution vector by summing\nalong the diagonals."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 284})","('type', 'Document')"
"('page_content', ""It's worth mentioning that, unlike the vector sum and inner product, the\nconvolution can be easily generalized to vectors of different lengths, a =\n(a0, a1, …, am-1) and b = (b0, b1, …, bn-1). In this more general case, we\ndefine a * b to be a vector with m + n - 1 coordinates, where coordinate k is\nequal to\nWe can picture this using the table of products aibj as before; the table is\nnow rectangular , but we still compute coordinates by summing along the\ndiagonals. (From here on, we'll drop explicit mention of the condition i <\nm,j < n in the summations for convolutions, since it will be clear from the\ncontext that we only compute the sum over terms that are defined.)\nIt's not just the definition of a convolution that is a bit hard to absorb at\nfirst; the motiva tion for the definition can also initially be a bit elusive.\nWhat are the circumstances where you'd want to compute the convolution\nof two vectors?  In fact, the convolution comes up in a surprisingly wide\nvariety of different contexts. To illustrate this, we mention the following\nexamples here.\nA first example  (which also proves that the convolution is something\nthat we all saw implicitly in high school) is polynomial multipli cation.\nAny polynomial A(x) = a0 + a1x + a2x2 + ··· am-1xm-1 can be\nrepresented just as naturally using its vector of coefficients, a = (a0, a1,\n…, am-1). Now, given two polynomials A(x) = a0 + a1x + a2x2 + ··· am-\n1xm-1 and B(x) = b0 + b1x + b2x2 + ··· bn-1xn-1, consider the polynomial\nC(x) = A(x)B(x) that is equal to their product. In this polynomial C(x),\nthe coef ficient on the xk term is equal to"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 285})","('type', 'Document')"
"('page_content', ""In other  words, the coefficient vector c of C(x) is the convolution of\nthe coef ficient vectors of A(x) and B(x).\nArguably the most important application of convolutions in practice is\nfor signal pr ocessing.  This is a topic that could fill an entire course, so\nwe'll just give a simple example here to suggest one way in which the\nconvolution arises.  \nSuppose we have a vector a = (a0, a1, …, am-1) which represe nts a\nsequence of measurements, such as a temperature or a stock price,\nsampled at m consecutive points in time. Sequences like this are often\nvery noisy due to measurement error or random fluctuations, and so a\ncommon operation is to “smooth” the measurements by averaging each\nvalue ai with a weighted  sum of its neighbors within k steps to the left\nand right in the sequence, the weights decaying quickly as one moves\naway from ai. For example, in Gaussian smoothing,  one replaces ai\nwith \n \nfor some “width” parameter k, and with Z chosen simply to normalize\nthe weights in the average to add up to 1. (There are some issues with\nboundary conditions—what do we do when i - k < 0 or i + k > m?—but\nwe could  deal with these, for example, by discarding the first and last k\nentries from the smoothed signal, or by scaling them differently to\nmake up for the missing terms.)  \nTo see the conn ection with the convolution operation, we picture this\nsmoothing operation as follows. W e first define a “mask”"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 286})","('type', 'Document')"
"('page_content', ""consisting of the weights we want to use for averaging each point with\nits neighbors. (For example,  \n in the Gaussian\ncase above.) We then iteratively position this mask so it is centered at\neach possible point in the sequence a; and for each positioning, we\ncompute the weighted average. In other words, we replace ai with a′i =\nΣk\ns=-k wsai+s. \nThis last expression is essentiall y a convolution; we just have to warp\nthe notation a bit so that this becomes clear . Let's define b = (b0, b1, …,\nb2k) by setting bℓ = wk-ℓ. Then it's not hard to check that with this\ndefinition we have the smoothed value\n \nIn other words, the smoothed sequence is just the convolution  of the\noriginal signal and the reverse of the mask (with some meaningless\ncoordinates at the beginning and end).\nWe mention one final application: the problem of combining\nhistograms. Suppose we're studying a population of people, and we\nhave the following two histograms: One shows the annual income of\nall the men in the population, and one shows the annual income of all\nthe women. We'd now like to produce a new histogram, showing for\neach k the number of pairs  (M, W) for which man M and woman W\nhave a combined income of k. \nThis is precisely  a convolution. We can write the first histogram as a\nvector a = (a0, …, am-1), to indicate that there are ai men with annua l\nincome equal to i. We can similarly write the second histogram as a\nvector b = (b0,…,bn-1). Now, let ck denote the number of pairs (m, w)\nwith combined income k; this is the number of ways of choosing a man\nwith income ai and a woman with income bj, for any pair (i,j) where i\n+ j = k. In other words,"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 287})","('type', 'Document')"
"('page_content', ""so the combined histogram c = (c0, …, cm+n-2) is simply the\nconvolution of a and b. \n(Using terminol ogy from probability that we will develop in Chapter\n13, one can view  this example as showing how convolution is the\nunderlying means for computing the distribution of the sum of two\nindependent random variables.)\nComputing the Convolution  Having now motivated the notion of\nconvolution, let's discuss the problem of computing it efficiently . For\nsimplicity , we will consider the case of equal length vectors (i.e., m = n),\nalthough everyth ing we say carries over directly to the case of vectors of\nunequal lengths.\nComputing the convolution is a more subtle question than it may first\nappear . The definition of convo lution, after all, gives us a perfectly valid\nway to compute it: for each k, we just calculate the sum\nand use this as the value of the kth coordinate. The trouble is that this direct\nway of computing the convoluti on involves calculating the product aibj for\nevery pair (i,j) (in the process  of distributing over the sums in the different\nterms) and this is Θ(n2) arithmetic operations. Spending O(n2) time on\ncomputing the convolution seems natural, as the definition involves O(n2)\nmultiplications aibj. Howeve r, it's not inherently clear that we have to spend\nquadratic time to compute a convolution, since the input and output both\nonly have size O(n). Could one design an algorithm that bypasses the\nquadratic-size definition of convolution and computes it in some smarter\nway?"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 288})","('type', 'Document')"
"('page_content', ""In fact, quite surprisingly , this is possible. We now describe a method\nthat computes the convolution  of two vectors using only O(n log n)\narithmetic opera tions. The crux of this method is a powerfu l technique\nknown as the Fast Fourier Transform  (FFT). The FFT has a wide range of\nfurther applications in analyzing sequences of numerical values; computing\nconvolutions quickly , which we focus on here, is just one of these\napplications.\nDesigning and Analyzing the Algorithm\nTo break  throug h the quadratic time barrier for convolutions, we are going\nto explo it the connection between the convolution and the multiplication of\ntwo polynomials, as illustrated in the first example discussed previously .\nBut rather than use convolution as a primitive in polynomial multiplication,\nwe are going to exploit this connection in the opposite direction.\nSuppose we are given the vectors a = (a0, a1, …, an-1) and b = (b0, b1,\n…, bn-1). We will view them as the polynomials A(x) = a0 + a1x + a2x2 + ···\nan-1xn-1 and B(x) = b0 + b1x + b2x2 + ··· bn-1xn-1, and we'll seek to compute\ntheir product C(x) = A(x)B(x) in O(n log n) time. If c = (c0, c1, …, c2n-2) is\nthe vector of coefficients of C, then we recall from our earlier discussion\nthat c is exactly the convolution a * b, and so we can then read off the\ndesired answer directly from the coef ficients of C(x).\nNow , rather than multiplying A and B symbolically , we can treat them\nas functions of the variable x and multiply them as follows.\n(i) First we choose 2n values x1, x2, …, x2n and evaluate A(xj) and B(xj) for\neach of j = 1,2, …, 2 n.\n(ii) We can now compute C(xj) for each j very easily: C(xj) is simply the\nproduct of the two numbers A(xj) and B(xj).\n(iii) Finally , we have to recover C from its values on x1, x2, …, x2n. Here we\ntake advantage of a fundamenta l fact about polynomials: any polynomial\nof degree d can be reconstructed from its values on any set of d + 1 or\nmore points. This is known as polynomial interpolation,  and we'll discuss\nthe mechanics of performing interpolation in more detail later. For the\nmoment, we simply observe that since A and B each have degre e at most\nn - 1, their product C has degree at most 2n - 2, and so it can be"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 289})","('type', 'Document')"
"('page_content', ""reconstructed from the values C(x1), C(x2), …, C(x2n) that we compu ted\nin step (ii).\nThis approach to multiplying polynomials has some promising aspects\nand some problematic ones. First, the good news: step (ii) requires only\nO(n) arithm etic operations, since it simply involves the multiplication of\nO(n) numbers. But the situation doesn't look as hopeful with steps (i) and\n(iii). In particul ar, evaluating the polynomials A and B on a single value\ntakes Ω(n) operations, and our plan calls for performing 2n such\nevaluations. This seems to bring us back to quadratic time right away .\nThe key idea that will make this all work is to find a set of 2n values\nx1, x2, …, x2n that are intimat ely related in some way, such that the work in\nevaluating A and B on all of them can be shared across different\nevaluations. A set for which this will turn out to work very well is the\ncomplex r oots of unity .\nThe Complex Roots of Unity  At this point, we're going to need to recall a\nfew facts about complex numbe rs and their role as solutions to polynomial\nequations.\nRecall that complex numbers can be viewed as lying in the “complex\nplane,” with axes representing their real and imaginary parts. We can write\na complex number using polar coordinates with respect to this plane as reθi,\nwhere eπi = -1 (and e2πi = 1). Now , for a positive integer k, the polynomial\nequation xk = 1 has k distinct  complex roots, and it is easy to identify them.\nEach of the complex numbers ωj,k = e2πji/k (for j = 0,1,2,…, k - 1) satisfies\nthe equation, since\nand each of these numbers is distinct, so these are all the roots.  We refer to\nthese numbers as the kth roots of unity . We can picture these roots as a set of\nk equally spaced points lying on the unit circle in the complex plane, as\nshown in Figure 5.9  for the case k = 8.\nFor our numbers x1, …, x2n on which to evaluate A and B, we will\nchoose the (2n)th roots of unity . It's worth mentioning (although it's not\nnecessary for understanding the algorithm) that the use of the complex roots"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 290})","('type', 'Document')"
"('page_content', 'of unity is the basis for the name Fast Fourier Transform:  the\nrepresentation of a degree- d polynomial P by its values on the (d + 1)st\nroots of unity is sometimes referred to as the discr ete Fourier transform  of\nP; and the heart of our procedure is a method for making this computation\nfast.\nFigur e 5.9  The 8th roots of unity in the complex plane.\nA Recur sive Procedure for Polynomial Evaluation  We want to design an\nalgorithm for evaluating A on each of the (2n)th roots of unity recursively ,\nso as to take advantage of the familiar recurrence from (5.1)—n amely , T(n)\n≤ 2T(n/2) + O(n) where T(n) in this case denotes the number of operations\nrequired to evaluate a polynomial of degree n - 1 on all the (2n)th roots of\nunity . For simplicity in describing this algorithm, we will assum e that n is a\npower of 2.\nHow does one break the evaluation of a polynomial into two equal-\nsized subproblems? A useful trick is to define two polynomials, Aeven(x)\nand Aodd(x), that consist of the even and odd coefficients of A, respectively .\nThat is,\nand')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 291})","('type', 'Document')"
"('page_content', ""Simple algebra shows us that\nand so this gives us a way to compute A(x) in a constant  number of\noperations, given the evaluation of the two constituent polynomials that\neach have half the degree of A.\nNow suppose that we evaluate each of Aeven and Aodd on the nth roots\nof unity . This is exactly a versi on of the problem we face with A and the\n(2n)th roots of unity , except that the input is half as large: the degree is (n -\n2)/2 rather than n - 1, and we have n roots of unity rather than 2n. Thus we\ncan perform these evaluations in time T(n/2) for each of Aeven and Aodd, for\na total time of 2 T(n/2).\nWe're now very close to having a recursive algorithm that obeys (5.1)\nand gives us the running time we want; we just have to produce the\nevaluations of A on the (2n)th roots of unity using O(n) additional\noperations. But this is easy, given the results from the recursive calls on\nAeven and Aodd. Consider one of these roots of unity ωj,2n = e2πji/2n. The\nquantity ω2\nj,2n is equal to (e2πji/2n)2 = e2πji/n, and hence ω2\nj,2n is an nth root\nof unity . So when we go to compute\nwe disco ver that both of the evaluations on the right-hand side have been\nperformed in the recursive step, and so we can determine A(ωj,2n) using a\nconstant number of operations. Doing this for all 2n roots of unity is\ntherefore O(n) additional operations after the two recursive calls, and so the\nbound T(n) on the number of operations indeed satisfies T(n) ≤ 2T(n/2) +\nO(n). We run the same procedure to evaluate the polynomial B on the (2n)th\nroots of unity as well, and this gives us the desired O(n log n) bound for\nstep (i) of our algorithm outline."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 292})","('type', 'Document')"
"('page_content', ""Polynomial Interpolation  We've now seen how to evaluat e A and B on the\nset of all (2n)th roots of unity using O(n log n) operations and, as noted\nabove, we can clearly compute the products C(ωj,n) = A(ωj,2n)B(ωj,2n) in\nO(n) more operations. Thus, to conclude the algorithm for multiplying A\nand B, we need to execute step (iii) in our earlier outline using O(n log n)\noperations, reconstructing C from its values on the (2 n)th roots of unity .\nIn describing this part of the algorithm, it's worth keeping track of the\nfollowing top-level point: it turns out that the reconstruction of C can be\nachieved simply  by defining an appropriate polynomial (the polynomial D\nbelow) and evaluating it at the (2n)th roots of unity . This is exactly what\nwe've just seen how to do using O(n log n) operations, so we do it again\nhere, spending an additional O(n log n) operations and concluding the\nalgorithms.\nConsider a polynomial \n  that we want to reconstruct\nfrom its values C(ωs,2n) at the (2n)th roots of unity . Define a new\npolynomial \n , where ds = C(ωs,2n). We now consider the\nvalues of D(x) at the (2 n)th roots of unity .\nby definition. Now recall that ωs,2n = (e2πi/2n)s. Using this fact and\nextending the notation to ωs,2n = (e2πi/2n)s even when s ≥ 2n, we get that"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 293})","('type', 'Document')"
"('page_content', ""To analyze the last line, we use the fact that for any (2n)th root of unity ω ≠\n1, we have \n . This is simply because ω is by definition a root of\nx2n - 1 = 0; since \n  and ω ≠ 1, it follows that ω is\nalso a root of (\n ).\nThus the only term of the last line's outer sum that is not equal to 0 is\nfor ct such that ωt+j,2n = 1; and this happens if t + j is a multiple of 2n, that\nis, if t = 2n - j. For this value, \n . So we get that\nD(ωj,2n) = 2nc2n-j. Evaluating the polynomial D(x) at the (2n)th roots of\nunity thus gives us the coeffients of the polynomial C(x) in reverse order\n(multiplied by 2 n each). W e sum this up as follows.\n(5.14)  For any polynomial  \n , and corresponding polynomial  \n, we have that  \n .\nWe can do all the evaluations of the values D(ω2n-s,2n) in O(n log n)\noperations using the divide-and-conquer approach developed for step (i).\nAnd this wraps everything up: we reconstruct the polynomial C from\nits values on the (2n)th roots of unity , and then the coefficients of C are the\ncoordinates in the convolution vector c = a*b that we were originally\nseeking.\nIn summary , we have shown the following.\n(5.15)  Using the Fast Fouri er Transform to determine the product polynomial C(x), we can compute\nthe convolution of the original vectors a and b in O (n log n) time.\nSolved Exercises"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 294})","('type', 'Document')"
"('page_content', ""Solved Exercise 1\nSuppose you are given an array A with n entries, with each entry holding a\ndistinct number . You are told that the sequence of values A[1], A[2], …,\nA[n] is unimodal : For some index p betw een 1and n, the values in the array\nentries increase up to position p in A and then decrease the remainde r of the\nway until positio n n. (So if you were to draw a plot with the array position j\non the x-axis and the value of the entry A[j] on the y-axis, the plotted  points\nwould rise until x-value p, where they'd achieve their maximum, and then\nfall from there on.)\nYou'd like to find the “peak entry” p without having to read the entire\narray—in fact, by reading as few entries of A as possi ble. Show how to find\nthe entry p by reading at most O(log n) entries of A.\nSolution  Let's start with a general discussion on how to achieve a running\ntime of O(log n) and then come  back to the specific problem here. If one\nneeds to compute something using only O(log n) operations, a useful\nstrategy that we discussed in Chapter 2 is to perform a constant amount of\nwork, throw away half the input, and continue recursively on what's left.\nThis was the idea, for example, behind the O(log n) running time for binary\nsearch.\nWe can view this as a divide-and-conquer approach: for some constant\nc > 0, we perform  at most c operatio ns and then continue recursively on an\ninput of size at most n/2. As in the chapter , we will assume that the\nrecursion “bottoms out” when n = 2, performing at most c operations to\nfinish the computation. If T(n) denote s the running time on an input of size\nn, then we have the recurrence\n(5.16)\nwhen n > 2, and"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 295})","('type', 'Document')"
"('page_content', ""It is not hard to solve this recurrence by unrolling it, as follows.\nAnalyzing the first few levels:  At the first level of recursion, we have a\nsingle problem of size n, which takes time at most c plus the time spent\nin all subsequent recursive calls. The next level has one problem of\nsize at most n/2, which contributes another c, and the level after that\nhas one problem of size at most n/4, which contributes yet another c.\nIdentifying a pattern:  No matter how many levels we continue, each\nlevel will have just one problem : level j has a single problem of size at\nmost n/2j, which contributes c to the running time, independent of j.\nSumming over all levels of recursion:  Each level of the recursion is\ncontributing at most c operations, and it takes log2 n levels of recursion\nto reduce n to 2. Thus the total running time is at most c times the\nnumber of levels of recursion, which is at most clog2 n = O(log n).\nWe can also do this by partial substitution. Suppose we guess that T(n)\n≤ k logb n, where we don't know k or b. Assuming that this holds for smaller\nvalues of n in an inductive ar gument, we would have\nThe first term on the right is exactly what we want, so we just need to\nchoose k and b to negate the added c at the end. This we can do by setting b\n= 2 and k = c, so that k logb 2 = c log2 2 = c. Hence we end up with the\nsolution T(n) ≤ c log2 n, which is exactly what we got by unrolling the\nrecurrence.\nFinally , we should mention that one can get an O(log n) running time,\nby essentially the same reasonin g, in the more general case when each level\nof the recursio n throws away any constant fraction of the input,\ntransforming an instance of size n to one of size at most an, for some\nconstant a < 1. It now takes at most log1/a n levels of recursion to reduce n"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 296})","('type', 'Document')"
"('page_content', ""down to a constant size, and each level of recursion involve s at most c\noperations.\nNow let's get back to the problem at hand. If we wanted to set\nourselves up to use (5.16), we could probe the midpoint of the array and try\nto determine whether the “peak entry” p lies before or after this midpoint.\nSo suppose we look at the value A[n/2]. From this value alone, we\ncan't tell whether p lies before or after n/2, since we need to know whether\nentry n/2 is sitting on an “up-slope” or on a “down-slope.” So we also look\nat the values A[n/2 - 1] and A[n/2 + 1]. There are now three possibilities.\nIf A[n/2 - 1] < A[n/2] < A[n/2 + 1], then entry n/2 must come strictly\nbefore p, and so we can continue recursi vely on entries n/2 + 1 through\nn.\nIf A[n/2 - 1] > A[n/2] > A[n/2 + 1], then entry n/2 must come strictly\nafter p, and so we can continue recursively on entries 1 through n/2 - 1.\nFinally , if A[n/2] is larger than both A[n/2 - 1] and A[n/2 + 1], we are\ndone: the peak entry is in fact equal to n/2 in this case.\nIn all these cases, we perform at most three probes of the array A and\nreduce the problem to one of at most half the size. Thus we can apply (5.16)\nto conclude that the running time is O(log n).\nSolved Exercise 2\nYou're consulting for a small computation-intensive investment company ,\nand they have the following type of problem that they want to solve over\nand over . A typical instance of the problem is the following. They're doing a\nsimulation in which they look at n consecutive days of a given stock, at\nsome point in the past. Let's number the days i = 1, 2, …, n; for each day i,\nthey have a price p(i) per share for the stock on that day. (We'll assume for\nsimplicity that the price was fixed during each day.) Suppose  during this\ntime period, they wanted to buy 1,000 shares on some day and sell all these\nshares on some  (later) day. They want to know: When should  they have\nbought and when should they have sold in order to have made as much\nmoney as possible? (If there was no way to make money during  the n days,\nyou should report this instead.)\nFor exam ple, suppose n = 3, p(1) = 9, p(2) = 1, p(3) = 5. Then you\nshould return “buy on 2, sell on 3” (buying on day 2 and selling on day 3"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 297})","('type', 'Document')"
"('page_content', ""means they would have made $4 per share, the maximum possible for that\nperiod).\nClearly , there's a simple algorithm that takes time O(n2): try all\npossible pairs of buy/sell days and see which makes them the most money .\nYour investment friends were hoping for something a little better .\nShow how to find the correct numbers i and j in time O(n log n).\nSolution  We've seen a number of instances in this chapter where a brute-\nforce search over pairs of eleme nts can be reduced to O(n log n) by divide\nand conquer . Since we're faced with a similar issue here, let's think about\nhow we might apply a divide-and-conquer strategy .\nA natural approach would be to consider the first n/2 days and the final\nn/2 days separately , solving the problem recursively on each of these two\nsets, and then figure out how to get an overall solution from this in O(n)\ntime. This would give us the usual recurrence \n , and\nhence O(n log n) by (5.1).\nAlso, to make things easier , we'll make the usual assumption that n is a\npower of 2. This is no loss of generality: if n′ is the next power of 2 greater\nthan n, we can set p(i) = p(n) for all i between n and n′. In this way, we do\nnot change the answer , and we at most double the size of the input (which\nwill not af fect the O() notation).\nNow , let S be the set of days 1,…, n/2, and S′ be the set of days n/2 +\n1, …, n. Our divide-and-conquer algorit hm will be based on the following\nobservation: either there is an optimal solution in which the investors are\nholding the stock at the end of day n/2, or there isn't. Now , if there isn't,\nthen the optimal solution is the better of the optimal solutions on the sets S\nand S′. If there is an optimal solution in which they hold the stock at the end\nof day n/2, then the value of this solution is p(j) - p(i) where i ∊ S and j ∊\nS′. But this value is maximized by simply choosing i ∊ S which minimizes\np(i), and choosing j ∊ S′ which maximizes p(j).\nThus our algorit hm is to take the best of the following three possible\nsolutions.\nThe optimal solution on S.\nThe optimal solution on S′.\nThe maximum of p(j) - p(i), over i ∊ S and j ∊ S′."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 298})","('type', 'Document')"
"('page_content', ""The first two alternatives are computed in time T(n/2), each by recursion,\nand the third alternative is comp uted by finding the minimum in S and the\nmaximum in S′, which takes time O(n). Thus the running time T(n) satisfies\nas desired.\nWe note that this is not the best running time achievable for this\nproblem. In fact, one can find the optimal pair of days in O(n) time using\ndynamic progra mming, the topic of the next chapter; at the end of that\nchapter , we will pose this question as Exercise 7.\nExercises\n1. You are interested in analyzing  some hard-to-obtain data from two\nseparate databases. Each datab ase contains n numerical values—so\nthere are 2n values total—and you may assume that no two values are\nthe same. You'd like to determine the median of this set of 2n values,\nwhich we will define here to be the nth smallest value.  \nHowever , the only way you can access these values is through queries\nto the databases. In a single query, you can specify a value k to one of\nthe two databases, and the chosen database will return the kth smallest\nvalue that it contains. Since queries are expensive, you would like to\ncompute the median using as few queries as possible.  \nGive an algorithm that finds the median value using at most O(log n)\nqueries.\n2. Recall the probl em of finding the number of inversions. As in the text,\nwe are given a sequence of n numbers a1, …, an, which we assume are\nall distinct, and we define an inversion to be a pair i < j such that ai >\naj. \nWe motivated the problem of counting inversions as a good measure of\nhow different two orderings are. However , one might feel that this"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 299})","('type', 'Document')"
"('page_content', ""measure is too sensitive. Let's call a pair a significant inversion  if i < j\nand ai > 2aj. Give an O(n log n) algorithm to count the number of\nsignificant inversions between two orderings.\n3. Suppose you're consulting for a bank that's concerned about fraud\ndetection, and they come to you with the following problem. They\nhave a collection of n bank cards that they've confiscated, suspecting\nthem of being used in fraud. Each bank card is a small plastic object,\ncontaining a magnetic stripe with some encrypted data, and it\ncorresponds to a unique account in the bank. Each account can have\nmany bank cards corresponding to it, and we'll say that two bank cards\nare equivalent  if they correspond to the same account.  \nIt's very difficult to read the account number off a bank card directly ,\nbut the bank has a high-tech “equivalence tester” that takes two bank\ncards and, after performing some computations, determines whether\nthey are equivalent.  \nTheir question is the following: among the collection of n cards, is\nthere a set of more than n/2 of them that are all equivalent to one\nanother? Assum e that the only feasible operations you can do with the\ncards are to pick two of them and plug them in to the equiv alence\ntester . Show how to decide the answer to their question with only O(n\nlog n) invocations of the equivalence tester .\n4. You've been working with some physicists who need to study , as part\nof their experimental design, the interactions among large numbers of\nvery small charged particles. Basically , their setup works as follows.\nThey have an inert lattice structure, and they use this for placing\ncharged particle s at regular spacing along a straight line. Thus we can\nmodel their structure as consisting of the points {1,2,3,…, n} on the\nreal line; and at each of these points j, they have a particle with charge\nqj (Each char ge can be either positive or negative.)  \nThey want to study the total force on each particle, by measuring it and\nthen comparing it to a computational prediction. This computational\npart is where they need your help. The total net force on partic le j, by\nCoulomb's Law , is equal to"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 300})","('type', 'Document')"
"('page_content', ""They've written the following simple program to compute Fj for all j: \nFor j = 1, 2, …, n\nInitialize Fj to 0\nFor i = 1, 2, …, n\nIf i < j then\nAdd \n  to Fj\nElse if i > j then\nAdd -\n  to Fj\nEndif\nEndfor\nOutput Fj\nEndfor\n \nIt's not hard to analyze the running time of this program: each\ninvocation of the inner loop, over i, takes O(n) time, and this inner\nloop is invoked O(n) times total, so the overall running time is O(n2). \nThe trouble is, for the large values of n they're working with, the\nprogram takes several minute s to run. On the other hand, their\nexperimental setup is optimized so that they can throw down n\nparticles, perfor m the measurements, and be ready to handle n more\nparticles within a few seconds. So they'd really like it if there were a\nway to compute  all the forces Fj much more quickly , so as to keep up\nwith the rate of the experiment.  \nHelp them out by designing an algorithm that computes all the forces\nFj in O(n log n) time.\n5. Hidden surface removal  is a problem in computer graphics that\nscarcely needs an introduction:  when Woody is standing in front of\nBuzz, you should be able to see Woody but not Buzz; when Buzz is\nstanding in front of W oody , … well, you get the idea.  \nThe magic of hidden surface removal is that you can often compute\nthings faster than your intuitio n suggests. Here's a clean geometric\nexample to illustrate a basic speed-up that can be achieved. You are\ngiven n nonvert ical lines in the plane, labeled L1, …, Ln, with the ith\nline specified by the equation y = aix + bi. We will make the"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 301})","('type', 'Document')"
"('page_content', ""assumption that no three of the lines all meet at a single point. We say\nline Li is uppermost  at a given x-coordinate x0 if its y-coordinate at x0\nis greater than the y-coordinates of all the other lines at x0: aix0 + bi >\najx0 + bj for all j ≠ i. We say line Li is visible  if there is some x-\ncoordinate at which it is upperm ost-intuitively , some portion of it can\nbe seen if you look down from “ y = ∞.”  \nGive an algorithm that takes n lines as input and in O(n log n) time\nreturns all of the ones that are visible. Figure 5.10  gives an example.\n6. Consider an n-node complete binary tree T, where n = 2d - 1 for some\nd. Each node v of T is labeled with a real number xv. You may assume\nthat the real numbers labeling the nodes are all distinct. A node  v of T\nis a local minimum  if the label xv is less than the label xw for all nodes\nw that are joined to v by an edge.  \nYou are given such a complete binary tree T, but the labeling is only\nspecified in the following implicit  way: for each node v, you can\ndetermine the value xv by probing  the node v. Show how to find a local\nminimum of T using only O(log n) probes to the nodes of T.\n7. Suppose now that you're given an n × n grid graph G. (An n × n grid\ngraph is just the adjacency graph of an n × n chessboard. To be\ncompletely precise, it is a graph whose node set is the set of all ordered\npairs of natural numbers (i,j), where 1 ≤ i ≤ n and 1 ≤ j ≤ n; the nodes\n(i,j) and ( k, ℓ) are joined by an edge if and only if | i - k| + |j - ℓ| = 1.)  \nWe use some of the terminology of the previous question. Again, each\nnode v is labeled by a real number xv; you may assum e that all these\nlabels are distinct. Show how to find a local minimum of G using only\nO(n) probes to the nodes of G. (Note that G has n2 nodes.)\nFigur e 5.10 An instance of hidden surface removal with five lines (labeled\n1-5 in the figure). All the lines except for 2 are visible."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 302})","('type', 'Document')"
"('page_content', 'Notes and Further Reading\nThe militaristic coinage “divide and conquer” was introduced somewhat\nafter the technique itself. Knuth (1998) credits John von Neuma nn with one\nearly explicit application of the approach, the development of the Mergesort\nAlgorithm in 1945. Knuth (1997b) also provides further discussion of\ntechniques for solving recurrences.\nThe algorithm for computing the closest pair of points in the plane is\ndue to Michael Shamos, and is one of the earliest nontrivial algorithms in\nthe field of computational geometry; the survey paper by Smid (1999)\ndiscusses a wide range of results on closest-point problem s. A faster\nrandomized algorithm for this problem will be discussed in Chapter 13.\n(Regarding the nonobviousness of the divide-and-conquer algorithm\npresented here, Smid also makes the interesting historical observation that\nresearchers originally suspected quadratic time might be the best one could\ndo for finding the closest pair of points in the plane.) More generally , the\ndivide-and-conquer approach has proved very useful in computational\ngeometry , and the books by Preparata and Shamos (1985) and de Berg et al.\n(1997) give many further examples of this technique in the design of\ngeometric algorithms.\nThe algorithm for multiplying two n-bit integers in subquadratic time\nis due to Karatsuba and Ofman (1962). Further back ground on\nasymptotically fast multiplication algorithms is given by Knuth (1997b). Of\ncourse, the number of bits in the input must be sufficiently large for any of\nthese subquadratic methods to improve over the standard algorithm.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 303})","('type', 'Document')"
"('page_content', 'Press et al. (1988) provide further coverage of the Fast Fourier\nTransform, including background on its applications in signal processing\nand related areas.\nNotes on the Exercises  Exercise 7 is based on a result of Donna Llewellyn,\nCraig T ovey , and Michael T rick.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 304})","('type', 'Document')"
"('page_content', 'Chapter 6')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 305})","('type', 'Document')"
"('page_content', ""Dynamic Programming\n6.1 W eighted Interval Scheduling: A Recursive Pr ocedur e \n6.2 Principles of Dynamic Programming: Memoization or Iteration\nover Subpr oblems  \n6.3 Segmented Least Squar es: Multi-way Choices  \n6.4 Subset Sums and Knapsacks: Adding a V ariable  \n6.5 RNA Secondary Structur e: Dynamic Pr ogramming over Intervals  \n6.6 Sequence Alignment  \n6.7 Sequence Alignment in Linear Space via Divide and Conquer  \n6.8 Shortest Paths in a Graph  \n6.9 Shortest Paths and Distance V ector Pr otocols  \n* 6.10 Negative Cycles in a Graph  \nSolved Exer cises  \nExer cises  \nNotes and Further Reading\nWe began our study of algorithmic techniques with greedy algorithms,\nwhich in some sense form the most natural approach to algori thm design.\nFaced with a new computationa l problem, we've seen that it's not hard to\npropose multipl e possible greedy algorithms; the challenge  is then to\ndetermine whether any of these algorithms provides a correct solution to the\nproblem in all cases.\nThe problems we saw in Chapter 4  were all unified by the fact that, in\nthe end, there really was a greedy algorithm that worked. Unfortunately ,\nthis is far from being true in general; for most of the problems that one\nencounters, the real difficulty is not in determining which of several greedy\nstrategies is the right one, but in the fact that there is no natural greedy\nalgorithm that works. For such problems, it is important to have other\napproaches at hand. Divide and conquer can sometimes serve as an\nalternative appro ach, but the versions of divide and conquer that we saw in\nthe previous chapter are often  not strong enough to reduce exponential\nbrute-force searc h down to polynomial time. Rather , as we noted  in Chapter"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 306})","('type', 'Document')"
"('page_content', ""5, the applicatio ns there tended to reduce a running time that was\nunnecessarily lar ge, but already polynomial, down to a faster running time.\nWe now turn to a more powerful and subtle design technique, dynamic\nprogramming . It will be easier to say exactly what characterizes dynamic\nprogramming after we've seen it in action, but the basic idea is drawn from\nthe intuition behind divide and conquer and is essentially the opposite of the\ngreedy strategy:  one implicitly explores the space of all possibl e solutions,\nby carefully decomposing things into a series of subpr oblems , and then\nbuilding up correct solutions to larger and larger subproblems. In a way, we\ncan thus view dynamic programming as operating dangerously close to the\nedge of brute-force search: although it's systematically working through the\nexponentially large set of possible solutions to the problem, it does this\nwithout ever examining them all explicitly . It is because of this careful\nbalancing act that dynamic programming can be a tricky techn ique to get\nused to; it typically takes a reasonable amount of practice before one is fully\ncomfortable with it.\nWith this in mind, we now turn to a first example of dynamic\nprogramming: the Weighted Interval Scheduling Problem that we defined\nback in Section 1.2. We are going to develop a dynamic programming\nalgorithm for this problem in two stages: first as a recursive procedure that\nclosely resembles brute-force search; and then, by reinterpreting this\nprocedure, as an iterative algori thm that works by building up solutions to\nlarger and lar ger subproblems.\n6.1 Weighted Interval Scheduling: A Recursive\nProcedure\nWe have seen that a particula r greedy algorithm produces an optimal\nsolution to the Interval Schedul ing Problem, where the goal is to accept as\nlarge a set of nonoverlapping intervals as possible. The Weighted Interval\nScheduling Problem is a strictly more general version, in which each\ninterval has a certain value  (or weight) , and we want to accept a set of\nmaximum value.\n Designing a Recursive Algorithm"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 307})","('type', 'Document')"
"('page_content', ""Since the original Interval Scheduling Problem is simply the special case in\nwhich all values are equal to 1, we know already that most greedy\nalgorithms will not solve this problem optimally . But even the algorithm\nthat worked before (repeatedly choosing the interval that ends earliest) is no\nlonger optimal in this more gene ral setting, as the simple examp le in Figure\n6.1 shows.\nIndeed, no natural greedy algorithm is known for this problem, which\nis what motivates our switch to dynamic programming. As discu ssed above,\nwe will begin our introduction to dynamic programming with a recursive\ntype of algorithm  for this problem, and then in the next section we'll move\nto a more iterative method that is closer to the style we use in the rest of this\nchapter .\nFigur e 6.1  A simple instance of weighted interval scheduling.\nWe use the notation from our discussion of Interval Scheduling in\nSection 1.2. We have n request s labeled 1, …, n, with each request i\nspecifying a start time si and a finish time fi. Each interval i now also has a\nvalue,  or weight vi. Two intervals are compatible  if they do not overlap. The\ngoal of our curre nt problem is to select a subset S ⊆ {1, …, n] of mutually\ncompatible intervals, so as to maximize the sum of the values of the\nselected intervals, Σi ∊S vi.\nLet's suppose that the requests are sorted in order of nondecreasing\nfinish time: f1 ≤ f2 ≤ … ≤ fn. We'll say a request i comes befor e a reques t j if\ni < j. This will be the natural left-t o-right order in which we'll consider\nintervals. To help in talking about this order , we define p(j), for an interva l\nj, to be the largest index i < j such that intervals i and j are disjoint. In other\nwords, i is the leftmost interval that ends before j begins. We define p(j) = 0\nif no request i < j is disjoint from j. An example of the definition of p(j) is\nshown in Figure 6.2 ."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 308})","('type', 'Document')"
"('page_content', ""Now , given an instance of the Weighted Interval Scheduling Problem,\nlet's consider an optimal solution \n , ignoring for now that we have no idea\nwhat it is. Here's something completely obvious that we can say about \n :\neither interval n (the last one) belongs to \n, or it doesn't. Suppose we\nexplore both sides of this dichot omy a little further . If n ∊ \n, then clearly no\ninterval indexed strictly between p(n) and n can belong to \n, because by the\ndefinition of p(n), we know that intervals p(n) + 1, p(n) + 2, …, n - 1 all\noverlap interval n. Moreover , if n ∊ \n, then \n  must include an optimal\nsolution to the problem consisting of requests {1, …, p(n)}—for if it didn't,\nwe could replace O's choice of requests from {1, …, p(n)} with a better\none, with no danger of overlapping request n.\nFigur e 6.2 An instance of weighted interval scheduling with the function s\np(j) defined for each interval j.\nOn the other hand, if n ∉ \n, then \n  is simply equal to the optimal\nsolution to the problem consist ing of requests {1, …, n - 1}. This is by\ncompletely analogous reasoning : we're assuming that \n  does not include\nrequest n; so if it does not choose the optimal set of requests from {1, …, n\n- 1}, we could replace it with a better one.\nAll this suggests that finding the optimal solution on intervals {1,2, …,\nn] involves looking at the optimal solutions of smaller problems of the form\n{1, 2, …, j}. Thus,  for any value of j between 1 and n, let \nj denote the\noptimal solution to the problem consisting of requests {1, …, j], and let\nopt(j) denote the value of this solutio n. (We define opt (0) = 0, based on the\nconvention that this is the optimum over an empty set of intervals.) The"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 309})","('type', 'Document')"
"('page_content', ""optimal solution  we're seeking is precisely \nn, with value OPT( n). For the\noptimal solution \n j on {1, 2, …,j}, our reasoning  above (generalizing from\nthe case in which j = n) says that either j ∊ \nj, in which case opt(j) = vj +\nopt(p(j)), or j ∉ \nj, in which case opt(j) = opt(j - 1). Since these are\nprecisely the two possible choices ( j ∊ \nj or j ∉ \nj), we can further say that\n(6.1)  OPT( j) = max( vj + opt( p(j)), opt( j - 1)).\nAnd how do we decide whether n belongs to the optimal solution  \nj?\nThis too is easy: it belongs to the optimal solution if and only if the first of\nthe options above is at least as good as the second; in other words,\n(6.2)  Request j belongs to an optimal solution on the set  [1,2, …, j} if and only if\n  \nThese facts form the first crucial component on which a dynamic\nprogramming solution is based: a recurrence equation that expresses the\noptimal solution (or its value) in terms of the optimal solutions to smaller\nsubproblems.\nDespite the simple reasoning that led to this point, (6.1) is already a\nsignificant development. It directly gives us a recursive algorithm to\ncompute OPT( n), assum ing that we have already sorted the requests by\nfinishing time and computed the values of p(j) for each j.\nCompute-Opt( j)\nIf j = 0 then\nReturn 0\nElse\nReturn max( vj+Compute-Opt(p(j)), Compute-Opt( j - 1)) Endif\nThe correctness of the algorithm follows directly by induction on j\n(6.3)  Compute-Opt (j) correctly computes OPT (j) for each j  = 1, 2, …, n.\nProof. By definition OPT(0) = 0. Now , take some j > 0, and suppose by way of induction that\nCompute-Opt( i) correctly computes OPT( i) for all i < j. By the induction hypothesis, we know that"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 310})","('type', 'Document')"
"('page_content', 'Compute-Opt( p(j)) = OPT( p(j)) and Compute-Opt( j - 1) = OPT( j - 1); and hence from (6.1) it follows\nthat\n  \n▪\nUnfortunately , if we really implemented the algorithm Compute-Opt as\njust written, it would take expo nential time to run in the worst case. For\nexample, see Figure 6.3  for the tree of calls issued for the instance of Figure\n6.2: the tree widens very quickly due to the recursive branching. To take a\nmore extreme example, on a nicely layered instance like the one in Figure\n6.4, where p(j) = j - 2 for each j = 2, 3, 4, …, n, we see that Compute-Opt( j)\ngenerates separate recursive calls on problems of sizes j - 1 and j - 2. In\nother words, the total number  of calls made to Compute-Opt on this\ninstance will grow like the Fibonacci numbers, which increase\nexponentially . Thus we have not achieved a polynomial-time solution.\nFigur e 6.3  The tree of subproblems called by Compute-Opt on the problem\ninstance of Figure 6.2 .')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 311})","('type', 'Document')"
"('page_content', ""Figur e 6.4  An instance of weighted interval scheduling on which the simple\nCompute-Opt recursion will take exponential time. The values of all\nintervals in this instance are 1.\nMemoizing the Recursion\nIn fact, though, we're not so far from having a polynomial-tim e algorithm.\nA funda mental observation, which forms the second crucial component of a\ndynamic programming solution, is that our recursive algorithm Compute-\nOpt is really only solving n + 1 different subproblems: Compute-Opt(0),\nCompute-Opt(1), …, Compute-Opt( n). The fact that it runs in exponential\ntime as written is simply due to the spectacular redundancy in the number\nof times it issues each of these calls.\nHow could we eliminate all this redundancy? We could store the value\nof Compute-Opt in a globally accessible place the first time we compute it\nand then simply  use this precom puted value in place of all future recursive\ncalls. This technique of saving values that have already been computed is\nreferred to as memoization .\nWe implement the above strategy in the more “intelligent” procedure\nM-Compute-Opt. This procedure will make use of an array M[0 … n]; M[j]\nwill start with the value “empty ,” but will hold the value of Compute-Opt( j)\nas soon  as it is first determined. To determine OPT( n), we invoke M-\nCompute-Opt( n).\nM-Compute-Opt( j)\nIf j =0 then\nReturn 0\nElse if M[j] is not empty then\nReturn M[j]\nDefine M[j] = max( vj+M-Compute-Opt( p(j)), M-Compute-Opt( j- 1))\nReturn M[j]\nEndif"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 312})","('type', 'Document')"
"('page_content', 'Analyzing the Memoized Version\nClearly , this looks very similar to our previous implementation of the\nalgorithm; however , memoization has brought the running time way down.\n(6.4)  The running time of M-Compute-Opt (n) is O(n) (assuming the input intervals ar e sorted by their\nfinish times ).\nProof. The time spent in a single call to M-Compute-Opt is O(1), exclud ing the time spent in\nrecursive calls it generates. So the running time is bounded by a constant times the number of calls\never issued  to M-Compute-Opt. Since the implementation itself gives no explicit upper bound on this\nnumber of calls, we try to find a bound by looking for a good measure of “progress.”\nThe most useful progress measure here is the number of entries in M that are not “empty .”\nInitially this number is 0; but each time the procedure invokes the recurrence, issuin g two recursive\ncalls to M-Compute-Opt, it fills in a new entry , and hence increases the number of filled-in entries by\n1. Since M has only n + 1 entries, it follows that there can be at most O(n) calls to M-Compute-Opt,\nand hence the running time of M-Compute-Opt( n) is O(n), as desired.\n▪\nComputing a Solution in Addition to Its Value\nSo far we have simply computed the value  of an optimal solution;\npresumably we want a full optim al set of intervals as well. It would be easy\nto exten d M-Co mpute-Opt so as to keep track of an optimal solution in\naddition to its value: we could maintain an additional array S so that S[i]\ncontains an optimal set of interv als among {1, 2, …, i}. Naively enhancing\nthe code to main tain the solutions in the array S, however , would blow up\nthe running time by an additional factor of O(n): while a positi on in the M\narray can be updated in O(1) time, writing down a set in the S array takes\nO(n) time. We can avoid this O(n) blow-up by not explicitly maintaining S,\nbut rather by recovering the optimal solution from values saved in the array\nM after the optimum value has been computed.\nWe know from (6.2) that j belongs to an optimal solution for the set of\nintervals {1, …, j] if and only if vj + OPT( p(j)) ≥ opt(j - 1). Using this\nobservation, we get the following simple procedure, which “traces back”\nthrough the array M to find the set of intervals in an optimal solution.\nFind-Solution( j)\nIf j = 0 then')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 313})","('type', 'Document')"
"('page_content', 'Output nothing\nElse\nIf vj + M[p(j)] > M[j - 1] then\nOutput j together with the result of Find-Solution( p(j))\nElse\nOutput the result of Find-Solution( j - 1)\nEndif\nEndif\nSince Find-Solution calls itself recursively only on strictly smaller\nvalues, it makes  a total of O(n) recursive calls; and since it spends constant\ntime per call, we have\n(6.5)  Given the array M of the optimal values of the sub-pr oblems,  Find-Solution returns an optimal\nsolution in O(n) time.\n6.2 Principles of Dynamic Programming:\nMemoization or Iteration over Subproblems\nWe now use the algorithm for the Weighted Interval Scheduli ng Problem\ndeveloped in the previous section to summarize the basic principles of\ndynamic program ming, and also to offer a different perspective that will be\nfundamental to the rest of the chapter: iterating over subproblems, rather\nthan computing solutions recursively .\nIn the previous section, we developed a polynomial-time solution to\nthe Weighted Interval Scheduling Problem by first designing an\nexponential-time recursive algorithm and then converting it (by\nmemoization) to an efficient recursive algorithm that consult ed a global\narray M of optimal solutions to subproblems. To really understand what is\ngoing on here, however , it helps to formulate an essentially equivalent\nversion of the algorithm. It is this new formulation that most explicitly\ncaptures the essence of the dynamic programming technique, and it will\nserve as a general template for the algorithms we develop in later sections.\n Designing the Algorithm')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 314})","('type', 'Document')"
"('page_content', 'The key to the efficient algori thm is really the array M. It encodes the\nnotion that we are using the value of optimal solutions to the subproblems\non intervals {1, 2, …, j] for each j, and it uses (6.1) to define the value of\nM[j] based on value s that come earlier in the array . Once we have the array\nM, the problem is solved: M[n] contains the value of the optimal solution on\nthe full instance, and Find-Solution can be used to trace back through M\nefficiently and return an optimal solution itself.\nThe point to realize, then, is that we can directly compute the entries in\nM by an iterative algorithm, rather than using memoized recursion . We just\nstart with M[0]= 0 and keep incrementing j; each time we need to determine\na value M[j], the answer is provided by (6.1). The algorithm looks as\nfollows.\nIterative-Compute-Opt\nM[0]= 0\nFor j =1, 2, …, n\nM[j]= max( vj + M[p(j)], M[j - 1])\nEndfor\n Analyzing the Algorithm\nBy exact analog y with the proof of (6.3), we can prove by induction on j\nthat this algorithm writes OPT( j) in array entry M[j]; (6.1) provides the\ninduction step. Also, as before, we can pass the filled-in array M to Find-\nSolution to get an optimal solution in addition to the value. Finally , the\nrunning time of Iterative-Compute-Opt is clearly O(n), since it explicitly\nruns for n iterations and spends constant time in each.\nAn example of the execution of Iterative-Compute-Opt is depicted in\nFigure 6.5. In each iteration, the algorithm fills in one additional entry of\nthe array M, by comparing the value of vj + M[p(j)] to the value of M[j - 1].\nA Basic Outline of Dynamic Programming\nThis, then, provides a second efficient algorithm to solve the Weighted\nInterval Scheduling Problem. The two approaches clearly have a great deal\nof conceptual overlap, since they both grow from the insight contained in')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 315})","('type', 'Document')"
"('page_content', 'the recurrence (6.1). For the remainder of the chapter , we will develop\ndynamic programming algorithms using the second type of approach—\niterative building up of subproblems—because the algorithms are often\nsimpler to express this way. But in each case that we consider , there is an\nequivalent way to formulate the algorithm as a memoized recursion.\nMost crucially , the bulk of our discussion about the particular problem\nof selecting intervals can be cast more generally as a rough template for\ndesigning dynamic programming algorithms. To set about developing an\nalgorithm based  on dynamic programming, one needs a collection of\nsubproblems derived from the original problem that satisfies a few basic\nproperties.\nFigur e 6.5 Part (b) shows the iterations of Iterative-Compute-Opt on the\nsample instance of W eighted Interval Scheduling depicted in part (a).\n(i) There are only a polynomial number of subproblems.\n(ii) The solution  to the original problem can be easily compute d from\nthe solutions to the subproblem s. (For example, the original problem may\nactually be one of the subproblems.)\n(iii) There is a natural orderin g on subproblems from “smallest” to\n“largest,” together with an easy-to-compute recurrence (as in (6.1) and\n(6.2)) that allow s one to determ ine the solution to a subproble m from the\nsolutions to some number of smaller subproblems.\nNaturally , these  are informal guidelines. In particular , the notion of\n“smaller” in part (iii) will depend on the type of recurrence one has.\nWe will see that it is sometimes  easier to start the process of designing\nsuch an algorithm by formulati ng a set of subproblems that looks natural,\nand then figurin g out a recurre nce that links them together; but often (as')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 316})","('type', 'Document')"
"('page_content', ""happened in the case of weighted interval scheduling), it can be useful to\nfirst define a recurrence by reasoning about the structure of an optimal\nsolution, and then determine which subproblems will be necessary to\nunwind the recurrence. This chicken-and-egg relationship between\nsubproblems and recurrences is a subtle issue underlying dynamic\nprogramming. It's never clear that a collection of subproblems will be\nuseful until one finds a recurrence linking them together; but it can be\ndifficult to think about recurrences in the absence of the “smaller”\nsubproblems that they build on. In subsequent sections, we will develop\nfurther practice in managing this design trade-of f.\n6.3 Segmented Least Squares: Multi-way Choices\nWe now discuss a different type of problem, which illustrate s a slightly\nmore complicated style of dynamic programming. In the previous section,\nwe developed a recurrence based on a fundamentally binary  choice: either\nthe interval n belonged to an optimal solution or it didn't. In the problem we\nconsider here, the recurrence will involve what might be called “multi-way\nchoices”: at each step, we have a polynomial number of possibilities to\nconsider for the structure of the optimal solution. As we'll see, the dynamic\nprogramming approach adapts to this more general situation very naturally .\nAs a separate issue, the problem developed in this section is also a nice\nillustration of how a clean algori thmic definition can formalize a notion that\ninitially seems too fuzzy and nonintuitive to work with mathematically .\n Problem\nOften when looking at scientific or statistical data, plotted on a two-\ndimensional set of axes, one tries to pass a “line of best fit” through the\ndata, as in Figure 6.6 .\nThis is a foundational problem  in statistics and numerical analysis,\nformulated as follows. Suppose our data consists of a set P of n points in\nthe plane, denoted (X1, y1), (X2,y2), …, (xn, yn); and suppose X1 < x2 < … <\nxn. Given a line L defined  by the equation y = ax + b, we say that the error\nof L with respect to P is the sum of its squared “distances” to the points in\nP:"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 317})","('type', 'Document')"
"('page_content', 'Figur e 6.6  A “line of best fit.”\nFigur e 6.7  A set of points that lie approximately on two lines.\nA natural goal is then to find the line with minimum error; this turns out to\nhave a nice closed-form solution that can be easily derived using calculus.\nSkipping the derivation here, we simply state the result: The line of\nminimum error is y = ax + b, where')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 318})","('type', 'Document')"
"('page_content', ""Now , here's a kind of issue that these formulas weren't desig ned to\ncover . Often we have data that looks something like the pictu re in Figure\n6.7. In this case, we'd like to make a statement like: “The points lie roughly\non a sequence of two lines.” How could we formalize this concept?\nEssentially , any single line through the points in the figure would have\na terrible error; but if we use two lines, we could achieve quite a small error .\nSo we could try formulating a new problem as follows: Rather than seek a\nsingle line of best fit, we are allowed to pass an arbitrary set of lines\nthrough the points, and we seek a set of lines that minimizes the error . But\nthis fails as a good problem formulation, because it has a trivial  solution: if\nwe're allowed to fit the points with an arbitrarily large set of lines, we could\nfit the points perfectly by having a different line pass through each pair of\nconsecutive points in P.\nAt the other extreme, we could try “hard-coding” the number two into\nthe problem; we could seek the best fit using at most two lines. But this too\nmisses a crucial feature of our intuition: We didn't start out with a\npreconceived idea that the points lay approximately on two lines; we\nconcluded that from looking at the picture. For example, most people would\nsay that the points in Figure 6.8  lie approximately on three lines.\nFigur e 6.8  A set of points that lie approximately on three lines.\nThus, intuitively , we need a problem formulation that requires us to fit\nthe points well, using as few lines as possible. We now formulat e a problem\n— the Segmented Leas t Squar es Problem —that captures these issues quite\ncleanly . The problem is a fundamental instance of an issue in data mining"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 319})","('type', 'Document')"
"('page_content', 'and statistics known as change detection:  Given a sequen ce of data point s,\nwe want to identify a few points in the sequence at which a discrete change\noccurs (in this case, a change from one linear approximation to another).\nFormulating the Problem  As in the discussion above, we are given a set of\npoints P = {(x1, y1), (x2, y2), …, (xn, yn)}, with x1 < x2 < … < xn. We will\nuse pi to deno te the point (xi, yi). We must first partition P into some\nnumber of segments. Each segment  is a subset of P that represents a\ncontiguous set of x-coordinates; that is, it is a subset of the form {pi, pi + 1,\n…, pj-1, pj} for some indices i ≤ j. Then, for each segment S in our partition\nof P, we compute the line minimizing the error with respect to the points in\nS, according to the formulas above.\nThe penalty  of a partition is defined to be a sum of the following\nterms.\n(i) The number of segments into which we partition P, times a fixed,\ngiven multiplier C > 0.\n(ii) For each segment, the error value of the optimal line throu gh that\nsegment.\nOur goal in the Segmented Least Squares Problem is to find a partition of\nminimum penalty . This minimization captures the trade-of fs we discussed\nearlier . We are allowed to consider partitions into any number of segments;\nas we increase the number of segments, we reduce the penalty terms in part\n(ii) of the definition, but we increase the term in part (i). (The multiplier C\nis provided with the input, and by tuning C, we can penalize the use of\nadditional lines to a greater or lesser extent.)\nThere are exponentially many possible partitions of P, and initially it is\nnot clear  that we should be able to find the optimal one efficiently . We now\nshow how to use dynamic programming to find a partition of minimum\npenalty in time polynomial in n.\n Designing the Algorithm\nTo begin with, we should recall the ingredients we need for a dynamic\nprogramming algorithm, as outlined at the end of Section 6.2. We want a\npolynomial number of subproblems, the solutions of which should yield a\nsolution to the original problem; and we should be able to build up solutions\nto these subproblems using a recurrence. As with the Weighted Interval\nScheduling Problem, it helps to think about some simple prope rties of the')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 320})","('type', 'Document')"
"('page_content', 'optimal solution. Note, however , that there is not really a direct analogy to\nweighted interval scheduling: there we were looking for a subset  of n\nobjects, whereas here we are seeking to partition n  objects.\nFor segmented least squares, the following observation is very useful:\nThe last point pn belongs to a single segment in the optimal partition, and\nthat segment begins at some earlier point pi. This is the type of observation\nthat can suggest  the right set of subproblems: if we knew the identity of the\nlast segment pi, …, pn (see Figure 6.9), then we could  remove those points\nfrom considerat ion and recursively solve the problem on the remaining\npoints p1, …, pi-1.\nFigur e 6.9  A possi ble solution: a single line segment fits points pi, pi+1, …,\npn, and then an optimal solution is found for the remaining points p1, p2, …,\npi-1.\nSuppose we let OPT( i) denote the optimum solution for the points p1,\n…, pi, and we let ei,j denote the minimum error of any line with respect to\npi, pi+1, …, pj. (We will write OPT(0) = 0 as a boundary case.) Then our\nobservation above says the following.\n(6.6)  If the last segment of the optimal partition is pi, …, pn, then the value of the optimal solution is\nOPT( n) = ei,n + C + OPT( i - 1).\nUsing the same observation for the subproblem consisting of the points\np1, …, pj, we see that to get opt(j) we should find the best way to produce a\nfinal segment pi, …, pj—paying the error plus an additive C for this')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 321})","('type', 'Document')"
"('page_content', 'segment— together with an optimal solution opt(i - 1) for the remaining\npoints. In other words, we have justified the following recurrence.\n(6.7)  For the subpr oblem on the points p 1, …, pj,\n  \nand the segment pi, …, pj is used in an optimum solution for the subpr oblem if and only if the\nminimum is obtained using index i.\nThe hard part in designing the algorithm is now behind us. From here,\nwe simply build up the solutions opt( i) in order of increasing i.\nSegmented-Least-Squares(n)\nArray M[0 … n]\nSet M[0]= 0\nFor all pairs i ≤ j\nCompute the least squares error ei,j for the segment pi, …, pj\nEndfor\nFor j =1, 2, …, n\nUse the recurrence (6.7) to compute M[j]\nEndfor\nReturn M[n]\nBy analogy with the arguments for weighted interval scheduling, the\ncorrectness of this algorithm can be proved directly by induction, with (6.7)\nproviding the induction step.\nAnd as in our algorithm for weighted interval scheduling, we can trace\nback through the array M to compute an optimum partition.\nFind-Segments( j)\nIf j=0 then\nOutput nothing\nElse\nFind an i that minimizes ei,j + C + M[i - 1]\nOutput the segment { pi, …, pj} and the result of\nFind-Segments( i-1)\nEndif')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 322})","('type', 'Document')"
"('page_content', ""Analyzing the Algorithm\nFinally , we consider the running time of Segmented-Least-Squar es. First we\nneed to compute the values of all the least-squares errors eij. To perform a\nsimple accountin g of the running time for this, we note that there are O(n2)\npairs (i,j) for which this computation is needed; and for each pair (i,j), we\ncan use the form ula given at the beginning of this section to compute ei,j in\nO(n) time. Thus the total running time to compute all ei,j values is O(N3).\nFollowing this, the algorithm has n iterations, for values; = 1, …, n.\nFor each value of j, we have to determine the minimum in the recurrence\n(6.7) to fill in the array entry M[j]; this takes time O(n) for each j, for a total\nof O(n2). Thus the running time is O(n2) once all the etj values have been\ndetermined.1\n6.4 Subset Sums and Knapsacks: Adding a\nVariable\nWe're seeing more and more that issues in scheduling provide a rich source\nof practically motivated algorithmic problems. So far we've considered\nproblems in which requests are specified by a given interval of time on a\nresource, as well as problems in which requests have a duration and a\ndeadline but do not mandate a particular interval during which they need to\nbe done.\nIn this section, we consider a version of the second type of problem,\nwith durations and deadlines, which is difficult to solve direct ly using the\ntechniques we've seen so far. We will use dynamic programm ing to solve\nthe problem, but with a twist: the “obvious” set of subproblems will turn\nout not to be enough, and so we end up creating a richer collection of\nsubproblems. As we will see, this is done by adding a new variable to the\nrecurrence underlying the dynamic program.\n The Problem"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 323})","('type', 'Document')"
"('page_content', ""In the scheduling problem we consider here, we have a single machine that\ncan process jobs, and we have a set of requests {1, 2, …, n}. We are only\nable to use this resource for the period between time 0 and time W, for some\nnumber W. Each request corresponds to a job that requires time wi to\nprocess. If our goal is to process jobs so as to keep the machine as busy as\npossible up to the “cut-of f” W, which jobs should we choose?\nMore formally , we are given n items {1, …, n], and each has a given\nnonnegative weight wi (for i = 1, …, n). We are also given a bound W. We\nwould like to select a subset S of the items so that Σi ∊S wi ≤ W and, subject\nto this restriction, Σi ∊S wi is as large as possible. We will call this the Subset\nSum Pr oblem.\nThis problem is a natural special case of a more general problem called\nthe Knapsack Problem,  where each request i has both a value vi and a\nweight wi. The goal in this more general problem is to select a subset of\nmaximum total value, subject to the restriction that its total weight not\nexceed W. Knapsack problems often show  up as subproblems in other , more\ncomplex problems. The name knapsack  refers to the problem of filling a\nknapsack of capacity W as full as possib le (or packing in as much value as\npossible), using a subset of the items {1, …, n}. We will use weight  or time\nwhen referring to the quantities wi and W.\nSince this resembles other scheduling problems we've seen before, it's\nnatural to ask whether a greedy algorithm can find the optimal solution. It\nappears that the answer is no—at least, no efficient greedy rule is known\nthat always constructs an optimal solution. One natural greedy approach to\ntry would be to sort the items by decreasing weight—or at least to do this\nfor all items of weight at most  W—and then start selecting items in this\norder as long as the total weight remains below W. But if W is a multiple of\n2, and we have three items with weights {W/2 + 1, W/2, W/2}, then we see\nthat this greedy algorithm will not produce the optimal solution.\nAlternately , we could sort by increasing  weight and then do the same thing;\nbut this fails on inputs like {1, W/2, W/2}.\nThe goal of this section is to show how to use dynamic progra mming\nto solve this problem. Recall the main principles of dynamic programming:\nWe have to come up with a small number of subproblems so that each\nsubproblem can be solved easily from “smaller” subproblems, and the\nsolution to the original problem  can be obtained easily once we know the"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 324})","('type', 'Document')"
"('page_content', ""solutions to all the subproblems. The tricky issue here lies in figuring out a\ngood set of subproblems.\n Designing the Algorithm\nA False Start  One general strategy , which worked for us in the case of\nWeighted Interval Scheduling, is to consider subproblems involving only\nthe first i requests. We start by trying this strategy here. We use the notation\nopt(i), analogou sly to the notation used before, to denote the best possible\nsolution using a subset of the requests {1, …, i}. The key to our method for\nthe Weighted Interval Schedulin g Problem was to concentrate on an optimal\nsolution 0 to our problem and consider two cases, depending on whether or\nnot the last request n is accepted or rejected by this optimum solution. Just\nas in that case, we have the first part, which follows immediate ly from the\ndefinition of opt(i).\nIf n ∉ \n, then OPT(rz) = OPT( n - 1).\nNext we have to consider the case in which n e 0. What we'd like here\nis a simple recursion, which tells us the best possible value we can get for\nsolutions that contain the last request n. For Weighted Interval Scheduling\nthis was easy, as we could simply delete each request that conflicted with\nrequest n. In the current problem, this is not so simple. Accepting request n\ndoes not immediately imply that we have to reject any other request.\nInstead, it means that for the subset of requests S c {1, …, n - 1} that we\nwill accept, we have less available weight left: a weight of wn is used on the\naccepted request n, and we only have W — wn weight left for the set S of\nremaining requests that we accept. See Figure 6.10 .\nA Better Solution  This suggests that we need more subproblems: To find\nout the value for OPT( n) we not only need the value of OPT( n - 1), but we\nalso need to know the best solution we can get using a subset of the first n -\n1 items and total allowed weight W - wn. We are therefore going to use\nmany more subproblems: one for each initial set {1, …, i} of the items, and\neach possible value for the remaining available weight w. Assume that W is\nan integer , and all requests i = 1, …, n have integer weights wi. We will\nhave a subproblem for each i = 0,1, …, n and each integer 0 ≤ w ≤ W. We"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 325})","('type', 'Document')"
"('page_content', ""will use opt(i, w) to denote the value of the optimal solution using a subset\nof the items {1, …, i} with maximum allowed weight w, that is,\nFigur e 6.10  After item n is included in the solution, a weight of wn is used\nup and there is W - wn available weight left.\n  \nwhere the maxim um is over subsets S ⊆ {1, …, i] that satisfy Σj ∊s wj ≤ w.\nUsing this new set of subproblems, we will be able to express the value\nopt(i, w) as a simple expression in terms of values from smaller proble ms.\nMoreover , OPT( i,w, W) is the quantity  we're looking for in the end. As\nbefore, let \n  denote an optimum solution for the original problem.\nIf n ∉ \n, then OPT( i,w, W) = OPT( n - 1, W), since we can simply\nignore item n.\nIf n ∉ \n, then OPT( i,w, W) = wn + OPT( i,w - 1, W - wn), since we now\nseek to use the remaining capac ity of W - wn in an optimal way across\nitems 1, 2, …, n - 1.\nWhen the nth item is too big, that is, W < wn, then we must have OPT( i,w,\nW) = OPT( i,w - 1, W). Otherwise, we get the optimum solution allowing all\nn requests by taking the better of these two options. Using the same line of\nargument for the subproblem for items {1, …, i], and maximum allowed\nweight w, gives us the following recurrence.\n(6.8)  If w < w i then  opt(i, w) = opt( i - 1, w). Otherwise\nopt(i, w) = max(OPT( i - 1, w), Wi + opt( i - 1, w - Wj))."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 326})","('type', 'Document')"
"('page_content', 'As befor e, we want to design an algorithm that builds up a table of all\nopt(i, w) values while computing each of them at most once.\nSubset-Sum(n, W)\nArray M[0 … n, 0 … W]\nInitialize M[0, w] = 0 for each w = 0, 1, …, W\nFor i = 1, 2, …, n\nFor w = 0, …, W\nUse the recurrence (6.8) to compute M[i,w]\nEndfor\nEndfor\nReturn M[n,W ]\nFigur e 6.11 The two-dimensional table of OPT values. The leftmost\ncolumn and bottom row is alwa ys 0. The entry for OPT( i, w) is computed\nfrom the two other entries OPT( i - 1, w) and OPT( i - 1, w - wi), as indicated\nby the arrows.\nUsing (6.8) one can immediately prove by induction that the returned\nvalue M[n, W] is the optimum  solution value for the requests 1, …, n and\navailable weight W.\n Analyzing the Algorithm\nRecall the tabular picture we considered in Figure 6.5, associated with\nweighted interval scheduling, where we also showed the way in which the')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 327})","('type', 'Document')"
"('page_content', ""array M for that algorithm was iteratively filled in. For the algorithm we've\njust designed, we can use a similar representation, but we need a two-\ndimensional table, reflecting the two-dimensional array of subproblems that\nis being built up. Figure 6.11 shows the building up of subproblems in this\ncase: the value M[i, w]is comp uted from the two other values M[i - 1, w]and\nM[i - 1, w - wi].\nAs an example of this algorithm executing, consider an instance with\nweight limit W = 6, and n = 3 items of sizes w1 = w2 = 2 and w3 = 3. We\nfind that the optimal value OPT (3, 6) = 5 (which we get by using the third\nitem and one of the first two items). Figure 6.12 illustrates the way the\nalgorithm fills in the two-dimensional table of OPT values row by row .\nNext we will worry about the running time of this algorithm. As before\nin the case of weighted interval scheduling, we are building up a table of\nsolutions M, and we compute each of the values M[i, w]in O(1) time using\nthe previous values. Thus the running time is proportional to the number of\nentries in the table.\nFigur e 6.12 The iterations of the algorithm  on a sample instance of the\nSubset Sum Problem.\n(6.9)  The Subset-Sum( n, W) Algorithm corr ectly computes the optimal value of the pr oblem, and runs\nin O(nW) time.\nNote that this method is not as efficient as our dynamic program for\nthe Weighted Interval Schedulin g Problem. Indeed, its running time is not a"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 328})","('type', 'Document')"
"('page_content', 'polynomial function of n; rather , it is a polynomial function of n and W, the\nlargest integer involved in defin ing the problem. We call such algorithms\npseudo-polynomial . Pseudo-polyn omial algorithms can be reasonably\nefficient when the numbers {wi} involved in the input are reasonably small;\nhowever , they become less practical as these numbers grow lar ge.\nTo recover an optimal set S of items, we can trace back through the\narray M by a procedur e similar to those we developed in the previous\nsections.\n(6.10)  Given a table M of the optimal values of the subpr oblems, the optimal set S can be found in\nO(n) time.\nExtension: The Knapsack Problem\nThe Knapsack Problem is a bit more complex than the scheduling problem\nwe discussed earlier . Consider  a situation in which each item i has a\nnonnegative weight wi as before, and also a distinct value vi. Our goal is\nnow to find a subset S of maximum value Σi ∊S vi, subject to the restriction\nthat the total weight of the set should not exceed W: Σi ∊S wi ≤ W.\nIt is not hard to extend our dynamic programming algorithm to this\nmore general problem. We use the analogous set of subproblems, opt(i, w),\nto denot e the value of the optim al solution using a subset of the items {1,\n…, i] and maximum available weigh t w. We consider an optimal solution 0,\nand identify two cases depending on whether or not n ∊ \n.\nIf n ∉ \n, then OPT( n, W) = OPT( n - 1, W).\nIf n ∊ \n, then OPT( n, W) = vn + OPT( n - 1, W - wn).\nUsing this line of argument for the subproblems implies the following\nanalogue of (6.8).\n(6.11) If w<wi then  opt(i, w) = opt( i - 1, w). Otherwise\nopt(i, w) = max(OPT( i - 1, w), vi + opt( i - 1, w - wi)).\nUsing this recurrence, we can write down a completely analogous\ndynamic programming algorithm, and this implies the following fact.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 329})","('type', 'Document')"
"('page_content', '(6.12)  The Knapsack Pr oblem can be solved in O(nW) time.\n6.5 RNA Secondary Structure: Dynamic\nProgramming over Intervals\nIn the Knapsack Problem, we were able to formulate a dynamic\nprogramming algorithm by adding a new variable. A different but very\ncommon way by which one ends up adding a variable to a dynamic\nprogram is through the following scenario. We start by thinking about the\nset of subproblems on {1, 2, …, j}, for all choice s of j, and find oursel ves\nunable to come up with a natural recurrence. We then look at the larger set\nof subproblems on { i, i + 1, …, j} for all choices of i and j (where i ≤ j), and\nfind a natural recurrence relation on these subproblems. In this way, we\nhave added the second variable i; the effect is to consider a subproblem for\nevery contiguous interval  in {1,2, …, n}.\nThere are a few canonical problems that fit this profile; those of you\nwho have studied parsing algorithms for context-free grammars have\nprobably seen at least one dynamic programming algorithm in this style.\nHere we focus on the problem of RNA secondary structure prediction, a\nfundamental issue in computational biology .\nFigur e 6.13 An RNA secondary structure. Thick lines connect adjacent\nelements of the sequence; thin lines indicate pairs of elements that are\nmatched.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 330})","('type', 'Document')"
"('page_content', ""The Problem\nAs one learns in introductory biology classes, W atson and Crick posited that\ndouble-stranded DNA is “zipped ” together by complementary base-pairing.\nEach strand of DNA can be view ed as a string of bases,  where each base is\ndrawn from the set {A, C, G, T}.2 The bases A and T pair with each other ,\nand the bases C and G pair with each other; it is these A-T and C-G pairings\nthat hold the two strands together .\nNow , single-stra nded RNA molecules are key components in many of\nthe processes that go on inside a cell, and they follow more or less the same\nstructural princi ples. However , unlike double-stranded DNA, there's no\n“second strand”  for the RNA to stick to; so it tends to loop back and form\nbase pairs with itself, resulting in interesting shapes like the one depicted in\nFigure 6.13. The set of pairs (and resulting shape) formed by the RNA\nmolecule through this process  is called the secondary structur e, and\nunderstanding the secondary structure is essential for understanding the\nbehavior of the molecule.\nFor our purposes, a single-strand ed RNA molecule can be view ed as a\nsequence of n symbols (bases) drawn from the alphabet {A, C, G, U}.3 Let\nB = b1 b2 … bn be a single-stranded RNA molecule, where each bi ∊ {A, C,\nG, U}. To a first approximation, one can model its secondary structure as\nfollows. As usual, we require that A pairs with U, and C pairs with G; we"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 331})","('type', 'Document')"
"('page_content', ""also require that each base can pair with at most one other base—in other\nwords, the set of base pairs forms a matching.  It also turns out that\nsecondary struct ures are (again, to a first approximation) “knot-free,” which\nwe will formalize as a kind of noncr ossing  condition below .\nThus, concretely , we say that a secondary struc ture on B is a set of\npairs S = {(i,j)}, where i,j ∊ {1, 2, …, n}, that satisfies the following\nconditions.\n(i) (No sharp turns. ) The ends of each pair in S are separated by at\nleast four intervening bases; that is, if ( i,j) ∊ S, then i < j - 4.\n(ii) The element s of any pair in S consist of either { A, U} or { C, G} (in\neither order).\n(iii) S is a matching: no base appears in more than one pair .\n(iv) (The noncr ossing condition. ) If (i,j) and (k, I) are two pairs in S,\nthen we cannot have i < k < j < ℓ. (See Figure 6.14  for an illustration.)\nNote that the RNA secondary structure in Figure 6.13  satisfies properties (i)\nthrough (iv). From a structural point of view , condition (i) arises simply\nbecause the RNA molecule cann ot bend too sharply; and conditions (ii) and\n(iii) are the fundamental Watson-Crick rules of base-pairing. Condition (iv)\nis the striking one, since it's not obvious why it should hold in nature. But\nwhile there are sporadic exceptions to it in real molecules (via so-called\npseudo-knotting ), it does turn out to be a good approximation to the spatial\nconstraints on real RNA secondary structures.\nNow , out of all the secondary structures that are possible for a single\nRNA molecule , which are the ones that are likely to arise under\nphysiological conditions? The usual hypothesis is that a single-stranded\nRNA molecule will form the secondary structure with the optimum total\nfree energy. The correct model for the free energy of a secondary structure\nis a subject of much debate; but a first approximation here is to assume that\nthe free energy of a secondar y structure is proportional simply to the\nnumber  of base pairs that it contains.\nThus, having said all this, we can state the basic RNA secondary\nstructure predict ion problem very simply: We want an efficien t algorithm\nthat takes a single-stranded RNA molecule B = b1b2 … bn and determines a\nsecondary structure S with the maximum possible number of base pairs.\nFigur e 6.14  Two views of an RNA secondary structure. In the second view ,\n(b), the string has been “stre tched” lengthwise, and edges connecting"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 332})","('type', 'Document')"
"('page_content', ""matched pairs appear as noncrossing “bubbles” over the string.\n Designing and Analyzing the Algorithm\nA First Attemp t at Dynamic Programming  The natural first attempt to\napply dynamic programming would presumably be based on the following\nsubproblems: We say that opt(/) is the maximum number of base pairs in a\nsecondary structure on b1b2 … bj. By the no-sharp-turns conditio n above,\nwe know  that opt(/) = 0 for j ≤ 5; and we know that OPT( n) is the solution\nwe're looking for .\nThe trouble comes when we try writing down a recurrence that\nexpresses opt(/)  in terms of the solutions to smaller subproble ms. We can\nget partway there: in the optimal secondary structure on b1b2 … bj, it's the\ncase that either\nj is not involved in a pair; or\nj pairs with t for some t < j - 4.\nIn the first case, we just need to consult our solution for opt(j - 1). The\nsecond case is depicted in Figure 6.15(a) ; because of the noncrossing\ncondition, we now know that no pair can have one end between 1 and t - 1\nand the other end between t + 1 and j - 1. We've therefore effectively\nisolated two new subproblems: one on the bases b1b2 … bt-1, and the other\non the bases. bt-1. … bt-1 The first is solved by OPT( t - 1), but the second is\nnot on our list of subproblems, because it does not begin with b1."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 333})","('type', 'Document')"
"('page_content', 'Figur e 6.15 Schem atic views of the dynamic programming recurrence\nusing (a) one variable, and (b) two variables.\nThis is the insig ht that makes us realize we need to add a variable. We\nneed to be able to work with subproblems that do not begin with b1; in\nother words, we need to consider subproblems on bibt+1 … bj for all choices\nof i ≤ j.\nDynamic Progr amming over Intervals  Once we make this decision, our\nprevious reasoning leads straig ht to a successful recurrence. Let opt(i, j)\ndenote the maximum number of base pairs in a secondary structure on\nbibt+1 … bt. The no-sharp-turns condition lets us initialize opt(i, j) = 0\nwhenever i ≥ j - 4. (For notational conveni ence, we will also allow\nourselves to refer to opt( i, j) even when i ≥ j; in this case, its value is 0.)\nNow , in the optimal secondary structure on bibi+1 … bj, we have the\nsame alternatives as before:\nj is not involved in a pair; or\nj pairs with t for some t < j - 4.\nIn the first case,  we have opt(i, j) = opt( i, j - 1). In the second case, depicted\nin Figure 6.15(b) , we recur on the two subproblems opt( i, t - 1) and OPT( t +\n1, j - 1); as argued above, the noncrossing condition has isolated these two\nsubproblems from each other .\nWe have therefore justified the following recurrence.\n(6.13)  opt(i,j) = max(OPT( i,j - 1), max(1 + opt(i, t - 1) + OPT( t + 1,j - 1))), wher e the max is taken\nover t such that bt and b t are an allowable base pair (under conditions (i) and (ii) from the definition\nof a secondary structur e).')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 334})","('type', 'Document')"
"('page_content', ""Now we just have to make sure we understand the proper order in\nwhich to build up the solutions to the subproblems. The form of (6.13)\nreveals that we're always invoking the solution to subproblems on shorter\nintervals: those for which k = j - i is smaller . Thus things will work without\nany trouble if we build up the solutions in order of increasing interval\nlength.\nFigur e 6.16 The iterations of the algorithm  on a sample instance of the\nRNA Secondary Structure Prediction Problem.\nInitialize OPT(z′, j)=0 whenever z ≥ j-4\nFor fe = 5, 6, …, n - 1\nFor i = 1,2, … n — k\nSet j = i + k\nCompute OPT(z′, j) using the recurrence in (6.13)\nEndfor\nEndfor\nReturn opt(1, n)\nAs an example of this algorit hm executing, we consider the input\nACCGGUAGU,  a subsequence of the sequence in Figure 6.14. As with the\nKnapsack Problem, we need two dimensions to depict the array M: one for\nthe left endpoint of the interval being considered, and one for the right end-"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 335})","('type', 'Document')"
"('page_content', 'point. In the figure, we only show entries corresponding to [i,j] pairs with i\n< i - 4, since these are the only ones that can possibly be nonzero.\nIt is easy to bound the running time: there are O(n2) subproblems to\nsolve, and evaluating the recurrence in (6.13) takes time O(n) for each.\nThus the running time is O(n3).\nAs alwa ys, we can recover the secondary structure itself (not just its\nvalue) by record ing how the minima in (6.13) are achieved and tracing back\nthrough the computation.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 336})","('type', 'Document')"
"('page_content', ""6.6 Sequence Alignment\nFor the remainder of this chapter , we consider two further dynamic\nprogramming algorithms that each have a wide range of applications. In the\nnext two sections we discuss sequence alignment,  a fundamental problem\nthat arises in comparing strings . Following this, we turn to the problem of\ncomputing shortest paths in graphs when edges have costs that may be\nnegative.\n The Problem\nDictionaries on the Web seem to get more and more useful: often it seems\neasier to pull up a bookmarked online dictionary than to get a physical\ndictionary down from the bookshelf. And many online dictionaries offer\nfunctions that you can't get from a printed one: if you're looking for a\ndefinition and type in a word it doesn't contain—say , ocurrance —it will\ncome back and ask, “Perhaps you mean occurr ence? ” How does it do this?\nDid it truly know what you had in mind?\nLet's defer the second question  to a different book and think a little\nabout the first one. To decide what you probably meant, it woul d be natural\nto search the dictionary for the word most “similar” to the one you typed in.\nTo do this, we have to answ er the question: How should we define\nsimilarity between two words or strings?\nIntuitively , we'd like to say that ocurrance  and occurr ence are similar\nbecause we can make the two words identical if we add a c to the first word\nand chan ge the a to an e. Since neither of these changes seems so large, we\nconclude that the words are quite similar . To put it another way, we can\nnearly  line up the two words letter by letter:\no-currance\noccurrence\nThe hyphen (-) indicates a gap where we had to add a letter to the second\nword to get it to line up with the first. Moreover , our lining up is not perfect\nin that an e is lined up with an a."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 337})","('type', 'Document')"
"('page_content', ""We want a model in which similarity is determined roughly by the\nnumber of gaps and mismatches we incur when we line up the two words.\nOf course, there are many possible ways to line up the two words; for\nexample, we could have written\no-curr -ance\noccurre-nce\nwhich involves three gaps and no mismatches. Which is better: one gap and\none mismatch, or three gaps and no mismatches?\nThis discussion has been made easier because we know roughly what\nthe corresponden ce ought to look like. When the two strings don't look like\nEnglish words— for example, abbbaabbbbaab and ababaaabbbbbab—it may\ntake a little work to decide whether they can be lined up nicely or not:\nabbbaa—bbbbaab\nababaaabbbbba-b\nDictionary interfaces and spell-checkers are not the most\ncomputationally intensive application for this type of problem. In fact,\ndetermining similarities among strings is one of the central computational\nproblems facing molecular biologists today .\nStrings arise very naturally in biology: an organism's genome —its full\nset of genetic material—is divided up into giant linear DNA molecules\nknown as chromosomes,  each of which serves conceptually as a one-\ndimensional chemical storage device. Indeed, it does not obscure reality\nvery much to think of it as an enormous linear tape, containing a string over\nthe alphabet {A, C, G, T}. The string of symbols encodes the instructions\nfor build ing protein molecules;  using a chemical mechanism for reading\nportions of the chromosome, a cell can construct proteins that in turn\ncontrol its metabolism.\nWhy is similarity important in this picture? To a first approxim ation,\nthe sequence of symbols in an organism's genome can be viewed as\ndetermining the properties of the organism. So suppose we have  two strains\nof bacteria, X and Y, which are closely related evolutionarily . Suppose\nfurther that we've determined that a certain substring in the DNA of X codes"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 338})","('type', 'Document')"
"('page_content', 'for a certain kind of toxin. Then , if we discover a very “similar” substring\nin the DNA of Y, we might be able to hypothesize, before performing any\nexperiments at all, that this porti on of the DNA in Y codes for a similar kind\nof toxin. This use of computation to guide decisions about biological\nexperiments is one of the hallmarks of the field of computational biology .\nAll this leaves us with the same question we asked initially , while\ntyping badly spelled words into our online dictionary: How should we\ndefine the notion of similarity  between two strings?\nIn the early 1970s, the two molecular biologists Needlema n and\nWunsch proposed a definition of similarity , which, basically unchanged, has\nbecome the standard definition in use today . Its position as a standard was\nreinforced by its simplicity and intuitive appeal, as well as through its\nindependent discovery by several other researchers around the same time.\nMoreover , this definition of similarity came with an efficient dynamic\nprogramming algorithm to compute it. In this way , the paradigm of dynamic\nprogramming was independently discovered by biologists some twenty\nyears after mathematicians and computer scientists first articulated it.\nThe definition is motivated by the considerations we discussed above,\nand in particular by the notion of “lining up” two strings. Suppose we are\ngiven two string s X and Y, where X consists of the sequence of symbols x 1\nx2 … xm and Y consists of the sequence of symbols y1y2 … yn. Consider the\nsets {1, 2, …, m} and {1,2, …, n} as representing the different positions in\nthe strings X and Y, and consider a matching of these sets; recall that a\nmatching  is a set of ordered pairs with the property that each item occurs in\nat most one pair . We say that a matching M of these two sets is an alignment\nif there are no “crossing” pairs : if (i,j), (i′,j) ∊ M and i < i′, then j < j.\nIntuitively , an alignment gives a way of lining up the two string s, by telling\nus which pairs of positions will be lined up with one anothe r. Thus, for\nexample,\nstop-\n-tops\ncorresponds to the alignment {(2,1), (3, 2), (4, 3)}.\nOur definition of similarity will be based on finding the optimal\nalignment between X and Y, according to the following criteria. Suppose M')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 339})","('type', 'Document')"
"('page_content', ""is a given alignment between X and Y.\nFirst, there is a parameter δ > 0 that defines a gap penalty . For each\nposition of X or Y that is not matched in M—it is a gap—we incur a\ncost of δ.\nSecond, for each pair of letters p, q in our alphabet, there is a mismatch\ncost of αpq for lining up p with q. Thus, for each (i,j) ∊ M, we pay the\nappropriate mism atch cost αxyj for lining up xi with yj. One generally\nassumes that αpp = 0 for each letter p—there is no mismatch cost to\nline up a letter with another copy of itself—although this will not be\nnecessary in anything that follows.\nThe cost of M is the sum of its gap and mismatch costs, and we seek an\nalignment of minimum cost.\nThe process of minimizing this cost is often referred to as sequence\nalignment  in the biology literature. The quantities δ and {αpq} are external\nparameters that must be plugg ed into software for sequence alignment;\nindeed, a lot of work goes into choosing the settings for these parameters.\nFrom our point of view , in desig ning an algorithm for sequence alignment,\nwe will take them as given. To go back to our first example, notice how\nthese parameters determine which alignment of ocurrance  and occurr ence\nwe should prefer: the first is strictly better if and only if δ + αae < 3δ.\n Designing the Algorithm\nWe now have a concrete numerical definition for the similarity between\nstrings X and Y: it is the minimum cost of an alignment between X and Y.\nThe lower this cost, the more similar we declare the strings to be. We now\nturn to the problem of compu ting this minimum cost, and an optimal\nalignment that yields it, for a given pair of strings X and Y.\nOne of the approaches we could try for this problem is dynamic\nprogramming, and we are motivated by the following basic dichotomy .\nIn the optimal alignment M, either (m, n) ∊ M or (m, n) ∉ M. (That is,\neither the last symbols in the two strings are matched to each other, or\nthey aren't.)"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 340})","('type', 'Document')"
"('page_content', 'By itself, this fact would be too weak to provide us with a dynamic\nprogramming solution. Suppose, however , that we compound  it with the\nfollowing basic fact.\n(6.14)  Let M be any alignm ent of X and Y. If (m, n) ∉ then either the mth position of X or the nth\nposition of Y is not matched in M.\nProof. Suppose by way of contradiction that (m, n) ∉ M, and there are numbers i < m and j < n so\nthat ( m,j) ∊ M and ( i, n) ∊ M. But this contradicts our definition of alignment:  we have (i, n), (m,j) ∊\nM with i < m, but n > i so the pairs ( i, n) and ( m,j) cross.\n▪\nThere is an equivalent way to write (6.14) that exposes three\nalternative possibilities, and leads directly to the formul ation of a\nrecurrence.\n(6.15)  In an optimal alignment M, at least one of the following is true:\n(i) (m, n) ∊ M; or\n(ii) the mth position of X is not matched; or\n(iii) the nth position of Y is not matched.\nNow , let opt(i, …) denote the minimum cost of an alignment between x1 x2 … xi and y1 y2. yj.\nIf case (i) of (6.15) holds, we pay αxmyn and then align x1 x2 … xm-1 as well as possible with y1y2\n… yn-1; we get OPT( m, n) = αxmyn + OPT( m - 1, n - 1). If case (ii) holds, we pay a gap cost of δ\nsince the mth position of X is not matched, and then we align x1 x2 … xm-1 as well as possible with\ny1y2 … yn. In this way, we get OPT(m, n) = 8 + OPT( m - 1, n). Similarly , if case (iii) holds, we get\nOPT( m, n) = 8 + OPT( m, n - 1).\nUsing the same argument for the subprob lem of finding the minimum-cost alignme nt between\nx1 x2 … xi and y1y2 … yj, we get the following fact.\n(6.16)  The minimum alignment costs satisfy the following r ecurr ence for i ≥ 1 and j ≥ 1:\nopt(i, j) = min[ ixiy + opt( i - 1, j - 1), 8 + opt( i - 1,j), 8 + opt( i, j - 1)].\nMoreover , (i,j) is in an optimal alignment M for this subpr oblem if and only if the minimum is\nachieved by the first of these values.\nWe have maneuvered ourselves into a position where the dynamic programming algorithm has\nbecome clear: We build up the values of opt(i, j) using the recurrence  in (6.16). There are only O(mn )\nsubproblems, and OPT( m, n) is the value we are seeking.\nWe now specify the algorithm to compute the value of the optimal alignment. For purposes of\ninitialization, we note that opt(i, 0) = opt(0, i) = iδ for all i, since the only way to line up an i-letter\nword with a 0-letter word is to use i gaps.\nAlignment( X,Y)\nArray A[0 … m, 0 … n]\nInitialize A[i, 0]= iδ for each i')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 341})","('type', 'Document')"
"('page_content', 'Initialize A[0, j]= jδ for each j\nFor j=1, …, n\nFor i=1, …, m\nUse the recurrence (6.16) to compute A[i, j]\nEndfor\nEndfor\nReturn A[m, n]\nAs in previous dynamic programming algorithms, we can trace back through the array A, using\nthe second part of fact (6.16), to construct the alignment itself.\n Analyzing the Algorithm\nThe correctness of the algorithm follows directly from (6.16). The running time is O(mn), since the\narray A has O(mn) entries, and at worst we spend constant time on each.\nFigur e 6.17  A graph-based picture of sequence alignment.\nThere is an appealin g pictorial way in which people think about this sequence  alignment\nalgorithm. Suppose we build a two-dimensional m × n grid graph GXY, with the rows labeled by\nsymbols in the string X, the columns labeled by symbols in Y, and directed edges as in Figure 6.17 .\nWe number the rows from 0 to m and the columns from 0 to n; we denote the node in the ith row\nand the jth column by the label (i,j). We put costs  on the edges of GXY: the cost of each horizontal\nand vertical edge is δ, and the cost of the diagonal edge from ( i - 1, j - 1) to ( i,j) is αxiyj.\nThe purpose of this picture now emer ges: the recurrence in (6.16) for opt(i, j) is precise ly the\nrecurrence one gets for the minimum-cost path in GXY from (0, 0) to ( i,j). Thus we can show\n(6.17)  Let f(i,j) denote the minimum cost of a path from (0, 0) to (i,j) in GXY. Then  for all i,j, we have\nf(i,j) = opt( i, j).\nProof. We can easily prove this by induction on i + j. When i + j = 0, we have i = j = 0, and indeed\nf(i,j) = opt( i, j) = 0.\nNow consider arbitrary values of i and j, and suppose the statement is true for all pairs ( i′,j′) with\ni′ + j′ < i + j.  The last edge on the shortest path to (i,j) is either from (i - 1, j - 1), (i - 1, j), or (i,j - 1).\nThus we have')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 342})","('type', 'Document')"
"('page_content', ""where we pass from the first line to the second using the induction hypothesis, and we pass from the\nsecond to the third using (6.16).\n▪\nFigur e 6.18  The OPT values for the problem of aligning the words mean  to name .\nThus the value of the optimal alignment is the length of the shortest path in GXY from (0, 0) to\n(m, n). (We'll call any path in GXY from (0, 0) to (m, n) a corner -to-corner path.) Moreover , the\ndiagonal edges used in a shortest path correspond precisely to the pairs used in a minimum-cost\nalignment. These connections to the Shorte st-Path Problem in the graph GXY do not directly yield an\nimprovement in the running time for the sequence alignment problem; however , they do help one's\nintuition for the problem and have been useful in suggesting algorithms for more complex variations\non sequence alignment.\nFor an example, Figure 6.18  shows the value of the shortest path from  (0, 0) to each node (i, j)\nfor the problem of aligning the words mean  and name . For the purpose of this example, we assume\nthat δ = 2; matching a vowel with a different vowel, or a consonant with a different consonant, costs\n1; while matching a vowel and a consonant with each other costs 3. For each cell in the table\n(representing the corresponding node), the arrow indicates the last step of the shortes t path leading to\nthat node— in other words, the way that the minimum is achieved in (6.16). Thus, by following\narrows backward from node (4, 4), we can trace back to construct the alignment.\n6.7 Sequence Alignment in Linear Space via\nDivide and Conquer\nIn the previous section, we showed how to compute the optimal alignment between two strings X and\nY of lengths m and n, respectively . Building up the two-dimensional m-by-n array of optimal\nsolutions to subproblems, OPT(·,·), turned out to be equivalent to constructing a graph GXY with mn"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 343})","('type', 'Document')"
"('page_content', ""nodes laid out in a grid and looking for the cheapest path between opposite corners. In either of these\nways of formulating the dynamic program ming algorithm, the running time is O(mn), because it\ntakes const ant time to determine the value  in each of the mn cells of the array OPT; and the space\nrequirement is O(mn) as well, since it was dominated by the cost of storing the array (or the graph\nGXY).\n The Problem\nThe questi on we ask in this section is: Should we be happy with O(mn) as a space bound? If our\napplication is to compare English words , or even English sentences, it is quite  reasonable. In\nbiological applications of sequence alignment, however , one often compares very long strings against\none another; and in these cases, the Θ(mn) space requirement can potentially be a more severe\nproblem than the Θ(mn) time requirement. Suppose, for example, that we are comparing two strings\nof 100,000 symbols each. Depending on the underlying processor , the prospect of performing\nroughly 10 billion primitive operations might be less cause for worry than the prospect of working\nwith a single 10-gigabyte array .\nFortunately , this is not the end of the story . In this section we describe a very clever\nenhancement of the sequence alignment algorithm that makes it work in O(mn) time using only O(m\n+ n) space. In other words, we can bring the space requirement down to linear while blowing up the\nrunning time by at most an additional constant factor . For ease of presentation, we'll describe various\nsteps in terms of paths in the graph GXY, with the natural equivalence back to the sequence alignment\nproblem. Thus, when we seek the pairs in an optimal alignment, we can equivalently ask for the\nedges in a shortest corner -to-corner path in GXY.\nThe algorithm itself will be a nice application of divide-and-conquer ideas. The crux of the\ntechnique is the observation that, if we divide the problem into several recursive calls, then the space\nneeded for the computation can be reused from one call to the next. The way in which this idea is\nused, however , is fairly subtle.\n Designing the Algorithm\nWe first show that if we only care about the value  of the optimal alignment, and not the alignment\nitself, it is easy to get away with linear space. The crucial observation is that to fill in an entry of the\narray A, the recurrence in (6.16) only needs information from the current column of A and the\nprevious column of A. Thus we will “collapse” the array A to an m × 2 array B: as the algorithm\niterates through values of j, entries of the form B[i, 0] will hold the “previous” column's value A[i,j -\n1], while entries of the form B[i, 1] will hold the “current” column's value A[i,j].\nSpace-Ef ficient-Alignment( X,Y)\nArray B[0 … m, 0 … 1]\nInitialize B[i, 0]= iδ for each i (just as in column 0 of A)\nFor j =1, …, n\nB[0, 1] = jδ (since this corresponds to entry A[0, j])\nFor i=1, …, m\nB[i, 1]= min[ αxiyj + B[i - 1, 0],\nδ + B[i - 1, 1], δ +B[i, 0]]\nEndfor\nMove column 1 of B to column 0 to make room for next iteration:\nUpdate B[i, 0]= B[i, 1] for each i"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 344})","('type', 'Document')"
"('page_content', ""Endfor\nIt is easy to verify that when this algorithm completes, the array entry B[i, 1]holds the value of\nOPT( i, n) for i = 0, 1, …, m. Moreover , it uses O(mn ) time and O(m) space. The problem is: where is\nthe alignment itself? We haven't left enough information around to be able to run a procedure like\nFind-Alignment. Since B at the end of the algorithm only contains the last two columns of the\noriginal dynamic programming array A, if we were to try tracing back to get the path, we'd run out of\ninformation after just these two columns. We could imagine getting around this difficulty by trying to\n“predict” what the alignment is going to be in the process of running our space-ef ficient procedure.\nIn particular , as we compute the values in the jth colum n of the (now implicit) array A, we could try\nhypothesizing that a certain entry has a very small value, and hence that the alignment that passes\nthrough this entry is a promising candidate to be the optimal one. But this promising alignment might\nrun into big problems later on, and a different alignment that currently looks much less attractive\ncould turn out to be the optimal one.\nThere is, in fact, a solution to this problem—we will be able to recover the alignment itself\nusing O(m + n) space—but it requires a genuinely new idea. The insight is based on employing the\ndivide-and-conquer technique that we've seen earlier in the book. We begin with a simple alternative\nway to implement the basic dynamic programming solution.\nA Backward Formulation of the Dynamic Program  Reca ll that we use f(i, j) to denote the length  of\nthe shortes t path from (0, 0) to (i, j) in the graph GXY. (As we showed in the initial sequence\nalignment algorithm, f(i, j) has the same value as OPT( i, j).) Now let's define g(i, j) to be the length of\nthe shortest path from (i, j) to (m, n) in GXY. The function g provides an equally natural dynamic\nprogramming approac h to sequence alignm ent, except that we build it up in reverse: we start with\ng(m, n) = 0, and the answer we want is g(0, 0). By strict analogy with (6.16), we have the following\nrecurrence for g.\n(6.18)  For i < m and j < n we have\ng(i, j) = min[ αxi+1yj+1 + g(i + 1, j + 1), δ + g(i, j + 1), δ + g(i + 1, j)].\nThis is just the recurr ence one obtains by taking the graph GXY, “rotating” it so that the node\n(m, n) is in the lower left corner , and using the previous approach. Using this picture, we can also\nwork out the full dynamic programming algorithm to build up the values of g, backwar d starting\nfrom (m, n). Similarly , there is a space-ef ficient version of this backward dynamic programm ing\nalgorithm, analogous  to Space-Ef ficient-Alignment, which computes the value of the optimal\nalignment using only O(m + n) space. We will refer to this backward version, naturally enough, as\nBackward-Space-Ef ficient-Alignment.\nCombining the Forward and Backward Formulations  So now we have symmetric algorithms which\nbuild up the values of the functions f and g. The idea will be to use these two algorith ms in concert to\nfind the optimal alignment. First, here are two basic facts summarizing some relationships between\nthe functions f and g.\n(6.19)  The length of the shortest corner -to-corner path in GXY that passes through  (i,j) is f(i,j) +\ng(i,j).\nProof. Let ℓij denote the length of the shortest corner -to-corner path in GXY that passes through (i,j).\nClearly , any such path must get from (0, 0) to (i,j) and then from (i,j) to (m, n). Thus its length is at\nleast f(i,j) + g(i,j), and so we have ℓij ≥ f(i,j) + g(i,j). On the other hand, consider the corner -to-corner\npath that consists of a minimum-length path from (0, 0) to (i,j), followed  by a minimum-length path"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 345})","('type', 'Document')"
"('page_content', ""from (i,j) to (m, n). This path has length f(i,j) + g(i,j), and so we have ℓij ≤ f(i,j) + g(i,j). It follows\nthat ℓij = f(i,j) + g(i,j).\n▪\n(6.20)  Let k be any number in {0, …, n], and let q be an index that minimizes the quantity f(q, k) +\ng(q, k). Then ther e is a corner -to-corner path of minimum length that passes thr ough the node  (q, k).\nProof. Let ℓ* denote the length of the shortest corner -to-corner path in GXY. Now  fix a value of k ∊\n{0, …, n}. The shortest corner -to-corner path must  use some  node in the kth colum n of GXY—let's\nsuppose it is node ( p, k)—and thus by (6.19)\n  \nNow consider the index q that achieves the minimum in the right-hand side of this expression; we\nhave\n  \nBy (6.19) again, the shortest corner -to-corner path using the node (q, k) has length f(q, k) + g(q, k),\nand since ℓ* is the minimum length of any corner -to-corner path, we have\n  \nIt follows that ℓ* = f(q, k) + g(q, k). Thus the shortest corner -to-corner path using the node (q, k) has\nlength ℓ*, and this proves (6.20).\n▪\nUsing (6.20) and our space-ef ficient algorithms to compute the value  of the optimal alignment,\nwe will proceed as follows. W e divide GXY along its center column and compute the value of f(i, n/2 )\nand g(i, n/2 ) for each value of i, using our two space-ef ficient algorithms. We can then determine the\nminimum value of f(i, n/2 ) + g(i, n/2 ), and conclude via (6.20) that there is a shortest corner -to-corner\npath passin g through the node (i, n/2). Given this, we can search for the shortest path recursively in\nthe portion of GXY between (0, 0) and (i, n/2) and in the portion between (i, n/2) and (m, n). The\ncrucial point is that we apply these recursive calls sequentially and reuse the working space from one\ncall to the next. Thus, since we only work on one recursive call at a time, the total space usage is O(m\n+ n). The key question we have to resolve is whether the running time of this algorithm remains\nO(mn).\nIn running the algorit hm, we maintain a globally accessible list P whic h will hold nodes on the\nshortest corner -to-corner path as they are discovered. Initially , P is empty . P need only have m + n\nentries, since no corner -to-corner path can use more than this many edges. We also use the following\nnotation: X[i: j], for 1 ≤ i ≤ j ≤ m, denotes the substrin g of X consisting of XiXi+1 … xj; and we\ndefine Y[i: j] analogously . We will assume for simplicity that n is a power of 2; this assumption\nmakes the discussion much cleaner , although it can be easily avoided."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 346})","('type', 'Document')"
"('page_content', 'Divide-and-Conquer -Alignment( X, Y)\nLet m be the number of symbols in X\nLet n be the number of symbols in Y\nIf m < 2 or n ≤ 2 then\nCompute optimal alignment using Alignment( X, Y)\nCall Space-Ef ficient-Alignment( X,Y[1 :n/2])\nCall Backward-Space-Ef ficient-Alignment( X,Y[n/2 + 1 : n])\nLet q be the index minimizing f(q, n/2) + g(q, n/2 )\nAdd ( q, n/2 ) to global list P\nDivide-and-Conquer -Alignment( X[1 :q], Y[1 :n/2])\nDivide-and-Conquer -Alignment( X[q + 1 : n], Y[n/2 + 1 : n])\nReturn P\nAs an example of the first level of recursion, consider Figure 6.19. If the minimizing index a\nturns out to be 1, we get the two subproblems pictured.\n Analyzing the Algorithm\nThe previous arguments already establish that the algorithm returns the correct answer and that it\nuses O(m + n ) space. Thus, we need only verify the following fact.\nFigur e 6.19  The first level of recurrence for the space-ef ficient Divide-and-Conquer -Alignment. The\ntwo boxed regions indicate the input to the two recursive cells.\n(6.21)  The running time of  Divide-and-Conquer -Alignment on strings of length m and n is  O(mn).\nProof. Let T(m, n) denote the maximum running time of the algorithm on strings of length m and n.\nThe algori thm perfor ms O(mn) work to build up the arrays B and B′; it then runs recursi vely on\nstrings of size q and n/2, and on strings of size m - q and n/2. Thus, for some constant c, and some\nchoice of index q, we have')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 347})","('type', 'Document')"
"('page_content', ""This recurr ence is more complex than the ones we've seen in our earlier applications of divide-\nand-conquer in Chapter 5 . First of all, the runni ng time is a function of two variables (m and n) rather\nthan just one; also, the division into subproblems is not necessarily an “even split,” but instead\ndepends on the value q that is found through the earlier work done by the algorithm.\nSo how should we go about solving such a recurrence? One way is to try guessing the form by\nconsidering a special case of the recurrence, and then using partial substitution to fill out the details\nof this guess. Specifically , suppose that we were in a case in which m = n, and in which the split point\nq were exactly in the middle. In this (admittedly restrictive) special case, we could write the function\nT(·) in terms of the single variable n, set q = n/2 (since we're assuming a perfect bisection), and have\n  \nThis is a useful expression, since it's something that we solved in our earlier discussion of\nrecurrences at the outset of Chapter 5 . Specifically , this recurrence implies T(n) = O(n2).\nSo when m = n and we get an even split, the running time grows like the square of n. Motivated\nby this, we move back to the fully general recurrence for the problem at hand and guess that T(m, n)\ngrows like the produc t of m and n. Specifically , we'll guess that T(m, n) ≤ kmn for some constant k,\nand see if we can prove this by induction. To start with the base cases m ≤ 2 and n ≤ 2, we see that\nthese hold as long as k ≥ c/2. Now , assuming T(m′, n′) ≤ km′n′  holds for pairs (m′, n′) with a smaller\nproduct, we have\n  \nThus the inductive step will work if we choose k = 2c,  and this completes the proof.\n▪\n6.8 Shortest Paths in a Graph\nFor the final three sections, we focus on the problem of finding shortest paths in a graph, together\nwith some closely related issues.\n The Problem"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 348})","('type', 'Document')"
"('page_content', ""Let G = (V, E) be a directed graph.  Assume that each edge (i,j) ∊ E has an associated weight  Cij. The\nweights can be used to model a number of different things; we will picture here the interpretation in\nwhich the weight cij represents a cost for going directly from node i to node j in the graph.\nEarlier we discussed Dijkstra's Algorithm for finding shortest paths in graphs with positive edge\ncosts. Here we consider the more complex problem in which we seek shortest paths when costs may\nbe negative. Among the motivations for studying this problem, here are two that particularly stand\nout. First, negative costs turn out to be crucial for modeling a number of phenomena with shortest\npaths. For example, the nodes may represe nt agents in a financial setting, and cij represents the cost\nof a transaction in which we buy from agent i and then immediately sell to agent j. In this case, a path\nwould represent a succession of transactions, and edges with negative costs would represent\ntransactions that result in profits. Second, the algorithm that we develop for dealing with edges of\nnegative cost turns out, in certain crucial ways, to be more flexible and decentralized  than Dijkstra's\nAlgorithm. As a consequence, it has important applications for the design of distributed routing\nalgorithms that determine the most ef ficient path in a communication network.\nIn this section and the next two, we will consider the following two related problems.\nGiven a graph G with weights, as described above, decide if G has a negative cycle— that is, a\ndirected cycle C such that  \n  \nIf the graph has no negative cycles, find a path P from an origin node s to a destination node  t\nwith minimum total cost:  \n  \nshould be as small as possible for any s-t path. This is generally called both the Minimum-Cost\nPath Pr oblem  and the Shortest-Path Pr oblem.\nIn terms of our financial motivation above, a negative cycle corresponds to a profita ble sequence of\ntransactions that takes us back to our starting point: we buy from i1, sell to i2, buy from i2, sell to i3,\nand so forth, finally arriving back at i1 with a net profit. Thus negative cycles in such a network can\nbe viewed as good arbitrage opportunities .\nIt makes sense to consider the minimum-cost s-t path problem under the assumption that there\nare no negative cycle s. As illustrated by Figure 6.20 , if there is a negative  cycle C, a path Ps from s\nto the cycle, and another path Pt from the cycle to t, then we can build an s-t path of arbitrarily\nnegative cost: we first use Ps to get to the negative  cycle C, then we go around C as many times as\nwe want, and then we use Pt to get from C to the destination t.\n Designing and Analyzing the Algorithm"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 349})","('type', 'Document')"
"('page_content', ""A Few False Starts  Let's  begin  by recalling Dijkstra's Algorithm for the Shortest-Path Problem when\nthere are no negative costs. That method computes a shortest path from the origin s to every other\nnode v in the graph, essentially using a greedy algorithm. The basic idea is to maintain a set S with\nthe property that the shortest path from s to each node in S is known. W e start with S = {s}—since we\nknow the shortest path from s to s has cost 0 when there  are no negative edges—and we add elements\ngreedily to this set S. As our first greedy step, we consider the minimum-cost edge leaving node s,\nthat is, min ie ycsi. Let v be a node on which this minimum is obtained. A key observation underlying\nDijkstra's Algorithm is that the shortest path from s to v is the single-edge path {s, v). Thus we can\nimmediately add the node v to the set S. The path {s, v) is clearly  the shortest to v if there are no\nnegative edge costs: any other path from s to v would have to start on an edge out of s that is at least\nas expensive as edge ( s,v).\nFigur e 6.20 In this graph, one can find s-t paths of arbitrarily negative cost (by going around the\ncycle C many times).\nFigur e 6.21 (a) With negative edge costs, Dijkstra's Algorithm can give the wrong answer for the\nShortest-Path Problem . (b) Adding 3 to the cost of each edge will make all edges nonnegative, but it\nwill change the identity of the shortest s-t path.\nThe above observation is no longer true if we can have negative edge costs. As sugge sted by the\nexample in Figure 6.21(a) , a path that starts on an expensive edge, but then compensates with\nsubsequent edges of negative cost, can be cheaper than a path that starts on a cheap edge. This\nsuggests that the Dijkstra-style greedy approach will not work here.\nAnother natural idea is to first modify the costs cij by adding some large constant M to each;\nthat is, we let c′ij + M for each edge (i,j) ∊ E. If the constant M is large enough, then all modified\ncosts are nonnegative, and we can use Dijkstra's Algorithm to find the minimum-cos t path subject to\ncosts c′. How ever, this approach fails to find the correct minimum-cost paths with respec t to the"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 350})","('type', 'Document')"
"('page_content', ""original costs c. The probl em here is that changing the costs from c to ti changes the minimum-cost\npath. For example (as in Figure 6.21(b) ), if a path P consisting of three edges is only slightly cheaper\nthan another path V that has two edges, then after the change in costs, P′ will be cheaper , since we\nonly add 2 M to the cost of P′ while adding 3 M to the cost of P.\nA Dynamic Programming Approach  We will try to use dynamic programming to solve the problem\nof finding a shortest path from s to t when there are negative edge costs but no negative cycles. We\ncould try an idea that has worked for us so far: subproblem i could be to find a shortest path using\nonly the first i nodes. This idea does not immediately work, but it can be made to work with some\neffort. Here, however , we will discuss a simpler and more efficient solution, the Bellman-For d\nAlgorithm.  The devel opment of dynamic programming as a general algorithmic technique is often\ncredited to the work of Bellman in the 1950's; and the Bellman-Ford Shortest-Path Algorithm was\none of the first applications.\nThe dynamic programming solution we develop will be based on the followi ng crucial\nobservation.\nFigur e 6.22  The minimum-cost path P from v to t using at most i edges.\n(6.22)  If G has no negative cycles, then there is a shortest path from s to t that is simple  (i.e., does not\nrepeat nodes ), and hence has at most n  - 1 edges.\nProof. Since every cycle has nonnegative cost, the shortest path P from s to t with the fewest number\nof edges does not repeat any vertex v. For if P did repeat a vertex v, we could remove the portion of P\nbetween consecutive visits to v, resulting in a path of no greater cost and fewer edges.\n▪\nLet's use opt(i, v) to denote the minimum cost of a v-t path using at\nmost i edges. By (6.22 ), our original problem is to compute OPT( n - 1, s).\n(We could instead design an algorithm whose subproblems correspond to\nthe minimum cost of an s-v path using at most i edges. This would form a\nmore natural parallel with Dijkstra's Algorithm, but it would not be as\nnatural in the context of the routing protocols we discuss later .)\nWe now need a simple way to express opt(i, v) using smaller\nsubproblems. We will see that the most natural approach involves the\nconsideration of many differen t options; this is another example of the\nprinciple of “multi-way choices” that we saw in the algorithm for the\nSegmented Least Squares Problem.\nLet's fix an optimal path P representing opt(i, v) as depicted in Figure\n6.22.\nIf the path P uses at most i - 1 edges, then opt( i, v) = opt( i - 1,v)."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 351})","('type', 'Document')"
"('page_content', 'If the path P uses i edges, and the first edge is (v, w), then opt(i, v) =\ncvw + opt( i - 1, w).\nThis leads to the following recursive formula.\n(6.23)  If i > 0 then\n  \nUsing this recurrence, we get the following dynamic programming\nalgorithm to compute the value OPT( n - 1, s).\nFigur e 6.23 For the directed graph in (a), the Shortest-Path Algorithm\nconstructs the dynamic programming table in (b).\nShortest-Path( G, s, t)\nn = number of nodes in G\nArray M[0 … n-1,V ]\nDefine M[0, t] = 0 and M[0, v] = ∞ for all other v ∊ V\nFor i = 1, …, n - 1')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 352})","('type', 'Document')"
"('page_content', ""For v ∊ V in any order\nCompute M[i, v] using the recurrence (6.23)\nEndfor\nEndfor\nReturn M[n - 1, s]\nThe correctness  of the method  follows directly by induction from\n(6.23). We can bound the running time as follows. The table M has n2\nentries; and each entry can take O(n) time to comput e, as there are at most n\nnodes w ∊ V we have to consider .\n(6.24)  The Shortest-Path method correctly computes the minimum cost of an s-t path in any graph\nthat has no negative cycles, and runs in  O(n3) time.\nGiven the table M containing the optimal values of the subproblems,\nthe shortest path using at most i edges can be obtained in O(in) time, by\ntracing back through smaller subproblems.\nAs an example, consider the graph in Figure 6.23(a) , where the goal is\nto find a shortest path from each node to t. The table in Figure 6.23(b)\nshows the array M, with entries corresponding to the values M[i, v] from the\nalgorithm. Thus  a single row in the table corresponds to the shortest path\nfrom a particular node to t, as we allow the path to use an increasing\nnumber of edges. For example, the shortest path from node d to t is updated\nfour times, as it changes from d-t, to d-a-t , to d-a-b-e-t , and finally to d-a-b-\ne-c-t.\nExtensions: Some Basic Improvements to the\nAlgorithm\nAn Improved Running-T ime Analysis  We can actual ly provide a better\nrunning-time analysis for the case in which the graph G does not have too\nmany edges. A directed graph with n nodes can have close to n2 edges,\nsince there could potentially be an edge between each pair of nodes, but\nmany graphs are much sparser than this. When we work with a graph for\nwhich the number of edges m is significantly  less than n2, we've already\nseen in a number of cases earlier in the book that it can be useful to write\nthe running-time in terms of both m and n; this way, we can quantify our\nspeed-up on graphs with relatively fewer edges."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 353})","('type', 'Document')"
"('page_content', 'If we are a little more careful in the analysis of the method above, we\ncan improve the running-time bound to O(mn ) without significantly\nchanging the algorithm itself.\n(6.25)  The Shortest-Path method can be implemented in O(mn) time.\nProof. Consider the computation of the array entry M[i, v] according to the recurrence (6.23); we\nhave\n  \nWe assumed it could take up to O(n) time to compute this minimum, since there are n possible\nnodes w. But, of course, we need only compute this minimum over all nodes w for which  v has an\nedge to w; let us use nv to denote this number . Then it takes time O(nv) to compute the array entry\nM[i, v]. We have to comput e an entry for every node v and every  index 0 ≤ i ≤ n - 1, so this gives a\nrunning-time bound of\n  \nIn Chapter 3, we perfor med exact ly this kind of analysis for other graph algorithms, and used\n(3.9) from that chapter to bound the expression Σv ∊V nv for undirected graphs. Here we are dealin g\nwith directed graphs, and nv denotes the number of edges leaving v. In a sense, it is even easier to\nwork out the value of Σv ∊V nv for the directed case:  each edge leaves exactly one of the nodes in V,\nand so each edge is counted exactly once by this expression. Thus we have Σv ∊V nv = m. Plugging\nthis into our expression\n  \nfor the running time, we get a running-time bound of O(mn). m\n▪\nImproving the Memory Requirements  We can also significantly improve\nthe memory requirements with only a small change to the implementation.\nA comm on problem with many dynamic programming algori thms is the\nlarge space usage, arising from the M array that needs to be stored. In the\nBellman-Ford Algorithm as written, this array has size n2; however , we\nnow show how to reduce this to O(n). Rather than recording M[i, v] for')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 354})","('type', 'Document')"
"('page_content', 'each value i, we will use and update a single value M[v] for each node v, the\nlength of the shortest path from v to t that we have found so far. We still run\nthe algorithm for iterations i = 1, 2, …, n - 1, but the role of i will now\nsimply be as a counter; in each iteration, and for each node v, we perform\nthe update\n \nWe now observe the following fact.\n(6.26)  Throughout the algorithm M[v] is the length of some path from v to t, and after i rounds of\nupdates the value M[v] is no larger than the length of the shortest path from v to t using at most i\nedges.\nGiven (6.26), we can then use (6.22) as before to show that we are\ndone after n - 1 iterations. Since we are only storing an M array that index es\nover the nodes, this requires only O(n) working memory .\nFinding the Shortest Paths  One issue to be concerned about is whether this\nspace-ef ficient version of the algorithm saves enough information to\nrecover the shortest paths themselves. In the case of the Sequence\nAlignment Problem in the previous section, we had to resort to a tricky\ndivide-and-conquer method to recover the solution from a similar space-\nefficient implementation. Here, however , we will be able to recover the\nshortest paths much more easily .\nTo help with recovering the shortest paths, we will enhance the code\nby having each node v maintain the first node (after itself) on its path to the\ndestination t; we will denote this first node by first[v]. To maintain first[v],\nwe update its value whenever the distance M[v] is updated. In other words,\nwhenever the value of M[v] is reset  to the minimum \n , we set\nfirst[v] to the node w that attains this minimum.\nNow let P denote the directed “pointer graph” whose nodes are V, and\nwhose edges are {( v, first [v])}. The main observation is the following.\n(6.27)  If the pointer graph P contains a cycle C, then this cycle must have negative cost.\nProof. Notice that if first[v] = w at any time, then we must have M[v] ≥ cvw + M[w]. Indeed, the left-\nand right-h and sides are equal after the update that sets first[v] equal to w; and since M[w ] may\ndecrease, this equation may turn into an inequality .')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 355})","('type', 'Document')"
"('page_content', ""Let v1, v2, …, vk be the nodes along the cycle C in the pointer graph, and assume that (vk, v1) is\nthe last edge to have been added. Now , consider the values right before this last update. At this time\nwe have M[vi] ≥ cviv1 + M[vi+1] for all i = 1, …, k - 1, and we also have M[vk] > cvkvi + M[v1] since\nwe are about to upda te M[vk] and change first[vk ] to vk. Adding all these inequalities, the M[vi]\nvalues cancel, and we get 0 > Σk-1k-1 cvivi+1 + cvkv1: a negative cycle, as claimed.\n▪\nNow note that if G has no negative  cycles, then (6.27) implies that the\npointer graph P will never have  a cycle. For a node v, consider the path we\nget by following the edges in P, from v to first[v]= v1, to first[v1]= v2, and\nso forth.  Since the pointer graph has no cycles, and the sink t is the only\nnode that has no outgoing edge, this path must lead to t. We claim that when\nthe algorithm terminates, this is in fact a shortest path in G from v to t.\n(6.28)  Suppose G has no negative cycles, and consider the pointer graph P at the termination of the\nalgorithm. For each node v , the path in P fr om v to t is a shortest v-t path in G.\nProof. Consider a node v and let w = first[v]. Since the algorithm terminated, we must have M[v]=\ncvw + M[w]. The value M[t]= 0, and hence the length of the path traced out by the pointer graph is\nexactly M[v], which we know is the shortest-path distance.\n▪\nNote that in the more space-ef ficient version of Bellman-Ford, the path\nwhose length is M[v] after i iterations can have substantially more edges\nthan i. For example, if the graph is a single path from s to t, and we perform\nupdates in the reverse of the order the edges appear on the path,  then we get\nthe final shortest-path values in just one iteration. This does not always\nhappen, so we cannot claim a worst-case running-time improve ment, but it\nwould be nice to be able to use this fact opportunistically to speed up the\nalgorithm on instances where it does happen. In order to do this, we need a\nstopping signal  in the algorithm—something that tells us it's safe to\nterminate before iteration n - 1 is reached.\nSuch a stoppin g signal is a simple consequence of the following\nobservation: If we ever execute a complete iteration i in which no M[v]\nvalue changes, then no M[v] value will ever change again, since future\niterations will begin with exactly the same set of array entries. Thus it is\nsafe to stop the algorithm. Note  that it is not enough for a particular M[v]\nvalue to remain the same; in order to safely terminate, we need for all these\nvalues to remain the same for a single iteration."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 356})","('type', 'Document')"
"('page_content', ""6.9 Shortest Paths and Distance Vector Protocols\nOne important application of the Shortest-Path Problem is for routers in a\ncommunication network to determine the most efficient path to a\ndestination. We represent the network using a graph in which the nodes\ncorrespond to routers, and there is an edge between v and w if the two\nrouters are connected by a direct communication link. We define a cost cvw\nrepresenting the delay on the link (v, w); the Shortest-Path Problem with\nthese costs is to determine the path with minimum delay from a source node\ns to a destination t. Delays are naturally nonnegative, so one could use\nDijkstra's Algorithm to compute the shortest path. However , Dijkstra's\nshortest-path computation requires global knowledge of the network: it\nneeds to maintain a set S of nodes for which shortest paths have been\ndetermined, and make a global decision about which node to add next to S.\nWhile routers can be made to run a protocol in the background that gathers\nenough global information to implement such an algorithm, it is often\ncleaner and more flexible to use algorithms that require only local\nknowledge of neighboring nodes.\nIf we think about it, the Bellman-Ford Algorithm discussed in the\nprevious section has just such a “local” property . Suppose we let each node\nv maintain its value M[v]; then to update  this value, v needs only obtain the\nvalue M[w] from each neighbor w, and compute\n  \nbased on the information obtained.\nWe now discuss an improvemen t to the Bellman-Ford Algorithm that\nmakes it better suited for routers  and, at the same time, a faster algorithm in\npractice. Our current implementation of the Bellman-Ford Algorithm can be\nthought of as a pull-based  algorithm. In each iteration i, each node v has to\ncontact each neighbor w, and “pull” the new value M[w] from it. If a node w\nhas not changed  its value, then there is no need for v to get the value  again;\nhowever , v has no way of knowing this fact, and so it must execute the pull\nanyway ."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 357})","('type', 'Document')"
"('page_content', ""This wastefulness suggests a symmetric push-based  implementation,\nwhere values are only transmitted when they change. Specifically , each\nnode w whose distance value M[w]changes in an iteration informs all its\nneighbors of the new value in the next iteration; this allows them to update\ntheir values accordingly . If M[w] has not changed, then the neighbors of w\nalready have the current value,  and there is no need to “push ” it to them\nagain. This leads to savings in the running time, as not all values need to be\npushed in each iteration. We also may terminate the algorithm  early , if no\nvalue changes during an iterat ion. Here is a concrete description of the\npush-based implementation.\nPush-Based-Shortest-Path( G, s, t)\nn = number of nodes in G\nArray M[V]\nInitialize M[t] = 0 and M[v] = ∞ for all other v ∊ V\nFor i = 1, …, n - 1\nFor w ∊ V in any order\nIf M[w] has been updated in the previous iteration then\nFor all edges ( v, w) in any order\nM[v]= min( M[v], cvw + M[w])\nIf this changes the value of M[v], then first[v]= w\nEndfor\nEndfor\nIf no value changed in this iteration, then end the algorithm\nEndfor\nReturn M[s]\nIn this algorithm, nodes are sent updates of their neighbors' distance\nvalues in rounds, and each node sends out an update in each iteration in\nwhich it has changed. Howeve r, if the nodes correspond to routers in a\nnetwork, then we do not expect everything to run in lockstep like this; some\nrouters may report updates much more quickly than others, and a router\nwith an update to report may sometimes experience a delay before\ncontacting its neighbors. Thus the routers will end up executing an\nasynchr onous  version of the algorithm: each time a node w experiences an\nupdate to its M[w] value, it becomes “active” and eventually notifies its\nneighbors of the new value. If we were to watch the behavior of all routers\ninterleaved, it would look as follows.\nAsynchronous-Shortest-Path( G, s, t)"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 358})","('type', 'Document')"
"('page_content', ""n = number of nodes in G\nArray M[V]\nInitialize M[t] = 0 and M[v] = ∞ for all other v ∊ V\nDeclare t to be active and all other nodes inactive\nWhile there exists an active node\nChoose an active node w\nFor all edges ( y,w) in any order\nM[v] = min( M[y], cvw + M[w])\nIf this changes the value of M[v], then\nfirst[v] = w\nv becomes active\nEndfor\nw becomes inactive\nEndWhile\nOne can show that even this version of the algorithm, with essentially\nno coordination in the ordering of updates, will conver ge to the correct\nvalues of the shortest-path dista nces to t, assumi ng only that each time a\nnode becomes active, it eventually contacts its neighbors.\nThe algorithm we have develop ed here uses a single destination  t, and\nall nodes v ∊ V compute their shortest path to t. More generally , we are\npresumably interested in finding distances and shortest paths between all\npairs of nodes in a graph. To obtain such distances, we effectively use n\nseparate computations, one for each destination. Such an algorithm is\nreferred to as a distance vector pr otocol , since each node maintains a vector\nof distances to every other node in the network.\nProblems with the Distance Vector Protocol\nOne of the majo r problems with the distributed implementation of Bellman-\nFord on routers  (the protocol we have been discussing above) is that it's\nderived from an initial dynamic  programming algorithm that assumes edge\ncosts will remain constant during the execution of the algorith m. Thus far\nwe've been designing algorithms with the tacit understanding that a\nprogram executing the algorithm will be running on a single computer (or a\ncentrally managed set of computers), processing some specifi ed input. In\nthis context, it's a rather benig n assumption to require that the input not\nchange while the program is actually running. Once we start thinking about\nrouters in a netw ork, however , this assumption becomes trouble some. Edge\ncosts may change for all sorts of reasons: links can become congested and"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 359})","('type', 'Document')"
"('page_content', ""experience slow -downs; or a link (v, w) may even fail, in which case the\ncost cvw effectively increases to ∞.\nHere's an indication of what can go wrong with our shorte st-path\nalgorithm when this happens. If an edge (v,w) is deleted (say the link goes\ndown), it is natural for node v to react as follows: it should check whether\nits short est path to some node t used the edge (v, w), and, if so, it should\nincrease the distance using other neighbors. Notice that this increase in\ndistance from v can now trigger increases at v's neighbors, if they were\nrelying on a path through v, and these changes can cascad e through the\nnetwork. Consider the extremely simple example in Figure 6.24, in which\nthe original graph has three edges ( s, v), (v, s) and ( v, t), each of cost 1.\nNow suppose the edge ( v, t) in Figure 6.24  is deleted. How does node v\nreact? Unfortunately , it does not have a global map of the netw ork; it only\nknows the shortest-path distance s of each of its neighbors to t. Thus it does\nnot know  that the deletion of (v, t) has eliminated all paths from s to t.\nInstead, it sees that M[s]= 2, and so it updates M[v]= cvs + M[s]= 3,\nassuming that it will use its cost-1 edge to s, followe d by the supposed cost-\n2 path from s to t. Seeing this change, node s will update M[s]= csv + M[v]=\n4, based  on its cost-1 edge to v, followed by the supposed cost-3 path from\nv to t. Nodes s and v will continue updating their distance to t until one of\nthem finds an alternate route; in the case, as here, that the netw ork is truly\ndisconnected, these updates will continue indefinitely—a beha vior known\nas the problem of counting to infinity .\nFigur e 6.24 When the edge (v, t) is deleted, the distributed Bellman-Ford\nAlgorithm will begin “counting to infinity .”\nTo avoid this problem and related difficulties arising from the limited\namount of information available to nodes in the Bellman-Ford Algorithm,\nthe designers of network routing schemes have tended to move from\ndistance vector protocols to more expressive path vector protocols , in"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 360})","('type', 'Document')"
"('page_content', ""which each node stores not just the distance and first hop of their path to a\ndestination, but some representa tion of the entire path. Given knowledge of\nthe paths, nodes can avoid updating their paths to use edges they know to be\ndeleted; at the same time, they require significantly more storage to keep\ntrack of the full paths. In the history of the Internet, there has been a shift\nfrom distance vector protocols to path vector protocols; currently , the path\nvector approach  is used in the Border Gateway Protocol  (BGP) in the\nInternet core.\n* 6.10 Negative Cycles in a Graph\nSo far in our consideration of the Bellman-Ford Algorithm , we have\nassumed that the underlying graph has negative edge costs but no negative\ncycles. We now consider the more general case of a graph that may contain\nnegative cycles.\n The Problem\nThere are two natural questions we will consider .\nHow do we decide if a graph contains a negative cycle?\nHow do we actually find a negative cycle in a graph that contains one?\nThe algorithm developed for finding negative cycles will also lead to an\nimproved practical implementation of the Bellman-Ford Algorithm from\nthe previous sections.\nIt turns out that the ideas we've seen so far will allow us to find\nnegative cycles that have a path reaching a sink t. Before we develop the\ndetails of this, let's compare the problem of finding a negative cycle that can\nreach a given t with the seemingly more natural problem of finding a\nnegative cycle anywher e in the graph, regardless of its position related to a\nsink. It turns out that if we deve lop a solution to the first problem, we'll be\nable to obtain a solution to the second problem as well, in the following\nway. Suppose we start with a graph G, add a new node t to it, and connect\neach other node v in the graph to node t via an edge of cost 0, as shown in\nFigure 6.25 . Let us call the new “augmented graph” G′."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 361})","('type', 'Document')"
"('page_content', 'Figur e 6.25  The augmented graph.\n(6.29)  The augmented graph G has a negative cycle C such that there is a path from C to the sink t if\nand only if the original graph has a negative cycle.\nProof. Assume G has a negative cycle. Then this cycle C clearly has an edge to t in G,′ since all\nnodes have an edge to t.\nNow suppose G′ has a negative cycle  with a path to t. Since no edge leaves t in G, this cycle\ncannot contain t. Since G is the same as G aside from the node t, it follows that this cycle is also a\nnegative cycle of G.\n▪\nSo it is really enough to solve the problem of deciding whether G has a\nnegative cycle that has a path to a given sink node t, and we do this now .\n Designing and Analyzing the Algorithm\nTo get started thinking about the algorithm, we begin by adopting the\noriginal version of the Bellman- Ford Algorithm, which was less efficient in\nits use of space. We first extend the definitions of opt(i, v) from the\nBellman-Ford Algorithm, defini ng them for values i ≥ n. With the presence\nof a negative cycle in the graph , (6.22) no longer applies, and indeed the\nshortest path may get shorter and shorter as we go around a negative cycle.\nIn fact, for any node v on a negative cycle that has a path to t, we have the\nfollowing.\n(6.30)  If node v can r each node t and is contained in a negative cycle, then')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 362})","('type', 'Document')"
"('page_content', ""If the graph has no negative cycles, then (6.22) implies following statement.\n(6.31)  If ther e are no negative cycles in G, then  opt(i, v) = OPT( n - 1, v) for all nodes v and all i ≥ n.\nBut for how large an i do we have to compute the values opt(i, v) before\nconcluding that the graph has no negative cycles? For exampl e, a node v\nmay satisfy the equation OPT( n, v) = OPT( n - 1, v), and yet still lie on a\nnegative cycle. (Do you see why?) However , it turns out that we will be in\ngood shape if this equation holds for all nodes.\n(6.32  There is no negative cycle with a path to t if and only if OPT( n, v) = OPT( n - 1,v) for all nodes\nv.\nProof. Statement  (6.31) has already proved the forward direction. For the other direction, we use an\nargument employed earlier for reasoning about when it's safe to stop the Bellman-Ford Algorithm\nearly . Specifically , suppose OPT( n, v) = OPT( n - 1, v) for all nodes v. The values of OPT( n + 1, v)\ncan be computed from OPT( n, v); but all these values are the same as the corresponding OPT( n - 1,\nv). It follows that we will have OPT( n + 1, v) = OPT( n - 1,v). Extending this reasoning to future\niterations, we see that none of the values will ever change again, that is, opt(i, v) = OPT( n - 1, v) for\nall nodes v and all i ≥ n. Thus there cannot be a negative cycle C that has a path to t; for any node w\non this cycle C, (6.30) implies that the values opt(i, w) would have to become arbitrarily negative as i\nincreased.\n▪\nStatement (6.32) gives an O(mn) method to decide if G has a negative\ncycle that can reach t. We compute values of opt(i, v) for nodes of G and for\nvalues of i up to n. By (6.32), there  is no negative cycle if and only if there\nis some value of i ≤ n at which opt( i, v) = opt( i - 1, v) for all nodes v.\nSo far we have determined whether or not the graph has a negative\ncycle with a path from the cycle to t, but we have not actually found the\ncycle. To find a negative cycle, we consider a node v such that OPT( n, v) ≠\nOPT( n - 1,v): for this node, a path P from v to t of cost OPT( n, v) must use\nexactly n edges. We find this minimum-cost path P from v to t by tracing\nback through the subproblems. As in our proof of (6.22), a simp le path can\nonly have n - 1 edges, so P must contain a cycle C. We claim that this cycle\nC has negative cost.\n(6.33)  If G has n nodes and OPT( n, v) = OPT( n - 1, v), then a path P from v to t of cost OPT( n, v)\ncontains a cycle C, and C has negative cost."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 363})","('type', 'Document')"
"('page_content', 'Proof. First observe that the path P must have n edges, as OPT( n, v) = OPT( n -1, v), and so every\npath using n - 1 edges has cost greater than that of the path P. In a graph with n nodes, a path\nconsisting of n edges must repeat a node somewhere; let w be a node that occu rs on P more than\nonce. Let C be the cycle on P between two consec utive occurrences of node w. If C were not a\nnegative cycle, then deleting C from P would give us a v-t path with fewer than n edges and no\ngreater cost. This contradicts our assumpti on that OPT( n, v) ≠ OPT( n - 1, v), and hence C must be a\nnegative cycle.\n▪\n(6.34)  The algorithm above finds a negative cycle in G, if such a cycle exists, and runs in O(mn) time.\nExtensions: Improved Shortest Paths and\nNegative Cycle Detection Algorithms\nAt the end of Section 6.8 we discussed a space-ef ficient implementation of\nthe Bellman-For d algorithm for graphs with no negative cycles. Here we\nimplement the detection of nega tive cycles in a comparably space-ef ficient\nway. In addition  to the savings in space, this will also lead to a considerable\nspeedup in practice even for graphs with no negative cycles. The\nimplementation will be based on the same pointer graph P derived from the\n“first edges” ( v, first[v]) that we used for the space-ef ficient implementation\nin Section 6.8. By (6.27), we know that if the pointer graph ever has a\ncycle, then the cycle has negat ive cost, and we are done. But if G has a\nnegative cycle, does this guaran tee that the pointer graph will ever have a\ncycle? Furthermore, how much extra computation time do we need for\nperiodically checking whether P has a cycle?\nIdeally , we would like to determine whether a cycle is created in the\npointer graph P every time we add a new edge (v, w) with first[v]= w. An\nadditional advan tage of such “instant” cycle detection will be that we will\nnot have to wait for n iterations to see that the graph has a negative cycle:\nWe can terminate as soon as a negative cycle is found. Earlier we saw that if\na graph G has no negative cycles, the algorithm can be stopped early if in\nsome iteration the shortest path values M[v] remain the same for all nodes\nv. Instant  negative cycle detection will be an analogous early termination\nrule for graphs that have negative cycles.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 364})","('type', 'Document')"
"('page_content', ""Consider a new edge (v, w), with first[v]= w, that is added to the\npointer graph P. Before we add (v, w) the pointer graph has no cycles, so it\nconsists of paths from each node v to the sink t. The most natural way to\ncheck whether adding edge (v, w) creates a cycle in P is to follow the\ncurrent path from w to the terminal t in time proportional to the length of\nthis path. If we encounter v along this path, then a cycle has been formed,\nand hence, by (6.27), the graph has a negative cycle. Consider Figure 6.26,\nfor example, where in both (a) and (b) the pointer first[v] is being update d\nfrom u to w; in (a), this does not result in a (negative) cycle, but in (b) it\ndoes. However , if we trace out the sequence of pointers from v like this,\nthen we could spend as much as O(n)  time following the path to t and still\nnot find a cycle. We now discuss a method that does not require an O(n)\nblow-up in the running time.\nWe know that before the new edge (v, w) was added, the pointer graph\nwas a directed tree. Another way to test whether the addition of (v, w)\ncreates a cycle is to consider all nodes in the subtree directed toward v. If w\nis in this subtree , then (v, w) forms a cycle; otherwise it does not. (Again,\nconsider the two sample cases in Figure 6.26.) To be able to find all nodes\nin the subtree directed toward v, we need to have each node v maintain a list\nof all other nodes whose selecte d edges point to v. Given these pointers, we\ncan find the subtree in time proportional to the size of the subtree pointing\nto v, at most O(n)  as before. However , here we will be able to make\nadditional use of the work done. Notice that the current distance value M[x]\nfor all nodes x in the subtree was derived from node v's old value. We have\njust updated v's distan ce, and hence we know that the distance values of all\nthese nodes will be updated again. We'll mark each of these  nodes x as\n“dormant,” delete the edge (x, first[x]) from the pointer graph, and not use x\nfor future updates until its distance value changes.\nFigur e 6.26 Changing the pointer graph P when first[v] is updated from u\nto w. In (b), this creates a (negative) cycle, whereas in (a) it does not."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 365})","('type', 'Document')"
"('page_content', 'This can save a lot of future work in updates, but what is the effect on\nthe worst-case running time? We can spend as much as O(n)  extra time\nmarking nodes dormant after every update in distances. However , a node\ncan be marked dormant only if a pointer had been defined for it at some\npoint in the past, so the time spent on marking nodes dormant is at most as\nmuch as the time the algorithm spends updating distances.\nNow consider the time the algorithm spends on operations other than\nmarking nodes dormant. Recall that the algorithm is divided into iterations,\nwhere iteration i + 1 processes nodes whose distance has been updated in\niteration i. For the original version of the algorithm, we showed in (6.26)\nthat after i iterations, the value M[v] is no larger than the value of the\nshortest path from v to t using at most i edges. However , with many nodes\ndormant in each iteration, this may not be true anymore. For example, if the\nshortest path from v to t using at most i edges starts on edge e = (v, w), and\nw is dorm ant in this iteration, then we may not update the distance value\nM[v], and so it stays at a value higher than the length of the path through the\nedge (v, w). This seems like a problem—however , in this case, the path\nthrough edge (v, w) is not actually the shortest path, so M[v] will have a\nchance to get updated later to an even smaller value.\nSo instead of the simpler property that held for M[v]in the original\nversions of the algorithm, we now have the the following claim.\n(6.35)  Throughout the algorithm M[v]is the length of some  simple path from v to t; the path has at\nleast i edges if the distance value M[v] is updated in iteration i; and after i iterations, the value M[v]\nis the length of the shortest path for all nodes v wher e there is a shortest v-t path using at most i\nedges.\nProof. The first pointers maintain a tree of paths to t, whic h implies that all paths used to update the\ndistance values are simple. The fact that updates in iteration i are caused by paths with at least i edges\nis easy to show by induction on i. Similarly , we use induction to show that after iteration i the value\nM[v] is the distance on all nodes v where the shortest path from v to t uses at most i edges. Note that')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 366})","('type', 'Document')"
"('page_content', ""nodes v where M[v] is the actual shortes t-path distance cannot be dormant, as the value M[v] will be\nupdated in the next iteration for all dormant nodes.\n▪\nUsing this claim , we can see that the worst-case running time of the\nalgorithm is still bounded by O(mn): Ignori ng the time spent on marking\nnodes dormant, each iteration is implemented in O(m) time, and there can\nbe at most n - 1 iterations that update values in the array M without finding\na negativ e cycle, as simple paths can have at most n - 1 edges. Final ly, the\ntime spent mark ing nodes dormant is bounded by the time spent on updates.\nWe summarize the discussion with the following claim about the worst-case\nperformance of the algorithm. In fact, as mentioned above, this new version\nis in practice the fastest implementation of the algorithm even for graphs\nthat do not have negative cycles, or even negative-cost edges.\n(6.36)  The improved algorithm outlined above finds a negative cycle in G if such a cycle exists. It\nterminates immediately if the pointer graph  P of first[v] pointers contains a cycle C, or if there is an\niteration in which no update occurs to any distance value M[v]. The algorithm uses O(n) space, has\nat most n iterations, and runs in O(mn) time in the worst case.\nSolved Exercises\nSolved Exercise 1\nSuppose you are managing the construction of billboards on the Stephen\nDaedalus Memorial Highway , a heavily traveled stretch of road that runs\nwest-east for M miles. The possible sites for billboards are given by\nnumbers x1, x2, …, xn, each in the interval [0, M] (specifying their position\nalong the highway , measured in miles from its western end). If you place a\nbillboard at location xi, you receive a revenue of ri > 0.\nRegulations imposed by the county's Highway Department require that\nno two of the billboards be within less than or equal to 5 miles of each\nother . You'd like to place billboards at a subset of the sites so as to\nmaximize your total revenue, subject to this restriction.\nExample.  Suppose M = 20, n = 4,"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 367})","('type', 'Document')"
"('page_content', ""and\n  \nThen the optimal solution woul d be to place billboards at x1 and x3, for a\ntotal revenue of 10.\nGive an algorith m that takes an instance of this problem as input and\nreturns the maximum total revenue that can be obtained from any valid\nsubset of sites. The running time of the algorithm should be polynomial in\nn.\nSolution  We can naturally apply dynamic programming to this problem if\nwe reason as follows. Consider an optimal solution for a given input\ninstance; in this solution, we either place a billboard at site xn or not. If we\ndon't, the optimal solution on sites x1, …, xn is really the same as the\noptimal solution on sites x1, …, xn-1; if we do, then we should eliminate xn\nand all other sites that are within 5 miles of it, and find an optimal solution\non what's left. The same reasoning applies when we're looking at the\nproblem defined  by just the first j sites, x1, …, xj: we either include xj in the\noptimal solution or we don't, with the same consequences.\nLet's define some notation to help express this. For a site xj, we let e(j)\ndenote the easternmost site xi that is more than 5 miles from xj. Since sites\nare numbered west to east, this means that the sites x1, x2, …, xe(j) are still\nvalid options once we've chose n to place a billboard at xj, but the sites\nxe(j)+1, …, xj-1 are not.\nNow , our reasoning above justif ies the following recurrence. If we let\nOPT( j) denote the revenue from the optimal subset of sites among x1, …, xj,\nthen we have"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 368})","('type', 'Document')"
"('page_content', ""We now have most of the ingredients we need for a dynamic\nprogramming algorithm. First, we have a set of n subproblems, consisting\nof the first j sites for j = 0, 1, 2, …, n. Second, we have a recurrence that lets\nus build up the solutions to subproblems, given by OPT( j) = max( rj +\nOPT( e(j)), OPT( j - 1)).\nTo turn this into an algorithm, we just need to define an array M that\nwill store the OPT values and throw a loop around the recurrence that\nbuilds up the values M[j] in order of increasing j.\nInitialize M[0]= 0 and M[1]= r1\nFor j =2, 3, …, n:\nCompute M[j] using the recurrence\nEndfor\nReturn M[n]\nAs with all the dynamic programming algorithms we've seen in this chapter ,\nan optimal set of billbo ards can be found by tracing back through the values\nin array M.\nGiven the value s e(j) for all j, the running time of the algorithm is\nO(n), since each iteration of the loop takes constant time. We can also\ncompute all e(j) values in O(n) time as follows. For each site location xt, we\ndefine x′t = xt — 5. We then merge the sorted list X1, …, xn with the sorted\nlist x′1, …, x′ in linear time, as we saw how to do in Chapter 2. We now\nscan through this merged list; when we get to the entry x′j, we know that\nanything from this point onwar d to Xj cannot be chosen together with Xj\n(since it's within 5 miles), and so we simply define e(j) to be the largest\nvalue of i for which we've seen xt in our scan.\nHere's a final observation on this problem. Clearly , the solution looks\nvery much like that of the Weighted Interval Scheduling Problem, and\nthere's a fundamental reason for that. In fact, our billboard placement\nproblem can be directly encoded as an instance of Weighted Interval\nScheduling, as follows. Suppose that for each site xt, we define an interval\nwith endpoints [ xj - 5, Xj] and weight ri. Then, given any nonoverlapping set\nof interv als, the corresponding set of sites has the property that no two lie\nwithin 5 miles of each other . Conversely , given any such set of sites (no two\nwithin 5 miles), the intervals associated with them will be nonoverlapping."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 369})","('type', 'Document')"
"('page_content', ""Thus the collections of nonoverl apping intervals correspond precisely to the\nset of valid billboard placements , and so dropping the set of intervals we've\njust defined (with their weights ) into an algorithm for Weighted Interval\nScheduling will yield the desired solution.\nSolved Exercise 2\nThrough some friends of friend s, you end up on a consulting visit to the\ncutting-edge biotech firm Clones 'R' Us (CRU). At first you're not sure how\nyour algorithmic  background will be of any help to them, but you soon find\nyourself called upon to help two identical-looking software engineers tackle\na perplexing problem.\nThe problem they are curre ntly working on is based on the\nconcatenation  of sequences of genetic materia l. If X and Y are each strings\nover a fixed alphabet §, then XY denotes the string obtained by\nconcatenating  them— writing X followed by Y. CRU has identi fied a target\nsequence A of genetic material, consisting of m symbols, and they want to\nproduce a sequence that is as similar to A as possi ble. For this purpose, they\nhave a library L consisting of k (shorter) sequences, each of length at most\nn. They can cheaply produce any sequence consisting of copies of the\nstrings in L concatenated together (with repetitions allowed).\nThus we say that a concatenation  over £ is any sequence of the form\nB1B2 …Bℓ, where each Bt belongs the set £. (Again, repetitions are allowed,\nso Bj and Bj could be the same string in £, for different values of i and j.)\nThe problem is to find a concatenation over {Bj} for which the sequence\nalignment cost is as small as possible. (For the purpose of computing the\nsequence alignm ent cost, you may assume that you are given a gap cost δ\nand a mismatch cost αpq for each pair p, q ∊ §.)\nGive a polynomial-time algorithm for this problem.\nSolution  This problem is vaguely remini scent of Segmented Least Squares:\nwe have  a long sequence of “data” (the string A) that we want to “fit” with\nshorter segments (the strings in L).\nIf we wanted to pursue this analogy, we could search for a solution as\nfollows. Let B = B1B2 … Bℓ denote a concatenation over £ that aligns as\nwell as possible with the given string A. (That is, B is an optimal solution to\nthe input instance.) Consider an optimal alignment M of A with B, let t be"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 370})","('type', 'Document')"
"('page_content', ""the first position in A that is matched with some symbol in Bℓ, and let Aℓ\ndenote the substring of A from position t to the end. (See Figure 6.27  for an\nillustration of this with l = 3.) Now , the point is that in this optimal\nalignment M, the substring Aℓ is optimally aligned with Bℓ; indeed, if there\nwere a way to better align Aℓ with Bℓ, we could substitute it for the portion\nof M that aligns Aℓ with Bℓ and obtain a better overall alignment of A with\nB.\nThis tells us that we can look at the optimal solution as follows.\nThere's some final piece of Aℓ that is aligned with one of the strings in £,\nand for this piece all we're doing is finding the string in £ that aligns with it\nas well as possi ble. Having found this optimal alignment for Aℓ, we can\nbreak it of f and continue to find the optimal solution for the remainder of A.\nThinking about the problem this way doesn't tell us exactly how to\nproceed—we don't know how long Aℓ is supposed to be, or which string in\n£ it should be aligned with. But this is the kind of thing we can search over\nin a dynamic programming algorithm. Essentially , we're in about the same\nspot we were in with the Segme nted Least Squares Problem: there we knew\nthat we had to break off some final subsequence of the input points, fit them\nas well as possi ble with one line, and then iterate on the remaining input\npoints.\nSo let's set up things to make the search for Aℓ possible. First, let A[x\n:y] denote the substring of A consisting of its symbols from  position x to\nposition y, inclusive. Let c(x, y) denote the cost of the optimal alignment of\nA[x : y] with any string in £. (That is, we search over each string in L and\nfind the one that aligns best with A[x :y].) Let opt(j) denote the alignment\ncost of the optimal solution on the string A[1 :j].\nFigur e 6.27  In the optimal concatentation of strings to align with A, there is\na final string (B3 in the figure) that aligns with a substring of A (A3 in the\nfigure) that extends from some position t to the end."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 371})","('type', 'Document')"
"('page_content', ""The argument above says that an optimal solution on A[1 : j] consists\nof identifying a final “segme nt boundary” t < j, finding the optimal\nalignment of A[t :j] with a single string in L, and iterating on A[1 : t - 1].\nThe cost of this alignment of A[t :j] is just c(t,j), and the cost of aligning\nwith what's left is just OPT( t - 1). This suggests that our subproblems fit\ntogether very nicely , and it justifies the following recurrence.\n(6.37)  OPT( j) = min t<j c(t,j) + OPT( i - 1) for j ≥ 1, and opt(0) = 0.\nThe full algorithm consists of first computing the quantities c(t,j), for t\n< j, and then building up the values opt(j) in order of increasing j. We hold\nthese values in an array M.\nSet M[0] = 0\nFor all pairs 1≤ t≤j≤ m\nCompute the cost c(t,j) as follows:\nFor each string B ∊ £\nCompute the optimal alignment of B with A[t:j]\nEndfor\nChoose the B that achieves the best alignment, and use\nthis alignment cost as c(t,j)\nEndfor\nFor j = 1,2, …, n\nUse the recurrence (6.37) to compute M[j]\nEndfor\nReturn M[n]\nAs usual, we can get a concaten tation that achieves it by tracin g back\nover the array of opt values.\nLet's consider the running time of this algorithm. First, there are O(m2)\nvalues c(t,j) that need to be computed. For each, we try each string of the k\nstrings B ∊ £, and comp ute the optimal alignment of B with A[t:j] in time\n0(mn(j - t)) = O(mn). Thus the total time to compute all c(t,j) values is\n0(km3n).\nThis dominates the time to compute all opt values: Computing opt(j)\nuses the recurrence in (6.37), and this takes O(m) time to compute the\nminimum. Summ ing this over all choices of j = 1, 2, …, m, we get 0(m2)\ntime for this portion of the algorithm."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 372})","('type', 'Document')"
"('page_content', ""Exercises\n1. Let G = (V, E) be an undirected graph with n nodes. Recall that a\nsubset of the nodes is called an independent set if no two of them are\njoined by an edge. Finding large independent sets is difficult in\ngeneral; but here we'll see that it can be done efficiently if the graph is\n“simple” enough.  \nCall a graph G = (V,E) a path if its nodes can be written as v1, v2,\n…, vn, with an edge between vi and vj if and only if the numbers i and j\ndiffer by exactly 1. With each node vi, we associate a positive integer\nweight wi.\nConsider , for example, the five-node path drawn in Figure 6.28.\nThe weights  are the numbers drawn inside the nodes.\nThe goal in this question is to solve the following problem:\nFind an indepe ndent set in a path G whose total weight is as\nlarge as possible.\n(a) Give an example to show that the following algorithm does not\nalways find an independent set of maximum total weight.\nThe “heaviest-first” greedy algorithm\nStart with S equal to the empty set\nWhile some node remains in G\nPick a node vi of maximum weight\nAdd vi to S\nDelete vi and its neighbors from G\nEndwhile\nReturn S\n(b) Give an example to show that the following algorithm also does\nnot always find an independent set of maximum total weight.\nLet S1 be the set of all vi where i is an odd number\nLet S2 be the set of all vi where i is an even number\n(Note that S1 and S2 are both independent sets)\nDetermine which of S1 or S2 has greater total weight,"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 373})","('type', 'Document')"
"('page_content', ""and return this one\nFigur e 6.28  A paths with weights on the nodes. The maximum weight\nof an independent set is 14.\n(c) Give an algorithm that takes an n-node path G with weights and\nreturns an independent set of maximum total weight. The running time\nshould be polynomial in n, independent of the values of the weights.\n2. Suppose you're managing a consulting team of expert computer\nhackers, and each week you have to choose a job for them to\nundertake. Now , as you can well imagine, the set of possible jobs is\ndivided into those that are low-str ess (e.g., setting up a Web site for a\nclass at the local elementary school) and those that are high-str ess\n(e.g., protecting  the nation's most valuable secrets, or helping a\ndesperate group of Cornell stude nts finish a project that has something\nto do with compilers). The basic question, each week, is whether to\ntake on a low-stress job or a high-stress job.  \nIf you select a low-stress job for your team in week i, then you get\na revenue of ℓi > 0 dollars; if you select a high-stress job, you get a\nrevenue of hi > 0 dollars. The catch, however , is that in order for the\nteam to take on a high-stress job in week i, it's required that they do no\njob (of either type) in week i - 1; they need a full week of prep time to\nget ready for the crushing stress level. On the other hand, it's okay for\nthem to take a low-stress job in week i even if they have done a job (of\neither type) in week i - 1.\nSo, given a sequence of n weeks, a plan is speci fied by a choice\nof “low- stress,” “high-stress,” or “none” for each of the n weeks, with\nthe property that if “high-stress”  is chosen for week i > 1, then “none”\nhas to be chosen  for week i - 1. (It's okay to choose a high-s tress job in\nweek 1.) The value  of the plan is determined in the natural way: for\neach i, you add ℓi to the value if you choose “low-stress” in week i,\nand you add hi to the value if you choose “high-stress” in week i. (You\nadd 0 if you choose “none” in week i.)"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 374})","('type', 'Document')"
"('page_content', 'The pr oblem.  Given sets of values ℓ1ℓ2, …,ℓn and h1h2, …, hn, find a\nplan of maximum value. (Such a plan will be called optimal.)\nExample . Suppose n = 4, and the values of ℓi and ℓi are given by the\nfollowing table. Then the plan of maximum value would be to choose\n“none” in week 1, a high-stress  job in week 2, and low-stress jobs in\nweeks 3 and 4. The value of this plan would be 0 + 50 + 10 + 10 = 70.\n(a) Show  that the following algorithm does not correctly solve this\nproblem, by giving an instance on which it does not return the correct\nanswer .\nFor iterations i = 1 to n\nIf hi+1 > ℓi + ℓi+1 then\nOutput ""Choose no job in week i""\nOutput ""Choose a high-stress job in week i + 1""\nContinue with iteration i + 2\nElse\nOutput ""Choose a low-stress job in week i""\nContinue with iteration i + 1\nEndif\nEnd\nTo avoid problems with overflowing array bounds, we define hi =\nℓi = 0 when i > n.\nIn your example, say what the correct answer is and also what the\nabove algorithm finds.\n(b) Give an efficient algorithm that takes values for ℓ1,ℓ2, …,ℓn and h1,\nh2, …, hn and returns the value  of an optimal plan.\n3. Let G = (V, E) be a directed graph with nodes v1, …, vn. We say that G\nis an ordered graph  if it has the following properties.  \n(i) Each  edge goes from a node with a lower index to a node with a\nhigher index. That is, every directed edge has the form ( vi, vj) with i <j.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 375})","('type', 'Document')"
"('page_content', '(ii) Each node except vn has at least one edge leaving it. That is, for\nevery node vi,i = 1,2, …,n-1, there is at least one edge of the form vi,\nvj).\nThe length of a path is the number of edges in it. The goal in this\nquestion is to solve the following problem (see Figure 6.29 for an\nexample).\nGiven an ordered graph G, find the length  of the longest path that begins at v 1\nand ends at v n.\n(a) Show  that the following algorithm does not correctly solve this\nproblem, by giving an example  of an ordered graph on which it does\nnot return the correct answer .\nFigur e 6.29 The correct answer for this ordered graph is 3: The\nlongest path from  v1 to vn uses the three edges (v1, v2),(v2, v4), and (v4,\nv5).\nSet w=v1\nSet L = 0\nWhile there is an edge out of the node w\nChoose the edge ( w, vj)\nfor which j is as small as possible\nSet w=vj\nIncrease L by 1\nend while\nReturn L as the length of the longest path\nIn your example, say what the correct answer is and also what the\nalgorithm above finds.\n(b) Give an efficient algorithm that takes an ordered graph G and\nreturns the length  of the longest path that begins at v1 and ends at vn.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 376})","('type', 'Document')"
"('page_content', ""(Again, the length  of a path is the number of edges in the path.)\n4. Suppose you're running a lightweight consulting business—just you,\ntwo associates, and some rented equipment. Your clients are\ndistributed between the East Coast and the West Coast, and this leads\nto the following question.  \nEach month, you can either run your business from an office in\nNew York (NY)  or from an office in San Francisco (SF). In month i,\nyou'll incur an operating cost of Ni if you run the business out of NY;\nyou'll incur an operating cost of Si if you run the business out of SF. (It\ndepends on the distribution of client demands for that month.)\nHowever , if you run the business out of one city in month i, and\nthen out of the other city in month i + 1, then you incur a fixed moving\ncost of M to switch base of fices.\nGiven a sequence of n months, a plan is a sequence of n locations\n—each one equal to either NY or SF—such that the ith location\nindicates the city in which you will be based in the ith month. The cost\nof a plan is the sum of the operating costs for each of the n months,\nplus a moving cost of M for each time you switch cities. The plan can\nbegin in either city .\nThe pr oblem.  Given a value for the moving cost M, and sequences of\noperating costs N1, …, Nn and S1, …, Sn, find a plan of minimum cost.\n(Such a plan will be called optimal .)\nExample.  Suppose n = 4, M = 10, and the operating costs are given by\nthe following table.\nThen the plan of minimum cost would be the sequence of\nlocations"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 377})","('type', 'Document')"
"('page_content', 'with a total cost of 1+ 3+ 2+ 4 + 10 = 20, where the final term of 10\narises because you change locations once.\n(a) Show  that the following algorithm does not correctly solve this\nproblem, by giving an instance on which it does not return the correct\nanswer .\nFor i=1 to n\nIf Ni < Si then\nOutput “NY in Month i”\nElse\nOutput “SF in Month i”\nEnd\nIn your example, say what the correct answer is and also what the\nalgorithm above finds.\n(b) Give an example of an insta nce in which every optimal plan must\nmove (i.e., change locations) at least three times.\nProvide a brief explanation, saying why your example has this\nproperty .\n(c) Give an efficient algorith m that takes values for n, M, and\nsequences of operating costs N1, …, Nn and S1, …, Sn, and returns the\ncost of an optimal plan.\n5. As some of you know well, and others of you may be interested to\nlearn, a number of languages (including Chinese and Japanese) are\nwritten without spaces between the words. Consequently , software that\nworks with text written in these languages must address the word\nsegmentation problem —inferring likely boundaries between\nconsecutive words in the text. If English were written without spaces,\nthe analogous problem woul d consist of taking a string like\n“meetateight” and deciding that the best segmentation is “meet at\neight” (and not “me et at eight,” or “meet ate ight,” or any of a huge\nnumber of even less plausible alternatives). How could we automate\nthis process?  \nA simple approach that is at least reasonably effective is to find a\nsegmentation that simply maximizes the cumulative “quality” of its\nindividual constituent words. Thus, suppose you are given a black box\nthat, for any string of letters x = x1x2 … xk, will return a number')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 378})","('type', 'Document')"
"('page_content', ""quality (x). This number can be either positive or negative; larger\nnumbers correspond to more plausible English words. (So\nquality (“me”) would be positive, while quality (“ght”) would be\nnegative.)\nGiven a long string of letters y = y1y2 … yn, a segmentation of y is\na partition of its letters into contiguous blocks of letters; each block\ncorresponds to a word in the segmentation. The total quality  of a\nsegmentation is determined by adding up the qualities of each of its\nblocks. (So we'd get the right answer above provided that\nquality (“meet ”) + quality (“at”) + quality (“eight ”) was greater than the\ntotal quality of any other segmentation of the string.)\nGive an efficient algorithm that takes a string y and computes a\nsegmentation of maximum total quality . (You can treat a single call to\nthe black box computing quality(x)  as a single computational step.)\n(A final note, not necessary for solving the problem:  To achieve\nbetter performance, word segm entation software in practice works\nwith a more complex formulation of the problem—for example,\nincorporating the notion that solutions should not only be reason able at\nthe word level, but also form coherent phrases and sentences. If we\nconsider the example “theyouth event,” there are at least three valid\nways to segmen t this into comm on English words, but one constitutes\na much more coherent phrase than the other two. If we think of this in\nthe terminology  of formal languages, this broader problem is like\nsearching for a segmentation that also can be parsed well according to\na grammar for the underlying language. But even with these additional\ncriteria and constraints, dynamic programming approaches lie at the\nheart of a number of successful segmentation systems.)\n6. In a word proce ssor, the goal of “pretty-printing” is to take text with a\nragged right mar gin, like this,  \nCall me Ishmael.\nSome years ago,\nnever mind how long precisely ,\nhaving little or no money in my purse,\nand nothing particular to interest me on shore,\nI thought I would sail about a little\nand see the watery part of the world."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 379})","('type', 'Document')"
"('page_content', ""and turn it into text whose right margin is as “even” as possib le, like\nthis.\nCall me Ishmael. Some years ago, never\nmind how long precisely , having little\nor no money in my purse, and nothing\nparticular to interest me on shore, I\nthought I would sail about a little\nand see the watery part of the world.\nTo make this precise enough for us to start thinking about how to\nwrite a pretty-pr inter for text, we need to figure out what it means for\nthe right margins to be “even.” So suppose our text consists of a\nsequence of words, W = {w1,w2, …, wn}, where wt consists of ct\ncharacters. We have a maximum line length of L. We will assume we\nhave a fixed-w idth font and ignore issues of punctuation or\nhyphenation.\nA formatting  of W consists  of a partition of the words in W into\nlines.  In the words assigned to a single line, there should be a space\nafter each word except the last; and so if wj, wj+1, …, wk are assigned\nto one line, then we should have\n  \nWe will call an assignment of words to a line valid  if it satisfies this\ninequality . The difference between the left-hand side and the right-\nhand side will be called the slack  of the line-that  is, the number  of\nspaces left at the right mar gin.\nGive an efficient algorithm to find a partition of a set of words W\ninto valid lines, so that the sum of the squar es of the slacks of all lines\n(including the last line) is minimized.\n7. As a solved exercise in Chapter 5, we gave an algorithm with 0(n log\nn) runnin g time for the following problem. We're looking at the price\nof a given stock  over n consecutive days, numbered i = 1,2, …, n. For"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 380})","('type', 'Document')"
"('page_content', ""each day i, we have a price p(i) per share for the stock on that day.\n(We'll assume for simplicity that the price was fixed during each day.)\nWe'd like to know: How should we choose a day i on whic h to buy the\nstock and a later day j > i on which to sell it, if we want to maximize\nthe profit per share, p(j) - p(i)? (If there is no way to make money\nduring the n days, we should conclude this instead.)\nIn the solved exercise, we showed how to find the optimal pair of\ndays i and j in time O(n log n). But, in fact, it's possible to do better\nthan this. Show how to find the optimal numbers i and j in time O(n).\n8. The residents of the under ground city of Zion defend themselves\nthrough a combination of kung fu, heavy artillery , and efficient\nalgorithms. Recently they have become interested in automated\nmethods that can help fend of f attacks by swarms of robots.  \nHere's what one of these robot attacks looks like.\nA swarm  of robots arrives over the course of n seconds; in the ith\nsecond, xi robots arrive. Based on remote sensing data, you know\nthis sequence x1, x2, …, xn in advance.\nYou have at your disposal an electr omagnetic pulse  (EMP), which\ncan destroy some of the robots as they arrive; the EMP's power\ndepends on how long it's been allowed to charge up. To make this\nprecise, there is a function f(·) so that if j seconds have passed\nsince the EMP was last used, then it is capable of destroying up to\nf(j) robots.\nSo specifically , if it is used in the kth second,  and it has been j\nseconds since it was previously  used, then it will destroy min( xk,\nf(j)) robots. (After this use, it will be completely drained.)\nWe will also assume that the EMP starts off completely drained,\nso if it is used for the first time in the jth second, then it is capable\nof destroying up to f(j) robots.\nThe pr oblem.  Given the data on robot arrivals x1, x2, …, xn, and given\nthe rechar ging function f(·), choose the points in time at which you're\ngoing to activate the EMP so as to destroy as many robots as possible.\nExample.  Suppose n = 4, and the values of xi and f(i) are given by the\nfollowing table."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 381})","('type', 'Document')"
"('page_content', ""The best solution would be to activate the EMP in the 3rd and the\n4th seconds. In the 3rd second , the EMP has gotten to charge for 3\nseconds, and so it destroys min(10, 4) = 4 robots; In the 4th second, the\nEMP has only gotten to charge for 1 second since its last use, and it\ndestroys min(1, 1) = 1 robot. This is a total of 5.\n(a) Show  that the following algorithm does not correctly solve this\nproblem, by giving an instance on which it does not return the correct\nanswer .\nSchedule-EMP(x 1, …, xn)\nLet j be the smallest number for which f(j) ≥ xn\n(If no such j exists then set j = n)\nActivate the EMP in the nth second\nIf n - j ≥ 1 then\nContinue recursively on the input x1, …,xn-j\n(i.e., invoke Schedule-EMP( x1, …, xn-j))\nIn your example, say what the correct answer is and also what the\nalgorithm above finds.\n(b) Give an efficient algorithm that takes the data on robot arriv als x1,\nx2, …, xn, and the rechar ging function f(·), and returns the maximum\nnumber of robots that can be destroyed by a sequence of EMP\nactivations.\n9. You're helping to run a high-performance computing system capable of\nprocessing several terabytes of data per day. For each of n days, you're\npresented with a quantity of data; on day i, you're presented with xi\nterabytes. For each terabyte you process, you receive a fixed revenue,\nbut any unproce ssed data becomes unavailable at the end of the day\n(i.e., you can't work on it in any future day).  \nYou can't always process everything each day because you're\nconstrained by the capabilities of your computing system, which can\nonly process a fixed number of terabytes in a given day. In fact, it's"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 382})","('type', 'Document')"
"('page_content', ""running some one-of-a-kind software that, while very sophisticated, is\nnot totally reliable, and so the amount of data you can process goes\ndown with each day that passe s since the most recent reboot  of the\nsystem. On the first day after a reboot, you can process s1 terabytes, on\nthe second day after a reboot, you can process s2 terabytes, and so on,\nup to sn; we assume s1 > s2 > s3 > … > sn > 0. (Of course,  on day i you\ncan only process up to xi terabytes, regardless of how fast your system\nis.) To get the system back to peak performance, you can choose to\nreboot it; but on any day you choose to reboot the system, you can't\nprocess any data at all.\nThe pr oblem.  Given the amounts of available data x1, x2, …, xn for the\nnext n days, and given  the profile of your system as expressed by s1,\ns2, …, sn (and starting from a freshly rebooted system on day 1),\nchoose the days on which you're going to reboot so as to maximize the\ntotal amount of data you process.\nExample.  Suppose n = 4, and the values of xi and si are given by\nthe following table.\nThe best solution would be to reboot on day 2 only; this way, you\nprocess 8 terabytes on day 1, then 0 on day 2, then 7 on day 3, then 4\non day 4, for a total of 19. (Note that if you didn't reboot at all, you'd\nprocess 8 + 1 + 2 + 1 = 12; and other rebooting strategies give you less\nthan 19 as well.)\n(a) Give an example of an instance with the following properties.\n- There is a “surplus” of data in the sense that xi > s1 for every i.\n- The optimal solution reboot s the system at least twice. In\naddition to the example, you should say what the optimal solution is.\nYou do not need to provide a proof that it is optimal.\n(b) Give an efficient algorithm that takes values for x1, x2, …, xn and\ns1, s2, …, sn and returns the total number  of terabytes processed by an\noptimal solution."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 383})","('type', 'Document')"
"('page_content', ""10. You're trying to run a large computing job in which you need to\nsimulate a physical system for as many discrete steps  as you can. The\nlab you're working in has two large supercomputers (which we'll call A\nand B) which are capable of processing this job. However , you're not\none of the high-priority users of these supercomputers, so at any given\npoint in time, you're only able to use as many spare cycles as these\nmachines have available.  \nHere's the problem you face. Your job can only run on one of the\nmachines in any given minute. Over each of the next n minutes, you\nhave a “profile” of how much processing power is available on each\nmachine. In minute i, you would be able to run at > 0 steps of the\nsimulation if your job is on machine A, and bt > 0 steps of the\nsimulation if your job is on machine B. You also have the ability to\nmove your job from one machine to the other; but doing this costs you\na minute of time in which no processing is done on your job.\nSo, given a sequence of n minutes, a plan is speci fied by a choice\nof A, B, or “move ” for each minu te, with the property that choices A\nand B cannot appear in consecutive minutes. For example, if your job\nis on machine A in minute i, and you want to switch to machine B, then\nyour choice for minute i +1must be move , and then your choice for\nminute i + 2 can be B. The value  of a plan is the total number of steps\nthat you manage to execute over the n minutes: so it's the sum of at\nover all minutes in which the job is on A, plus the sum of bt over all\nminutes in which the job is on B.\nThe pr oblem.  Given values a1, a2, …, an and b1, b2, …, bn, find a plan\nof maximum value. (Such a strategy will be called optimal .) Note that\nyour plan can start with either of the machines A or B in minute 1.\nExample.  Suppose n = 4, and the values of ai and bi are given by the\nfollowing table.\nThen the plan of maximum value would be to choose A for\nminute 1, then move  for minute 2, and then B for minutes 3 and 4. The"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 384})","('type', 'Document')"
"('page_content', ""value of this plan would be 10 + 0 + 20 + 20 = 50.\n(a) Show  that the following algorithm does not correctly solve this\nproblem, by giving an instance on which it does not return the correct\nanswer .\nIn minute 1, choose the machine achieving the lar ger of a1, b1\nSet i = 2\nWhile i ≤ n\nWhat was the choice in minute i - 1?\nIf A:\nIf bi+i > ai + ai+i then\nChoose move  in minute i and B in minute i + 1\nProceed to iteration i + 2\nElse\nChoose A in minute i\nProceed to iteration i + 1\nEndif\nIf B: behave as above with roles of A and B reversed\nEndWhile\nIn your example, say what the correct answer is and also what the\nalgorithm above finds.\n(b) Give an efficient algorithm that takes values for a1, a2, …, an and\nb1, b2, …, bn and returns the value  of an optimal plan.\n11. Suppose you're consulting for a company that manufactures PC\nequipment and ships it to distributors all over the country . For each of\nthe next n weeks, they have a projected supply st of equipment\n(measured in pounds), which has to be shipped by an air freight carrier . \nEach week's supply can be carried by one of two air freig ht\ncompanies, A or B.\nCompany A charges a fixed rate r per pound (so it costs r· si to\nship a week's supply st).\nCompany B makes contracts for a fixed amount c per week,\nindependent of the weight. However , contracts with company B\nmust be made in blocks of four consecutive weeks at a time.\nA schedule , for the PC company , is a choice of air freight\ncompany (A or B) for each of the n weeks, with the restriction that\ncompany B, whenever it is chosen, must be chosen for blocks of four"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 385})","('type', 'Document')"
"('page_content', ""contiguous weeks at a time. The cost of the schedule is the total\namount paid to company A and B, according to the description above.\nGive a polynom ial-time algorith m that takes a sequence of supply\nvalues s1, s2, …, sn and returns a schedule  of minimum cost.\nExample.  Suppose r = 1, c = 10, and the sequence of values is\n  \nThen the optimal schedule would be to choose company A for the first\nthree weeks, then company B for a block of four consecutive weeks,\nand then company A for the final three weeks.\n12. Suppose we want to replicate a file over a collection of n servers,\nlabeled S1, S2, …, Sn. To place a copy  of the file at server Si results in a\nplacement cost  of ci, for an integer ci > 0. \nNow , if a user requests the file from server Si, and no copy of the\nfile is present at Si, then the servers St+1, St+2, St+3 … are searched in\norder until a copy of the file is finally found, say at server Sj, where j >\ni. This results in an access cost of j - i. (Note that the lower -indexed\nservers St-1, Si-2, … are not consulted in this search.) The access cost is\n0 if St holds a copy of the file. We will require that a copy of the file be\nplaced at server Sn, so that all such searches will terminate, at the\nlatest, at Sn.\nWe'd like to place copies of the files at the servers so as to\nminimize the sum of placement and access costs. Formally , we say that\na configuration  is a choice, for each server Si with i = 1, 2, …, n - 1, of\nwhether to place a copy of the file at Si or not. (Recall that a copy is\nalways placed at Sn.) The total cost  of a configuration is the sum of all\nplacement costs for servers with a copy of the file, plus the sum of all\naccess costs associated with all n servers.\nGive a polynomial-time algorithm to find a configuration of\nminimum total cost.\n13. The problem of searching for cycles in graphs arises naturally in\nfinancial trading applications. Consider a firm that trades shares in n"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 386})","('type', 'Document')"
"('page_content', ""different companies. For each pair i ≠ j, they maintain a trade ratio rij,\nmeaning that one share of i trades for rij shares of j. Here we allow the\nrate r to be fractional; that is, rij = 2/3 means that you can trade three\nshares of i to get two shares of j. \nA trading cycle  for a sequence of shares i1, i2, …, ik consists of\nsuccessively trading shares in company i1 for shares in company i2,\nthen shares in company i2 for shares i3, and so on, finally trading\nshares in ik back to shares in company i1. After such a sequence of\ntrades, one ends up with shares in the same company i1 that one starts\nwith. Trading around a cycle is usually a bad idea, as you tend to end\nup with fewer shares than you started with. But occasionally , for short\nperiods of time, there are opportunities to increase shares. We will call\nsuch a cycle an opportunity cycle , if trading along the cycle increases\nthe number of shares. This happens exactly if the product of the ratios\nalong the cycle is above 1. In analyzing the state of the market,  a firm\nengaged in trading would like to know if there are any opportunity\ncycles.\nGive a polynomial-time algorithm that finds such an opportunity\ncycle, if one exists.\n14. A large collecti on of mobile wireless devices can naturally form a\nnetwork in which the devices are the nodes, and two devices x and y\nare connected by an edge if they are able to directly communica te with\neach other (e.g., by a short-ra nge radio link). Such a network of\nwireless devices  is a highly dynamic object, in which edges can appear\nand disappear over time as the devices move around. For instan ce, an\nedge (x, y) might disappear as x and y move far apart from each other\nand lose the ability to communicate directly . \nIn a network that changes over time, it is natural to look for\nefficient ways of maintaining  a path between certain designated nodes.\nThere are two opposing concerns in maintaining such a path: we want\npaths that are short, but we also do not want to have to change the path\nfrequently as the network structu re changes. (That is, we'd like a single\npath to continue  working, if possible, even as the network gains and\nloses edges.) Here is a way we might model this problem.\nSuppose we have a set of mobile nodes V, and at a particular point\nin time there is a set E0 of edges among these nodes. As the nodes"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 387})","('type', 'Document')"
"('page_content', ""move, the set of edges changes from E0 to E1, then to E2, then to E3,\nand so on, to an edge set Eb. For i = 0,1,2, …, b, let Gt denote the\ngraph (V, Ei). So if we were  to watch the structure of the network on\nthe nodes V as a “time lapse,” it would look precisely like the sequence\nof graphs G0, G1, G2, …, Gb-1, Gb. We will assume that each of these\ngraphs Gi is connected.\nNow consider two particular nodes s, t ∊ V. For an s-t path P in\none of the graphs G, we define the length  of P to be simply the number\nof edges in P, and we denote  this ℓ{P). Our goal is to produce a\nsequence of paths P0,P1, …,Pb so that for each i, Pt is an s-t path in Q.\nWe want the paths to be relatively short. We also do not want there to\nbe too many changes—points  at which the identity of the path\nswitches. Formally , we define changes (P0, P1, …, Pb) to be the\nnumber of indices i (0 ≤ i ≤ b - 1) for which Pi ≠ Pi+1.\nFix a constant K > 0. We define the cost of the sequence of paths\nP0,P1, …,Pb to be\n  \n(a) Supp ose it is possible to choose a single path P that is an s-t path in\neach of the graphs G0,G1, …,Gb. Give a polynomial-time algorithm to\nfind the shortest such path.\n(b) Give a polynomial-time algorithm to find a sequence of paths\nP0,P1, …, Pb of minimum cost, where Pi is an s-t path in Gi for i = 0,\n1, …, b\n15. On most clear days, a group of your friends in the Astronomy\nDepartment gets together to plan out the astronomical events they're\ngoing to try observing that night. We'll make the following\nassumptions about the events.  \nThere are n events, which for simplicity we'll assume occur in\nsequence separated by exactly one minute each. Thus event j"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 388})","('type', 'Document')"
"('page_content', ""occurs at minute j; if they don't observe this event at exactly\nminute j, then they miss out on it.\nThe sky is mapped according to a one-dimensional coordinate\nsystem (measured in degrees from some central baseline); event j\nwill be taking place at coordinate dj, for some integer value dj.\nThe telescope starts at coordinate 0 at minute 0.\nThe last event, n, is much more important than the others; so it is\nrequired that they observe event n.\nThe Astronomy Department operates a large telescope that can be\nused for viewing these events. Because it is such a complex\ninstrument, it can only move at a rate of one degree per minute. Thus\nthey do not expe ct to be able to observe all n events; they just want to\nobserve as many as possible, limited by the operation of the telescope\nand the requirement that event n must be observed.\nWe say that a subset S of the events is viewable  if it is possible to\nobserve each event j ∊ S at its appointed time j, and the telescope has\nadequate time (moving at its maximum of one degree per minute) to\nmove between consecutive events in S.\nThe problem.  Given the coordinates of each of the n events, find a\nviewable subset of maximum size, subject to the requirement that it\nshould contain event n. Such a solution will be called optimal .\nExample.  Suppose the one-dimensional coordinates of the events are\nas shown here.\nThen the optima l solution is to observe events 1, 3, 6, 9. Note that\nthe telescope has time to move from one event in this set to the next,\neven moving at one degree per minute.\n(a) Show  that the following algorithm does not correctly solve this\nproblem, by giving an instance on which it does not return the correct\nanswer .\nMark all events j with | dn - dj| > n - j as illegal (as\nobserving them would prevent you from observing event n)\nMark all other events as legal"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 389})","('type', 'Document')"
"('page_content', 'Initialize current position to coordinate 0 at minute 0\nWhile not at end of event sequence\nFind the earliest legal event j that can be reached without\nexceeding the maximum movement rate of the telescope\nAdd j to the set S\nUpdate current position to be coord. ≃dj at minute j\nEndwhile\nOutput the set S\nIn your example, say what the correct answer is and also what the\nalgorithm above finds.\n(b) Give an efficient algorithm that takes values for the coordina tes d1,\nd2, …, dn of the events and returns the size of an optimal solution.\n16. There are many sunny days in Ithaca, New York; but this year, as it\nhappens, the spring ROTC picnic at Cornell has fallen on a rainy day.\nThe ranking officer decides to postpone the picnic and must notify\neveryone by phone. Here is the mechanism she uses to do this.  \nEach ROTC person on campus except the ranking officer repor ts\nto a unique superior officer . Thus the reporting hierarchy  can be\ndescribed by a tree T, rooted at the ranking officer, in which each other\nnode v has a parent node u equal to his or her superior officer.\nConversely , we will call v a direct subor dinate  of u. See Figure 6.30 , in\nwhich A is the ranking officer, B and D are the direct subordin ates of\nA, and C is the direct subordinate of B.\nTo notify everyone of the postp onement, the ranking officer first\ncalls each of her direct subordinates, one at a time. As soon as each\nsubordinate gets the phone call, he or she must notify each of his or her\ndirect subordinates, one at a time. The process continues this way until\neveryone has been notified. Note that each person in this process can\nonly call direct subordinates on the phone; for example, in Figure 6.30 ,\nA would not be allowed to call C.\nWe can picture this process as being divided into rounds . In one\nround, each person who has already learned of the postponement can\ncall one of his or her direct subordinates on the phone. The number of\nrounds it takes for everyone to be notified depends on the seque nce in\nwhich each person calls their direct subordinates. For example, in\nFigure 6.30 , it will take only two rounds if A starts by calling B, but it\nwill take three rounds if A starts by calling D.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 390})","('type', 'Document')"
"('page_content', ""Give an efficient algorithm that determines the minimum number\nof rounds needed for everyone to be notified, and outputs a sequence\nof phone calls that achieves this minimum number of rounds.\n17. Your friends have been studyi ng the closing prices of tech stocks,\nlooking for interesting patterns. They've defined something called a\nrising tr end, as follows.  \nFigur e 6.30 A hierarchy with four people. The fastest broadcast\nscheme is for A to call B in the first round. In the second round, A\ncalls D and B calls C. If A were to call D first, then C could not learn\nthe news until the third round.\nThey have the closing price for a given stock recorded for n days\nin succession; let these prices be denoted P[1], P[2], …, P[n]. A rising\ntrend in these prices  is a subsequen ce of the prices P[i1], P[i2], …,\nP[ik], for days i1 < i2 < … < ik, so that\ni1 = 1, and\nP[ij] < P[ij+1] for each j = 1, 2, …, k - 1.\nThus a rising trend is a subsequence of the days—beginning on the\nfirst day and not necessarily contiguous—so that the price strictly\nincreases over the days in this subsequence.\nThey are interested in finding the longest rising trend in a given\nsequence of prices.\nExample.  Suppose n = 7, and the sequence of prices is"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 391})","('type', 'Document')"
"('page_content', ""Then the longes t rising trend is given by the prices on days 1, 4, and 7.\nNote that days 2, 3, 5, and 6 consist of increasing prices; but because\nthis subsequence  does not begin on day 1, it does not fit the definition\nof a rising trend.\n(a) Show  that the following algorithm does not correctly return the\nlength  of the longest rising trend, by giving an instance on which it\nfails to return the correct answer .\nDefine i=1\nL=1\nFor j=2 to n\nIf P[j] > P[i] then\nSet i=j.\nAdd 1 to L\nEndif\nEndfor\nIn your example, give the actual  length of the longest rising trend,\nand say what the algorithm above returns.\n(b) Give  an efficient algorithm that takes a sequence of prices P[1],\nP[2], …, P[n] and returns the length  of the longest rising trend.\n18. Consider the sequence alignment problem over a four-letter alphabet\n{z1, z2, z3, z4}, with a given gap cost and given mismatch costs.\nAssume that each of these parameters is a positive integer . \nSuppose you are given two strings A = axa2 … am and B = blb2 …\nbn and a proposed  alignment between them. Give an O(mn) algorithm\nto decide whether this alignment is the unique  minimum-cost\nalignment between A and B.\n19. You're consulting for a group of people (who would prefer not to be\nmentioned here by name) whose jobs consist of monitoring and\nanalyzing electronic signals coming from ships in coastal Atlantic\nwaters. They want a fast algor ithm for a basic primitive that arises\nfrequently: “untangling” a superposition of two known signals.\nSpecifically , they're picturing a situation in which each of two ships is\nemitting a short sequence of Os and Is over and over, and they want to"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 392})","('type', 'Document')"
"('page_content', ""make sure that the signal they're hearing is simply an interleaving  of\nthese two emissions, with nothing extra added in.  \nThis describes the whole problem; we can make it a little more\nexplicit as follows. Given a string x consisting of Os and Is, we write\nxk to deno te k copies of x concatenated together . We say that a string x′\nis a repetition  of x if it is a prefix  of xk for some number k. So x′ =\n10110110110 is a repetition of x = 101.\nWe say that a string s is an interleaving  of x and y if its symbols\ncan be partitioned into two (not necessarily contiguous) subsequences\ns′ and s″, so that s′ is a repetition of x and s″ is a repetition of y. (So\neach symbol in s must belong to exactly one of s′ or s′.) For example,\nif x = 101 and y = 00, then s = 100010101 is an interleaving of x and y,\nsince characters  1,2,5,7,8,9 form 101101-a repetition of x—and the\nremaining characters 3,4,6 form 000—a repetition of y.\nIn terms of our application, x and y are the repeating sequences\nfrom the two ships, and s is the signal we're listening to: We want to\nmake sure s “unrave ls” into simple repetitions of x and y. Give an\nefficient algorithm that takes strings s, x, and y and decides if s is an\ninterleaving of x and y.\n20. Suppose it's nearing the end of the semester and you're taking n\ncourses, each with a final project that still has to be done. Each project\nwill be graded on the following scale: It will be assigned an integer\nnumber on a scale of 1 to g > 1, higher numbers being better grades.\nYour goal, of course, is to maximize your average grade on the n\nprojects.  \nYou have a total of H > n hours in which to work on the n projects\ncumulatively , and you want to decide how to divide up this time. For\nsimplicity , assume H is a positive integer, and you'll spend an integer\nnumber of hours on each project. To figure out how best to divide up\nyour time, you've come up with a set of functions {fi: i = 1,2, …, n}\n(rough estimates, of course) for each of your n courses; if you spend h\n≤ H hours on the project for course i, you'll get a grade of fi(h). (You\nmay assume that the functions fi are nondecr easing: if h < h′, then fi(h)\n≤ fi(h′).)\nSo the problem is: Given these functions {fi}, decide how many\nhours to spend on each project (in integer values only) so that your"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 393})","('type', 'Document')"
"('page_content', ""average grade, as computed according to the fi, is as large as possible.\nIn order to be efficient, the running time of your algorithm should be\npolynomial in n, g, and H; none of these quantities should appear as an\nexponent in your running time.\n21. Some time back, you helped a group of friends who were doing\nsimulations for a computation-intensive investment company , and\nthey've come back to you with a new problem. They're looking at n\nconsecutive days of a given stock, at some point in the past. The days\nare numbered i = 1,2, …, n; for each day i, they have a price p(i) per\nshare for the stock on that day . \nFor certain (possibly large) values of k, they want to study what\nthey call k-shot strategies.  A k-shot strategy is a collection of m pairs\nof days ( b1, S1), …, ( bm, sm), where 0 ≤ m ≤ k and\n  \nWe view these as a set of up to k nonoverlapping  intervals, during\neach of which the investors buy 1,000 shares of the stock (on day bi)\nand then sell it (on day si). The return  of a given k-shot strategy is\nsimply the profit obtained from the m buy-sell transactions, namely ,\n \nThe investors want to assess the value of k-shot strategies by\nrunning simulations on their n-day trace of the stock price. Y our goal is\nto design  an efficient algorithm that determines, given the sequence of\nprices, the k-shot strategy with the maximum possible return. Since fc\nmay be relatively large in these simulations, your running time should\nbe polynomial in both n and fe; it should not contain k in the exponent.\n22. To assess how “well-connected” two nodes in a directed graph are, one\ncan not only look at the length of the shortest path between them, but\ncan also count the number  of shortest paths."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 394})","('type', 'Document')"
"('page_content', ""This turns out to be a problem that can be solved efficiently ,\nsubject to some restrictions on the edge costs. Suppose we are given a\ndirected graph G = (V,E), with costs on the edges; the costs may be\npositive or negative, but every cycle in the graph has strictly positive\ncost. We are also given two nodes v,w ∊ V. Give an efficient algorithm\nthat computes the number of shortest v-w paths in G. (The algorithm\nshould not list all the paths; just the number suf fices.)\n23. Suppose you are given a directed graph G = (V, E) with costs on the\nedges ce for e ∊ E and a sink t (costs may be negative). Assum e that\nyou also have finite values d(v) for v ∊ V. Someone claims that, for\neach node v ∊ V, the quantity d(v) is the cost of the minimum-cos t path\nfrom node v to the sink t. \n(a) Give a linear -time algorithm (time O(m) if the graph has m edges)\nthat verifies whether this claim is correct.\n(b) Assume that the distances are correct, and d(v) is finite for all v ∊\nV. Now you need to compute distances to a different sink t′. Give an\nO(m log n) algorithm for computing distances d′(v) for all nodes v ∊ V\nto the sink node t′. (Hint:  It is useful to consider a new cost function\ndefined as follows: for edge e = (v, w), let c′e = ce - d(v) + d(w). Is there\na relation between costs of paths for the two dif ferent costs c and c?)\n24. Gerrymandering  is the practice of carving up electoral districts in very\ncareful ways so as to lead to outcomes that favor a particular political\nparty . Recent court challenges to the practice have argued that through\nthis calculated redistricting, large numbers of voters are being\neffectively (and intentionally) disenfranchised.  \nComputers, it turns out, have been implicated as the source of\nsome of the “villainy” in the news coverage on this topic: Thanks to\npowerful software, gerrymandering has changed from an activity\ncarried out by a bunch of people with maps, pencil, and paper into the\nindustrial-strength process that it is today . Why is gerrymandering a\ncomputational problem? There are database issues involved in tracking\nvoter demograph ics down to the level of individual streets and houses;\nand there are algorithmic issues involved in grouping voters into\ndistricts. Let's think a bit about what these latter issues look like.\nSuppose we have a set of n precincts P1,P2, …,Pn, each\ncontaining m registered voters. We're supposed to divide these"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 395})","('type', 'Document')"
"('page_content', ""precincts into two districts,  each consisting of n/2 of the precincts.\nNow , for each precinct, we have information on how many voters are\nregistered to each of two politica l parties. (Suppose, for simplicity , that\nevery voter is registered to one of these two.) We'll say that the set of\nprecincts is susceptible  to gerrymandering if it is possible to perform\nthe division into two districts in such a way that the same party holds a\nmajority in both districts.\nGive an algorithm to determine whether a given set of precincts is\nsusceptible to gerrymandering; the running time of your algorithm\nshould be polynomial in n and m.\nExample.  Suppose we have n = 4 precincts, and the follo wing\ninformation on registered voters.\nThis set of preci ncts is susceptible since, if we grouped precincts\n1 and 4 into one district, and precincts 2 and 3 into the other , then\nparty A would have a majority in both districts. (Presumably , the “we”\nwho are doing the grouping here are members of party A.) This\nexample is a quick illustration of the basic unfairne ss in\ngerrymandering: Although party A holds only a slim majority in the\noverall populatio n (205 to 195), it ends up with a majority in not one\nbut both districts.\n25. Consider the problem faced by a stockbroker trying to sell a large\nnumber of shares of stock in a company whose stock price has been\nsteadily falling in value. It is always hard to predict the right moment\nto sell stock, but owning a lot of shares in a single company adds an\nextra complication: the mere act of selling many shares in a single day\nwill have an adverse ef fect on the price.  \nSince future market prices, and the effect of large sales on these\nprices, are very hard to predict, brokerage firms use models of the\nmarket to help them make such decisions. In this problem, we will\nconsider the following simple model. Suppose we need to sell x shares\nof stock in a company , and suppose that we have an accurate model of\nthe market: it predicts that the stock price will take the values p1, p2,"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 396})","('type', 'Document')"
"('page_content', ""…, pn over the next n days. Moreove r, there is a function f(·) that\npredicts the effect of large sales : if we sell y shares on a single day, it\nwill perm anently decrease the price by f(y) from that day onward. So,\nif we sell y1 shares on day 1, we obtain a price per share of p1 - f(y1),\nfor a total incom e of y1 · (p1 - f(y1)). Having sold y1 shares on day 1,\nwe can then sell y2 shares on day 2 for a price per share of p2 - f(y1) -\nf(y2); this yields an additional income of y2 · (p2 - f(y1) - f(y2)). This\nprocess continues over all n days. (Note, as in our calculation for day\n2, that the decre ases from earlier days are absorbed into the prices for\nall later days.)\nDesign an efficient algorithm that takes the prices p1, …, pn and\nthe function f(·) (written as a list of values f(1), f(2), …, f(x)) and\ndetermines the best way to sell x shares by day n. In other words, find\nnatural numbers y1,y2, …, yn so that x = y1 + … + yn, and selling yt\nshares on day i for i = 1,2, …, n maximizes the total income\nachievable. You should assume that the share value Pi is monotone\ndecreasing, and f(·) is monotone increasing; that is, selling a larger\nnumber of shares causes a larger drop in the price. Your algorithm's\nrunning time can have a polynomial dependence on n (the number of\ndays), x (the number of shares), and P1 (the peak price of the stock).\nExample  Consider the case when n = 3; the prices for the three days\nare 90, 80,40; and f(y) = 1 for y ≤ 40,000 and f(y) = 20 for y > 40, 000.\nAssume you start with x = 100,000 share s. Selling all of them on day 1\nwould yield a price of 70 per share, for a total income of 7,000,000.\nOn the other hand, selling 40,00 0 shares on day 1 yields a price of 89\nper share, and selling the remain ing 60,000 shares on day 2 results in a\nprice of 59 per share, for a total income of 7,100,000.\n26. Consider the following inventory problem. You are running a company\nthat sells some large product (let's assume you sell trucks), and\npredictions tell you the quantity of sales to expect over the next n\nmonths. Let di denote the number of sales you expect in month i. We'll\nassume that all sales happen at the beginning of the month, and trucks\nthat are not sold are stored until the beginning of the next month. You\ncan store at most S trucks, and it costs C to store a singl e truck for a\nmonth. You receive shipments of trucks by placing orders for them,"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 397})","('type', 'Document')"
"('page_content', 'and there is a fixed ordering fee of K each time you place an order\n(regardless of the number of trucks you order). You start out with no\ntrucks. The problem is to design an algorithm that decides how to\nplace orders so that you satisfy all the demands {di, and minimize the\ncosts. In summary:  \nThere are two parts to the cost: (1) storage—it costs C for every\ntruck on hand that is not needed that month; (2) ordering fees— it\ncosts K for every order placed.\nIn each month you need enough trucks to satisfy the demand d,\nbut the number left over after satisfying the demand for the month\nshould not exceed the inventory limit S.\nGive an algorithm that solves this problem in time that is polynomial\nin n and S.\n27. The owners of an independently operated gas station are faced with the\nfollowing situati on. They have a large under ground tank in whic h they\nstore gas; the tank can hold up to L gallons at one time. Ordering gas is\nquite expensive, so they want to order relatively rarely . For each order ,\nthey need to pay a fixed price P for delivery in addition to the cost of\nthe gas ordered. However , it costs c to store a gallon of gas for an extra\nday, so ordering too much ahead increases the storage cost.  \nThey are planning to close for a week in the winter , and they want\ntheir tank to be empty by the time they close. Luckily , based on years\nof experience, they have accura te projections for how much gas they\nwill need each day until this point in time. Assume that there are n\ndays left until they close, and they need gi gallons of gas for each of\nthe days i = 1, …, n. Assume that the tank is empty at the end of day 0.\nGive an algorithm to decide on which days they should place orders,\nand how much to order so as to minimize their total cost.\n28. Recall the scheduling problem from Section 4.2  in which we sought to\nminimize the maximum lateness. There are n jobs, each with a\ndeadline di and a required processing time ti, and all jobs are available\nto be scheduled starting at time s. For a job i to be done, it needs to be\nassigned a period from si ≥ s to fi = si + ti, and different jobs should be\nassigned nonoverlapping intervals. As usual, such an assignment of\ntimes will be called a schedule.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 398})","('type', 'Document')"
"('page_content', ""In this problem, we consider the same setup, but want to optimize\na different objective. In particular , we consider the case in which each\njob must either be done by its deadline or not at all. We'll say that a\nsubset J of the jobs is schedulable  if there is a schedule for the jobs in\nJ so that each of them finishes by its deadline. Your problem  is to\nselect a schedulable subset of maximum possible size and give a\nschedule for this subset that allows each job to finish by its deadline.\n(a) Prove that there is an optimal solution J (i.e., a schedula ble set of\nmaximum size) in which the jobs in J are scheduled in increasing order\nof their deadlines.\n(b) Assume that all deadlines di and required times ti are integers. Give\nan algorithm to find an optimal solution. Your algorithm should  run in\ntime polynomial in the number of jobs n, and the maximu m deadline D\n= maxi; dt.\n29. Let G = (V, E) be a graph with n nodes in which each pair of nodes is\njoined by an edge. There is a positive weight wij on each edge (i,j); and\nwe will assume these weights satisfy the triangle inequality wik ≤ wij +\nwjk. For a subset V′ ⊆ V, we will use G[V′] to denote the subgraph\n(with edge weights) induced on the nodes in V′. \nWe are given a set X ⊆ V of k terminals  that must be connected\nby edges. We say that a Steiner tr ee on X is a set Z so that X ⊆ Z ⊆ V,\ntogether with a spanning subtre e T of G[Z]. The weight  of the Steiner\ntree is the weight of the tree T.\nShow that there is function f(·) and a polynomial function p(·) so\nthat the problem of finding a minimum-weight Steiner tree on X can be\nsolved in time O(f(k) · p(n)).\nNotes and Further Reading\nRichard Bellma n is credited with pioneering the systematic study of\ndynamic programming (Bellman 1957); the algorithm in this chapter for\nsegmented least squares is based on Bellman's work from this early period\n(Bellman 1961) . Dynamic programming has since grown into a technique\nthat is widely used across computer science, operations research, control\ntheory , and a number of other areas. Much of the recent work on this topic"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 399})","('type', 'Document')"
"('page_content', 'has been concerned with stochastic dynamic programming : Whereas our\nproblem formulations tended to tacitly assume that all input is known at the\noutset, many problems in scheduling, production and inventory planning,\nand other domains involve uncertainty , and dynamic programming\nalgorithms for these problems encode this uncertainty using a probabilistic\nformulation. The book by Ross (1983) provides an introduction to\nstochastic dynamic programming.\nMany extensions and variations  of the Knapsack Problem have been\nstudied in the area of combinat orial optimization. As we discussed in the\nchapter , the pseudo-polynomial bound arising from dynamic programming\ncan beco me prohibitive when the input numbers get large; in these cases,\ndynamic progra mming is often combined with other heuristics to solve\nlarge instances of Knapsack Problems in practice. The book by Martello\nand Toth (1990) is devoted to computational approaches to versions of the\nKnapsack Problem.\nDynamic programming emer ged as a basic technique in computational\nbiology in the early 1970s, in a flurry of activity on the problem of\nsequence comparison. Sankof f (2000) gives an interesting historical account\nof the early work in this period. The books by Waterman (1995) and\nGusfield (1997) provide extensive coverage of sequence  alignment\nalgorithms (as well as many related algorithms in computational biology);\nMathews and Zuker (2004) discuss further approaches to the problem of\nRNA secondary structure prediction. The space-ef ficient algorithm for\nsequence alignment is due to Hirschber g (1975).\nThe algorithm for the Shortest-Path Problem described in this chapter\nis based originally on the work of Bellman (1958) and Ford (1956). Many\noptimizations, motivated both by theoretical and experimental\nconsiderations, have been added to this basic approach to shortest paths; a\nWeb site maintained by Andrew Goldber g contains state-of-the-art code that\nhe has developed for this problem (among a number of others), based on\nwork by Cherkassky , Goldber g and Radzik (1994). The applications of\nshortest-path methods to Internet routing, and the trade-of fs among the\ndifferent algorit hms for networking applications, are covered in books by\nBertsekas and Gallager (1992), Keshav (1997), and Stewart (1998).\nNotes on the Exercises  Exercise 5 is based on discussions with Lillian Lee;\nExercise 6 is based on a result of Donald Knuth; Exercise 25 is based on')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 400})","('type', 'Document')"
"('page_content', 'results of Dimitr is Bertsimas and Andrew Lo; and Exercise 29 is based on a\nresult of S. Dreyfus and R. W agner .\n1 In this analysis, the running time is dominated by the O(n3) needed to\ncompute all ei,j values. But, in fact, it is possible to compute all these values\nin O(n2) time, which brings the running time of the full algorithm down to\nO(n2). The idea, whose details we will leave as an exercise for the reader , is\nto first compute ei,j for all pairs (i, j) where j - i = 1, then for all pairs where\nj - i = 2, then j - i = 3, and so forth. This way, when we get to a particular ei,j\nvalue, we can use the ingredient s of the calculation for ei,j-1 to deter mine ei,j\nin constant time.\n2 Adenine, cytosine, guanine, and thymine, the four basic units of\nDNA.\n3 Note that the symbol T from the alphabet of DNA has been replaced\nby a U, but this is not important for us here.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 401})","('type', 'Document')"
"('page_content', 'Chapter 7')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 402})","('type', 'Document')"
"('page_content', ""Network Flow\n7.1 The Maximum-Flow Pr oblem and the Ford-Fulkerson Algorithm  \n7.2 Maximum Flows and Minimum Cuts in a Network  \n7.3 Choosing Good Augmenting Paths  \n* 7.4 The Pr eflow-Push Maximum-Flow Algorithm  \n7.5 A First Application: The Bipartite Matching Pr oblem  \n7.6 Disjoint Paths in Dir ected and Undir ected Graphs  \n7.7 Extensions to the Maximum-Flow Pr oblem  \n7.8 Survey Design  \n7.9 Airline Scheduling  \n7.10 Image Segmentation  \n7.11 Project Selection\n7.12 Baseball Elimination  \n* 7.13 A Further Dir ection: Adding Costs to the Matching Pr oblem  \nSolved Exer cises  \nExer cises  \nNotes and Further Reading\nIn this chapter , we focus on a rich set of algorithmic problems that grow , in\na sense, out of one of the origin al problems we formulated at the beginning\nof the course: Bipartite Matching.\nRecall the set-up of the Bipartite  Matching Problem. A bipartite graph\nG= (V,E) is an undirected graph whose node set can be partitioned as V = X\n∪ Y, with the property that every edge e ∊ E has one end in X and the other\nend in Y. We often draw bipartite graphs as in Figure 7.1, with the nodes in\nX in a column on the left, the nodes in Y in a column on the right, and each\nedge crossing from the left column to the right column.\nNow , we've already seen the notion of a matching  at several points in\nthe course: We've used the term to describe collections of pairs over a set,\nwith the property that no eleme nt of the set appears in more than one pair.\n(Think of men (X) matched to women (Y) in the Stable Matching Proble m,\nor characters in the Sequence Alignment Problem.) In the case of a graph,"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 403})","('type', 'Document')"
"('page_content', ""the edges constitute pairs of nodes, and we consequently say that a\nmatching  in a graph G = (V, E) is a set of edges M ⊆ E with the property\nthat each node appears in at most one edge of M. A set of edges M is a\nperfect matching  if every node appears in exactly one edge of M.\nFigur e 7.1  A bipartite graph.\nMatchings in bipartite graphs can model situations in which objects are\nbeing assigned  to other  objects. We have seen a number of such situations\nin our earlier discussions of graphs and bipartite graphs. One natural\nexample arises when the nodes in X represent jobs, the nodes in Y represent\nmachines, and an edge (xi, yj) indicates that machine yj is capable of\nprocessing job xi. A perfect matching is, then, a way of assigning each job\nto a machine that can process it, with the property that each machine is\nassigned exactl y one job. Bipartite graphs can represent many other\nrelations that arise between two distinct sets of objects, such as the relation\nbetween custom ers and stores; or houses and nearby fire stations; and so\nforth.\nOne of the oldest problems in combinatorial algorithms is that of\ndetermining the size of the largest matching in a bipartite graph G. (As a\nspecial case, note that G has a perfect matching if and only if |X| = |Y| and it\nhas a matching of size |X|.) This problem  turns out to be solvable by an\nalgorithm that runs in polynomial time, but the development of this\nalgorithm needs ideas fundamentally different from the techniques that\nwe've seen so far .\nRather than developing the algorithm directly , we begin by\nformulating a general class of problems— network flow problems—that\nincludes the Bipartite Matching Problem as a special case. We then develop\na polynomial-time algorithm for a general problem, the Maximum-Flow"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 404})","('type', 'Document')"
"('page_content', ""Problem , and show how this provides an efficient algorithm for Bipartite\nMatching as well. While the initial motivation for network flow problems\ncomes from the issue of traffic in a network, we will see that they have\napplications in a surprisingly diverse set of areas and lead to efficient\nalgorithms not just for Bipartite Matching, but for a host of other problems\nas well.\n7.1 The Maximum-Flow Problem and the Ford-\nFulkerson Algorithm\n The Problem\nOne often uses graphs to model transportation networks —networks whose\nedges carry some sort of traffic and whose nodes act as “switches” passing\ntraffic between different edges. Consider , for example, a highway system in\nwhich the edges are highway s and the nodes are interchanges; or a\ncomputer network in which the edges are links that can carry packets and\nthe node s are switches; or a fluid network in which edges are pipes that\ncarry liquid, and the nodes are junctures where pipes are plugg ed together .\nNetwork models of this type have several ingredients: capacities  on the\nedges, indicatin g how much they can carry; source nodes in the graph,\nwhich generate traffic; sink (or destination) nodes in the graph, which can\n“absorb” traffic as it arrives; and finally , the traffic itself , which is\ntransmitted across the edges.\nFlow Networks  We'll be considering graphs of this form, and we refer to\nthe traffic as flow—an abstract entity that is generated at source nodes,\ntransmitted across edges, and absorbed at sink nodes. Formally , we'll say\nthat a flow network  is a directed graph G = (V, E) with the following\nfeatures.\nAssociated with each edge e is a capacity , which is a nonnegative\nnumber that we denote ce.\nThere is a single source node s ∊ V.\nThere is a single sink node t ∊ V."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 405})","('type', 'Document')"
"('page_content', 'Nodes other than s and t will be called internal  nodes.\nWe will make two assumptions about the flow networks we deal with:\nfirst, that no edge enters the source s and no edge leaves the sink t; second,\nthat there is at least one edge incident to each node; and third, that all\ncapacities are integers. These assumptions make things cleaner to think\nabout, and while they eliminate a few pathologies, they preserve essentially\nall the issues we want to think about.\nFigure7.2 illustrates a flow network with four nodes and five edges, and\ncapacity values given next to each edge.\nDefining Flow  Next we defin e what it means for our network to carry\ntraffic, or flow. We say that an s-t flow  is a function f that maps each edge e\nto a nonnegative real number , f:E → R+; the value f(e) intuitively represents\nthe amount of flow carried by edge e. A flow f must satisfy the following\ntwo properties.*\n(i) (Capacity conditions)  For each e ∊ E, we have 0 ≤ f (e) ≤ ce.\n(ii) (Conservation conditions)  For each node v other than s and t, we\nhave\n \nHere Σe into v f(e) sums the flow value f(e) over all edges entering node v,\nwhile Σe out of v f  f(e) is the sum of flow values over all edges leaving node v.\nThus the flow on an edge canno t exceed the capacity of the edge. For\nevery node other than the sourc e and the sink, the amount of flow entering\nmust equal the amount of flow leaving. The source has no entering edges\n(by our assumption), but it is allowed to have flow going out; in other\nwords, it can generate flow. Symmetrically , the sink is allowed to have flow\ncoming in, even though it has no edges leaving it. The value  of a flow f,\ndenoted v(f), is defined to be the amount of flow generated at the source:')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 406})","('type', 'Document')"
"('page_content', ""Figur e 7.2 A flow network, with source s and sink t. The numbers next to\nthe edges are the capacities.\nTo make the notation more compact, we define fout(v) = Σe out of v f(e)\nand fin(v) = Σe into v f(e). We can extend  this to sets of vertices; if S ⊆ V, we\ndefine fout(S) = Σe out of s  f(e) and fin(S) = Σe into S  f(e). In this terminology , the\nconservation condition for nodes v ≠ s becomes fin(v) = fout(v); and we can\nwrite v(f) = fout(s).\nThe Maximum-Flow Problem  Given a flow network, a natural goal is to\narrange the traffic so as to make  as efficient use as possible of the available\ncapacity . Thus the basic algorithmic problem we will consider is the\nfollowing: Given a flow network, find a flow of maximum possible value.\nAs we think about designing algorithms for this problem, it's useful to\nconsider how the structure of the flow network places upper bounds on the\nmaximum value of an s-t flow. Here is a basic “obstacle”  to the existence of\nlarge flows: Suppose we divide the nodes of the graph into two sets, A and\nB, so that s ∊ A and t ∊ B. Then, intuitively , any flow that goes from s to t\nmust cross from  A into B at some point, and thereby use up some of the\nedge capacity from A to B. This suggests that each such “cut” of the graph\nputs a bound on the maximum possible flow value. The maximum-flow\nalgorithm that we develop here will be intertwined with a proof that the\nmaximum-flow value equals the minimum capacity of any such division,\ncalled the minimum cut. As a bonus, our algorithm will also compute the\nminimum cut. We will see that the problem of finding cuts of minimum\ncapacity in a flow network turns out to be as valuable, from the point of\nview of applications, as that of finding a maximum flow ."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 407})","('type', 'Document')"
"('page_content', ""Designing the Algorithm\nSuppose we wanted to find a maximum flow in a network. How  should we\ngo about doing this? It takes some testing out to decide that an approach\nsuch as dynamic  programming doesn't seem to work—at least, there is no\nalgorithm know n for the Maximum-Flow Problem that could really be\nviewed as naturally belonging to the dynamic programming paradigm. In\nthe absence of other ideas, we could go back and think about simple greedy\napproaches, to see where they break down.\nSuppose we start with zero flow: f(e) = 0 for all e. Clearly this respects\nthe capacity and conservation conditions; the problem is that its value is 0.\nWe now try to increase the value of f by “pushing” flow along a path from s\nto t, up to the limits imposed by the edge capacities. Thus, in Figure 7.3 , we\nmight choose the path consisting of the edges {(s, u), (u, v), (v, t)} and\nincrease the flow on each of these edges to 20, and leave f (e) = 0 for the\nother two. In this way, we still respect the capacity conditions —since we\nonly set the flow as high as the edge capacities would allow—and the\nconservation conditions— since when we increase flow on an edge entering\nan internal node, we also increa se it on an edge leaving the node. Now , the\nvalue of our flow is 20, and we can ask: Is this the maximum possible for\nthe graph in the figure? If we think about it, we see that the answer is no,\nsince it is possible to construct a flow of value 30. The problem is that we're\nnow stuck—there is no s-t path on which we can directly push flow without\nexceeding some capacity—and yet we do not have a maximum  flow. What\nwe need is a more general way of pushing flow from s to t, so that in a\nsituation such as this, we have a way to increase the value of the current\nflow.\nFigur e 7.3 (a) The networ k of Figure 7.2. (b) Pushing 20 units of flow\nalong the path s, u, v, t. (c) The new kind of augmenting path using the edge\n(u, v) backward."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 408})","('type', 'Document')"
"('page_content', ""Essentially , we'd like to perform the following operation denoted by a\ndotted line in Figure 7.3(c) . We push 10 units of flow along (s, v); this now\nresults in too much flow comin g into v. So we “undo” 10 units of flow on\n(u, v); this restores the conservation  condition at v but results in too little\nflow leaving u. So, finally , we push 10 units of flow along (u, t), restoring\nthe conservation condition at u. We now have a valid flow, and its value is\n30. See Figure 7.3, where the dark edges are carrying flow before the\noperation, and the dashed edges form the new kind of augmentation.\nThis is a more general way of pushing flow: We can push forwar d on\nedges with leftover capacity , and we can push backwar d on edges that are\nalready carrying  flow, to divert it in a different direction. We now define the\nresidual graph , which provide s a systematic way to search for forward-\nbackward operations such as this.\nThe Residual Graph  Given a flow network G, and a flow f on G, we define\nthe residual graph Gf of G with respect to f as follows. (See Figure 7.4 for\nthe residual graph of the flow on Figure 7.3 after pushing 20 units of flow\nalong the path s, u, v, t.)\nThe node set of Gf is the same as that of G.\nFor each edge e = (u, v) of G on which f(e) < ce, there are ce - f(e)\n“leftover” units  of capacity on which we could try pushin g flow\nforward. So we include the edge e = (u, v) in Gf, with a capacity of ce -\nf(e). We will call edges included this way forwar d edges.\nFor each edge e = (u, v) of G on whic h f(e) > 0, there are f (e) units of\nflow that we can “undo” if we want to, by pushing flow backw ard. So\nwe include the edge e′ = (v, u) in Gf, with a capacity of f(e). Note that\ne′ has the same ends as e, but its direction is reversed; we will call\nedges included this way backwar d edges."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 409})","('type', 'Document')"
"('page_content', 'Figur e 7.4 (a) The graph G with the path s,u,v,t used to push the first 20\nunits of flow. (b) The residual graph of the resulting flow f, with the\nresidual capacity  next to each edge. The dotted line is the new augmenting\npath. (c) The residual graph after pushing an additional 10 units of flow\nalong the new augmenting path s, v, u, t.\nThis completes the definition of the residual graph Gf. Note that each edge e\nin G can give rise to one or two edge s in Gf: If 0 < f(e) < ce it results in both\na forwar d edge and a backward  edge being included in Gf. Thus Gf has at\nmost twice as many edges as G. We will sometimes refer to the capacity of\nan edge in the residual graph as a residual capacity , to help distinguish it\nfrom the capacity of the corresponding edge in the original flow network G.\nAugmenting Paths in a Residual Graph  Now we want to make precise the\nway in which we push flow from  s to t in Gf. Let P be a simple s-t path in\nGf— that is, P does not visit any node more than once. We define\nbottleneck( P, f) to be the minimum residual capacity of any edge on P, with\nrespect to the flow f. We now define the following operation augment( f, P),\nwhich yields a new flow f in G.\naugment( f, P)\nLet b = bottleneck( P, f)\nFor each edge ( u, v) ∊ P\nIf e = (u, v) is a forward edge then\nincrease f(e) in G by b\nElse (( u, v) is a backward edge, and let e = (v, u))\ndecrease f(e) in G by b\nEndif\nEndfor\nReturn( f)')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 410})","('type', 'Document')"
"('page_content', ""It was purely to be able to perform this operation that we defined the\nresidual graph; to reflect the importance of augment, one often refers to any\ns-t path in the residual graph as an augmenting path.\nThe result of augment( f, P) is a new flow f in G, obtained by\nincreasing and decreasing the flow values on edges of P. Let us first verify\nthat f is indeed a flow .\n(7.1)  f is a flow in G.\nProof. We must verify the capacity and conservation conditions.\nSince f′ differs from f only on edges of P, we need to check the capacity conditions only on\nthese edges. Thus, let (u, v) be an edge of P. Informally , the capacity condition continues to hold\nbecause if e = (u, v) is a forward edge, we specifically avoided increasing the flow on e above ce; and\nif (u, v) is a backward edge arising from edge e = (v, u) ∊ E, we specifically avoided decreasing the\nflow on e below 0. More concretely , note that bottle neck( P, f) is no larger than the residual capacity\nof (u, v). If e = (u, v) is a forward edge, then its residual capacity is ce - f(e); thus we have\n  \nso the capacity condition holds. If (u, v) is a backward edge arising from edge e = (v,u) ∊ E, then its\nresidual capacity is f(e), so we have\n  \nand again the capacity condition holds.\nWe need to check the conservation condition at each internal node that lies on the path P. Let v\nbe such a node; we can verify that the change in the amount of flow entering v is the same as the\nchange in the amount of flow exiting v; since f satisfied the conserv ation condition at v, so must f′.\nTechnically , there are four cases to check , depending on whether the edge of P that enters v is a\nforward or backward  edge, and whether the edge of P that exits v is a forward or backward edge.\nHowever , each of these cases is easily worked out, and we leave them to the reader .\n▪\nThis augmentation operation captures the type of forward and\nbackward pushing of flow that we discussed earlier . Let's now consider the\nfollowing algorithm to compute an s-t flow in G.\nMax-Flow\nInitially f(e) = 0 for all e in G\nWhile there is an s-t path in the residual graph Gf\nLet P be a simple s-t path in Gf\nf = augment( f, P)"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 411})","('type', 'Document')"
"('page_content', ""Update f to be f\nUpdate the residual graph Gf to be Gf\nEndwhile\nReturn f\nWe'll call this the Ford-Fulkerson Algorithm,  after the two researchers who\ndeveloped it in 1956. See Figure 7.4 for a run of the algorithm. The Ford-\nFulkerson Algo rithm is really quite simple. What is not at all clear is\nwhether its central While loop terminates, and whether the flow returned is\na maximum flow. The answers to both of these questions turn out to be\nfairly subtle.\n Analyzing the Algorithm: Termination and\nRunning Time\nFirst we consider some properties that the algorithm maintains by induction\non the number of iterations of the While loop, relying on our assumption\nthat all capacities are integers.\n(7.2)  At every intermediate stage of the Ford-Fulkerson Algorithm, the flow values  [f(e)} and the\nresidual capacities in Gf ar e integers.\nProof. The statem ent is clearly true before any iterations of the While loop. Now suppose it is true\nafter j iterations. Then, since all residual capacities in Gf are integers, the value bottleneck( P, f) for\nthe augmenting path found in iteration j + 1 will be an integer . Thus the flow f will have integer\nvalues, and hence so will the capacities of the new residual graph.\n▪\nWe can use this property to prove that the Ford-Fulkerson Algorithm\nterminates. As at previous point s in the book we will look for a measure of\nprogress that will imply termination.\nFirst we show that the flow value strictly increases when we apply an\naugmentation.\n(7.3)  Let f be a flow in G, and let P be a simple s-t path in Gf. Then  v(f′) = v(f) + bottleneck( P, f); and\nsince  bottleneck( P, f) > 0, we have v(f′) > v(f).\nProof. The first edge e of P must be an edge out of s in the residual graph Gf; and since the path is\nsimple, it does not visit s again. Since G has no edges entering  s, the edge e must  be a forward edge.\nWe increase the flow on this edge by bottleneck( P,f), and we do not change the flow on any other\nedge incident to s. Therefore the value of f exceeds the value of f by bottleneck( P, f).\n▪"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 412})","('type', 'Document')"
"('page_content', ""We need one more observation to prove termination: We need  to be\nable to bound the maximum possible flow value. Here's one upper bound: If\nall the edges out of s could be compl etely saturated with flow, the value of\nthe flow would be Σe out of s  ce. Let C denote this sum. Thus we have v(f) ≤ C\nfor all s-t flows f. (C may be a huge overestimate of the maximum value of\na flow in G, but it's handy for us as a finite, simply stated bound.) Using\nstatement (7.3), we can now prove termination.\n(7.4)  Suppose, as above, that all capacities in the flow network G are integers. Then the Ford-\nFulkerson Algorithm terminates in at most C iterations of the  While loop.\nProof. We noted above that no flow in G can have value greate r than C, due to the capacity condition\non the edges leaving s. Now , by (7.3), the value of the flow maintained by the Ford-Fulkerson\nAlgorithm increases in each iteration; so by (7.2), it increases by at least 1 in each iteration. Since it\nstarts with the value 0, and cannot go higher than C, the While loop in the Ford-Fulkerson Algorithm\ncan run for at most C iterations.\n▪\nNext we consider the running time of the Ford-Fulkerson Algo rithm.\nLet n denote the number of nodes in G, and m denote the number of edges\nin G. We have assumed that all nodes have at least one incident edge , hence\nm ≥ n/2, and so we can use O(m + n) = O(m) to simplify the bounds.\n(7.5)  Suppose, as above, that all capacities in the flow network G are integers. Then the Ford-\nFulkerson Algorithm can be implemented to run in O(mC) time.\nProof. We know from (7.4)  that the algorithm terminates in at most C iterations of the While loop.\nWe therefore consider the amount of work involved in one iteration when the current flow is f.\nThe residual graph Gf has at most 2m edges, since each edge of G gives rise to at most two\nedges in the residual graph. We will maintain Gf using an adjacency list representation; we will have\ntwo linked lists for each node v, one conta ining the edges entering v, and one containing the edges\nleaving v. To find an s-t path in Gf, we can use breadth-first search or depth-fi rst search, which run in\nO(m + n) time; by our assumption that m ≥ n/2, O(m + n) is the same as O(m). The procedure\naugment( f, P) takes time O(n), as the path P has at most n - 1 edges. Given the new flow f′, we can\nbuild the new residual graph in O(m) time: For each edge  e of G, we constr uct the correct forward\nand backward edges in Gf′.\n▪\nA somewhat more efficient version of the algorithm would maintain\nthe linke d lists of edges in the residual graph Gf as part of the augment\nprocedure that changes the flow f via augmentation."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 413})","('type', 'Document')"
"('page_content', '7.2 Maximum Flows and Minimum Cuts in a\nNetwork\nWe now continue with the analysis of the Ford-Fulkerson Algorithm, an\nactivity that will occupy this whole section. In the process, we will not only\nlearn a lot about the algorithm, but also find that analyzing the algorithm\nprovides us with considerable insight into the Maximum-Flow Problem\nitself.\n Analyzing the Algorithm: Flows and Cuts\nOur next goal is to show that the flow that is returned by the Ford-\nFulkerson Algor ithm has the maximum possible value of any flow in G. To\nmake progress toward this goal, we return to an issue that we raised in\nSection 7.1: the way in which the structure of the flow network places\nupper bounds on the maximum value of an s-t flow. We have already seen\none upper bound: the value v(f) of any s-t-flow f is at most C = Σe out of s ce.\nSometimes this bound is useful, but sometimes it is very weak. We now use\nthe notion of a cut to develop a much more general means of placing upper\nbounds on the maximum-flow value.\nConsider dividin g the nodes of the graph into two sets, A and B, so that\ns ∊ A and t ∊ B. As in our discussion in Section 7.1, any such division\nplaces an upper bound on the maximum possible flow value, since all the\nflow must cross from A to B somewhere. Formally , we say that an s-t cut is\na partition (A, B) of the vertex set V, so that s ∊ A and t ∊ B. The capacity\nof a cut (A, B), which we will denote c(A, B), is simply the sum of the\ncapacities of all edges out of A: C(A,B) = Σe out of A  Ce.\nCuts turn out to provide very natural upper bounds on the values of\nflows, as expressed by our intuition above. We make this precise via a\nsequence of facts.\n(7.6)  Let f be any s-t flow , and  (A,B) any s-t cut. Then v(f) = fout(A) - fin(A).\nThis statement is actually much stronger than a simple upper bound. It says that by watching the\namount of flow f sends across a cut, we can exactly measur e the flow value: It is the total amount that\nleaves A, minus the amount that “swirls back” into A. This makes sense intuitively , although the\nproof requires a little manipulation of sums.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 414})","('type', 'Document')"
"('page_content', ""Proof. By definit ion v(f) = fout(s). By assum ption we have fin(s) = 0, as the source s has no entering\nedges, so we can write v(f) = fout(s) - fin(s). Since every node v in A other than s is internal, we know\nthat fout(v) - fin(v) = 0 for all such nodes. Thus\n  \nsince the only term in this sum that is nonzero is the one in which v is set to s.\nLet's try to rewrite the sum on the right as follows. If an edge e has both ends in A, then f(e)\nappears once in the sum with a “+” and once with a “-”, and hence these two terms cancel out. If e\nhas only its tail in A, then f(e) appears just once in the sum, with a “+”. If e has only its head in A,\nthen f (e) also appears just once in the sum, with a “-”. Finally , if e has neither end in A, then f (e)\ndoesn't appear in the sum at all. In view of this, we have\n  \nPutting together these two equations, we have the statement of (7.6).\n▪\nIf A = [s], then fout(A) = fout(s), and fin(A) = 0 as there are no edges\nentering the source by assumption. So the statement for this set A = {s} is\nexactly the definition of the flow value v(f).\nNote that if ( A, B) is a cut, then the edges into B are precisely the edges\nout of A. Similarly , the edges out of B are precisely the edges into A. Thus\nwe have fout(A) = fin(B) and fin(A) = fout(B), just by comparing the\ndefinitions for these two expressions. So we can rephrase (7.6) in the\nfollowing way .\n(7.7)  Letf beany s-t flow , and (A,B) anys-tcut. Then  v(f) = fin(B) - fout(B).\nIf we set A = V - {t} and B = {t} in (7.7), we have v(f) = fin(B) - fout (B)\n= fin(t) - fout(t). By our assumption the sink t has no leaving edges, so we\nhave fout(t) = 0. This says that we could have originally defined the value  of\na flow equally well in terms of the sink t: It is fin(t), the amount of flow\narriving at the sink.\nA very useful consequence of (7.6) is the following upper bound.\n(7.8)  Let f be any s-t flow , and  (A, B) any s-t cut. Then  v(f) ≤ c(A, B)."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 415})","('type', 'Document')"
"('page_content', 'Proof.\n  \nHere the first line is simply (7.6); we pass from the first to the second since fin(A) ≥ 0, and we pass\nfrom the third to the fourth by applying the capacity conditions to each term of the sum.\n▪\nIn a sense, (7.8) looks weaker than (7.6), since it is only an inequality\nrather than an equality . However , it will be extremely useful for us, since its\nright-hand side is independent of any particular flow f. What (7.8) says is\nthat the value of every flow is upper -bounded by the capacity of every cut.\nIn other  words, if we exhibit any s-t cut in G of some value c*, we know\nimmediately by (7.8) that there cannot be an s-t flow in G of value  greater\nthan c*. Conversely , if we exhibit any s-t flow in G of some value v*, we\nknow immediately by (7.8) that there cannot be an s-t cut in G of value  less\nthan v*.\n Analyzing the Algorithm: Max-Flow Equals\nMin-Cut\nLet (\n) denote the flow that is returned by the Ford-Fulkerson Algo rithm.\nWe want to show that \n  has the maximu m possible value of any flow in G,\nand we do this by the method discussed above: We exhibit an s-t cut (A*,\nB*) for which v(\n) = c(A*, B*). This immedi ately establishes  that \n  has the\nmaximum value of any flow , and that ( A*, B*) has the minim um capacity of\nany s-t cut.\nThe Ford-Fulkerson Algorithm terminates when the flow f has no s-t\npath in the resid ual graph Gf. This turns out to be the only property needed\nfor proving its maximality .')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 416})","('type', 'Document')"
"('page_content', '(7.9)  Iff is an s-t-flow such that there is no s-t path in the residual graph Gf, then there is an s-t cut\n(A*,B*) in G for which  v(f) = c(A*,B*). Consequently , f has the maximum value of any flow in G, and\n(A*,B*) has the minimum capacity of any s-t cut in G.\nProof. The statement claims the existence of a cut satisfying a certain desirable property ; thus we\nmust now identify such a cut. To this end, let A* denote the set of all nodes v in G for which there is\nan s-v path in Gf. Let B* denote the set of all other nodes: B* = V - A*.\nFigur e 7.5  The ( A*,B*) cut in the proof of (7.9).\nFirst we establish that (A*,B* ) is indeed an s-t cut. It is clearly a partition of V. The source s\nbelongs to A* since there is always a path from s to s. Moreover , t ≠ A* by the assumption that there\nis no s-t path in the residual graph; hence t ∊ B* as desired.\nNext, supp ose that e = (u, v) is an edge in G for which u ∊ A* and y ∊ B*, as shown in Figure\n7.5. We claim that f (e) = ce. For if not, e would be a forward edge in the residual graph Gf, and since\nu ∊ A*, there is an s-u path in Gf; appending e to this path, we would obtain an s-v path in Gf,\ncontradicting our assumption that v ∊ B*.\nNow suppo se that e′ = (u′, v′) is an edge  in G for which u′ ∊ B* and v′ ∊ A*. We claim that f(e′)\n= 0. For if not, e′ would give rise to a backward edge e″ = (v′, u′) in the residual graph  Gf, and since\nv′ ∊ A*, there is an s-v′ path in Gf; appending e″ to this path, we would obtain an s-u′ path in Gf,\ncontradicting our assumption that u′ ∊ B*.\nSo all edges out of A* are completely saturated with flow , while all edges into A* are completely\nunused. W e can now use (7.6) to reach the desired conclusion:')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 417})","('type', 'Document')"
"('page_content', '▪\nNote how, in retrospect, we can see why the two types of residual\nedges—forward and backward—are crucial in analyzing the two terms in\nthe expression from (7.6).\nGiven that the Ford-Fulkerson Algorithm terminates when there is no\ns-t in the residual graph, (7.6) immediately implies its optimality .\n(7.10)  The flow f r eturned by the For d-Fulkerson Algorithm is a maximum flow .\nWe also observe that our algorithm can easily be extended to compute\na minimum s-t cut ( A*, B*), as follows.\n(7.11) Given a flow f of maximum value, we can compute an s-t cut of minimum capacity in O(m)\ntime.\nProof. We simply follow the construction in the proof of (7.9). We construct the residual graph Gf,\nand perform  breadth-first search or depth-first search to determine the set A* of all nodes that s can\nreach. W e then define B* = V - A*, and return the cut ( A*, B*).\n▪\nNote that there can be many minimum-capacity cuts in a graph G; the\nprocedure in the proof of (7.11) is simply finding a particular one of these\ncuts, starting from a maximum flow \n .\nAs a bonus, we have obtained the following striking fact through the\nanalysis of the algorithm.\n(7.12)  In every flow network, ther e is a flow f and a cut  (A, B) so that v(f) = c(A,B).\nThe point is that f in (7.12) must be a maximum s-t flow; for if there\nwere a flow f′ of greater value, the value of f′ would exceed the capacity of\n(A, B), and this woul d contradict (7.8). Similarly , it follows that (A,B) in\n(7.12) is a minimum cut—no other cut can have smaller capacity—for if\nthere were a cut (A′, B′) of smaller capacity , it would be less than the value\nof f, and this again would contradic t (7.8). Due to these implication s, (7.12)\nis often called the Max-Flow Min-Cut Theor em, and is phrased as follows.\n(7.13)  In every flow network, the maximum value of an s-t flow is equal to the minimum capacity of\nan s-t cut.\nFurther Analysis: Integer-Valued Flows')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 418})","('type', 'Document')"
"('page_content', 'Among the many corollaries emerging from our analysis of the Ford-\nFulkerson Algorithm, here is another extremely important one. By (7.2), we\nmaintain an integer -valued flow at all times, and by (7.9), we conclude with\na maximum flow . Thus we have\n(7.14)  If all capacities in the flow network are integers, then there is a maximum flow f for which\nevery flow value f(e) is an integer .\nNote that (7.14) does not claim that every  maximum flow is integer -\nvalued, only that some  maxim um flow has this property . Curiously ,\nalthough (7.14) makes no reference to the Ford-Fulkerson Algorithm, our\nalgorithmic approach here provides what is probably the easiest way to\nprove it.\nReal Numbers as Capacities?  Finally , before moving on, we can ask how\ncrucial our assumption of integ er capacities was (ignoring (7.4), (7.5) and\n(7.14), which clearly needed it). First we notice that allowing capacities to\nbe rational numbers does not make the situation any more general, since we\ncan determine the least common multiple of all capacities, and multiply\nthem all by this value to obtain an equivalent problem with integer\ncapacities.\nBut what if we have real numb ers as capacities? Where in the proof\ndid we rely on the capacities being integers? In fact, we relied on it quite\ncrucially: We used (7.2) to establish, in (7.4), that the value of the flow\nincreased by at least 1 in every step. With real numbers as capacities, we\nshould be conce rned that the value of our flow keeps increa sing, but in\nincrements that become arbitrar ily smaller and smaller; and hence we have\nno guara ntee that the number of iterations of the loop is finite. And this\nturns out to be an extremely real worry , for the following reason: With\npathological choices for the augmenting path, the Ford-Fulkerson\nAlgorithm with r eal-valued capacities can run for ever.\nHowever , one can still prove that the Max-Flow Min-Cut Theorem\n(7.12) is true even if the capacities may be real numbers. Note that (7.9)\nassumed only that the flow f has no s-t path in its resid ual graph Gf, in order\nto conclude that there is an s-t cut of equal value. Clearly , for any flow f of\nmaximum value, the residual graph has no s-t-path; otherwise there would\nbe a way to increase the value of the flow. So one can prove (7.12) in the\ncase of real-valued capacities by simply establishing that for every flow\nnetwork, there exists a maximum flow .')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 419})","('type', 'Document')"
"('page_content', 'Of course, the capacitiesinany practical application of network flow\nwould be integers or ration al numbers. However , the problem of\npathological choices for the augmenting paths can manifest itself even with\ninteger capacities: It can make the Ford-Fulkerson Algorithm take a\ngigantic number of iterations.\nIn the next section, we discuss how to select augmenting paths so as to\navoid the potential bad behavior of the algorithm.\n7.3 Choosing Good Augmenting Paths\nIn the previous section, we saw that any way of choosing an augmenting\npath increases the value of the flow, and this led to a bound of C on the\nnumber of augmentations, where C = Σe out of s ce. When C is not very large,\nthis can be a reasonable bound; however , it is very weak when C is lar ge.\nTo get a sense for how bad this bound can be, consider the example\ngraph in Figure 7.2 ; but this time assume the capacities are as follows: The\nedges ( s, v), (s, u), (v, t) and ( u, t) have capacity 100, and the edge (u, v) has\ncapacity 1, as shown in Figure 7.6 . It is easy to see that the maximum flow\nhas value 200, and has f(e) = 100 for the edges (s, v), (s, u), (v, t) and (u, t)\nand value 0 on the edge (u, v). This flow can be obtained by a sequence of\ntwo augmentatio ns, using the paths of nodes s, u, t and path s, v, t. But\nconsider how bad the Ford-Fulk erson Algorithm can be with pathological\nchoices for the augmenting paths. Suppose we start with augm enting path\nP1 of node s s, u, v, t in this order (as shown in Figure 7.6). This path has\nbottleneck ( P1, f) = 1. After this augmentation, we have f (e) = 1 on the edge\ne = (u, v), so the reverse edge is in the residual graph. For the next\naugmenting path, we choose the path P2 of the nodes s, v, u, t in this order .\nIn this second augmentation, we get bottleneck (P2, f) = 1 as well. After this\nsecond augmentation, we have f(e) = 0 for the edge e = (u, v), so the edge is\nagain in the residual graph. Suppose we alternate between choosing P1 and\nP2 for augmentati on. In this case, each augmentation will have 1 as the\nbottleneck capacity , and it will take 200 augmentations to get the desired\nflow of value 200. This is exact ly the bound we proved in (7.4), since C =\n200 in this example.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 420})","('type', 'Document')"
"('page_content', 'Designing a Faster Flow Algorithm\nThe goal of this section is to show that with a better choice of paths, we can\nimprove this bound significantly . A large amount of work has been devoted\nto finding good ways of choosin g augmenting paths in the Maximum-Flow\nProblem so as to minimize the number of iterations. We focus here on one\nof the most natural approaches and will mention other approaches at the end\nof the section. Recall that augmentation increases the value of the\nmaximum flow by the bottleneck capacity of the selected path; so if we\nchoose paths with large bottlen eck capacity , we will be making a lot of\nprogress. A natural idea is to select the path that has the largest bottleneck\ncapacity . Having to find such paths can slow down each individ ual iteration\nby quite  a bit. We will avoid this slowdown by not worrying about selecting\nthe path that has exactly  the largest bottleneck capacity . Instead, we will\nmaintain a so-called scaling parameter  Δ, and we will look for paths that\nhave bottleneck capacity of at least Δ.\nFigur e 7.6  Parts (a) throug h (d) depict four iterations of the Ford-Fulkerso n\nAlgorithm using  a bad choice of augmenting paths: The augmentations\nalternate between the path P1 through the nodes s, u, v, t in order and the\npath P2 through the nodes s, v, u, t in order .')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 421})","('type', 'Document')"
"('page_content', 'Let Gf (Δ) be the subset of the residual graph consisting only of edges\nwith residual capacity of at least Δ. We will work with values of Δ that are\npowers of 2. The algorithm is as follows.\nScaling Max-Flow\nInitially f(e)=0  for all e in G\nInitially set Δ to be the lar gest power of 2 that is no lar ger\nthan the maximum capacity out of s: Δ ≤ max e out of s  ce\nWhile Δ >1\nWhile there is an s-t path in the graph Gf (Δ)\nLet P be a simple s-t path in Gf (Δ)\nf′ = augment( f, P)\nUpdate f to be f and update Gf(Δ)\nEndwhile\nΔ = Δ/2\nEndwhile\nReturn f\n Analyzing the Algorithm')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 422})","('type', 'Document')"
"('page_content', 'First observe that the new Scaling Max-Flow Algorithm is really just an\nimplementation of the original Ford-Fulkerson Algorithm. The new loops,\nthe value Δ, and the restricted residual graph Gf(Δ) are only used to guide\nthe selection of residual path—with the goal of using edges  with large\nresidual capacity  for as long as possible. Hence all the properties that we\nproved about the original Max-Flow Algorithm are also true for this new\nversion: the flow remains integer -valued throughout the algorithm, and\nhence all residual capacities are integer -valued.\n(7.15)  If the capa cities are integer -valued, then throughout the Scaling Max-Flow Algorithm the flow\nand the residual capa cities remain integer -valued. This implies that when  Δ = 1, Gf(Δ) is the same  as\nGf, and hence when the algorithm terminates the flow , f is of maximum value.\nNext we conside r the running time. We call an iteration of the outside\nWhile loop—with a fixed value of Δ—the Δ-scaling phase.  It is easy to\ngive an upper bound on the number of different Δ-scaling phases, in terms\nof the value C = Σe out of s ce that we also used in the previo us section. The\ninitial value of Δ is at most C, it drops by factors of 2, and it never gets\nbelow 1. Thus,\n(7.16)  The number of iterations of the outer While loop is at most  1 + [log 2 C].\nThe harder part is to bound the number of augmentations done in each\nscaling phase. The idea here is that we are using paths that augment the\nflow by a lot, and so there shou ld be relatively few augmentations. During\nthe Δ-scaling phase, we only use edges with residual capacity of at least Δ.\nUsing (7.3), we have\n(7.17)  During the A-scaling phase, each augmentation incr eases the flow value by at least A.\nThe key insight is that at the end of the Δ-scaling phase, the flow f cannot\nbe too far from the maximum possible value.\n(7.18)  Let f be the flow at the end of the A-scaling phase. There is an s-t cut (A, B) in G for which\nc(A, B) ≤ v(f) + mΔ, wher e m is the number of edges in the graph G. Consequently , the maximum flow\nin the network has value at most v (f) + mΔ.\nProof. This proof is analogous to our proof of (7.9), which establishe d that\nthe flow returned by the origi nal Max-Flow Algorithm is of maximum')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 423})","('type', 'Document')"
"('page_content', 'value.\nAs in that proof, we must identify a cut (A, B) with the desired\nproperty . Let A denote the set of all nodes v in G for which there is an s-v\npath in Gf(Δ). Let B denote the set of all other nodes: B = V - A. We can see\nthat ( A, B) is indeed an s-t cut as otherwise the phase would not have ended.\nNow consider an edge e = (u, v) in G for which u ∊ A and v ∊ B. We\nclaim that ce < f(e) + Δ. For if this were not the case, then e would be a\nforward edge in the graph Gf(Δ), and since u ∊ A, there is an s-u path in\nGf(Δ); appending e to this path, we would obtain an s-v path in Gf(Δ),\ncontradicting our assumption that v ∊ B. Similarly , we claim that for any\nedge e′ = (u′, v′) in G for which u′ ∊ B and v′ ∊ A, we have f(e′) < A.\nIndeed, if f(e′) > A, then e′ would give rise to a backward edge e′ = (v′, u′) in\nthe graph Gf(Δ), and since v′ ∊ A, there is an s-v′ path in Gf(Δ) appending e′\nto this path, we would obtain an s-u′ path in Gf(Δ), contradicting our\nassumption that u′ ∊ B.\nSo all edges e out of A are almost satur ated—they satisfy ce < f(e) + A\n— and all edge s into A are almost empty—they satisfy f(e) < Δ. We can\nnow use (7.6) to reach the desired conclusion:\n  \nHere the first inequality follow s from our bounds on the flow values of\nedges across the cut, and the second inequality follows from the simple fact\nthat the graph only contains m edges total.\nThe maximum-flow value is bounded by the capacity of any cut by\n(7.8). We use the cut (A, B) to obtain the bound claimed in the second\nstatement.\n▪')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 424})","('type', 'Document')"
"('page_content', '(7.19)  The number of augmentations in a scaling phase is at most 2m.\nProof. The statem ent is clearly true in the first scaling phase: we can use each of the edges out of s\nonly for at most one augmentation in that phase. Now consider a later scaling phase  Δ, and let fp be\nthe flow at the end of the previous  scaling phase. In that phase, we used Δ′ = 2Δ as our parameter . By\n(7.18), the maximum flow f* is at most v(f*) ≤ v(fp) + mΔ′ = v(fp) + 2mΔ. In the Δ-scaling phase,\neach augmentation increases the flow by at least Δ, and hence there can be at most 2m\naugmentations.\n▪\nAn augm entation takes O(m) time, including the time required to set\nup the graph and find the appropriate path. We have at most 1 + [log2 C]\nscaling phases and at most 2m augmen tations in each scaling phase. Thus\nwe have the following result.\n(7.20)  The Scalin g Max-Flo w Algorithm in a graph with m edges and integer capacities finds a\nmaximum flow in at most  2m(1 + log2 C) augmentations. It can be implemented to run in at most\nO(m2 log2 C) time.\nWhen C is large, this time bound is much better than the O(mC ) bound\nthat applied to an arbitrary implementation of the Ford-Fulkerson\nAlgorithm. In our example at the beginning of this sectio n, we had\ncapacities of size 100, but we could just as well have used capacities of size\n2100; in this case, the generic Ford-Fulkerson Algorithm could take time\nproportional to 2100, while the scaling algorithm will take time proportional\nto log2(2100) = 100. One way to view this distinction is as follows: The\ngeneric Ford-Fulkerson Algorithm requires time proportional to the\nmagnitude  of the capacities, while the scaling algorithm only requires time\nproportional to the number of bits needed to specify the capacitie s in the\ninput to the problem. As a result, the scaling algorithm is running in time\npolynomial in the size of the input (i.e., the number of edges and the\nnumerical representation of the capacities), and so it meets our traditional\ngoal of achieving a polynomial-time algorithm. Bad implementations of the\nFord-Fulkerson Algorithm, which can require close to C iterations, do not\nmeet this standard of polynomiality . (Recall that in Section 6.4  we used the\nterm pseudo-polynomial  to describe such algorithms, which are polynomial\nin the magnitudes of the input numbers but not in the number of bits needed\nto represent them.)\nExtensions: Strongly Polynomial Algorithms')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 425})","('type', 'Document')"
"('page_content', ""Could we ask for something qualitatively better than what the scaling\nalgorithm guarantees? Here is one thing we could hope for: Our example\ngraph ( Figure 7.6 ) had four nodes  and five edges;  so it would be nice to use\na number of iterations that is polynomial in the numbers  4 and 5,\ncompletely independently of the values of the capacities. Such an\nalgorithm, which  is polynomial in |V| and |E| only, and work s with numbers\nhaving a polynomial number of bits, is called a strongly polynomial\nalgorithm.  In fact, there is a simple and natural implementation of the Ford -\nFulkerson Algor ithm that leads to such a strongly polynomial bound: each\niteration choose s the augmenting path with the fewest number of edges.\nDinitz, and independently Edmo nds and Karp, proved that with this choice\nthe algorithm terminates in at most O(mn) iterations. In fact, these were the\nfirst polynomial algorithms for the Maximum-Flow Problem. There has\nsince been a huge amount of work devoted to improving the running times\nof maximum-flow algorithms. There are currently algorithms that achieve\nrunning times of O(mn log n), O(n3), and O(min(n2/3, m1/2;)m log n log U),\nwhere the last bound assumes that all capacities are integral and at most U.\nIn the next section, we'll discuss a strongly polynomial maximum-flow\nalgorithm based on a dif ferent principle.\n* 7.4 The Preflow-Push Maximum-Flow\nAlgorithm\nFrom the very beginning, our discussion of the Maximum-Flow Problem\nhas been  center ed around the idea of an augmenting path in the residual\ngraph. However , there are some very powerful techniques for maximum\nflow that are not explicitly based on augmenting paths. In this section we\nstudy one such technique, the Preflow-Push Algorithm.\n Designing the Algorithm\nAlgorithms based on augmenting paths maintain a flow f, and use the\naugment procedure to increase the value of the flow . By way of contrast, the\nPreflow-Push Algorithm will, in essence, increase the flow on an edge-by-\nedge basis. Changing the flow on a single edge will typically violate the\nconservation condition, and so the algorithm will have to maintain"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 426})","('type', 'Document')"
"('page_content', 'something less well behaved than a flow—something that does not obey\nconservation—as it operates.\nPreflows  We say that an s-t preflow  (preflow , for short) is a function f that\nmaps each edge e to a nonnegative real number , f : E → R+. A preflow f\nmust satisfy the capacity conditions:\n(i) For each e ∊ E, we have 0 ≤ f(e) ≤ ce.\nIn place  of the conservation conditions, we require only inequalities: Each\nnode other than s must have at least as much flow entering as leaving.\n(ii) For each node v other than the source s, we have\n \nWe will call the dif ference\n  \nthe excess  of the preflow at node y. Notice that a preflow where all nodes\nother than s and t have zero excess is a flow, and the value of the flow is\nexactly ef(t) = -ef(s). We can still define the concept of a residual graph Gf\nfor a preflow f, just as we did for a flow. The algorithm will “push” flow\nalong edges of the residual graph (using both forward and backward edges).\nPreflows and Labelings  The Preflow-Push Algorithm will maintain a\npreflow and work on converting  the preflow into a flow. The algorithm is\nbased on the physical intuition that flow naturally finds its way “downhill.”\nThe “heights” for this intuition will be labels h(v) for each node v that the\nalgorithm will define and maintain, as shown in Figure 7.7. We will push\nflow from nodes  with higher labels to those with lower labels, following the\nintuition that fluid flows down hill. To make this precise, a labeling  is a\nfunction h : V → Z≥0 from the nodes  to the nonnegative integers. We will\nalso refer to the labels as heights  of the nodes. We will say that a labeling h\nand an s-t preflow f are compatible  if\n(i) (Source and sink conditions ) h(t) = 0 and h(s) = n,')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 427})","('type', 'Document')"
"('page_content', '(ii) (Steepness conditions ) For all edges (v, w) ∊ Ef in the residual\ngraph, we have h{v) ≤ h{w) + 1.\nFigur e 7.7 A residual graph and a compatible labeling. No edge in the\nresidual graph can be too “steep ”—its tail can be at most one unit above its\nhead in height. The source node s must have h(s) = n and is not drawn in the\nfigure.\nIntuitively , the height difference n between the source and the sink is meant\nto ensur e that the flow starts high enough to flow from s toward the sink t,\nwhile the steepn ess condition will help by making the descent  of the flow\ngradual enough to make it to the sink.\nThe key propert y of a compatibl e preflow and labeling is that there can\nbe no s-t path in the residual graph.\n(7.21)  If s-t preflow f is compatible with a labelin g h, then there is no s-t path in the residual graph\nGf.\nProof. We prove the statement by contradiction. Let P be a simple s-t path in the residual graph G.\nAssume that the nodes along P are s, v1, …, vk = t. By defini tion of a labeling compatible with\npreflow f, we have that h(s) = n. The edge ( s, v1) is in the residual graph, and hence h(v1) ≥ h(s) - 1 =\nn - 1. Using induction on i and the steepness condition for the edge ( vi-1, vi), we get that for all nodes\nvi in path P the height is at least h(vi) ≥ n - i. Notice that the last node of the path is vk = t; hence we\nget that h(t) ≥ n - k. However , h(t) = 0 by definition; and k < n as the path P is simple. This\ncontradiction proves the claim.\n▪')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 428})","('type', 'Document')"
"('page_content', 'Recall from (7.9) that if there is no s-t path in the resid ual graph Gf of\na flow f, then the flow has maximum value. This implies the following\ncorollary .\n(7.22)  If s-t flow f is compatible with a labeling h, then f is a flow of maximum value.\nNote that (7.21) applies to preflows, while (7.22) is more restrictive in\nthat it applies only to flows.  Thus the Preflow-Push Algorithm will\nmaintain a preflow f and a labeling h compatible with f, and it will work on\nmodifying f and h so as to move f toward being a flow. Once f actually\nbecomes a flow, we can invok e (7.22) to conclude that it is a maximum\nflow. In light of this, we can view the Preflow-Push Algorithm as being in a\nway orthogonal  to the Ford-F ulkerson Algorithm. The Ford-Fulkerson\nAlgorithm maintains a feasible flow while changing it gradually toward\noptimality . The Preflow-Push Algorithm, on the other hand, maintains a\ncondition that would imply the optimality of a preflow f, if it were to be a\nfeasible flow, and the algorithm gradually transforms the preflow f into a\nflow.\nTo start the algorithm, we will need to define an initial preflow f and\nlabeling h that are compat ible. We will use h(v) = 0 for all v ≠ s, and h(s) =\nn, as our initial labeling. To make a preflow f compatible with this labeling,\nwe need to make sure that no edges leaving s are in the residual graph (as\nthese edges do not satisfy the steepness condition). To this end, we define\nthe initial preflow as f(e) = ce for all edges e = (s, v) leaving the source, and\nf (e) = 0 for all other edges.\n(7.23)  The initial pr eflow f and labeling h ar e compatible.\nPushing and Relabeling  Next we will discuss the steps the algorithm\nmakes toward turning the prefl ow f into a feasible flow, while keeping it\ncompatible with some labeling h. Consider any node v that has excess—that\nis, ef(v) > 0. If there is any edge e in the residual graph Gf that leaves v and\ngoes to a node w at a lower heigh t (note that h(w) is at most 1 less than h(v)\ndue to the steepness condition),  then we can modify f by pushing some of\nthe excess flow from v to w. We will call this a push  operation.\npush( f, h, v , w)\nApplicable if ef(v) > 0, h(w) < h(v) and ( v, w) ∊ Ef')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 429})","('type', 'Document')"
"('page_content', ""If e = (v,w) is a forward edge then\nlet δ = min( ef (y), ce - f(e)) and\nincrease f(e) by δ\nIf (v, w) is a backward edge then\nlet e = (w,v), δ = min( ef(y), f(e)) and\ndecrease f(e) by δ\nReturn( f, h)\nIf we cannot push the excess of v along any edge  leaving v, then we\nwill need to raise v's height. W e will call this a relabel  operation.\nrelabel( f, h, v )\nApplicable if ef(y) > 0, and\nfor all edges ( y,w) ∊ Ef we have h(w) > h(y)\nIncrease h(y) by 1\nReturn( f, h)\nThe Full Preflow-Push Algorithm  So, in summa ry, the Preflow-Push\nAlgorithm is as follows.\nPreflow-Push\nInitially h(v)=0 for all v ≠ s and h(s)=n and\nf(e) = ce for all e = (s,v) and f(e)=0 for all other edges\nWhile there is a node v ≠ t with excess ef(v) > 0\nLet v be a node with excess\nIf there is w such that push( f, h, v, w) can be applied then\npush( f, h, v, w)\nElse\nrelabel( f, h, v)\nEndwhile\nReturn(f)\n Analyzing the Algorithm\nAs usual, this algorithm is somewhat underspecified. For an implementation\nof the algorithm, we will have to specify which node with exces s to choose,\nand how to efficiently select an edge on which to push. However , it is clear\nthat each iteration of this algorithm can be implemented in polynomial time."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 430})","('type', 'Document')"
"('page_content', ""(We'll discuss later how to implement it reasonably efficiently .) Further , it is\nnot hard to see that the preflow f and the labeling h are compatible\nthroughout the algorithm. If the algorithm terminates—something that is far\nfrom obvious based on its descr iption—then there are no nodes other than t\nwith positive excess, and hence the preflow f is in fact a flow. It then\nfollows from (7.22) that f would be a maximum flow at termination.\nWe summarize a few simple observations about the algorithm.\n(7.24)  Throughout the Pr eflow-Push Algorithm:\n(i) the labels ar e nonnegative integers;\n(ii) f is a pr eflow , and if the capacities ar e integral, then the pr eflow f is integral; and\n(iii) the pr eflow f and labeling h ar e compatible.\nIf the algorithm r eturns a pr eflow f, then f is a flow of maximum value.\nProof. By (7.23) the initial preflow f and labelin g h are compatible. We will show using induction on\nthe number of push and relabel operations that f and h satisfy the propertie s of the statement. The\npush opera tion modifies the preflow f, but the bounds on δ guarantee that the f returned satisfies the\ncapacity constraints, and that excesses all remain nonnegative, so f is a preflow . To see that the\npreflow f and the labeling h are compatible, note that push( f, h, v, w) can add one edge to the residual\ngraph, the reverse edge (v, w), and this edge does satisfy the steepn ess condition. The relabel\noperation increases the label of v, and hence  increases the steepness of all edges leaving v. However ,\nit only applies when no edge leaving v in the residual graph is going downward, and hence the\npreflow f and the labeling h are compatible after relabeling.\nThe algorithm terminates if no node other than s or t has excess. In this case, f is a flow by\ndefinition; and since the preflow f and the labeling h remain compatible throughout the algorithm,\n(7.22) implies that f is a flow of maximum value.\n▪\nNext we will consider the numb er of push and relabel operation s. First\nwe will prove a limit on the relabel operations, and this will help prove a\nlimit on the maximum number of push operations possible. The algorithm\nnever changes the label of s (as the source never has positive excess). Each\nother node v starts with h(v) = 0, and its label increases by 1 every time it\nchanges. So we simply need to give a limit on how high a label can get. We\nonly consider a node v for relabel when v has excess. The only source of\nflow in the network is the sourc e s; hence, intuitively , the excess at v must\nhave originated at s. The following consequence of this fact will be key to\nbounding the labels.\n(7.25)  Let f be a pr eflow . If the node v has excess, then ther e is a path in Gf fr om v to the sour ce s.\nProof. Let A denote all the nodes w such that there is a path from w to s in the residual graph  Gf, and\nlet B = V-A. We need to show that all nodes with excess are in A.\nNotice that s eA.  Further , no edges e = (x, y) leaving A can have positive flow, as an edge with\nf(e) > 0 woul d give rise to a reverse edge (y, x) in the residual graph, and then y would have been in"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 431})","('type', 'Document')"
"('page_content', ""A. Now  consider the sum of excesses in the set B, and recall  that each node in B has nonnegative\nexcess, as s ∉ B.\n  \nLet's rewri te the sum on the right as follow s. If an edge e has both ends in B, then f (e) appears\nonce in the sum with a “+” and once with a “—”, and hence these two terms cancel out. If e has only\nits head in B, then e leaves A, and we saw above that all edges leaving A have f(e) = 0. If e has only\nits tail in B, then f(e) appears just once in the sum, with a “—”. So we get\n  \nSince flows are nonn egative, we see that the sum of the excesses in B is zero; since each individual\nexcess in B is nonnegative, they must therefore all be 0.\n▪\nNow we are ready to prove that the labels do not change too much.\nRecall that n denotes the number of nodes in V.\n(7.26)  Throughout the algorithm, all nodes have  h(v) ≤ 2 n - 1.\nProof. The initial labels h(t) = 0 and h(s) = n do not change during the algorithm. Consider some\nother node v ≠ s,t. The algorithm changes v's label only when applying the relabel operation, so let f\nand h be the preflow and labeling returned by a relabel( f, h, v) operation. By (7.25) there is a path P\nin the residual graph Gf from v to s. Let |P| denote the number of edges in P, and note that |P| n - 1.\nThe steepness condition implies that heights of the nodes can decrease by at most 1 along each edge\nin P, and hence h(v) - h(s) ≤ |P|, which proves the statement.\n▪\nLabels are monotone increasing throughout the algorithm, so this\nstatement immediately implies a limit on the number of relabeling\noperations.\n(7.27)  Throughout the algorithm, each node is relabeled at most 2n - 1 times, and the total number of\nrelabeling operations is less than 2n2.\nNext we will bound the number of push operations. We will distinguish two\nkinds of push operations. A push( f, h, v, w) operation is saturating  if either e\n= (v, w) is a forward edge in Ef and δ = ce - f(e), or ( v, w) is a backward edge\nwith e = (w,v) and δ = f(e). In other words , the push is saturating if, after the"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 432})","('type', 'Document')"
"('page_content', ""push, the edge (v, w) is no longer in the residual graph. All other push\noperations will be referred to as nonsaturating\n(7.28)  Throughout the algorithm, the number of saturating  push operations is at most 2nm.\nProof. Consider an edge (v, w) in the residual graph. After a saturating push( f, h, v, w) operation, we\nhave h(v) = h(w) + 1, and the edge (v, w) is no longer in the residual graph Gf, as shown in Figure\n7.8. Before we can push again along this edge, first we have to push from w to v to make the edge (v,\nw) appe ar in the residual graph. However , in order to push from w to v, we first need for w's label to\nincrease by at least 2 (so that w is above v). The label of w can increase by 2 at most n - 1 times , so a\nsaturating push from v to w can occur at most n times. Each edge e ∊ E can give rise to two edges in\nthe residual graph, so overall we can have at most 2nm saturating pushes.\n▪\nThe hardest part of the analysis is proving a bound on the number of\nnonsaturating pushes, and this also will be the bottleneck for the theoretical\nbound on the running time.\n(7.29)  Throughout the algorithm, the number of nonsaturating  push operations is at most 2n2m.\nFigur e 7.8  After a saturating push( f, h, v, w), the height of v exceeds the height of w by 1.\nProof. For this proof, we will use a so-called potential function method.  For a preflow f and a\ncompatible labeling h, we define\n  \nto be the sum of the heights of all nodes with positive excess. (Φ is often called a potential  since it\nresembles the “potential ener gy” of all nodes with positive excess.)"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 433})","('type', 'Document')"
"('page_content', 'In the initial preflow and labeling, all nodes with positive excess are at height 0, so Φ(f, h) = 0.\nΦ(f, h) remains nonnegative throughout the algorithm. A nonsaturating push( f, h, v, w) operation\ndecreases Φ(f, h) by at least 1, since after the push the node v will have no excess,  and w, the only\nnode that gets new excess from the operation, is at a height 1 less than v. However , each saturating\npush and each relabel  operation can increa se Φ(f,h). A relabel operation  increases Φ(f, h) by exactly\n1. There are at most 2n2 relabel operations, so the total increase in Φ(f,h) due to relabel opera tions is\n2n2. A saturati ng push( f, h, v, w) operation does not change labels, but it can increase Φ(f, h), since\nthe node w may suddenly acquire positive excess after the push. This would increase Φ(f, h) by the\nheight of w, which is at most 2n - 1. There  are at most 2nm saturating push operations, so the total\nincrease in Φ( f, h) due to push operations is at most 2mn(2n - 1). So, between the two causes, Φ(f, h)\ncan increase by at most 4mn2 during the algorithm.\nBut since Φ remains nonnegative throughout, and it decreases by at least 1 on each\nnonsaturating push operation, it follows  that there can be at most 4mn2 nonsaturating push\noperations.\n▪\nExtensions: An Improved Version of the\nAlgorithm\nThere has been a lot of work devoted to choosing node selection rules for\nthe Preflow-Pus h Algorithm to improve the worst-case running time. Here\nwe consider a simple rule that leads to an improved O(n3) bound on the\nnumber of nonsaturating push operations.\n(7.30)  If at each step we choose the node with excess at maximum height, then the number of\nnonsaturating  push operations thr oughout the algorithm is at most  4n3.\nProof. Consider the maximum height H = maxv:ef(v)>0 h(v) of any node with excess as the\nalgorithm proceeds. The analysis will use this maximum height H in place of the potential function Φ\nin the previous O(n2m) bound.\nThis maximum height H can only increase due to relabeling (as flow is always pushed to nodes\nat lower height), and so the total increase in H throughou t the algorithm is at most 2n2 by (7.26). H\nstarts out 0 and remains nonnegative, so the number of times H changes is at most 4 n2.\nNow consi der the behavior of the algorithm  over a phase of time in which H remains constant.\nWe claim that each node can have at most one nonsaturating push operation during this phase.\nIndeed, during this phase, flow is being pushed from nodes at height H to nodes at height H - 1; and\nafter a nonsaturating push operation from v, it must receive flow from a node at height H + 1 before\nwe can push from it again.\nSince there  are at most n nonsaturating push operations between each change to H, and H\nchanges at most 4 n2 times, the total number of nonsaturating push operations is at most 4 n3.\n▪')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 434})","('type', 'Document')"
"('page_content', 'As a follow-up to (7.30), it is interesting to note that experim entally\nthe computation al bottleneck of the method is the number of relabeling\noperations, and a better experim ental running time is obtained by variants\nthat work on increasing labels faster than one by one. This is a point that we\npursue further in some of the exercises.\nImplementing the Preflow-Push Algorithm\nFinally , we need to briefly discuss how to implement this algorithm\nefficiently . Maintaining a few simple data structures will allow us to\neffectively imple ment the operations of the algorithm in constant time each,\nand overall to implement the algorithm in time O(mn) plus the number of\nnonsaturating push operations. Hence the generic algorithm will run in\nO(mn2) time, while the version that always selects the node at maxi mum\nheight will run in O(n3) time.\nWe can maintain  all nodes with excess on a simple list, and so we will\nbe able to select a node with excess in constant time. One has to be a bit\nmore careful to be able to select a node with maximum height H in constant\ntime. In order to do this, we will maintain a linked list of all nodes with\nexcess at every possible height. Note that whenever a node v gets relabeled,\nor continues to have positive excess after a push, it remains a node with\nmaximum height H. Thus we only have to select a new node after a push\nwhen the current node v no longer has positive excess. If node v was at\nheight H, then the new node at maximum height will also be at height H or,\nif no node at height H has excess, then the maximum height will be H - 1,\nsince the previous push operation out of v pushed flow to a node at height H\n- 1.\nNow assume we have selected a node v, and we need to select an edge\n(v, w) on which to apply push( f, h, v, w) (or relabel( f, h, v) if no such w\nexists). To be able to select an edge quickly , we will use the adjacency list\nrepresentation of the graph. More precisely , we will maintain, for each node\nv, all possible edges leaving v in the residual  graph (both forward and\nbackward edges) in a linked list, and with each edge we keep its capacity\nand flow value. Note that this way we have two copies of each edge in our\ndata structure: a forward and a backward copy . These two copies will have\npointers to each other , so that updates done at one copy can be carried over\nto the other one in O(1) time. We will select edges leaving a node v for push')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 435})","('type', 'Document')"
"('page_content', ""operations in the order they appear on node v's list. To facilitate this\nselection, we will maintain a pointer current( v) for each node v to the last\nedge on the list that has been considered for a push operation. So, if node v\nno longer has excess after a nonsaturating push operation out of node v, the\npointer current( v) will stay at this edge, and we will use the same edge for\nthe next push operation out of v. After a saturating push operat ion out of\nnode v, we advance current( v) to the next edge on the list.\nThe key observation is that, after advancing the pointer current( v) from\nan edge (v, w), we will not want to apply push to this edge again until we\nrelabel v.\n(7.31)  After the curr ent(v) pointer is advanced fr om an edge  (v, w), we cannot apply  push to this edge\nuntil v gets r elabeled.\nProof. At the moment current( v) is advanced from the edge (v, w), there is some reaso n push cannot\nbe applied to this edge. Either h(w) ≥ h(v), or the edge is not in the residual graph. In the first case,\nwe clearly need to relabel v before applying a push on this edge. In the latter case, one needs to apply\npush to the reverse edge (w, v) to make (v, w) reenter the residual graph. However , when we apply\npush to edge ( w, v), then w is above v, and so v needs to be relabeled before one can push flow from v\nto w again.\n▪\nSince edges do not have to be considered again for push before\nrelabeling, we get the following.\n(7.32)  When the  current( v) pointer reaches the end of the edge list for v, the relabel operation can be\napplied to node v .\nAfter relabeling node v, we reset curren t(v) to the first edge on the list and\nstart considering edges again in the order they appear on v's list.\n(7.33)  The running time of the Pr eflow-Push Algorithm, implemented using the above data structur es,\nis O(mn) plus O(1) for each nonsaturating  push operation. In particular , the generic Preflow-Push\nAlgorithm runs in O(n2m) time, while  the version wher e we always select the node at maximum\nheight runs in O (n3) time.\nProof. The initial flow and relabeling is set up in O(m) time. Both push and relabel operations can be\nimplemented in O(1) time, once the operation has been selec ted. Consider a node v. We know that v\ncan be relabeled at most 2n times throughout the algorithm. We will consider the total time the\nalgorithm spends on finding the right edge on which to push flow out of node v, between two times\nthat node v gets relabeled. If node v has dv adjacent edges, then by (7.32) we spend O(dv) time on\nadvancing the current( v) pointer between consecutive relabelings of v. Thus the total time spent on\nadvancing the current pointers throughout the algorithm is O(Σv ∊V ndv) = O(mn), as claimed.\n▪"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 436})","('type', 'Document')"
"('page_content', '7.5 A First Application: The Bipartite Matching\nProblem\nHaving developed a set of powerful algorithms for the Maximum-Flow\nProblem, we now turn to the task of developing applications of maximum\nflows and minimum cuts in graphs. We begin with two very basic\napplications. First, in this section, we discuss the Bipartite Matching\nProblem mentio ned at the begin ning of this chapter . In the next section, we\ndiscuss the more general Disjoint Paths Pr oblem.\n The Problem\nOne of our original goals in developing the Maximum-Flow Problem was to\nbe able to solve the Bipartite Matching Problem, and we now show how to\ndo this. Recall that a bipartite graph G = (V, E) is an undirected graph\nwhose node set can be partitioned as V = X ∪ Y, with the propert y that every\nedge e ∊ E has one end in X and the other end in Y. A matching M in G is a\nsubset of the edges M ⊆ E such that each node appears in at most one edge\nin M. The Bipartite Matching Problem is that of finding a matching in G of\nlargest possible size.\n Designing the Algorithm\nThe graph defining a matching problem is undirected, while flow networks\nare directed; but it is actually  not difficult to use an algorithm for the\nMaximum-Flow Problem to find a maximum matching.\nBeginning with the graph G in an instance of the Bipartite Matching\nProblem, we construct a flow network G′ as shown in Figure 7.9. First we\ndirect all edges in G from X to Y. We then add a node s, and an edge (s, x)\nfrom s to each node in X. We add a node t, and an edge (y, t) from each\nnode in Y to t. Finally , we give each edge in G′ a capacity of 1.\nWe now compute a maximum s-t flow in this network G′. We will\ndiscover that the value of this maximum is equal to the size of the\nmaximum match ing in G. Moreover , our analysis will show how one can\nuse the flow itself to recover the matching.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 437})","('type', 'Document')"
"('page_content', 'Figur e 7.9  (a) A bipartite graph. (b) The corresponding flow network, with\nall capacities equal to 1.\n Analyzing the Algorithm\nThe analysis is based on show ing that integer -valued flows in G′ encode\nmatchings in G in a fairly transparent fashion. First, suppose there is a\nmatching in G consisting of k edges ( xi1, yi1), …, (xik, yik). Then consider the\nflow f that sends one unit along each path of the form s,xik, yij, t—that is,\nf(e) = 1 for each edge on one of these paths. One can verify easily that the\ncapacity and conservation condi tions are indeed met and that f is an s-t flow\nof value k.\nConversely , suppose there is a flow f′ in G′ of value k. By the\nintegrality theor em for maximum flows (7.14), we know there is an integer -\nvalued flow f of value k; and since all capacities are 1, this means that f(e) is\nequal to either 0 or 1 for each edge e. Now , consider the set M′ of edges of\nthe form ( x, y) on which the flow value is 1.\nHere are three simple facts about the set M′.\n(7.34)  M′ contains k edges.\nProof. To prove this, consid er the cut (A, B) in G′ with A = {s} ∪ X. The value of the flow is the total\nflow leaving A, minus the total flow entering A. The first of these terms is simply the cardinality of\nM′, since these are the edges leaving A that carry flow, and each carries exactly one unit of flow. The\nsecond of these terms is 0, since there are no edges entering A. Thus, M′ contains k edges.\n▪\n(7.35)  Each node in X is the tail of at most one edge in M′.\nProof. To prove this, suppo se x ∊ X were the tail of at least two edges in M′. Since our flow is\ninteger -valued, this means that at least two units of flow leave from x. By conser vation of flow, at')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 438})","('type', 'Document')"
"('page_content', ""least two units of flow would have to come into x—but this is not possible, since only a single edge\nof capacity 1 enters x. Thus x is the tail of at most one edge in M′.\n▪\nBy the same reasoning, we can show\n(7.36)  Each node in Y is the head of at most one edge in M′.\nCombining these facts, we see that if we view M′ as a set of edges in\nthe original bipartite graph G, we get a match ing of size k. In summ ary, we\nhave proved the following fact.\n(7.37)  The size of the maxim um matching in G is equal to the value of the maximum flow in G′; and\nthe edges in such a matching in G ar e the edges that carry flow fr om X to Y in G′.\nNote the crucial way in which the integrality theorem (7.14) figured in\nthis construction: we needed to know if there is a maximum flow in G′ that\ntakes only the values 0 and 1.\nBounding the Running Time Now let's consider how quickly we can\ncompute a maximum matching  in G. Let n=|X| = |Y|, and let m be the\nnumber of edges of G. We'll tacitly assume that there is at least one edge\nincident to each node in the original problem, and hence m ≥ n/2. The time\nto compute a maximum matchin g is dominated by the time to compute an\ninteger -valued maximum flow in G, since converting this to a matching in\nG is simp le. For this flow problem, we have that C = Σe out of s ce = |X| = n,\nas s has an edge of capacity 1 to each node of X. Thus, by using  the O(mC)\nbound in (7.5), we get the following.\n(7.38)  The Ford-Fulkerson Algorithm can be used to find a maximum matching in a bipart ite graph\nin O(mn) time.\nIt's interesting that if we were to use the “better” bounds of O(m2 log2\nC) or O(n3) that we developed in the previo us sections, we'd get the inferior\nrunning times of O(m2 log n) or O(n3) for this problem. There is nothing\ncontradictory in this. These bounds were designed to be good for all\ninstances, even when C is very large relative to m and n. But C = n for the\nBipartite Matching Problem, and so the cost of this extra sophistication is\nnot needed."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 439})","('type', 'Document')"
"('page_content', ""It is worthwhile  to consider what the augmenting paths mean  in the\nnetwork G′. Consider the matching M consisting of edges (x2,y2), (x3,y3),\nand ( x5,y5) in the bipartite graph in Figure 7.1 ; see also Figure 7.10 . Let f be\nthe corresponding flow in G′. This matching is not maximum , so f is not a\nmaximum s-t flow, and hence there is an augmenting path in the residual\ngraph G′f. One such augmenting path is marked in Figure 7.10(b) . Note that\nthe edges ( x2,y2) and ( x3,y3) are used backward, and all other edges are used\nforward. All augmenting paths must alternate between edges used backward\nand forward, as all edges of the graph G′ go from  X to Y. Augmenting paths\nare therefore also called alternating paths  in the context of finding a\nmaximum matching. The effect of this augmentation is to take the edges\nused backward out of the matching, and replace them with the edges going\nforward. Becaus e the augmenting path goes from s to t, there is one more\nforward edge than backward edge; thus the size of the matching increases\nby one.\nFigur e 7.10 (a) A bipartite graph, with a matching M. (b) The augme nting\npath in the corre sponding residual graph. (c) The matching obtained by the\naugmentation.\nExtensions: The Structure of Bipartite Graphs\nwith No Perfect Matching\nAlgorithmically , we've seen how to find perfect matchings: We use the\nalgorithm above  to find a maximum matching and then check to see if this\nmatching is perfect."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 440})","('type', 'Document')"
"('page_content', ""But let's ask a slightly less algorithmic question. Not all bipartite\ngraphs have perfect matchings. What does a bipartite graph without a\nperfect matching look like? Is there an easy way to see that a bipartite graph\ndoes not have a perfect matching—or at least an easy way to convince\nsomeone the graph has no perfect matching, after we run the algorithm?\nMore concretely , it would be nice if the algorithm, upon concluding that\nthere is no perfect matching, could produce a short “certificate” of this fact.\nThe certificate could allow someone to be quickly convinced that there is\nno perfect matching, without having to look over a trace of the entire\nexecution of the algorithm.\nOne way to understand the idea of such a certificate is as follow s. We\ncan decide if the graph G has a perfect matching by checking if the\nmaximum flow in a related graph G has value at least n. By the Max-Flow\nMin-Cut Theore m, there will be an s-t cut of capacity less than n if the\nmaximum-flow value in G has value less than n. So, in a way, a cut with\ncapacity less than n provides such a certificate. However , we want a\ncertificate that has a natural meaning in terms of the original graph G.\nWhat might such a certificate look like? For example, if there are\nnodes X1, x2 ∊ X that have only one incident edge each, and the other end of\neach edge is the same node y, then clearly the graph has no perfect\nmatching: both X1 and x2 would need to get matched to the same node y.\nMore generally , consider a subset of nodes A ⊆ x, and let Γ(A) ⊆ Y denote\nthe set of all nodes that are adjac ent to nodes in A. If the graph has a perfect\nmatching, then each node in A has to be matched to a dif ferent node in Γ( A),\nso Γ( A) has to be at least as lar ge as A. This gives us the following fact.\n(7.39)  If a bipartite graph G = (V, E) with two sides X and Y has a perfect matching, then for all A ⊆\nX we must have  |Γ(A)| ≥ |A|.\nThis statement suggests a type of certificate demonstrating that a graph\ndoes not have a perfect matching: a set A ⊆ X such that |Γ(A)| < |A|. But is\nthe converse of (7.39) also true? Is it the case that whenever there is no\nperfect matching, there is a set A like this that proves it? The answer turns\nout to be yes, provided we add the obvious condition that |X| = |Y| (without\nwhich there could certainly not be a perfect matching). This statement is\nknown in the literature as Hall's Theor em, though versions of it were\ndiscovered indep endently by a number of different people—perhaps first by"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 441})","('type', 'Document')"
"('page_content', ""Konig—in the early 1900s. The proof of the statement also provides a way\nto find such a subset A in polynomial time.\n(7.40)  Assume that the bipartite graph G = (V,E) has two sides X and Y such that |X| = |Y|. Then the\ngraph G either has a perfect matching or there is a subset A ⊆ X such that |Γ(A)| < |A|. A perfect\nmatching or an appr opriate subset A can be found in O (mn) time.\nProof. We will use the same graph G′ as in (7.37). Assume  that |X| = |Y| = n. By (7.37) the graph G\nhas a maximum matching if and only if the value of the maximum flow in G′ is n.\nWe need to show that if the value of the maximum flow is less than n, then there is a subset A\nsuch that |Γ(A)| < |A|, as claimed in the statement. By the Max-Flow Min-Cut Theorem (7.12), if the\nmaximum-flow value is less than n, then there is a cut (A′, B′) with capacity less than n in G′. Now\nthe set A′ contains s, and may contain nodes from both X and Y as shown in Figure 7.11. We claim\nthat the set A = X ∩ A′ has the claimed property. This will prove both parts of the statement, as we've\nseen in (7.11) that a minimum cut (A′, B′) can also be found by running the Ford-Fulkerson\nAlgorithm.\nFirst we claim that one can modify the minimum cut (A′, B′) so as to ensure that Γ(A) ⊆ A′,\nwhere A = X ∩ A′ as before.  To do this, consider a node y ∊ Γ(A) that belongs to B′ as shown in\nFigure 7.1 1(a). We claim  that by moving y from B′ to A′, we do not increase the capacity of the cut.\nFor what happens when we move y from B′ to A′? The edge  (y, t) now crosses the cut, increasing the\ncapacity by one. But previously there was at least  one edge (x,y) with x ∊ A, since y ∊ Γ(A); all\nedges from A and y used to cross the cut, and don't anymore. Thus, overall, the capacity of the cut\ncannot increase. (Note that we don't have to be concerned about nodes x ∊ X that are not in A. The\ntwo ends of the edge (x, y) will be on different sides of the cut, but this edge does not add to the\ncapacity of the cut, as it goes from B′ to A′.)\nFigur e 7.11 (a) A minimum cut in proof of (7.40). (b) The same cut after moving node y to the A′\nside. The edges crossing the cut are dark.\nNext consider the capacity of this minimum cut (A′, B′) that has Γ(A) ⊆ A′ as shown in Figure\n7.11(b). Since all neighbors of A belong to A′, we see that the only edges out of A′ are either edges\nthat leave the source s or that enter the sink t. Thus the capacity of the cut is exactly\n  \nNotice that | X∩B | = n - |A|, and |Y ∩ A| > |Γ( A)|. Now the assumption that c(A′,B′ ) < n implies that"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 442})","('type', 'Document')"
"('page_content', ""Comparing the first and the last terms, we get the claimed inequality | A| > |Γ( A)|.\n▪\n7.6 Disjoint Paths in Directed and Undirected\nGraphs\nIn Section 7.1, we described a flow f as a kind of “traffic” in the network.\nBut our actual definition of a flow has a much more static feel to it: For\neach edge e, we simply specify a number f(e) saying  the amount of flow\ncrossing e. Let's see if we can revive the more dynamic, traffic-oriented\npicture a bit, and try formalizin g the sense in which units of flow “travel”\nfrom the source to the sink. From  this more dynamic view of flows, we will\narrive at something called the s-t Disjoint Paths Pr oblem.\n The Problem\nIn defining this problem precisely , we will deal with two issues. First, we\nwill make precise this intuitive correspondence between units of flow\ntraveling along paths, and the notion of flow we've studied so far. Second,\nwe will extend the Disjoint Paths Problem to undir ected  graphs. We'll see\nthat, despite the fact that the Maximum-Flow Problem was defined for a\ndirected graph, it can naturally be used also to handle related problems on\nundirected graphs.\nWe say that a set of paths is edge-disjoint  if their edge sets are disjoint,\nthat is, no two paths share an edge, though multiple paths may go through\nsome of the same nodes. Given a directed graph G = (V, E) with two\ndistinguished nodes s,t ∊ V, the Directed Edge-D isjoint Paths Problem  is to\nfind the maximum number of edge-disjoint s-t paths in G. The Undir ected\nEdge-Disjoint Paths Problem  is to find the maximum number of edge-\ndisjoint s-t paths in an undirected graph G. The related question of finding\npaths that are not only edge-disjoint, but also node-disjoint (of course, other\nthan at nodes s and t) will be considered in the exercises to this chapter ."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 443})","('type', 'Document')"
"('page_content', ""Designing the Algorithm\nBoth the directed and the undirected versions of the problem can be solved\nvery naturally using flows. Let's  start with the directed problem . Given the\ngraph G = (V, E), with its two distinguished nodes s and t, we define a flow\nnetwork in which s and t are the source and sink, respectively , and with a\ncapacity of 1 on each edge. Now suppose there are k edge-disjoint s-t paths.\nWe can make each of these paths carry one unit of flow: We set the flow to\nbe f(e) = 1 for each edge e on any of the paths, and f(e′) = 0 on all other\nedges, and this defines a feasible flow of value k.\n(7.41)  If there are k edge-disjoint paths in a directed graph G from s to t, then the value of the\nmaximum s-t flow in G is at least k.\nSuppose we could show the converse to (7.41) as well: If there is a\nflow of value k, then there exist k edge-disjoint s-t paths. Then we could\nsimply compute a maximum s-t flow in G and declare (correctly) this to be\nthe maximum number of edge-disjoint s-t paths.\nWe now proceed to prove this converse statement, confirming that this\napproach using flow indeed gives us the correct answer . Our analysis will\nalso provide a way to extract k edge-disjoint paths from an integer -valued\nflow sending k units from s to t. Thus computing a maximum flow in G will\nnot only give us the maximum number  of edge -disjoint paths, but the paths\nas well.\n Analyzing the Algorithm\nProving the converse direction of (7.41) is the heart of the analysis, since it\nwill immediatel y establish the optimality of the flow-based algorithm to\nfind disjoint paths.\nTo prove this, we will consider a flow of value at least k, and construct\nk edge-di sjoint paths. By (7.14), we know that there is a maxim um flow f\nwith integer flow values. Since  all edges have a capacity bound of 1, and\nthe flow is integ er-valued, each edge that carries flow under f has exactly\none unit of flow on it. Thus we just need to show the following.\n(7.42)  If f is a 0-1 valued flow of value v, then the set of edges with flow value  f(e) = 1 contains a set\nof v edge-disjoint paths."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 444})","('type', 'Document')"
"('page_content', ""Proof. We prove this by induction on the number of edges in f that carry flow. If v = 0, there is\nnothing to prove. Otherwise, there must be an edge (s, u) that carries one unit of flow. We now “trace\nout” a path of edges that must also carry flow: Since (s, u) carries a unit of flow, it follows by\nconservation that there is some edge (u, v) that carries one unit of flow, and then there must be an\nedge (v, w) that carries one unit of flow, and so forth. If we continue in this way, one of two things\nwill eventually happen: Either we will reach t, or we will reach a node v for the second time.\nIf the first case happens—we find a path P from s to t—then we'll use this path as one of our v\npaths. Let f be the flow obtained  by decreasing the flow values on the edges along P to 0. This new\nflow f has value v - 1, and it has fewer edges that carry flow. Applying the induction hypothesis for f,\nwe get v - 1 edge-disjoint paths, which, along with path P, form the v paths claimed.\nIf P reaches a node v for the second time, then we have a situation like the one pictured in\nFigure 7.12 . (The  edges in the figure all carry one unit of flow, and the dashed edges indicate the path\ntraversed so far, which has just reached a node v for the second time. ) In this case, we can make\nprogress in a dif ferent way .\nConsider the cycle C of edges visited between the first and second appearances of v. We obtain a\nnew flow f from f by decreasing the flow values on the edges along C to 0. This new flow f has value\nv, but it has fewer edges that carry flow. Applying the induction hypothesis for f, we get the v edge-\ndisjoint paths as claimed.\n▪\nFigur e 7.12  The edges in the figure all carry one unit of flow. The path P of\ndashed edges is one possible path in the proof of (7.42).\nWe can summarize (7.41) and (7.42) in the following result.\n(7.43)  There are k edge-disjoint paths in a directed graph G from stot if and only if the value of the\nmaximum value of an s-t flow in G is at least k.\nNotice also how the proof of (7.42) provides an actual procedure for\nconstructing the k paths, given an integer -valued maximum flow in G. This\nprocedure is sometimes referred to as a path decomposition  of the flow,\nsince it “decomposes” the flow into a constituent set of paths. Hence we\nhave shown that our flow-based  algorithm finds the maximum number of\nedge-disjoint s-t paths and also gives us a way to construct the actual paths."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 445})","('type', 'Document')"
"('page_content', ""Bounding the Running T ime For this flow problem, C = Σe out of s ce ≤ |V| =\nn, as there are at most | V| edges out of s, each of which has capacity 1. Thus,\nby using  the O(mC) bound in (7.5), we get an integer maximum flow in\nO(mn) time.\nThe path decomposition procedure in the proof of (7.42), which\nproduces the paths themselves, can also be made to run in O(mn) time. To\nsee this, note that this procedure, with a little care, can produce a single path\nfrom s to t using at most constant work per edge in the graph, and hence in\nO(m) time. Since there can be at most n - 1 edge-disjoint paths from s to t\n(each must use a different edge out of s), it therefore takes time O(mn) to\nproduce all the paths.\nIn summary , we have shown\n(7.44)  The Ford-Fulkerson Algorithm can be used to find a maximum set of edge-disjoint s-t paths in\na dir ected graph G in O(mn) time.\nA Version of the Max-Flow Min-Cut Theorem for Disjoint  Paths  The\nMax-Flow Min- Cut Theorem (7.13) can be used to give the following\ncharacterization of the maximum number of edge-disjoint s-t paths. We say\nthat a set F ⊆ E of edges separates s from t if, after removi ng the edges F\nfrom the graph G, no s-t paths remain in the graph.\n(7.45)  In every directed graph with nodes s and t, the maximum number of edge-disjoint s-t paths is\nequal to the minimum number of edges whose r emoval separates s fr om t.\nProof. If the removal of a set F ⊆ E of edges separates s from t, then each s-t path must use at least\none edge from F, and hence the number of edge-disjoint s-t paths is at most | F|.\nTo prove the other direction, we will use the Max-Flow Min-Cut Theorem (7.13). By (7.43) the\nmaximum number of edge-disjoint paths is the value v of the maximum s-t flow. Now (7.13) states\nthat there is an s-t cut ( A, B) with capacity v. Let F be the set of edges that go from A to B. Each edge\nhas capacity 1, so | F| = v and, by the definition  of an s-t cut, removing these v edges from G separates\ns from t.\n▪\nThis result, then, can be viewed as the natural special case of the Max-\nFlow Min-Cut Theorem in which all edge capacities are equal to 1. In fact,\nthis special case was proved by Menger in 1927, much before the full Max-\nFlow Min-Cut Theorem was formulated and proved; for this reason, (7.45)\nis often called Menger's Theor em. If we think about it, the proof of Hall's\nTheorem (7.40) for bipartite matchings involves a reduction to a graph with\nunit-capacity edges, and so it can be proved using Menger's Theorem rather"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 446})","('type', 'Document')"
"('page_content', ""than the general Max-Flow Min-Cut Theorem. In other words, Hall's\nTheorem is really a special case of Menger's Theorem, which in turn is a\nspecial case of the Max-Flow Min-Cut Theorem. And the history follows\nthis progression, since they were discovered in this order , a few decades\napart.2\nExtensions: Disjoint Paths in Undirected Graphs\nFinally , we consider the disjoint paths problem in an undirecte d graph G.\nDespite the fact that our graph G is now undire cted, we can use the\nmaximum-flow algorithm to obtain edge-disjoint paths in G. The idea is\nquite simple: We replace each undirected edge (u, v) in G by two directed\nedges (u, v) and (v, u), and in this way create a directed version G′ of G.\n(We may delete the edges into s and out of t, since they are not useful.) Now\nwe want to use the Ford-Fulkerson Algorithm in the resulting directed\ngraph. However , there is an important issue we need to deal with first.\nNotice that two paths P1 and P2 may be edge-disjoint in the directed graph\nand yet share an edge in the undirected graph G: This happens if P1 uses\ndirected edge (u, v) while P2 uses edge (v, u). Howeve r, it is not hard to see\nthat there always exists a maximum flow in any network that uses at most\none out of each pair of oppositely directed edges.\n(7.46)  In any flow network, there is a maximum flow f wher e for all opposite directed edges e = (u, v)\nand e′  = (v, u), either f (e) = 0 or f(e′) = 0. If the capacities of the flow network are integral, then there\nalso is such an integral maximum flow .\nProof. We consid er any maximum flow f, and we modify it to satisfy the claimed condition. Assume\ne = (u,v) and e′ = (v,u) are opposite directed edges, and f(e) ≠ 0, f(e′) ≠ 0. Let δ be the smaller of these\nvalues, and modify f by decreasing the flow value on both e and e′ by δ. The resulting flow f is\nfeasible, has the same value as f, and its value on one of e and e′ is 0.\n▪\nNow we can use the Ford-Fulkerson Algorithm and the path\ndecomposition procedure from (7.42) to obtain edge-disjoint paths in the\nundirected graph G.\n(7.47)  There are k edge-disjoint paths in an undir ected graph G fr om s to t if and only if the maximum\nvalue of an s-t flow in the directed version G of G is at least k. Furthermor e, the Ford-Fulkerson\nAlgorithm can be used to find a maximum set of disjoint s-t paths in an undir ected graph G in O(mn)\ntime."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 447})","('type', 'Document')"
"('page_content', 'The undirected analogue of (7.45) is also true, as in any s-t cut, at most\none of the two oppositely directed edges can cross from the s-side to the t-\nside of the cut (for if one crosses, then the other must go from the t-side to\nthe s-side).\n(7.48)  In every undir ected graph with nodes s and t, the maximum number of edge-disjoint  s-t paths\nis equal to the minimum number of edges whose r emoval separates s fr om t.\n7.7 Extensions to the Maximum-Flow Problem\nMuch of the power of the Maximum-Flow Problem has essentially nothing\nto do with the fact that it models traffic in a network. Rather , it lies in the\nfact that many problems with a nontrivial combinatorial search  component\ncan be solved in polynomial time because they can be reduced to the\nproblem of finding a maximum flow or a minimum cut in a directed graph.\nBipartite Matching is a natural first application in this vein; in the\ncoming sections, we investigate a range of further applications. To begin\nwith, we stay with the picture of flow as an abstract kind of “traffic,” and\nlook for more general conditions we might impose on this traffic. These\nmore general conditions will turn out to be useful for some of our further\napplications.\nIn particular , we focus on two generalizations of maximum flow. We\nwill see that both can be reduced to the basic Maximum-Flow Problem.\n The Problem: Circulations with Demands\nOne simplifying aspect of our initial formulation of the Maximum-Flow\nProblem is that we had only a single source s and a single sink t. Now\nsuppose that there can be a set S of sources generating flow, and a set T of\nsinks that can absorb flow. As before, there is an integer capacity on each\nedge.\nWith multiple sources and sinks, it is a bit unclear how to decide which\nsource or sink to favor in a maximization problem. So instead of\nmaximizing the flow value, we will consider a problem where sources have\nfixed supply  values and sinks have fixed demand  values, and our goal is to\nship flow from nodes with available supply to those with given demands.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 448})","('type', 'Document')"
"('page_content', 'Imagine, for example, that the network represents a system of highways or\nrailway lines in which we want to ship products from factories (which have\nsupply) to retail outlets (which have demand). In this type of problem, we\nwill not be seeking to maximize a particular value; rather , we simply want\nto satisfy all the demand using the available supply .\nThus we are given a flow netw ork G = (V, E) with capacities on the\nedges. Now, associated with each node v ∊ V is a demand dv. If dv > 0, this\nindicates that the node v has a demand  of dv for flow; the node is a sink, and\nit wishes to receive dv units more flow than it sends out. If dv < 0, this\nindicates that v has a supply  of — dv; the node is a source, and it wishes to\nsend out -dv units more flow than it receives. If dv = 0, then the node v is\nneither a source  nor a sink. We will assume that all capacities and demands\nare integers.\nWe use S to deno te the set of all nodes with negative demand and T to\ndenote the set of all nodes with positive demand. Although a node v in S\nwants to send out more flow than it receives, it will be okay for it to have\nflow that enters on incoming edges; it should just be more than\ncompensated by the flow that leaves v on outgoing edges. The same applies\n(in the opposite direction) to the set T.\nFigur e 7.13 (a) An instance of the Circulation Problem together with a\nsolution: Numbers inside the nodes are demands; numbers labeling the\nedges are capacities and flow values, with the flow values inside boxes. (b)\nThe result of reducing this instance to an equivalent instance of the\nMaximum-Flow Problem.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 449})","('type', 'Document')"
"('page_content', 'In this setting, we say that a circulation  with demands {dv} is a\nfunction f that assigns a nonnegative real number to each edge and satisfi es\nthe following two conditions.\n(i) (Capacity conditions ) For each e ∊ E, we have 0 ≤ f (e) ≤ ce.\n(ii) (Demand conditions ) For each v ∊ V, we have v, fin(v) - fout(v) = dv.\nNow , instead of considering a maximization problem, we are concerned\nwith a feasibility problem:  We want to know whether there exists  a\ncirculation that meets conditions (i) and (ii).\nFor exam ple, consider the instance in Figure 7.13(a) . Two of the nodes\nare sources, with demands -3 and -3; and two of the nodes are sinks, with\ndemands 2 and 4. The flow values in the figure constitute a feasible\ncirculation, indicating how all demands can be satisfied while respecting the\ncapacities.\nIf we consider an arbitrary insta nce of the Circulation Problem, here is\na simple condition that must hold in order for a feasible circulation to exist:\nThe total supply must equal the total demand.\n(7.49)  If ther e exists a feasible cir culation with demands  {dv}, then Σv dv = 0.\nProof. Suppose there exists  a feasible circulation  f in this setting. Then  Σv dv = Σv fin(v) - fout(v).\nNow , in this latter expression, the value f(e) for each edge e = (u, v) is counted exactly twice: once in\nfout(u) and once in fin(v). These two terms cancel out; and since this holds for all values f(e), the\noverall sum is 0.\n▪\nFigur e 7.14 Reduci ng the Circulation Problem to the Maximum-Flow\nProblem.\nThanks to (7.49), we know that')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 450})","('type', 'Document')"
"('page_content', 'Let D denote this common value.\n Designing and Analyzing an Algorithm for\nCirculations\nIt turns out that we can reduce the problem of finding a feasible  circulation\nwith demands {dv} to the problem of finding a maximum s-t flow in a\ndifferent network, as shown in Figure 7.14 .\nThe reduction looks very much like the one we used for Bipartite\nMatching: we attach a “super -source” s* to each node in S, and a “super -\nsink” t* to each node in T. More specifically , we create a graph G from G\nby adding new nodes s* and t* to G. For each node v ∊ T—that is, each\nnode v with dv > 0—w e add an edge (v, t*) with capacity dv. For each node\nu ∊ S—that is, each node with du < 0—we add an edge ( s*, u) with capacity\n— du. We carry the remaining structure of G over to G unchanged.\nIn this graph G′, we will be seeking a maximum s*-t*  flow. Intuitively ,\nwe can think of this reduction as introducing a node s* that “supplies” all\nthe sourc es with their extra flow, and a node t* that “siphons” the extra flow\nout of the sinks. For example, part (b) of Figure 7.13 shows the result of\napplying this reduction to the instance in part (a).\nNote that there cannot be an s*-t*  flow in G of value greate r than D,\nsince the cut (A, B) with A = {s*} only has capacity D. Now , if there is a\nfeasible circulation f with demands {dv} in G, then by sendin g a flow value\nof — dv on each edge (s*, v), and a flow value of dv on each edge (v, t*), we\nobtain an s*-t*  flow in G of value D, and so this is a maximum flow.\nConversely , suppose there is a (maximum) s*-t*  flow in G of value D. It\nmust be that every edge out of s*, and every edge  into t*, is completely\nsaturated with flow. Thus, if we delete these edges, we obtain a circulation f\nin G with fin(v) - fout(v) = dv for each node v. Further , if there is a flow of\nvalue D in G, then there is such a flow that takes integer values.\nIn summary , we have proved the following.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 451})","('type', 'Document')"
"('page_content', '(7.50)  There is a feasible circulation with demands [dv] in G if and only if the maximum s*-t* flow in\nG has value D. If all capacities and demands in G are integers, and there is a feasible circulation,\nthen ther e is a feasible cir culation that is integer -valued.\nAt the end of Section 7.5 , we used the Max-Flow Min-Cu t Theorem to\nderive the characterization (7.40) of bipartite graphs that do not have\nperfect matchings. We can give an analogous characterization  for graphs\nthat do not have  a feasible circulation. The characterization uses the notion\nof a cut, adapted  to the present settin g. In the context of circulati on\nproblems with demands, a cut (A, B) is any partition of the node set V into\ntwo sets, with no restriction on which side of the partition the sources and\nsinks fall. W e include the characterization here without a proof.\n(7.51)  The graph G has a feasible cir culation with demands  [dv] if and only if for all cuts  (A,B),\n  \nIt is important to note that our network has only a single “kind” of\nflow. Although the flow is supplied from multiple sources, and absorbed at\nmultiple sinks, we cannot place restrictions on which source will supply the\nflow to which sink; we have to let our algorithm decide this. A harder\nproblem is the Multicommodity Flow Pr oblem;  here sink ti must be supplie d\nwith flow that originated at source si, for each i. We will discuss  this issue\nfurther in Chapter 1 1.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 452})","('type', 'Document')"
"('page_content', ""The Problem: Circulations with Demands and\nLower Bounds\nFinally , let us generalize the previous problem a little. In many applications,\nwe not only want to satisfy demands at various nodes; we also want to force\nthe flow to make use of certai n edges. This can be enforced by placing\nlower bounds  on edge s, as well as the usual upper bounds imposed by edge\ncapacities.\nConsider a flow network G = (V, E) with a capacity ce and a lower\nbound ℓe on each edge e. We will assume  0 ≤ ℓe ≤ ce for each e. As before,\neach node v will also have a demand dv, which can be either positive or\nnegative. W e will assume that all demands, capacities, and lower bounds are\nintegers.\nThe given quantities have the same meaning as before, and now a\nlower bound ℓe means that the flow value on e must be at least ℓe. Thus a\ncirculation in our flow network must satisfy the following two conditions.\n(i) (Capacity conditions ) For each e ∊ E, we have ℓe ≤ f(e) ≤ ce.\n(ii) (Demand conditions ) For every v ∊ V, we have fin(v) - fout(v) = dv.\nAs before, we wish to decide whether there exists a feasible circulation —\none that satisfies these conditions.\n Designing and Analyzing an Algorithm with\nLower Bounds\nOur strategy will be to reduce this to the problem of finding a\ncirculation with demands but no lower bounds. (We've seen that this latter\nproblem, in turn, can be reduced  to the standard Maximum-Flow Problem.)\nThe idea is as follows. We know that on each edge e, we need to send at\nleast ℓe units of flow. So suppose that we define an initial circulation f0\nsimply by f0(e) = ℓe. f0 satisfies all the capacity conditions (both lower and\nupper bounds); but it presumably does not satisfy all the demand\nconditions. In particular ,"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 453})","('type', 'Document')"
"('page_content', 'Let us denote this quantity by Lv. If Lv = dv, then we have satisfied the\ndemand condition at v; but if not, then we need to superimpose a circulation\nf1 on top of f0 that will clear the remaining “imbalance” at v. So we need\nf1in(v) - f1out(v) = dv - Lv. And how much  capacity do we have with which to\ndo this? Having already sent ℓe units of flow on each edge e, we have ce - ℓe\nmore units to work with.\nThese considerations directly motivate the following construction. Let\nthe graph G′ have the same nodes and edges, with capacities and demands,\nbut no lower bounds. The capacity of edge e will be ce - ℓe. The demand of\nnode v will be dv - Lv.\nFor exam ple, consider the instance in Figure 7.15(a) . This is the same\nas the instance we saw in Figure 7.13, except that we have now given one\nof the edges a lower bound of 2. In part (b) of the figure, we eliminate this\nlower bound by sending two units of flow across the edge. This reduces the\nupper bound on the edge and changes the demands at the two ends of the\nedge. In the process, it becomes clear that there is no feasible  circulation,\nsince after applying the construction there is a node with a demand of -5,\nand a total of only four units of capacity on its outgoing edges.\nWe now claim that our genera l construction produces an equivalent\ninstance with demands but no lower bounds; we can therefore use our\nalgorithm for this latter problem.\nFigur e 7.15  (a) An instance  of the Circulati on Problem with lower bounds:\nNumbers inside the nodes are demands, and numbers labeling the edges are\ncapacities. We also assign a lower bound of 2 to one of the edges. (b) The\nresult of reducin g this instance to an equivalent instance of the Circulation\nProblem without lower bounds.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 454})","('type', 'Document')"
"('page_content', '(7.52)  There is a feasible circulation in G if and only if there is a feasible circulation in G. If all\ndemands, capacities, and lower bounds in G are integers, and there is a feasible circulation, then\nthere is a feasible cir culation that is integer -valued.\nProof. First suppose there is a circulation f′ in G′. Define a circulation f in G by f(e) = f′(e) + ℓe. Then\nf satisfies the capacity conditions in G, and\n  \nso it satisfies the demand conditions in G as well.\nConversely , suppose there is a circulation f in G, and define a circulat ion f′ in G′′ by f′(e) = f(e) -\nℓe. Then f satisfies the capacity conditions in G′, and\n  \nso it satisfies the demand conditions in G′ as well.\n▪\n7.8 Survey Design\nMany problems that arise in applications can, in fact, be solved efficiently\nby a reduction to Maximum Flow , but it is often difficult to discover when\nsuch a reduction is possible. In the next few sections, we give several\nparadigmatic examples of such problems. The goal is to indicate what such')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 455})","('type', 'Document')"
"('page_content', ""reductions tend to look like and to illustrate some of the most common uses\nof flows  and cuts in the design of efficient combinatorial algorithms. One\npoint that will emerge is the following: Sometimes the solution  one wants\ninvolves the computation of a maximum flow, and sometimes it involves\nthe computation of a minimum cut; both flows and cuts are very useful\nalgorithmic tools.\nWe begin with a basic application that we call survey design,  a simple\nversion of a task faced by many companies wanting to measure customer\nsatisfaction. More generally , the problem illustrates how the construction\nused to solve the Bipartite Matching Problem arises naturally in any setting\nwhere we want to carefully balance decisions across a set of options—in\nthis case, designing questionnair es by balancing relevant questions across a\npopulation of consumers.\n The Problem\nA major issue in the burgeoning field of data mining  is the study of\nconsumer preference patterns. Consider a company that sells k products and\nhas a database containing the purchase histories of a large number of\ncustomers. (Those of you with “Shopper's Club” cards may be able to guess\nhow this data gets collected.) The company wishes to conduct a survey ,\nsending customized questionnaires to a particular group of n of its\ncustomers, to try determining which products people like overall.\nHere are the guidelines for designing the survey .\nEach customer will receive questions about a certain subset of the\nproducts.\nA customer can only be asked about products that he or she has\npurchased.\nTo make each questionnaire informative, but not too long so as to\ndiscourage participation, each customer i should be asked about a\nnumber of products between ci and c′i.\nFinally , to collect sufficient data about each product, there must be\nbetween pj and p′j distinct customers asked about each product j.\nMore formally , the input to the Survey Design Problem  consists of a\nbipartite graph G whose nodes are the customers and the products, and there"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 456})","('type', 'Document')"
"('page_content', 'is an edge betwe en customer i and product j if he or she has ever purchased\nproduct j. Further , for each customer i = 1, …, n, we have limits ci ≤ c′i on\nthe number of products he or she can be asked about; for each product j = 1,\n…, k, we have limits pj ≤ pj on the number of distinct customers that have to\nbe asked about it. The problem is to decide if there is a way to design a\nquestionnaire for each customer so as to satisfy all these conditions.\nFigur e 7.16 The Survey Design Problem can be reduced to the problem of\nfinding a feasible circulation: Flow passes from customers (with capacity\nbounds indicatin g how many questions they can be asked) to products (with\ncapacity bounds indicating how many questions should be asked about each\nproduct).\n Designing the Algorithm\nWe will solve this problem by reducing it to a circulation proble m on a flow\nnetwork G with demands and lower boun ds as shown in Figure 7.16. To\nobtain the graph  G from G, we orient the edges of G from customers to\nproducts, add nodes s and t with edges (s, i) for each customer i = 1, …, n,\nedges (j, t) for each product j = 1, …, k, and an edge (t, s). The circulation\nin this network will correspond  to the way in which questions are asked.\nThe flow on the edge (s, i) is the number of products included on the\nquestionnaire for customer i, so this edge will have a capacity of c′i and a\nlower bound of ci. The flow on the edge (j, t) will correspond to the number\nof custo mers who were asked about product j, so this edge will have a\ncapacity of pj and a lower bound of pj. Each edge (i,j) going from a')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 457})","('type', 'Document')"
"('page_content', ""customer to a product he or she bought has capacity 1, and 0 as the lower\nbound. The flow carried by the edge ( t, s) corresponds to the overall number\nof quest ions asked. We can give this edge a capacity of Σi c′i and a lower\nbound of Σici. All nodes have demand 0.\nOur algorithm is simply to construct this network G′ and check\nwhether it has a feasible circulation. We now formulate a claim that\nestablishes the correctness of this algorithm.\n Analyzing the Algorithm\n(7.53)  The graph G just constructed has a feasibl e circulation if and only if there is a feasib le way to\ndesign the survey .\nProof. The construction above immediately suggests a way to turn a survey design  into the\ncorresponding flow. The edge (i, j) will carry one unit of flow if customer i is asked about product j\nin the survey , and will carry no flow otherwise. The flow on the edges (s, i) is the number of\nquestions asked from customer i, the flow on the edge (j, t) is the number of customers who were\nasked about product j, and finally , the flow on edge (t, s) is the overall number of questions asked .\nThis flow satisfies the 0 demand, that is, there is flow conservation at every node. If the survey\nsatisfies these rules, then the corresponding flow satisfies the capacities and lower bounds.\nConversely , if the Circulation Problem is feasible, then by (7.52) there is a feasible circulation\nthat is integer -valued , and such an integer -valued circulation naturally corresponds to a feasible\nsurvey design. Custom er i will be surveyed about product j if and only if the edge (i, j) carries a unit\nof flow .\n▪\n7.9 Airline Scheduling\nThe computation al problems faced by the nation's large airline carriers are\nalmost too complex to even imagine. They have to produce schedules for\nthousands of routes each day that are efficient in terms of equip ment usage,\ncrew allocation, customer satisfaction, and a host of other factors—all in the\nface of unpredictable issues like weather and breakdowns. It's not surprising\nthat they're among the largest consumers of high-powered algorithmic\ntechniques.\nCovering these computational problems in any realistic level of detail\nwould take us much too far afield. Instead, we'll discuss a “toy” problem\nthat captures, in a very clean way, some of the resource allocation issues\nthat arise in a context such as this. And, as is common in this book, the toy\nproblem will be much more useful for our purposes than the “real” problem,"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 458})","('type', 'Document')"
"('page_content', ""for the solution to the toy problem involves a very general technique that\ncan be applied in a wide range of situations.\n The Problem\nSuppose you're in charge of managing a fleet of airplanes and you'd like to\ncreate a flight schedule for them. Here's a very simple model for this. Your\nmarket research has identified a set of m particular flight segments that\nwould be very lucrative if you could serve them; flight segment j is\nspecified by four parameters: its origin airport, its destination airport, its\ndeparture time, and its arrival time. Figure 7.17(a)  shows a simple example,\nconsisting of six flight segments you'd like to serve with your planes over\nthe course of a single day:\n(1) Boston (depart 6 A.M.) – W ashington DC (arrive 7 A.M.)\n(2) Philadelphia (depart 7 A.M.) – Pittsbur gh (arrive 8 A.M.)\nFigur e 7.17  (a) A small instance of our simple Airline Scheduling Problem.\n(b) An expanded graph showin g which flights are reachable from which\nothers.\n(3) Washington DC (depart 8 A.M.) – Los Angeles (arrive 1 1 A.M.)\n(4) Philadelphia (depart 1 1 A.M.) – San Francisco (arrive 2 P .M.)"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 459})","('type', 'Document')"
"('page_content', ""(5) San Francisco (depart 2:15 P .M.) – Seattle (arrive 3:15 P .M.)\n(6) Las V egas (depart 5 P .M.) – Seattle (arrive 6 P .M.)\nNote that each segment includes the times you want the flight  to serve as\nwell as the airports.\nIt is possible to use a single plane for a flight segment i, and then later\nfor a flight segment j, provided that\n(a) the destination of i is the same as the origin of j, and there's enough\ntime to perform maintenance on the plane in between; or\n(b) you can add a flight segmen t in between that gets the plane from\nthe destination of i to the origin of j with adequate time in between.\nFor example, assuming an hour for intermediate maintenanc e time, you\ncould use a single plane for flights (1), (3), and (6) by having the plane sit\nin W ashington, DC, between flights (1) and (3), and then inserting the flight\nLos Angeles (depart 12 noon) - Las V egas (1 p.m. )\nin between flights (3) and (6).\nFormulating the Problem  We can model this situation in a very general\nway as follows,  abstracting away from specific rules about maintenance\ntimes and intermediate flight segments: We will simply say that flight j is\nreachable  from flight i if it is possible to use the same plane for flight i, and\nthen later for flight j as well. So under our specific rules (a) and (b) above,\nwe can easily determine for each pair i,j whether flight j is reach able from\nflight i. (Of course, one can easily imagine more complex rules for\nreachability . For example, the length of maintenance time needed in (a)\nmight depend on the airport; or in (b) we might require that the flight\nsegment you insert be sufficien tly profitable on its own.) But the point is\nthat we can handle any set of rules with our definition: The input to the\nproblem will include not just the flight segments, but also a specification of\nthe pairs (i,j) for which a later flight j is reach able from an earlier flight i.\nThese pairs can form an arbitrary directed acyclic graph.\nThe goal in this problem is to determine whether it's possible to serve\nall m flights on your original list, using at most k planes total. In order to do\nthis, you need to find a way of efficiently reusing planes for multiple\nflights.\nFor example, let's go back to the instance in Figure 7.17 and assume\nwe have k = 2 planes. If we use one of the planes for flights (1), (3), and (6)\nas proposed above, we wouldn't be able to serve all of flights (2), (4), and\n(5) with the other (since there wouldn't be enough maintenance time in San"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 460})","('type', 'Document')"
"('page_content', 'Francisco between flights (4) and (5)). However , there is a way to serve all\nsix flights using two planes, via a different solution: One plane serves\nflights (1), (3), and (5) (splicing in an LAX-SFO flight), while the other\nserves (2), (4), and (6) (splicing in PIT -PHL and SFO-LAS).\n Designing the Algorithm\nWe now discuss  an efficient algorithm that can solve arbitrary instances of\nthe Airline Scheduling Problem , based on network flow. We will see that\nflow techniques adapt very naturally to this problem.\nThe solution is based on the following idea. Units of flow will\ncorrespond to airplanes. W e will have an edge for each flight, and upper and\nlower capacity bounds of 1 on these edges to require that exactly one unit of\nflow crosses this edge. In other words, each flight must be served by one of\nthe planes. If (uj, vj) is the edge representing flight i, and (uj, vj) is the edge\nrepresenting flight j, and flight j is reachable from flight i, then we will have\nan edge from vi to uj with capacity 1; in this way, a unit of flow can traverse\n(ui, vi) and then move directly to (uj, vj). Such a construction of edges is\nshown in Figure 7.17(b) .\nWe extend this to a flow network by including a source and sink; we\nnow give the full construction in detail. The node set of the underlying\ngraph G is defined as follows.\nFor each flight i, the graph G will have the two nodes ui and vi.\nG will also have a distinct source node s and sink node t.\nThe edge set of G is defined as follows.\nFor each i, there is an edge (ui, vi) with a lower bound of 1 and a\ncapacity of 1. ( Each flight on the list must be served. )\nFor each i and j so that flight j is reachable from flight i, there is an\nedge (vi, uj) with a lower bound of 0 and a capacity of 1. (The same\nplane can perform flights i and j. )\nFor each i, there is an edge (s, ui) with a lower bound of 0 and a\ncapacity of 1. ( Any plane can begin the day with flight i. )')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 461})","('type', 'Document')"
"('page_content', ""For each j, there is an edge (vj, t) with a lower bound of 0 and a\ncapacity of 1. ( Any plane can end the day with flight j. )\nThere is an edge (s, t) with lower bound 0 and capac ity k. (If we have\nextra planes, we don't need to use them for any of the flights. )\nFinally , the node s will have a demand of -k, and the node t will have a\ndemand of k. All other nodes will have a demand of 0.\nOur algorithm is to construct the network G and search for a feasible\ncirculation in it. W e now prove the correctness of this algorithm.\n Analyzing the Algorithm\n(7.54)  There is a way to perform all flights using at most k planes if and only if there is a feasible\ncirculation in the network G.\nProof. First, suppose there is a way to perform  all flights using k′ ≤ k planes. The set of flights\nperformed by each individual plane defines a path P in the network G, and we send one unit of flow\non each such path P. To satisfy the full demands at s and t, we send k - k′ units of flow on the edge (s,\nt). The resulting circulation satisfies all demand, capacity , and lower bound conditions.\nConversely , consider a feasible circulation in the network G. By (7.52), we know that there is a\nfeasible circulation with integer flow values. Suppose that k′ units of flow are sent on edges other\nthan ( s,t). Since all other edges have a capacity bound of 1, and the circulation is integer -valued, each\nsuch edge that carries flow has exactly one unit of flow on it.\nWe now convert this to a schedule using the same kind of construction we saw in the proof of\n(7.42), where we converted a flow to a collection of paths. In fact, the situation is easier here since\nthe graph has no cycles. Consider an edge (s, ut) that carries one unit of flow. It follows by\nconservation that (u, vt) carries one unit of flow, and that there is a unique edge out of vi that carries\none unit of flow. If we continue in this way, we construct a path P from s to t, so that each edge on\nthis path carries one unit of flow. We can apply this construction to each edge of the form (s, uj)\ncarrying one unit of flow; in this way, we produce k′ paths from  s to t, each consisting of edges that\ncarry one unit of flow. Now , for each path P we create in this way, we can assign a single plane to\nperform all the flights contained in this path.\n▪\nExtensions: Modeling Other Aspects of the\nProblem\nAirline scheduli ng consumes countless hours of CPU time in real life. We\nmentioned at the beginning, however , that our formulation here is really a\ntoy problem; it ignores several obvious factors that would have  to be taken\ninto account in these application s. First of all, it ignores the fact that a given\nplane can only fly a certain number of hours before it needs to be"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 462})","('type', 'Document')"
"('page_content', ""temporarily taken out of service for more significant maintenance. Second,\nwe are making up an optimal schedule for a single day (or at least for a\nsingle span of time) as though there were no yesterday or tomor row; in fact\nwe also need the planes to be optimally positioned for the start of day N + 1\nat the end of day N. Third, all these planes need to be staffed by flight\ncrews, and while crews are also reused across multiple flights, a whole\ndifferent set of constraints operates here, since human beings and airplanes\nexperience fatigue at different rates. And these issues don't even begin to\ncover the fact that serving any particular flight segment is not a hard\nconstraint; rather , the real goal is to optimize revenue, and so we can pick\nand choose among many possible flights to include in our schedule (not to\nmention designing a good fare structure for passengers) in order to achieve\nthis goal.\nUltimately , the message is probably this: Flow techniques are useful\nfor solving problems of this type, and they are genuinely used in practice.\nIndeed, our solution above is a general approach to the efficient reuse of a\nlimited set of resources in many settings. At the same time, running an\nairline ef ficiently in real life is a very dif ficult problem.\n7.10 Image Segmentation\nA central problem in image processing is the segmentation  of an image into\nvarious coherent regions. For example, you may have an image\nrepresenting a picture of three people standing in front of a complex\nbackground scene. A natural but difficult goal is to identify each of the\nthree people as coherent objects in the scene.\n The Problem\nOne of the most basic problems to be considered along these lines is that of\nforeground/background segmentation: We wish to label each pixel in an\nimage as belong ing to either the foreground of the scene or the background.\nIt turns out that a very natural model here leads to a problem that can be\nsolved ef ficiently by a minimum cut computation.\nLet V be the set of pixels  in the underlyin g image that we're analyzing.\nWe will declare certain pairs of pixels to be neighbors,  and use E to denote"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 463})","('type', 'Document')"
"('page_content', ""the set of all pairs of neighboring pixels. In this way, we obtain an\nundir ected  graph G = (V, E). We will be deliberately vague on what exactly\nwe mean  by a “pixel,” or what we mean by the “neighbor” relation. In fact,\nany graph G will yield an efficiently solvable problem, so we are free to\ndefine these notions in any way that we want. Of course, it is natural to\npicture the pixels as constituting a grid of dots, and the neighbo rs of a pixel\nto be those that are directly adjacent to it in this grid, as shown in Figure\n7.18(a) .\nFigur e 7.18 (a) A pixel graph. (b) A sketch of the corresponding flow\ngraph. Not all edges from the source or to the sink are drawn.\nFor each pixel i, we have a likelihood aj that it belong s to the\nforeground, and a likelihood bi that it belongs to the background. For our\npurposes, we will assume that these likelihood values are arbitrary\nnonnegative numbers provided as part of the problem, and that they specify\nhow desirable it is to have pixel i in the background or foreground. Beyond\nthis, it is not crucial precisely what physical properties of the image they are\nmeasuring, or how they were determined.\nIn isolation, we would want to label pixel i as belonging to the\nforeground if ai > bi, and to the back ground otherwise. However , decisions\nthat we make about the neighbors of i should affect our decision about i. If\nmany of i's neighbors are labeled “backgr ound,” for example, we should be"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 464})","('type', 'Document')"
"('page_content', ""more inclined to label i as “background” too; this makes the labeling\n“smoother” by minimizing the amount of foreground/background boundary .\nThus, for each pair (i, j) of neighboring pixels, there is a separation penalty\npij ≥ 0 for placing one of i or j in the foreground and the other in the\nbackground.\nWe can now specify our Segmentation Problem  precisely , in terms of\nthe likelihood and separation parameters: It is to find a partition of the set of\npixels into sets A and B (foreground and background, respectively) so as to\nmaximize\n \nThus we are rewarded for having high likelihood values and penalized for\nhaving neighboring pairs (i,j) with one pixel  in A and the other in B. The\nproblem, then, is to compute an optimal labeling —a partition (A, B) that\nmaximizes q(A,B).\n Designing and Analyzing the Algorithm\nWe notice right away that there is clearly a resemblance between the\nminimum-cut problem and the problem of finding an optimal labeling.\nHowever , there are a few signi ficant differences. First, we are seeking to\nmaximize an objective function rather than minimizing one. Second, there\nis no source and sink in the labeling problem; and, moreover , we need to\ndeal with values  aj and bj on the nodes. Third, we have an undirected graph\nG, whereas for the minimum-cut problem we want to work with a directed\ngraph. Let's address these problems in order .\nWe deal with the fact that our Segmentation Problem  is a\nmaximization problem through the following observation. Let Q = Σi(ai +\nbi). The sum Σi ∊aai + Σj ∊bbj is the same as the sum Q - σi ∊A bj - Σj ∊baj, so\nwe can write"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 465})","('type', 'Document')"
"('page_content', ""Thus we see that the maximiza tion of q(A, B) is the same problem as the\nminimization of the quantity\n \nAs for the missi ng source and the sink, we work by analogy with our\nconstructions in previous sections: We create a new “super -source” s to\nrepresent the foreground, and a new “super -sink” t to represent the\nbackground. This also gives us a way to deal with the values aj and bj that\nreside at the nodes (whereas minimum cuts can only handle numbers\nassociated with edges). Specifically , we will attach each of s and t to every\npixel, and use aj and bj to define appropriate capacit ies on the edges\nbetween pixel i and the source and sink respectively .\nFinally , to take care of the undirected edges, we mode l each\nneighboring pair ( i,j) with two directed edges, ( i,j) and ( j, i), as we did in the\nundirected Disjo int Paths Problem. We will see that this works very well\nhere too, since in any s-t cut, at most one of these two oppositely directed\nedges can cross from the s-side to the t-side of the cut (for if one does, then\nthe other must go from the t-side to the s-side).\nSpecifically , we define the following flow network G = (V, E′) shown\nin Figure 7.18(b) . The node set V consists  of the set V of pixels, together\nwith two additional nodes s and t. For each neighboring pair of pixels i and\nj, we add directe d edges (i,j) and (j,i), each with capacity pij. For each pixel\ni, we add an edge ( s, i) with capacity aj and an edge ( i, t) with capacity bj.\nNow , an s-t cut (A, B) corresponds to a partition of the pixels into sets\nA and B. Let's consider how the capacit y of the cut c(A, B) relates  to the\nquantity q′(A, B) that we are trying to minimiz e. We can group the edges\nthat cross the cut ( A, B) into three natural categories."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 466})","('type', 'Document')"
"('page_content', 'Edges ( s,j), where j ∊ B; this edge contributes aj to the capacity of the\ncut.\nEdges ( i, t), where i ∊ A; this edge contributes bj to the capacity of the\ncut.\nEdges (i,j) where i ∊ A and; ∊  B; this edge contributes pij to the\ncapacity of the cut.\nFigure 7.19 illustrates what each of these three kinds of edges looks like\nrelative to a cut, on an example with four pixels.\nFigur e 7.19 An s-t cut on a graph constructed from four pixels. Note how\nthe three types of terms in the expression for q′(A, B) are captured by the\ncut.\nIf we add up the contributions of these three kinds of edges, we get')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 467})","('type', 'Document')"
"('page_content', ""So every thing fits together perfectly . The flow network is set up so that the\ncapacity of the cut (A,B) exactly  measures the quantity q′(A,B): The three\nkinds of edges crossing the cut (A,B), as we have just defined them (edges\nfrom the source , edges to the sink, and edges involving neithe r the source\nnor the sink), correspond to the three kinds of terms in the expression for q′\n(A, B).\nThus, if we want to minimize q′(A, B) (since we have argued earlier\nthat this is equivalent to maximizing q(A,B)), we just have to find a cut of\nminimum capac ity. And this latter problem, of course, is something that we\nknow how to solve ef ficiently .\nThus, through solving this minimum-cut problem, we have an optimal\nalgorithm in our model of foreground/background segmentation.\n(7.55)  The solution to the Segmentation Problem can be obtained by a minimum-cut algorit hm in the\ngraph G constructed above. For a minimu m cut (A′, B′), the partition  (A, B) obtained by deleting s*\nand t* maximizes the segmentation value q {A,B).\n7.11 Project Selection\nLarge (and small) companies are constantly faced with abalancing act\nbetween project s that can yield revenue, and the expenses needed for\nactivities that can support these projects. Suppose, for example, that the\ntelecommunications giant CluNet is assessing the pros and cons of a project\nto offer some new type of high-speed access service to residential\ncustomers. Marketing research shows that the service will yield a good\namount of revenue, but it must be weighed against some costly preliminary\nprojects that would be needed in order to make this servic e possible:\nincreasing the fiber-optic capacity in the core of their network, and buying a\nnewer generation of high-speed routers.\nWhat makes these types of decisions particularly tricky is that they\ninteract in complex ways: in isolation, the revenue from the high-speed\naccess service might not be enough to justify modernizing the routers;\nhowever , once the comp any has modernized the routers, they'll also be in a\nposition to pursue a lucrative  additional project with their corporate\ncustomers; and maybe this addit ional project will tip the balance. And these\ninteractions chain together: the corporate project actually would require"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 468})","('type', 'Document')"
"('page_content', ""another expense, but this in turn would enable two other lucrat ive projects\n—and so forth. In the end, the question is: Which projects should be\npursued, and which should be passed up? It's a basic issue of balancing\ncosts incurred with profitable opportunities that are made possible.\n The Problem\nHere's a very general framewo rk for modeling a set of decisions such as\nthis. There is an underlying set P of projects,  and each project i ∊ P has an\nassociated revenue pi, which can either be positive or negative. (In other\nwords, each of the lucrative opportunities and costly infrastructure-building\nsteps in our exam ple above will be referred to as a separate proje ct.) Certain\nprojects are prerequisites for other projects, and we model this by an\nunderlying directed acyclic graph G = (P, E). The nodes of G are the\nprojects, and there is an edge (i,j) to indicate that project i can only be\nselected if project j is selected as well. Note that a project i can have many\nprerequisites, and there can be many projects that have project j as one of\ntheir prerequisites. A set of projects A ⊆ P is feasible  if the prerequisite of\nevery project in A also belongs to A: for each i ∊ A, and each edge (i,j) ∊ E,\nwe also have j ∊ A. We will refer  to requirements of this form as\nprecedence constraints.  The profit of a set of projects is defined to be\n  \nThe Project Selection Problem  is to select a feasible set of projects with\nmaximum profit.\nThis problem also became a hot topic of study in the mining literature,\nstarting in the early 1960s; here it was called the Open-Pit Mining\nProblem .3 Open-p it mining is a surface mining operation in which blocks of\nearth are extracted from the surface to retrieve the ore contained in them.\nBefore the mining operation begins, the entire area is divided into a set P of\nblocks,  and the net value pi of each block is estimated: This is the value of\nthe ore minus the processing costs, for this block considered in isolation.\nSome of these net values will be positive, others negative. The full set of"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 469})","('type', 'Document')"
"('page_content', 'blocks has precedence constraints that essentially prevent blocks from being\nextracted before  others on top of them are extracted. The Open-Pit Mining\nProblem is to determine the most profitable set of blocks to extract, subject\nto the preceden ce constraints. This problem falls into the framework of\nproject selection—each block corresponds to a separate project.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 470})","('type', 'Document')"
"('page_content', ""Designing the Algorithm\nHere we will show that the Project Selection Problem can be solved by\nreducing it to a minimum-cut computation on an extended graph G,′ defined\nanalogously to the graph we used in Section 7.10 for image segmentation.\nThe idea is to construct G′ from G in such a way that the source side of a\nminimum cut in G′ will correspond to an optimal set of projects to select.\nTo form the graph G′, we add a new source s and a new sink t to the\ngraph G as shown in Figure 7.20. For each node i ∊ P with pi > 0, we add\nan edge (i, t) with capacity pj. For each node i ∊ P with pi < 0, we add an\nedge (i, t) with capacity -pi. We will set the capacities on the edges in G\nlater. However , we can already see that the capacity of the cut ({s},P ∪ {t})\nis C = Σi ∊P:pi>0 pi, so the maximum-flow value in this network is at most C.\nWe want to ensure that if (A′,B′ ) is a minimum cut in this graph, then A\n= A′ - {s] obeys the precedence constrain ts; that is, if the node i ∊ A has an\nedge (i,j) ∊ E, then we must have j ∊ A. The conceptually cleanest way to\nensure this is to give each of the edges in G capacity of ∞. We haven't\npreviously formalized what an infinite capacity would mean, but there is no\nproblem in doing this: it is simply an edge for which the capaci ty condition\nimposes no upper bound at all. The algorithms of the previous sections, as\nwell as the Max-Flow Min-Cut Theorem, carry over to handle infinite\ncapacities. However , we can also avoid bringing in the notion of infinite\ncapacities by simply assigning  each of these edges a capacity that is\n“effectively infinite.” In our context, giving each of these edge s a capacity\nof C + 1 would accomplish this: The maximum possible flow value in G is\nat most C, and so no minimum cut can contain an edge with capacity above\nC. In the descript ion below , it will not matter which of these options we\nchoose.\nFigur e 7.20  The flow graph  used to solve the Project Selection Problem. A\npossible minimum-capacity cut is shown on the right."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 471})","('type', 'Document')"
"('page_content', 'We can now state the algorithm: We compute a minimum cut (A′, B′)\nin G, and we declare A′ - {s] to be the optim al set of projects. We now turn\nto proving that this algorithm indeed gives the optimal solution.\n Analyzing the Algorithm\nFirst consider a set of projects A that satisfies the precedence constraints.\nLet A′ = A ∪ {s} and B′ = (P-A) ∪ {t}, and consider the s-t cut (A′, B′). If\nthe set A satisfies the precedence constraints, then no edge (i,j) ∊ E crosses\nthis cut, as shown in Figure 7.20. The capacity of the cut can be expressed\nas follows.\n(7.56)  The capacity of the cut (A′, B′), as defined from a project set A satisfying  the precedence\nconstraints, is c (A′, B′ ) = C - Σi ∊A pi.\nProof. Edge s of G′ can be divided into three categories: those corresponding to the edge set E of G,\nthose leaving the source s, and those  entering the sink t. Because A satisfies the precedence\nconstraints, the edges in E do not cross the cut (A′, B′), and hence do not contribute to its capacity .\nThe edges entering the sink t contribute\n  \nto the capacity of the cut, and the edges leaving the source s contribute')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 472})","('type', 'Document')"
"('page_content', 'Using the definition of C, we can rewrite this latter quantity as C-Σi ∊A and pi>0 pi. The capac ity of\nthe cut ( A′, B′ ) is the sum of these two terms, which is\n  \nas claimed.\n▪\nNext, recall that edges of G have capacity more than C = Σi ∊P:pi>0 pi,\nand so these edges cannot cross a cut of capacity at most C. This implies\nthat such cuts define feasible sets of projects.\n(7.57)  If (A′, B′) is a cut with capacity  at most C, then the set A = A′ -{s} satisfies the precedence\nconstraints.\nNow we can prove the main goal of our construction, that the\nminimum cut in G′ determines the optimum set of projects. Putting the\nprevious two claims together , we see that the cuts (A′, B′) of capacity at\nmost C are in one-to-one correspondenc e with feasible sets of project A = A′\n-{s}. The capacity of such a cut ( A′, B′ ) is\n  \nThe capacity value C is a constant, independent of the cut ( A′, B′ ), so the cut\nwith minimum capacity correspo nds to the set of projects A with maximum\nprofit. W e have therefore proved the following.\n(7.58)  If (A′,B′ ) is a minimum cut in G then the set A = A′-{s} is an optimum solution to the Project\nSelection Pr oblem.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 473})","('type', 'Document')"
"('page_content', ""7.12 Baseball Elimination\nOver on the radio side the producer's saying, “See that thing in the\npaper last week about Einstein? …, Some reporter asked him to figur e out\nthe mathematics  of the pennant race. You know , one team wins so many of\ntheir remaining games, the other teams win this number or that number .\nWhat ar e the myriad possibilities? Who's got the edge?”\n“The hell does he know?”\n“Appar ently not much. He picked the Dodgers to eliminate the Giants\nlast Friday .”\n—Don DeLillo, Underworld\n The Problem\nSuppose you're a reporter for the Algorithmic Sporting News,  and the\nfollowing situati on arises late one September . There are four baseball teams\ntrying to finish in first place in the American League Eastern Division; let's\ncall them New York, Baltimore, Toronto, and Boston. Currently , each team\nhas the following number of wins:\nNew Y ork: 92, Baltimor e: 91, T oronto: 91, Boston: 90.\nThere are five games left in the season: These consist of all possible\npairings of the four teams above, except for New Y ork and Boston.\nThe question is: Can Boston finish with at least as many wins as every\nother team in the division (that is, finish in first place, possibly in a tie)?\nIf you think about it, you realize that the answer is no. One argument is\nthe follo wing. Clearly , Boston must win both its remaining games and New\nYork must lose both its remaining games. But this means that Baltimore and\nToronto will both beat New York; so then the winner of the Baltimore-\nToronto game will end up with the most wins.\nHere's an argument that avoids this kind of cases analysis. Boston can\nfinish with at most 92 wins. Cumulatively , the other three teams have 274\nwins currently , and their three games against each other will produce\nexactly three more wins, for a final total of 277. But 277 wins over three\nteams means that one of them must have ended up with more than 92 wins."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 474})","('type', 'Document')"
"('page_content', 'So now you might start wondering: (i) Is there an efficient algor ithm to\ndetermine whether a team has been eliminated from first place? And (ii)\nwhenever a team has been eliminated from first place, is there an\n“averaging” ar gument like this that proves it?\nIn more concrete notation, supp ose we have a set S of teams, and for\neach x e S, its current number of wins is wx. Also, for two teams x,y e S,\nthey still have to play gxy games against one another . Finally , we are given a\nspecific team z.\nWe will use maximum-flow techniques to achieve the following two\nthings. First, we give an efficient algorithm to decide whether z has been\neliminated from first place—or , to put it in positive terms, whether it is\npossible to choose outcomes for all the remaining games in such a way that\nthe team z ends with at least as many wins  as every other team in S. Second,\nwe prove the following clean characterization theorem for baseball\nelimination—essentially , that there is always a short “proof” when a team\nhas been eliminated.\n(7.59)  Suppose that team z has indeed been eliminated. Then there exists a “proof of this fact of the\nfollowing form:\nz can finish with at most m wins .\nThere is a set of teams T  ⊆ S so that\n  \n(And hence one of the teams in T must end with strictly mor e than m wins.)\nAs a second, more complex illustration of how the averaging argument\nin (7.59) works, consider the following example. Suppose we have the same\nfour teams as before, but now the current number of wins is\n  \nThe remaining games are as follows. Boston still has four games\nagainst each of the other three teams. Baltimore has one more game against\neach of New York and Toronto. And finally , New York and Toronto still')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 475})","('type', 'Document')"
"('page_content', ""have six games  left to play against each other . Clearly , things  don't look\ngood for Boston, but is it actually eliminated?\nThe answer is yes; Boston has been eliminated. To see this, first note\nthat Boston can end with at most 91 wins; and now consider the set of\nteams T = {New York, Toronto}. Together New York and Toronto already\nhave 177 wins; their six remain ing games will result in a total of 183; and \n. This means that one of them must end up with more than 91 wins,\nand so Boston can't finish in first. Interestingly , in this instance the set of all\nthree teams ahead of Boston cannot constitute a similar proof: All three\nteams taken togeher have a total of 265 wins with 8 games left among them;\nthis is a total of 273, and \n  — not enough by itself to prove that\nBoston couldn't end up in a multi-way tie for first. So it's crucial for the\naveraging argument that we choose the set T consisti ng just of New York\nand T oronto, and omit Baltimore.\n Designing and Analyzing the Algorithm\nWe begin by constructing a flow network that provides an efficient\nalgorithm for determining whether z has been eliminated. Then, by\nexamining the minimum cut in this network, we will prove (7.59).\nClearly , if there's any way for z to end up in first place, we should have\nz win all its rema ining games. Let's suppose that this leaves it with m wins.\nWe now want to carefully allocate the wins from all remaining games so\nthat no other team ends with more than m wins. Allocating wins in this way\ncan be solved by a maximum-flow computation, via the following basic\nidea. We have a source s from which all wins emanate. The ith win can pass\nthrough one of the two teams involved in the ith game. We then impose a\ncapacity constraint saying that at most m - wx wins can pass through team x.\nMore concretely , we construct the following flow network G, as shown\nin Figure 7.21. First, let S′ = S - {z}, and let g* = Σx,y ∊S′ gxy—the total\nnumber of games left between all pairs of teams in S′. We include nodes s\nand t, a node  vx for each team x ∊ S′, and a node uxy for each pair of teams\nx,y ∊  S′ with a nonzero number of game s left to play against each other . We\nhave the following edges.\nEdges (s, uxy) (wins emanate fr om s);"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 476})","('type', 'Document')"
"('page_content', ""Edges (uxy, vx) and (uxy, vy) (only x or y can win a game that they play\nagainst each other) ; and\nEdges (vx, t) (wins ar e absorbed at t) .\nLet's consider what capacities we want to place on these edges. We want gxy\nwins to flow from s to uxy at satura tion, so we give (s, uxy) a capacity of gxy.\nWe want to ensure that team x cannot win more than m - wx games, so we\ngive the edge (vx, t) a capacity of m - wx. Finally , an edge of the form (uxy,\nvy) should  have at least gxy units of capacity , so that it has the ability to\ntransport all the wins from uxy on to vx; in fact, our analysis will be the\ncleanest if we give it infinite  capacity . (We note that the construction still\nworks even if this edge is given only gxy units of capacity , but the proof  of\n(7.59) will become a little more complicated.)\nFigur e 7.21  The flow netwo rk for the second example. As the minimum cut\nindicates, there is no flow of value g*, and so Boston has been eliminated.\nNow , if there is a flow of value g*, then it is possible for the outcomes\nof all remaining games to yield a situation where no team has more than m\nwins; and hence, if team z wins all its remaining games, it can still achieve\nat least a tie for first place. Conversely , if there are outcomes for the\nremaining games in which z achieves at least a tie, we can use these\noutcomes to define a flow of value g*. For example, in Figure 7.21, which\nis based on our second example, the indicated cut shows that the maximum\nflow has value at most 7, whereas g* = 6 + 1 + 1 = 8.\nIn summary , we have shown"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 477})","('type', 'Document')"
"('page_content', '(7.60)  Team z has been eliminated if and only if the maximum flow in G has value strictly less than\ng*. Thus we can test in polynomial time whether z has been eliminated .\nCharacterizing When a Team Has Been\nEliminated\nOur netw ork flow construction can also be used to prove (7.59). The idea is\nthat the Max-Flow Min-Cut Theorem gives a nice “if and only if”\ncharacterization for the existe nce of flow, and if we interpret this\ncharacterization in terms of our application, we get the comparably nice\ncharacterization here. This illustrates a general way in which one can\ngenerate characterization theorems for problems that are reducible to\nnetwork flow .\nProof of (7.59).  Suppose that z has been elimin ated from first place. Then\nthe maximum s-t flow in G has value g′ < g* ; so there is an s-t cut (A, B) of\ncapacity g′, and (A, B) is a minimum cut. Let T be the set of teams x for\nwhich vx ∊ A. We will now prove that T can be used in the “averaging\nargument” in (7.59).\nFirst, consider the node uxy, and suppose one of x or y is not in T, but\nuxy ∊ A. Then the edge (uxy, vx) would cross from A into B, and hence the\ncut (A, B) would have infinite capacity . This contradicts the assumption that\n(A, B) is a minimum cut of capacity less than g*. So if one of x or y is not in\nT, then uxy ∊ B. On the other hand, suppose both x and y belong to T, but\nuxy ∊ B. Consider the cut (A′, B′) that we would obtain by addin g uxy to the\nset A and deleting it from the set B. The capacity of (A′, B′) is simply the\ncapacity of (A, B), minus the capacity gxy of the edge (s, uxy)—for this edge\n(s, uxy) used to cross from A to B, and now it does not cross from A′ to B′.\nBut since gxy > 0, this means  that (A′, B′) has smaller capacity than (A, B),\nagain contradicting our assumpt ion that (A, B) is a minimum cut. So, if both\nx and y belong to T, then uxy ∊ A.\nThus we have established the following conclusion, based on the fact\nthat ( A, B) is a minimum cut: uxy ∊ A if and only if both x, y ∊ T.\nNow we just need to work out the minimum-cut capacity c(A, B) in\nterms of its constituent edge capacities. By the conclusion in the previous')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 478})","('type', 'Document')"
"('page_content', 'paragraph, we know that edges crossing from A to B have one of the\nfollowing two forms:\nedges of the form ( vx, t), where x ∊ T, and\nedges of the form (s, uxy), where at least one of x or y does not belong\nto T (in other words, { x,y} ⊄ T).\nThus we have\n  \nSince we know that c(A, B) = g′ < g* , this last inequality implies\n  \nand hence\n \nFor example, applying the argument in the proof of (7.59) to the\ninstance in Figure 7.21 , we see that the nodes for New Y ork and T oronto are\non the source side of the minim um cut, and, as we saw earlier , these two\nteams indeed constitute a proof that Boston has been eliminated.\n* 7.13 A Further Direction: Adding Costs to the\nMatching Problem')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 479})","('type', 'Document')"
"('page_content', ""Let's go back to the first probl em we discussed in this chapt er, Bipartite\nMatching. Perfect matchings in a bipartite graph formed a way to model the\nproblem of pairing one kind of object with another—jobs with machines,\nfor exam ple. But in many settings, there are a large number of possible\nperfect matching s on the same set of objects, and we'd like a way to express\nthe idea that some perfect matchings may be “better” than others.\n The Problem\nA natura l way to formulate a problem based on this notion is to introduce\ncosts . It may be that we incur a certain cost to perform a given job on a\ngiven machine, and we'd like to match jobs with machines in a way that\nminimizes the total cost. Or there may be n fire trucks that must be sent to n\ndistinct houses; each house is at a given distance from each fire station, and\nwe'd like a matc hing that minimizes the average distance each truck drives\nto its associated house. In short, it is very useful to have an algorithm that\nfinds a perfect matching of minimum total cost .\nFormally , we consider a bipartit e graph G = (V, E) whose node set, as\nusual, is partitioned as V = X  ∪ Y so that every edge e ∊ E has one end in X\nand the other end in Y. Furthermore, each edge e has a nonnegative cost ce.\nFor a matching M, we say that the cost of the matching is the total cost of\nall edges in M, that is, cost(M)  = Σe ∊M ce. The Minimum-Cost Perfect\nMatching Problem  assumes that |X| = |Y| = n, and the goal is to find a\nperfect matching of minimum cost.\n Designing and Analyzing the Algorithm\nWe now describe an efficient algorithm to solve this problem, based on the\nidea of augment ing paths but adapted to take the costs into account. Thus,\nthe algorithm will iteratively construct matchings using i edges, for each\nvalue of i from 1 to n. We will show that when the algorithm concludes with\na matching of size n, it is a minimum-cost perfect matching. The high-level\nstructure of the algorithm is quite simple. If we have a minimum-cost\nmatching of size i, then we seek an augmenting path to produce a matching\nof size i + 1; and rathe r than looking for any augmenting path (as was\nsufficient in the case without costs), we use the cheapest augmenting path\nso that the lar ger matching will also have minimum cost."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 480})","('type', 'Document')"
"('page_content', 'Recall the construction of the residual graph used for finding\naugmenting paths. Let M be a matching. We add two new nodes s and t to\nthe graph. We add edges (s, x) for all nodes x ∊ X that are unmatched and\nedges ( y, t) for all nodes y ∊ Y that are unmatched. An edge e = (x, y)  ∊ E is\noriented from x to y if e is not in the matching M and from y to x if e ∊ M.\nWe will use GM to deno te this residual graph. Note that all edges going\nfrom Y to X are in the matc hing M, while the edges going from X to Y are\nnot. Any directe d s-t path P in the graph GM corresponds to a matching one\nlarger than M by swapping edges along P, that is, the edges in P from X to Y\nare added to M and all edges in P that go from Y to X are deleted from M.\nAs before, we will call a path P in GM an augmenting path , and we say that\nwe augment  the matching M using the path P.\nNow we would like the resultin g matching to have as small a cost as\npossible. To achieve this, we will search for a cheap augmenting path with\nrespect to the following natural  costs. The edges leaving s and entering t\nwill have cost 0; an edge e oriented from X to Y will have cost ce (as\nincluding this edge in the path means that we add the edge to M); and an\nedge e oriented from Y to X will have cost -ce (as including this edge in the\npath means that we delete the edge from M). We will use cost(P)  to denote\nthe cost of a path P in GM. The following statement summarizes this\nconstruction.\n(7.61)  Let M be a matching and P be a path in GM from s to t. Let M′ be the matching obtaine d from\nM by augmenting along P . Then |M′| = |M| + 1 and cost(M′) = cost(M) + cost(P) .\nGiven this statement, it is natural to suggest an algorithm to find a\nminimum-cost perfect matching: We iteratively find minimum-cost paths in\nGM, and use the paths to augment the matchings. But how can we be sure\nthat the perfect matching we find is of minimum cost? Or even worse, is\nthis algorithm even meaningful ? We can only find minimum-cost paths if\nwe know that the graph GM has no negative cycles.\nAnalyzing Negative Cycles  In fact, understanding the role of negative\ncycles in GM is the key to analyzing the algor ithm. First consider the case in\nwhich M is a perfect matching. Note that in this case the node s has no\nleaving edges, and t has no enterin g edges in GM (as our matching is\nperfect), and hence no cycle in GM contains s or t.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 481})","('type', 'Document')"
"('page_content', '(7.62)  Let M be a perfect matching. If there is a negative-cost directed cycle C in GM, then M is not\nminimum cost .\nProof. To see this, we use the cycle C for augmentation, just the same way we used directed paths to\nobtain larger matchings. Augmenting M along C involves swapping edges along C in and out of M.\nThe resulting new perfect matching M′ has cost cost(M′) = cost(M) + cost(C) ; but cost(C)  < 0, and\nhence M is not of minimum cost.\n▪\nMore importantly , the converse of this statement is true as well; so in\nfact a perfect matching M has minimum cost precisely when there is no\nnegative cycle in GM.\n(7.63)  Let M be a perfect matching. If there are no negative-cost directed cycles C in GM, then M is a\nminimum-cost perfect matching .\nProof. Suppose the stateme nt is not true, and let M′ be a perfect matching of smaller cost. Consider\nthe set of edges in one of M and M′ but not in both. Obse rve that this set of edges corresponds to a set\nof node-disjoint directed cycles in GM. The cost of the set of directed cycles is exactly cost(M′)  -\ncost(M) . Assuming M′ has smaller cost than M, it must be that at least one of these cycles has\nnegative cost.\n▪\nOur plan is thus to iterate throu gh matchings of larger and larger size,\nmaintaining the property that the graph GM has no negative cycles in any\niteration. In this way, our computation of a minimum-cost path will always\nbe well defined; and when we terminate with a perfect matching, we can\nuse (7.63) to conclude that it has minimum cost.\nMaintaining Prices on the Nodes  It will help to think about a numerical\nprice p(v) associa ted with each node v. These prices will help both in\nunderstanding how the algorithm runs, and they will also help speed up the\nimplementation. One issue we have to deal with is to maintain the property\nthat the graph GM has no negative cycles in any iteration. How do we know\nthat after an augmentation, the new residual graph still has no negative\ncycles? The prices will turn out to serve as a compact proof to show this.\nTo understand prices, it helps to keep in mind an economic\ninterpretation of them. For this purpose, consider the following scenario.\nAssume that the set X represen ts peop le who need to be assigned to do a set\nof jobs Y. For an edge e = (x, y), the cost ce is a cost associa ted with having\nperson x doing job y. Now we will think of the price p(x) as an extra bonus\nwe pay for person x to participate in this system, like a “signing bonus.”\nWith this in mind, the cost for assigning person x to do job y will become')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 482})","('type', 'Document')"
"('page_content', 'p(x) + ce. On the other hand, we will think of the price p(y) for node s y ∊ Y\nas a reward, or value gained by taking care of job y (no matter which person\nin X takes care of it). This way the “net cost” of assigning person x to do job\ny becomes p(x) + ce - p(y): this is the cost of hiring x for a bonus of p(x),\nhaving him do job y for a cost of ce, and then cashing in on the reward p(y).\nWe will call this the reduced cost of an edge e = (x, y) and denote it by \n. However , it is important to keep in mind that only the\ncosts ce are part of the problem description; the prices (bonuses and\nrewards) will be a way to think about our solution.\nSpecifically , we say that a set of numbers {p(v): v ∊ V} forms a set of\ncompatible prices  with respect to a matching M if\n(i) for all unmatched nodes x ∊ X we have p(x) = 0 (that is, people not\nasked to do any job do not need to be paid);\n(ii) for all edges e = (x, y) we have  p(x) + ce≥ p(y)  (that is, every edge has a\nnonnegative reduced cost); and\n(iii) for all edges e = (x, y) ∊ M we have  p(x) + ce = p(y) (every edge used\nin the assignment has a reduced cost of 0).\nWhy are such prices useful? Intuitively , compatible prices suggest that\nthe matc hing is cheap: Along the matched edges reward equals cost, while\non all other edges the reward is no bigger than the cost. For a partial\nmatching, this may not imply that the matching has the smallest possible\ncost for its size (it may be taking care of expensive jobs). However , we\nclaim that if M is any matching for which there exists a set of compatible\nprices, then GMhas no negative cycles. For a perfect matching M, this will\nimply that M is of minimum cost by (7.63).\nTo see why GM can have no negative cycles, we extend the definition\nof reduced cost to edges in the residual graph by using the same expression  \n for any edge e = (v, w). Observ e that the definition of\ncompatible prices implies that all edges in the residual graph GM have\nnonnegative reduced costs. Now , note that for any cycle C, we have')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 483})","('type', 'Document')"
"('page_content', ""since all the terms on the right-h and side corresponding to prices cancel out.\nWe know that each term on the right-hand side is nonnegative, and so\nclearly cost(C)  is nonnegative.\nThere is a second, algorithmic reason why it is useful to have prices on\nthe nodes. When you have a graph with negative-cost edges but no negative\ncycles, you can compute shorte st paths using the Bellman-Ford Algorithm\nin O(mn)  time. But if the graph in fact has no negative-cost edges, then you\ncan use Dijkstra's Algorithm instead, which only requires time O(m log n)\n—almost a full factor of n faster .\nIn our case, having the prices around allows us to compute shortest\npaths with respect to the nonnegative reduced costs \n , arriving at an\nequivalent answ er. Indeed, suppose we use Dijkstra's Algorithm  to find the\nminimum cost dp,M(v) of a directed path from s to every node v ∊ X ∪  Y\nsubject to the costs \n . Given the minimum costs dp,M(y) for an unmatched\nnode y ∊ Y, the (nonreduced) cost of the path from s to t through y is dp,M(y)\n+p(y) , and so we find the minimum cost in O(n)  additional time. In\nsummary , we have the following fact.\n(7.64)  Let M be a matching, and p be compatible prices. We can use one run of Dijkstra's Algorithm\nand O(n) extra time to find the minimum-cost path fr om s to t .\nUpdating the Node Prices  We took advantage of the prices to improve one\niteration of the algorithm. In order to be ready for the next iteration, we\nneed not only the minimum-cost path (to get the next matching), but also a\nway to produce a set of compatible prices with respect to the new matching.\nFigur e 7.22 A matching M (the dark edges), and a residual graph used to\nincrease the size of the matching."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 484})","('type', 'Document')"
"('page_content', ""To get some intuition on how to do this, consider an unmatched node x\nwith respect to a matching M, and an edge e = (x, y), as shown in Figure\n7.22. If the new matching M′ includes edge e (that is, if e is on the\naugmenting path we use to update the matching), then we will want to have\nthe reduced cost of this edge to be zero. However , the prices p we used with\nmatching M may result in a reduced cost \n  — that is, the assignment of\nperson x to job y, in our economic interpretatio n, may not be viewed as\ncheap enough. We can arrange the zero reduced cost by either increasing\nthe price p(y) (y's reward) by \n , or by decreasing the price p(x) by the same\namount. To keep prices nonnegative, we will increase the price p(y).\nHowever , node y may be matched in the matchin g M to some other node x′\nvia an edge e′ = (x′, y), as shown in Figure 7.22. Increasing the reward p(y)\ndecreases the reduced cost of edge e′ to negative, and hence the prices are\nno longer compatible. To keep things compatible, we can increase p(x′) by\nthe same amount. However , this change might cause problems on other\nedges. Can we update all prices and keep the matching and the prices\ncompatible on all edges? Surprisingly , this can be done quite simply by\nusing the distances from s to all other nodes computed  by Dijkstra's\nAlgorithm.\n(7.65)  Let M be a matching, let p be compatible prices, and let M′ be a matching obtained by\naugmenting along the minimum-cost path from s to t. Then p′(v) = dp,M(v) + p(v) is a compatible set\nof prices for M′ .\nProof. To prove compatibility , consider first an edge e = (x′,y) ∊  M. The only edge enter ing x′ is the\ndirected edge (y, x′), and hence \n , where \n , and\nthus we get the desired equation on such edges. Next consider edges (x,y) in M′-M . These edges are\nalong the minimum-cost path from s to t, and hence they satisfy \n  as\ndesired. Finally, we get the required inequa lity for all other edges since all edges e = (x, y) ∉  M must\nsatisfy \n .\n▪\nFinally , we have to consider how to initialize the algorithm, so as to\nget it underway . We initialize M to be the empty  set, define p(x) = 0 for all x\n∊ X, and define p(y), for y ∊ Y, to be the minim um cost of an edge entering\ny. Note that these prices are compatible with respect to M = φ.\nWe summarize the algorithm below .\nStart with M equal to the empty set"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 485})","('type', 'Document')"
"('page_content', 'Define p(x) = 0 for x ∊ X, and \n  for y ∊ Y\nWhile M is not a perfect matching\nFind a minimum-cost s-t path P in GM using (7.64) with prices p\nAugment along P to produce a new matching M′\nFind a set of compatible prices with respect to M′ via (7.65)\nEndwhile\nThe final set of compatible prices yields a proof that GM has no\nnegative cycles; and by (7.63), this implies that M has minimum cost.\n(7.66)  The minimum-cost perfect matching can be found in the time requir ed for n shortest-path\ncomputations with nonegative edge lengths .\nExtensions: An Economic Interpretation of the\nPrices\nTo conclude our discussion of the Minimum-Cost Perfect Matching\nProblem, we develop the econom ic interpretation of the prices a bit further .\nWe consider the following scenario. Assume X is a set of n people each\nlooking to buy a house, and Y is a set of n houses that they are all\nconsidering. Let v(x,y)  denote the value of house y to buyer x. Since each\nbuyer wants one of the houses,  one could argue that the best arrangement\nwould be to find a perfect matching M that maximizes Σ(x, y) ∊ M v(x,y) . We\ncan find such a perfect matc hing by using our minimum-cost perfect\nmatching algorithm with costs ce = -v(x,y)  if e = (x,y).\nThe question we will ask now is this: Can we convince these buyers to\nbuy the house they are allocated? On her own, each buyer x would want to\nbuy the house y that has maximum value v(x, y) to her. How can we\nconvince her to buy instead the house that our matching M allocated? We\nwill use prices to change the incentives of the buyers. Suppo se we set a\nprice p(y) for each house y, that is, the person buying the house y must pay\nP(y). With these prices in mind, a buyer will be interested in buying the\nhouse with maximum net value, that is, the house y that maximizes v(x,y) -\nP(y). We say that a perfect matching M and house prices P are in\nequilibrium  if, for all edges ( x,y) ∊ M and all other houses y′, we have')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 486})","('type', 'Document')"
"('page_content', ""But can we find a perfect matching and a set of prices so as to achieve this\nstate of affairs, with every buyer ending up happy? In fact, the minimum-\ncost perfect matching and an associated set of compatible prices provide\nexactly what we're looking for .\n(7.67)  Let M be a perfect matching of minimum cost, wher e ce = -v(x, y) for each edge e = (x,y), and\nlet p be a compatible  set of prices. Then the matching M and the set of prices {P(y) = -p(y) :y ∊  Y}\nare in equilibrium .\nProof. Consider an edge e = (x, y) ∊ M, and let e′ = (x, y′). Since M and p are compatible, we have\np(x) + ce =p(y)  and p(x) + ce′ ≥ p(y′). Subtracti ng these two inequalities to cancel p(x), and\nsubstituting the values of p and c, we get the desired inequality in the definition of equilibrium.\n▪\nSolved Exercises\nSolved Exercise 1\nSuppose you are given a directed graph G = (V,E), with a positive integer\ncapacity ce on each edge e, a designated source s ∊ V, and a designated sink\nt ∊ V. You are also given an integer maximum s-t flow in G, defined by a\nflow value fe on each edge e.\nNow suppose we pick a specifi c edge e ∊ E and increase its capacity\nby one unit. Show how to find a maximum flow in the resulting  capacitated\ngraph in time O(m + n), where m is the number of edges in G and n is the\nnumber of nodes.\nSolution  The point here is that O(m + n) is not enough time to compute a\nnew maximum flow from scratch, so we need to figure out how to use the\nflow f that we are given. Intuitively , even after we add 1 to the capacity of\nedge e, the flow f can't be that far from maximum; after all, we haven't\nchanged the network very much.\nIn fact, it's not hard to show that the maximum flow value can go up\nby at most 1."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 487})","('type', 'Document')"
"('page_content', ""(7.68)  Consider the flow network G′ obtained by adding  1 to the capacity of e. The value of the\nmaximum flow in G′ is either v(f) or v(f) +  1.\nProof. The value of the maximum flow in G′ is at least v(f), since f is still a feasible flow in this\nnetwork. It is also integer -valued. So it is enough to show that the maximum-flow value in G′ is at\nmost v(f) + 1.\nBy the Max-Flow Min-Cut Theorem, there is some s-t cut ( A, B) in the original flow network G\nof capacity v(f). Now we ask: What is the capacity of (A, B) in the new flow network G′? All the\nedges crossing ( A, B) have the same capacity in G′ that they did in G, with the possible exception of e\n(in case e crosses (A, B)). But ce only increased by 1, and so the capacity of (A, B) in the new flow\nnetwork G′ is at most v(f) + 1.\n▪\nStatement (7.68) suggests a natural algorithm. Starting with the\nfeasible flow f in G′, we try to find a single augmenting path from s to t in\nthe resid ual graph G′f. This takes time O(m + n). Now one of two things\nwill happen. Either we will fail to find an augmenting path, and in this case\nwe know that f is a maximum flow. Otherwise the augmentation succeeds,\nproducing a flow f′ of value at least v(f) + 1. In this case, we know by (7.68)\nthat f′ must be a maximum flow. So either way, we produce a maximum\nflow after a single augmenting path computation.\nSolved Exercise 2\nYou are helping the medical consulting firm Doctors Without Weekends set\nup the work schedules of doctor s in a large hospital. They've got the regular\ndaily schedules mainly worked out. Now , however , they need to deal with\nall the special cases and, in particular , make sure that they have  at least one\ndoctor covering each vacation day .\nHere's how this works. There are k vacation periods (e.g., the week of\nChristmas, the July 4th weekend, the Thanksgiving weekend, …), each\nspanning several contiguous days. Let Dj be the set of days included in the\njth vacation period; we will refer to the union of all these days, UjDj, as the\nset of all vacation days .\nThere are n doctors  at the hospital, and doctor i has a set of vacation\ndays Si when he or she is available to work. (This may include certain days\nfrom a given vacation period but not others; so, for example, a doctor may\nbe able to work the Friday , Saturday, or Sunday of Thanksgiving weekend,\nbut not the Thursday .)"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 488})","('type', 'Document')"
"('page_content', ""Give a polynomial-time algorithm that takes this information and\ndetermines whether it is possible to select a single doctor to work on each\nvacation day , subject to the following constraints.\nFor a given parameter c, each doctor should be assigned to work at\nmost c vacation days total, and only days when he or she is available.\nFor each vacation period j, each doctor should be assigned to work at\nmost one of the days in the set Dj. (In other words, although a\nparticular doctor  may work on several vacation days over the course of\na year, he or she should not be assigned to work two or more days of\nthe Thanksgivin g weekend, or two or more days of the July 4th\nweekend, etc.)\nThe algorithm should either return an assignment of doctors satisfying these\nconstraints or report (correctly) that no such assignment exists.\nSolution  This is a very natural setting in which to apply network flow, since\nat a high level we're trying to match one set (the doctors) with another set\n(the vacation days). The complication comes from the requirement that each\ndoctor can work at most one day in each vacation period.\nSo to begin, let's see how we'd solve the problem without that\nrequirement, in the simpler case where each doctor i has a set Si of days\nwhen he or she can work, and each doctor should be scheduled for at most c\ndays total. The construction is pictured in Figure 7.23(a) . We have a node ui\nrepresenting each doctor attached to a node Vℓ representing each day when\nhe or she can work; this edge has a capacity of 1. We attach a super -source s\nto each doctor node ui by an edge of capacity c, and we attach  each day\nnode vℓ to a super -sink t by an edge with upper and lowe r bounds of 1. This\nway, assigned days can “flow” through doctors to days when they can work,\nand the lower bounds on the edges from the days to the sink guarantee that\neach day is covered. Finally , suppose there are d vacation days total; we put\na demand of +d on the sink and -d on the source, and we look for a feasible\ncirculation. (Recall that once we've introduced lower bounds on some\nedges, the algor ithms in the text are phrased in terms of circulations with\ndemands, not maximum flow .)"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 489})","('type', 'Document')"
"('page_content', 'Figur e 7.23 (a) Doctors are assigned to holiday days without restricting\nhow many days in one holiday a doctor can work. (b) The flow network is\nexpanded with “gadgets” that prevent a doctor from working more than one\nday from each vacation period. The shaded sets correspond to the different\nvacation periods.\nBut now we have to handle the extra requirement, that each doctor can\nwork at most one day from each vacation period. To do this, we take each\npair (i,j) consisting of a doctor i and a vacation  period j, and we add a\n“vacation gadget” as follows. We include a new node wij with an incoming\nedge of capacity 1 from the doctor node ui, and with outgoing edges of\ncapacity 1 to each day in vacation period j when doctor i is available to\nwork. This gadget serves to “choke off” the flow from ui into the days\nassociated with vacation period j, so that at most one unit of flow can go to\nthem collectively . The construct ion is pictured in Figure 7.23(b) . As before,\nwe put a deman d of +d on the sink and -d on the source, and we look for a\nfeasible circulation. The total running time is the time to construct the\ngraph, which is O(nd) , plus the time to check for a single feasible\ncirculation in this graph.\nThe correctness of the algorithm is a consequence of the following\nclaim.\n(7.69)  There is a way to assign doctors to vacation days in a way that respects all constrai nts if and\nonly if ther e is a feasible cir culation in the flow network we have constructed .\nProof. First, if there is a way to assign doctors to vacation days in a way that respects all constraints,\nthen we can construct the following circulation. If doctor i work s on day ℓ of vacation period j, then\nwe send one unit of flow along the path s, ui, wij, vℓ, t; we do this for all such (i, ℓ) pairs. Since the\nassignment of doctors satisfied all the constraints, the resulting circulation respects all capacities; and\nit sends d units of flow out of s and into t, so it meets the demands.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 490})","('type', 'Document')"
"('page_content', 'Conversely , suppose there is a feasible circulation. For this direction of the proof, we will show\nhow to use the circulation to construct a schedule for all the doctors. First, by (7.52), there is a\nfeasible circulation in which all flow values are integers. We now construct the following schedule: If\nthe edge (wij, vℓ) carries a unit of flow, then we have doctor i work on day ℓ. Because of the\ncapacities, the resulting schedule has each doctor work at most c days, at most one in each vacation\nperiod, and each day is covered by one doctor .\nExercises\n1. (a) List all the minimum s-t cuts in the flow network pictured in Figure\n7.24. The capacity of each edge appears as a label next to the edge.  \n(b) What is the minimum capacity of an s-t cut in the flow network in\nFigure 7.25? Again, the capacity of each edge appears as a label next\nto the edge.  \nFigur e 7.24  What are the minimum s-t cuts in this flow network?\n \nFigur e 7.25 What is the minimum capacity of an s-t cut in this flow\nnetwork?')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 491})","('type', 'Document')"
"('page_content', '2. Figure 7.26 shows a flow network on which an s-t flow has been\ncomputed. The capacity of each edge appears as a label next to the\nedge, and the numbers in boxes  give the amount of flow sent on each\nedge. (Edges without boxed numbers—specifically , the four edges of\ncapacity 3—have no flow being sent on them.)  \n(a) What is the value of this flow? Is this a maximum (s,t) flow in this\ngraph?  \n(b) Find a minimum  s-t cut in the flow network pictured in Figure\n7.26, and also say what its capacity is.\n3. Figure 7.27 shows a flow network on which an s-t flow has been\ncomputed. The capacity of each edge appears as a label next to the\nedge, and the numbers in boxes  give the amount of flow sent on each\nedge. (Edges without boxed numbers have no flow being sent on\nthem.)  \n(a) What is the value of this flow? Is this a maximum (s,t) flow in this\ngraph?  \nFigur e 7.26 What is the value of the depict ed flow? Is it a maximum\nflow? What is the minimum cut?\n \nFigur e 7.27 What is the value of the depict ed flow? Is it a maximum\nflow? What is the minimum cut?')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 492})","('type', 'Document')"
"('page_content', ""(b) Find a minimum  s-t cut in the flow network pictured in Figure\n7.27, and also say what its capacity is.\n4. Decide whether you think the following statement is true or false. If it\nis true, give a short explanation. If it is false, give a counterexample.  \nLet G be an arbitrary flow network, with a source s, a sink t, and a positive\ninteger capacity ce on every edge e. If f is a maximum s-t flow in G, then f\nsaturates every edge out of s with flow (i.e., for all edges e out of s, we have f(e)\n= ce).\n5. Decide whether you think the following statement is true or false. If it\nis true, give a short explanation. If it is false, give a counterexample.  \nLet G be an arbitrary flow network, with a source s, a sink t, and a positive\ninteger capacity ce on every edge e; and let (A,B) be a mimimum s-t cut with\nrespect to these capacities {ce:e ∊ E}. Now suppos e we add 1 to every capacity;\nthen (A,B) is still a minimum s-t cut with respect to these new capacities  {1 + ce\n:e ∊ E}.\n6. Suppose you're a consultant for the Ergonomic Architecture\nCommission, and they come to you with the following problem.  \n \nThey're really concerned about designing houses that are “user -\nfriendly ,” and they've been having a lot of trouble with the setup of\nlight fixtures and switches in newly designed houses. Consider , for\nexample, a one-floor house with n light fixtures and n locations for\nlight switches mounted in the wall. You'd like to be able to wire up one\nswitch to contro l each light fixture, in such a way that a person at the\nswitch can see the light fixture being controlled."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 493})","('type', 'Document')"
"('page_content', ""Figur e 7.28 The floor plan in (a) is ergonomic, because we can wire\nswitches to fixtures in such a way that each fixture is visible from the\nswitch that controls it. (This can be done by wiring switch 1 to a,\nswitch 2 to b, and switch 3 to c.) The floor plan in (b) is not\nergonomic, because no such wiring is possible.\n \nSometimes this is possible and sometimes it isn't. Consider the two\nsimple floor plans for houses in Figure 7.28. There are three light\nfixtures (labeled a, b, c) and three switches (labeled 1, 2, 3). It is\npossible to wire switches to fixtures in Figure 7.28(a)  so that every\nswitch has a line of sight to the fixture, but this is not possible in\nFigure 7.28(b) . \nLet's call a floor plan, together  with n light fixture locations and n\nswitch locations, ergonomic  if it's possible to wire one switch to each\nfixture so that every fixture is visible from the switch that controls it.\nA floor plan will be represented by a set of m horizontal or vertical line\nsegments in the plane (the walls), where the ith wall has endpoints (xi,\nyi), (x′i, y′i). Each of the n switches and each of the n fixtures is given\nby its coordinates in the plane. A fixture is visible  from a switch if the\nline segment joining them does not cross any of the walls.  \nGive an algorith m to decide if a given floor plan is ergonomic. The\nrunning time should be polynom ial in m and n. You may assume that\nyou have a subroutine with O(1) running time that takes two line\nsegments as input and decides whether or not they cross in the plane.\n7. Consider a set of mobile computing clients in a certain town who each\nneed to be connected to one of several possible base stations . We'll"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 494})","('type', 'Document')"
"('page_content', ""suppose there are n clients, with the position of each client specified by\nits (x,y) coordinates in the plane. There are also k base stations; the\nposition of each of these is specified by ( x,y) coordinates as well.  \nFor each client, we wish to connect it to exactly one of the base\nstations. Our choice of connections is constrained in the following\nways.  \nThere is a range parameter r —a client can only be connected to a base\nstation that is within distance r. There is also a load parameter L—no\nmore than L clients can be connected to any single base station.  \nYour goal is to design a polynomial-time algorithm for the following\nproblem. Given  the positions of a set of clients and a set of base\nstations, as well as the range and load parameters, decide whether\nevery client can be connected simultaneously to a base station, subject\nto the range and load conditions in the previous paragraph.\n8. Statistically , the arrival of spring typically results in increased\naccidents and increased need for emer gency medical treatment, which\noften requires blood transfusions. Consider the problem faced by a\nhospital that is trying to evaluate whether its blood supply is suf ficient.  \nThe basic rule for blood donat ion is the following. A person 's own\nblood supply has certain antigens  present (we can think of antigens as\na kind of molecular signature); and a person cannot receive blood with\na partic ular antigen if their own blood does not have this antigen\npresent. Concretely , this principle underpins the division of blood into\nfour types : A, B, AB, and O. Blood of type A has the A antigen, blood\nof type B has the B antigen, blood of type AB has both, and blood of\ntype O has neither . Thus, patients with type A can receive only blood\ntypes A or O in a transfusion, patients with type B can receive only B\nor O, patients with type O can receive only O, and patients with type\nAB can receive any of the four types.4 \n(a) Let sO, sA, sB, and sAB denote the supply in whole units of the\ndifferent blood types on hand.  Assume that the hospital knows the\nprojected deman d for each blood type dO, dA, dB, and dAB for the\ncoming week. Give a polynomial-time algorithm to evaluate if the\nblood on hand would suf fice for the projected need.  \n(b) Consider the following example. Over the next week, they expect\nto need at most 100 units of blood. The typical distribution of blood\ntypes in U.S. patients is roughly  45 percent type O, 42 percent type A,"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 495})","('type', 'Document')"
"('page_content', ""10 percent type B, and 3 percent type AB. The hospital wants to know\nif the blood supply it has on hand would be enough if 100 patients\narrive with the expected type distribution. There is a total of 105 units\nof blood on hand. The table below gives these demands, and the\nsupply on hand.  \n \nIs the 105 units of blood on hand enough to satisfy the 100 units of\ndemand? Find an allocation that satisfies the maximum possible\nnumber of patients. Use an ar gument based on a minimum-capacity cut\nto show  why not all patients can receive blood. Also, provide an\nexplanation for this fact that would be understandable to the clinic\nadministrators, who have not taken a course on algorithms. (So, for\nexample, this explanation should not involve the words flow, cut, or\ngraph  in the sense we use them in this book.)\n9. Network flow issues come up in dealing with natural disasters and\nother crises, since major unexpected events often require the\nmovement and evacuation of large numbers of people in a short\namount of time.  \nConsider the following scenar io. Due to large-scale flooding in a\nregion, paramedics have identifi ed a set of n injured people distributed\nacross the region who need to be rushed to hospitals. There are k\nhospitals in the region, and each of the n people needs to be brought to\na hospit al that is within a half-hour's driving time of their current\nlocation (so different people will have different options for hospitals,\ndepending on where they are right now).  \nAt the same time, one doesn't want to overload any one of the hospitals\nby sending too many patients its way. The paramedics are in touch by\ncell phone, and they want to collectively work out whether they can\nchoose a hospital for each of the injured people in such a way that the\nload on the hospitals is balanced : Each hospital receives at most ⌈n/k ⌉\npeople."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 496})","('type', 'Document')"
"('page_content', ""Give a polynomial-time algorithm that takes the given information\nabout the people's locations and determines whether this is possible.\n10. Suppose you are given a directed graph G = (V, E), with a positive\ninteger capacity ce on each edge e, a sourc e s ∊ V, and a sink t ∊ V.\nYou are also given a maximum s-t flow in G, defined  by a flow value\nfe on each edge e. The flow f is acyclic : There is no cycle in G on\nwhich all edges carry positive flow . The flow f is also integer -valued.  \nNow suppose we pick a specific edge e* ∊  E and reduce its capacity\nby 1 unit. Show how to find a maximum flow in the resulting\ncapacitated graph in time O(m + n) , where m is the number of edges in\nG and n is the number of nodes.\n11. Your friends have written a very fast piece of maximum-flow code\nbased on repeatedly finding augmenting paths as in Section 7.1.\nHowever , after you've looked at a bit of output from it, you realize that\nit's not always finding a flow of maximum  value. The bug turns out to\nbe pretty easy to find; your friends hadn't really gotten into the whole\nbackward-edge thing when writing the code, and so their\nimplementation builds a variant of the residual graph that only includes\nthe forwar d edges . In other words, it searches for s-t paths in a graph  \nconsisting only of edges e for which f(e) < ce, and it terminates when\nthere is no augm enting path consisting entirely of such edges. We'll\ncall this the Forward-Edge-Only Algorithm. (Note that we do not try to\nprescribe how this algorithm chooses its forward-edge paths; it may\nchoose them in any fashion it wants, provided that it terminates only\nwhen there are no forward-edge paths.)  \nIt's hard to conv ince your friends they need to reimplement the code.\nIn addition to its blazing speed, they claim, in fact, that it never returns\na flow whose value is less than a fixed fraction of optimal. Do you\nbelieve this? The crux of their claim can be made precise in the\nfollowing statement.  \nThere is an absolute constant b > 1 (independent of the particular input flow\nnetwork), so that on every instance of the Maximum-Flow Problem, the Forwar d-\nEdge-Only Algorithm  is guaranteed to find a flow of value at least  1/b times the\nmaximum-flow value (r egardless of how it chooses its forwar d-edge paths) .\n \nDecide whether you think this statement is true or false, and give a"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 497})","('type', 'Document')"
"('page_content', 'proof of either the statement or its negation.\n12. Consider the following problem . You are given a flow network with\nunit-capacity edges: It consists of a directed graph G = (V, E), a source\ns ∊ V, and a sink t ∊ V; and ce = 1 for every e ∊ E. You are also given\na parameter k. \nThe goal is to delete k edges so as to reduce the maximum s-t flow in\nG by as much as possible. In other words, you should find a set of\nedges F ⊆ E so that |F| = k and the maximum s-t flow in G′ = (V, E -\nF) is as small as possible subject to this.  \nGive a polynomial-time algorithm to solve this problem.\n13. In a standard s-t Maximum-Flow  Problem, we assume edges have\ncapacities, and there is no limit on how much flow is allowed to pass\nthrough a node. In this probl em, we consider the variant of the\nMaximum-Flow and Minimum-Cut problems with node capacities.  \nLet G = (V, E) be a directed graph, with source s ∊ V, sink t ∊ V, and\nnonnegative node capacities {cv ≥ 0} for each v ∊ V. Given a flow f in\nthis graph, the flow though a node v is defined as fin(v). We say that a\nflow is feasible if it satisfies the usual flow-conservation constraints\nand the node-capacity constraints: fin(v) ≤ cv for all nodes.  \nGive a polynomial-time algorithm to find an s-t maximum flow in such\na node- capacitated network. Define an s-t cut for node-capacitated\nnetworks, and show that the analogue of the Max-Flow Min-Cut\nTheorem holds true.\n14. We define the Escape Problem  as follows. We are given a directed\ngraph G = (V, E) (picture a netw ork of roads). A certain collection of\nnodes X ⊂ V are designated as populated nodes , and a certain other\ncollection S ⊂ V are designated as safe nodes . (Assume that X and S\nare disjoint.) In case of an emer gency , we want evacuation route s from\nthe popu lated nodes to the safe nodes. A set of evacuation routes is\ndefined as a set of paths in G so that (i) each node in X is the tail of one\npath, (ii) the last node on each path lies in S, and (iii) the paths do not\nshare any edges. Such a set of paths gives a way for the occupants of\nthe populated nodes to “escape” to S, without overly congesting any\nedge in G. \n(a) Given G, X, and S, show how to decide in polynomial time whether\nsuch a set of evacuation routes exists.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 498})","('type', 'Document')"
"('page_content', ""(b) Suppose we have exactly the same problem as in (a), but we want\nto enfor ce an even stronger version of the “no congestion” condition\n(iii). Thus we change (iii) to say “the paths do not share any nodes.”  \nWith this new condition, show how to decide in polynomial time\nwhether such a set of evacuation routes exists.  \nAlso, provide an example with the same G, X, and S, in which the\nanswer is yes to the question in (a) but no to the question in (b).\n15. Suppose you and your friend Alanis live, together with n - 2 other\npeople, at a popular off-campus cooperative apartment, the Upson\nCollective. Over the next n nights, each of you is supposed to cook\ndinner for the co-op exactly once, so that someone cooks on each of\nthe nights.  \nOf course, everyone has schedu ling conflicts with some of the nights\n(e.g., exams, concerts, etc.), so deciding who should cook on which\nnight becomes a tricky task. For concreteness, let's label the people  \n  \nthe nights  \n  \nand for person pi, there's a set of nights Si ⊂ {d1, …,dn} when they are\nnot able to cook.  \nA feasible dinner schedule  is an assignmen t of each person  in the coop\nto a different night, so that each person cooks on exactly one night,\nthere is someone cooking on each night, and if pi cooks on night dj\nthen dj ∉ Si. \n(a) Describe a bipartite graph G so that G has a perfect matching if and\nonly if there is a feasible dinner schedule for the co-op.  \n(b) Your friend Alanis takes on the task of trying to construct a feasible\ndinner schedule. After great effort, she constructs what she claims is a\nfeasible schedule and then heads of f to class for the day ."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 499})","('type', 'Document')"
"('page_content', ""Unfortunately , when you look at the schedule she created, you\nnotice a big problem. n - 2 of the peop le at the co-op are assigned to\ndifferent nights on which they are available: no problem there. But for\nthe other two people, pi and pj, and the other two days, dk and dℓ, you\ndiscover that she has accidental ly assigned both pi and pj to cook on\nnight dk, and assigned no one to cook on night dℓ.\nYou want to fix Alanis's mistake but without having to recompu te\neverything from  scratch. Show that it's possible, using her “almost\ncorrect” schedule, to decide in only O(n2) time whether there exists a\nfeasible dinner schedule for the co-op. (If one exists, you should also\noutput it.)\n16. Back in the euph oric early days of the Web, people liked to claim that\nmuch of the enormous potential  in a company like Yahoo! was in the\n“eyeballs”—the simple fact that millions of people look at its pages\nevery day. Further , by convincin g people to register personal data with\nthe site, a site like Yahoo! can show each user an extremely targeted\nadvertisement whenever he or she visits the site, in a way that TV\nnetworks or magazines couldn't hope to match. So if a user has told\nYahoo! that he or she is a 20-year -old computer science majo r from\nCornell University , the site can present a banner ad for apartments in\nIthaca, New York; on the other hand, if he or she is a 50-year -old\ninvestment bank er from Greenwich, Connecticut, the site can display a\nbanner ad pitching Lincoln T own Cars instead.  \nBut deciding on which ads to show to which people involves some\nserious computation behind the scenes. Suppose that the managers of a\npopular Web site have identifie d k distinct demographic groups  G1,\nG2, …, Gk. (These  groups can overlap; for example, G1 can be equal to\nall residents of New York State, and G2 can be equal to all people with\na degree in computer science.) The site has contracts with m different\nadvertisers , to show  a certain number of copies of their ads to users of\nthe site. Here's what the contract with the ith advertiser looks like.  \n \nFor a subset Xi ⊆ {G1, …, Gk} of the demographic groups,\nadvertiser i wants its ads shown only to users who belong to at\nleast one of the demographic groups in the set Xi."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 500})","('type', 'Document')"
"('page_content', ""For a number ri, advertiser i wants its ads shown to at least ri\nusers each minute.\n \n \nNow consider the problem of designing a good advertising policy —a\nway to show a single ad to each user of the site. Suppose at a given\nminute, there are n users visiting the site. Because we have registration\ninformation on each of these users, we know that user; (for j = 1,2,\n…,n) belong s to a subset Uj ⊆ {G1, …, Gk} of the demographic\ngroups. The problem is: Is there  a way to show a single ad to each user\nso that the site's contracts with each of the m advertisers is satisfied for\nthis minute? (That is, for each i = 1,2, …,m, can at least ri of the n\nusers, each belonging to at least one demographic group in Xi, be\nshown an ad provided by advertiser i?) \nGive an efficient algorithm to decide if this is possible, and if so, to\nactually choose an ad to show each user .\n17. You've been called in to help some network administrators diagnose\nthe extent of a failure in their network. The network is designed to\ncarry traffic from a designated source node s to a designated target\nnode t, so we will model the network as a directed graph G = (V, E), in\nwhich the capac ity of each edge  is 1 and in which each node lies on at\nleast one path from s to t. \nNow , when everything is running smoothly in the network, the\nmaximum s-t flow in G has value k. However , the current situation\n(and the reason you're here) is that an attacker has destroyed some of\nthe edges in the network, so that there is now no path from s to t using\nthe remaining (surviving) edge s. For reasons that we won't go into\nhere, they believe the attacker has destroyed only k edges, the\nminimum number needed to separate s from t (i.e., the size of a\nminimum s-t cut); and we'll assume they're correct in believing this.  \nThe netw ork administrators are running a monitoring tool on node s,\nwhich has the following behavior . If you issue the command ping(v) ,\nfor a given node v, it will tell you whether there is currently a path\nfrom s to v. (So ping(t ) reports that no path currently exists; on the\nother hand, ping(s ) always reports a path from s to itself .) Since it's not\npractical to go out and inspect every edge of the network, they'd like to"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 501})","('type', 'Document')"
"('page_content', ""determine the extent of the failure using this monitoring tool, through\njudicious use of the ping command.  \nSo here's the problem you face: Give an algorithm that issues a\nsequence of ping commands to various nodes in the network and then\nreports the full set of nodes that are not currently reachable from s. You\ncould do this by pinging every node in the network, of course, but\nyou'd like to do it using many fewer pings (given the assumption that\nonly k edges have been deleted). In issuing this sequence, your\nalgorithm is allowed to decide which node to ping next based on the\noutcome of earlier ping operations.  \nGive an algorith m that accomplishes this task using only O(k log n)\npings.\n18. We consider the Bipartite Match ing Problem on a bipartite graph G =\n(V,E). As usual, we say that V is partitioned into sets X and Y, and each\nedge has one end in X and the other in Y. \nIf M is a matching in G, we say that a node y ∊ Y is cover ed by M if y\nis an end of one of the edges in M. \n(a) Consider the following problem . We are given G and a matching M\nin G. For a given number k, we want to decide if there is a matching\nM′ in G so that  \n(i) M′ has k more edges than M does, and\n(ii) every node y ∊ Y that is covered by M is also covered by M′.\nWe call this the Coverage Expansion Problem , with input G, M, and k.\nand we will say that M′ is a solution  to the instance.\nGive a polynomial-time algorithm that takes an instance of\nCoverage Expansion and either returns a solution M′ or reports\n(correctly) that there is no solution. (You should include an\nanalysis of the running time and a brief proof of why it is correct.)\nNote:  You may wish to also look at part (b) to help in thinking about\nthis.\nExample.  Consider Figure 7.29, and suppose M is the matching\nconsisting of the edge (x1, y2). Suppose we are asked the above\nquestion with k = 1.\nThen the answer to this instance of Coverage Expansion is yes.\nWe can let M′ be the matching consisting (for example) of the two\nedges (x1,y2) and (x2,y4); M′ has one more edge than M, and y2 is\nstill covered by M′."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 502})","('type', 'Document')"
"('page_content', 'Figur e 7.29  An instance of Coverage Expansion.\n(b) Give an example of an instance  of Coverage Expansion, specified\nby G, M, and k, so that the following situation happens.\nThe instanc e has a solution; but in any solution M′, the edges of M do not form a\nsubset of the edges of M′.\n(c) Let G be a bipartite graph, and let M be any matching in G.\nConsider the following two quantities.\n- K1 is the size of the largest matching M′ so that every node y\nthat is covered by M is also covered by M′.\n- K2 is the size of the lar gest matching M"" in G.\nClearly K1 ≤ K2, since K2 is obtained by considering all possible\nmatchings in G.\nProve that in fact K1 = K2; that is, we can obtain a maxi mum\nmatching even if we\'re constrained to cover all the nodes covered\nby our initial matching M.\n19. You\'ve periodically helped the medical consulting firm Doctors\nWithout Weekends on various hospital scheduling issues, and they\'ve\njust come to you with a new problem. For each of the next n days, the\nhospital has determined the number of doctors they want on hand;\nthus, on day i, they have a requirement that exactly pi doctors be\npresent.  \nThere are k doctors, and each is asked to provide a list of days on\nwhich he or she is willing to work. Thus doctor j provides a set Lj of\ndays on which he or she is willing to work.\nThe system produced by the consulting firm should take these\nlists and try to return to each doctor j a list Lj with the following')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 503})","('type', 'Document')"
"('page_content', 'properties.\n(A) Lj′ is a subset of Lj, so that doctor j only works on days he or she\nfinds acceptable.\n(B) If we consid er the whole set of lists L′1, …,L′k, it causes exactly\npidoctors to be present on day i, for i = 1,2, …, n.\n(a) Describe a polynomial-time algorithm that implements this system.\nSpecifically , give a polynomial-time algorithm that takes the numbers\np1,p2, …, pn, and the lists L1, …,Lk, and does one of the following two\nthings.\n- Return lists L1′, L′2, …, L′k satisfying properties (A) and (B); or\n- Report (correctly) that there is no set of lists L′1, L′2, …,L′k that\nsatisfies both properties (A) and (B).\n(b) The hospital finds that the doctors tend to submit lists that are\nmuch too restrictive, and so it often happens that the system reports\n(correctly , but unfortunately) that no acceptable set of lists L′1,L′2, …,\nL′k exists.\nThus the hospital relaxes the requirements as follows. They add a\nnew parameter c > 0, and the system now shoul d try to return to\neach doctor j a list L′j with the following properties.\n(A*) L′j contains at most c days that do not appear on the list Lj.\n(B) ( Same as befor e) If we consider the whole set of lists L′1, …,L′k, it\ncauses exactly Pi doctors to be present on day i, for i = 1,2, …, n.\nDescribe a polynomial-time algorithm that implements this\nrevised system. It should take the numbers P1,p2, …,pn, the lists\nL1, …,Lk, and the parameter c > 0, and do one of the following\ntwo things.\n- Return lists L′1,L′2, …, L′k satisfying properties (A*) and (B); or\n- Report (correctly) that there is no set of lists L′1′1,L′2, …,L′k that\nsatisfies both properties (A*) and (B).\n20. Your friends are involved in a large-scale atmospheric science\nexperiment. They need to get good measurements on a set S of n\ndifferent condit ions in the atmosphere (such as the ozone level at\nvarious places), and they have a set of m balloons that they plan to')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 504})","('type', 'Document')"
"('page_content', ""send up to make these measurements. Each balloon can make at most\ntwo measurements.  \nUnfortunately , not all balloons are capable of measuring all\nconditions, so for each balloon i=1, …,m, they have a set Si of\nconditions that balloon i can measure. Finally , to make the results more\nreliable, they plan to take each measurement from at least k different\nballoons. (Note that a single balloon should not measure the same\ncondition twice.) They are having trouble figuring out which\nconditions to measure on which balloon.\nExample.  Suppose that k = 2, there are n = 4 conditions labeled\nC1,c2,c3,c4, and there are m = 4 balloons that can measure conditions,\nsubject to the limitation that S1 = S2 = {q,c2,c3}, and S3 = S4 = {q,\nc3,c4}. Then one possible way to make sure that each condition is\nmeasured at least k = 2 times is to have\nballoon 1 measure conditions c1,c2,\nballoon 2 measure conditions c2,c3,\nballoon 3 measure conditions c3,c4, and\nballoon 4 measure conditions c1, c4.\n(a) Give a polynomial-time algor ithm that takes the input to an\ninstance of this problem (the n conditions, the sets Si for each of the m\nballoons, and the parameter k) and decides whether there is a way to\nmeasure each condition by k different balloons, while each balloon\nonly measures at most two conditions.\n(b) You show your friends a solut ion computed by your algorithm\nfrom (a), and to your surprise they reply , “This won't do at all—one of\nthe conditions is only being measured by balloons from a single\nsubcontractor .” You hadn't heard anything about subcontractors before;\nit turns out there's an extra wrinkle they for got to mention. …\nEach of the balloons is produced by one of three different\nsubcontractors involved in the experiment. A requirement of the\nexperiment is that there be no condition for which all k measurements\ncome from balloons produced by a single subcontractor .\nFor example, suppose balloon 1 comes from the first\nsubcontractor , balloons 2 and 3 come from the second subcontractor ,\nand balloon 4 comes from the third subcontractor . Then our previous"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 505})","('type', 'Document')"
"('page_content', ""solution no longer works, as both of the measurements for condition c3\nwere done by balloons from the second subcontractor . However , we\ncould use balloons 1 and 2 to each measure conditions c1, c2, and use\nballoons 3 and 4 to each measure conditions c3,c4.\nExplain how to modify your polynomial-time algorithm for part\n(a) into a new algorithm that decides whether there exists a solution\nsatisfying all the conditions from  (a), plus the new requiremen t about\nsubcontractors.\n21. You're helping to organize a class on campus that has decided to give\nall its students wireless laptop s for the semester . Thus there is a\ncollection of n wireles s laptops; there is also have a collection of n\nwireless access points,  to whic h a laptop can connect when it is in\nrange.  \nThe laptops are currently scattered across campus; laptop ℓ is\nwithin range of a set Sℓ of access points. We will assume that each\nlaptop is within range of at least one access point (so the sets Sℓ are\nnonempty); we will also assume that every access point p has at least\none laptop within range of it.\nTo make sure that all the wireless connectivity software is\nworking correct ly, you need to try having laptops make conta ct with\naccess points in such a way that each laptop and each access point is\ninvolved in at least one connection. Thus we will say that a test set T  is\na collection of ordered pairs of the form (ℓ,p), for a laptop ℓ and access\npoint p, with the properties that\n(i) If ( ℓ,p) ∊ T, then ℓ is within range of p (i.e., p ∊ Sℓ).\n(ii) Each laptop appears in at least one ordered pair in T.\n(iii) Each access point appears in at least one ordered pair in T.\nThis way, by trying out all the connections specified by the pairs in T,\nwe can be sure that each laptop and each access point have correctly\nfunctioning software.\nThe problem is: Given the sets Sℓ for each laptop  (i.e., which\nlaptops are within range of which access points), and a number k,\ndecide whether there is a test set of size at most k.\nExample.  Suppose that n = 3; laptop 1 is within range of access points\n1 and 2; laptop 2 is within range of access point 2; and laptop 3 is\nwithin range of access points 2 and 3. Then the set of pairs"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 506})","('type', 'Document')"
"('page_content', ""(laptop 1, access point 1), (laptop 2, access point 2), (laptop 3, access point 3 )\nwould form a test set of size 3.\n(a) Give an exampl e of an instance  of this problem for which there is\nno test set of size n. (Recall that we assume each laptop is within range\nof at least one access point, and each access point p has at least one\nlaptop within range of it.)\n(b) Give a polynomial-time algorithm that takes the input to an\ninstance of this problem (including the parameter k) and decides\nwhether there is a test set of size at most k.\n22. Let M be an n × n matrix with each entry equal to either 0 or 1. Let mij\ndenote the entry in row i and column j. A diagonal entry  is one of the\nform mii for some i. \nSwapping  rows i and; of the matrix M denotes the following\naction: we swap the values mik and mjk for k = 1,2, …, n. Swapping\ntwo columns is defined analogously .\nWe say that M is rearrangeable  if it is possible to swap some of\nthe pairs of rows and some of the pairs of columns (in any sequence)\nso that, after all the swapping, all the diagonal entries of M are equa l to\n1.\n(a) Give an exampl e of a matrix M that is not rearrangeable, but for\nwhich at least one entry in each row and each column is equal to 1.\n(b) Give a polynomial-time algorithm that determines whether a\nmatrix M with 0-1 entries is rearrangeable.\n23. Suppose you're looking at a flow network G with source s and sink t,\nand you want to be able to express something like the following\nintuitive notion: Some nodes are clearly on the “source side” of the\nmain bottleneck s; some nodes are clearly on the “sink side” of the\nmain bottlenecks; and some nodes are in the middle. However , G can\nhave many minimum cuts, so we have to be careful in how we try\nmaking this idea precise.  \nHere's one way to divide the nodes of G into three categories of\nthis sort.\nWe say a node v is upstr eam if, for all minimum s-t cuts (A, B),\nwe have v ∊ A-that is, v lies on the source side of every minimum\ncut."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 507})","('type', 'Document')"
"('page_content', ""We say a node v is downstr eam if, for all minimum s-t cuts (A, B),\nwe have v ∊ B-that is, v lies on the sink side of every minimum\ncut.\nWe say a node v is central  if it is neith er upstream nor\ndownstream; there is at least one minimum s-t cut (A, B) for\nwhich v ∊ A, and at least one minimum s-t cut ( A′, B′ ) for which v\n∊ B′.\nGive an algorithm that takes a flow network G and classifies each\nof its nodes as being upstream, downstream, or central. The running\ntime of your algorithm should be within a constant factor of the time\nrequired to compute a single  maximum flow .\n24. Let G = (V, E) be a directed graph, with source s ∊ V, sink t ∊ V, and\nnonnegative edge capacities { ce}. Give a polyno mial-time algorithm to\ndecide whether G has a unique  minimum s-t cut (i.e., an s-t of capacity\nstrictly less than that of all other s-t cuts).\n25. Suppose you live in a big apartment with a lot of friends. Over the\ncourse of a year , there are many occasions when one of you pays for an\nexpense shared by some subset of the apartment, with the expectation\nthat everything will get balance d out fairly at the end of the year. For\nexample, one of you may pay the whole phone bill in a given month,\nanother will occasionally make communal grocery runs to the nearby\norganic food emporium, and a third might sometimes use a credit card\nto cover the whole bill at the local Italian-Indian restaurant, Little Idli.  \nIn any case, it's now the end of the year and time to settle up.\nThere are n people in the apartment; and for each ordered pair (i,j)\nthere's an amount aij ≥ 0 that i owes j, accumulated over the course of\nthe year. We will require that for any two people i and j, at least one of\nthe quantities aij or aji is equal  to 0. This can be easily made to happen\nas follows: If it turns out that i owes j a positive amount x, and; owes i\na positive amount y < x, then we will subtract off y from both sides and\ndeclare aij = x-y while aji = 0. In terms of all these quantities, we now\ndefine the imbalance  of a person i to be the sum of the amounts that i\nis owed by everyone else, minus the sum of the amounts that i owes\neveryone else. (Note that an imbalance can be positive, negative, or\nzero.)"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 508})","('type', 'Document')"
"('page_content', ""In order to resto re all imbalances to 0, so that everyone departs on\ngood terms, certain people will write checks to others; in other words,\nfor certain ordered pairs (i,j), i  will write a check to j for an amount bij\n> 0.\nWe will say that a set of checks constitutes a reconciliation  if, for each\nperson i, the total value of the checks received by i, minus the total\nvalue of the checks written by i, is equal  to the imbalance of i. Finally ,\nyou and your friends feel it is bad form for i to write j a check if i did\nnot actually owe j money , so we say that a reconciliation is consistent\nif, whenever i writes a check to j, it is the case that aij > 0.\nShow that, for any set of amoun ts aji there is always  a consistent\nreconciliation in which at most n - 1 checks get written, by giving a\npolynomial-time algorithm to compute such a reconciliation.\n26. You can tell that cellular phones are at work in rural commu nities,\nfrom the giant microwave towers you sometimes see sprouting  out of\ncorn fields and cow pastures. Let's consider a very simplified model of\na cellular phone network in a sparsely populated area.  \nWe are given the locations of n base stations,  specified as points\nb1, …, bn in the plane. We are also given the locations of n cellular\nphones, specified as points p1, …,pn in the plane. Finally, we are given\na range parameter  Δ > 0. We call the set of cell phones fully connected\nif it is possible to assign each phone to a base station in such a way\nthat\nEach phone is assigned to a dif ferent base station, and\nIf a phone at Pi is assigned to a base station at bj then the straigh t-\nline distance between the points Pi and bj is at most Δ.\nSuppose that the owner of the cell phone at point P1 decides to go\nfor a drive, trave ling continuously for a total of z units of distance due\neast. As this cell phone moves, we may have to update the assignment\nof phones to base stations (possibly several times) in order to keep the\nset of phones fully connected.\nGive a polynomial-time algorith m to decide whether it is possible\nto keep the set of phones fully connected at all times during the travel\nof this one cell phone. (You should assume that all other phones\nremain stationar y during this travel.) If it is possible, you should report\na sequence of assignments of phones to base stations that will be"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 509})","('type', 'Document')"
"('page_content', ""sufficient in order to maintain full connectivity; if it is not possible,\nyou should report a point on the traveling phone's path at which full\nconnectivity cannot be maintained.\nYou should try to make your algorithm run in O(n3) time if\npossible.\nExample.  Suppos e we have phones at P1 = (0, 0) and p2 =(2,1); we\nhave base stations at b1 = (1,1) and b2 = (3,1); and Δ = 2. Now\nconsider the case in which the phone at p1 moves due east a distance of\n4 units, ending at (4,0). Then it is possible to keep the phones fully\nconnected during this motion: We begin by assigning p1 to b1 and p2 to\nb2, and we reassign p1 to b2 and p2 to b1 during the motion (for\nexample, when p1 passes the point (2, 0)).\n27. Some of your friends with jobs out West decide they really need some\nextra time each day to sit in front of their laptops, and the morning\ncommute from Woodside to Palo Alto seems like the only option. So\nthey decide to carpool to work.  \nUnfortunately , they all hate to drive, so they want to make sure\nthat any carpool arrangement they agree upon is fair and doesn't\noverload any individual with too much driving. Some sort of simple\nround-robin scheme is out, because none of them goes to work every\nday, and so the subset of them in the car varies from day to day .\nHere's one way to define fairness.  Let the people be labeled S =\n{p1, …,pk}. We say that the total driving obligation  of pj over a set of\ndays is the expected number of times that pj would have driven, had a\ndriver been chosen uniformly at random from among the people going\nto work each day. More concretely , suppose the carpool plan lasts for d\ndays, and on the ith day a subset Si ⊆ S of the people go to work. Then\nthe above definition of the total driving obligation Δj for pj can be\nwritten as \n . Ideally , we'd like to require that pj drives at\nmost Δj times; unfortunately , Δj may not be an integer .\nSo let's say that a driving schedule  is a choice of a driver for each\nday-that is, a sequence pi,pi2, …,pid with pit ∊ St-and that a fair driving\nschedule  is one in which each pj is chose n as the driver on at most [Δj]\ndays."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 510})","('type', 'Document')"
"('page_content', ""(a) Prove that for any sequence of sets S1, …,Sd, there exists a fair\ndriving schedule.\n(b) Give an algorithm to compute a fair driving schedule with running\ntime polynomial in k and d.\n28. A group of students has decided to add some features to Corne ll's on-\nline Course Management System (CMS), to handle aspects of course\nplanning that are not currentl y covered by the software. They're\nbeginning with a module that helps schedule office hours at the start of\nthe semester . \nTheir initial prototype works as follows. The office hour schedule\nwill be the same  from one week  to the next, so it's enough to focus on\nthe scheduling problem for a single week. The course administrator\nenters a collection of nonoverlapping one-hour time intervals\nI1,I2,…,Ik when it would be possible for teaching assistants (TAs) to\nhold office hours; the eventual office-hour schedule will consi st of a\nsubset of some, but generally not all, of these time slots. Then each of\nthe TAs enters his or her weekly schedule, showing the times when he\nor she would be available to hold of fice hours.\nFinally , the course administrator specifies, for parameters a, b,\nand c, that they woul d like each TA to hold between a and b office\nhours per week, and they would like a total of exactly c office hours to\nbe held over the course of the week.\nThe problem, then, is how to assign each TA to some of the\noffice-hour time slots, so that each TA is available for each of his or\nher office-hour slots, and so that the right number of office hours gets\nheld. (There should be only one T A at each of fice hour .)\nExample.  Suppose there are five possible time slots for of fice hours:\nI1 = Mon 3–4 P .M.; I 2 = Tue 1–2 P .M.; I 3 = Wed 10–1 1 A.M.; I 4 = Wed 3–4 P.M.;\nand I 5 = Thu 10–1 1 A.M.\nThere are two TAs; the first would be able to hold office hours at any\ntime on Monday  or Wednesday afternoons, and the second would be\nable to hold office hours at any time on Tuesday , Wednesd ay, or\nThursday . (In general, TA avail ability might be more complicated to\nspecify than this, but we're keep ing this example simple.) Finally , each"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 511})","('type', 'Document')"
"('page_content', ""TA should hold between a =1 and b = 2 office hours, and we want\nexactly c = 3 of fice hours per week total.\nOne possible solution would be to have the first TA hold office\nhours in time slot I1, and the second  TA to hold office hours in time\nslots I2 and I5.\n(a) Give a polynomial-time algor ithm that takes the input to an\ninstance of this problem (the time slots, the TA schedules, and the\nparameters a, b, and c) and does one of the following two things:\n– Constructs a valid schedule for of fice hours, specifying which\nTA will cover which time slots, or – Reports (correctly) that there\nis no valid way to schedule of fice hours.\n(b) This office-hour scheduling feature becomes very popular , and so\ncourse staffs begin to demand more. In particular , they observe that it's\ngood to have a greater density of office hours closer to the due date of\na homework assignment.\nSo what they want to be able to do is to specify an office-hour\ndensity  parame ter for each day of the week: The number di specifies\nthat they want to have at least di office hours on a given day i of the\nweek.\nFor example, suppose that in our previous example, we add the\nconstraint that we want at least one office hour on Wednesday and at\nleast one office hour on Thursda y. Then the previous solution does not\nwork; but there is a possible solution in which we have the first TA\nhold office hours in time slot I1, and the second TA hold office hours\nin time slots I3 and I5. (Another solution would be to have the first TA\nhold office hours in time slots I1 and I4, and the second TA hold office\nhours in time slot I5.)\nGive a polynomial-time algorithm that computes office-hour\nschedules under  this more complex set of constraints. The algorithm\nshould either construct a schedule or report (correctly) that none exists.\n29. Some of your friends have recently graduated and started a small\ncompany , which they are currently running out of their parents' garages\nin Santa Clara. They're in the process of porting all their software from\nan old system to a new, revved-up system; and they're facing the\nfollowing problem."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 512})","('type', 'Document')"
"('page_content', ""They have a collection of n softwar e applications, {1,2, …, n},\nrunning on their old system; and they'd like to port some of these to the\nnew system. If they move application i to the new syste m, they expect\na net (monetary) benefit of bi ≥ 0. The different software applications\ninteract with one another; if applications i and; have extensive\ninteraction, then the company will incur an expense if they move one\nof i or j to the new system but not both;  let's denote this expense by xij\n≥ 0.\nSo, if the situatio n were really this simple, your friends would just\nport all n applicat ions, achieving a total benefit of Σibi. Unfortunately ,\nthere's a problem….\nDue to small but fundamental incompatibilities between the two\nsystems, there's no way to port application 1 to the new system;  it will\nhave to remain on the old system. Nevertheless, it might still pay off to\nport some of the other applicatio ns, accruing the associated benefit and\nincurring the expense of the interaction between applications on\ndifferent systems.\nSo this is the question they pose to you: Which of the remaining\napplications, if any, should be moved? Give a polynomial-time\nalgorithm to find a set S ⊆ {2,3, …, n} for which the sum of the\nbenefits minus the expenses of moving the applications in S to the new\nsystem is maximized.\n30. Consider a variation on the previous problem. In the new scenario, any\napplication can potentially be moved, but now some of the benefits bi\nfor moving to the new system are in fact negative:  If bi < 0, then it is\npreferable (by an amount quanti fied in bi) to keep i on the old system.\nAgain, give a polynomial-time algorithm to find a set S ⊆ {1,2, …, n}\nfor whic h the sum of the benef its minus the expenses of moving the\napplications in S to the new system is maximized.\n31. Some of your friends are interning at the small high-tech company\nWeb-Exodus. A running joke among the employees there is that the\nback room has less space devoted to high-end servers than it does to\nempty boxes of computer equipment, piled up in case something needs\nto be shipped back to the supplier for maintainence.  \nA few days ago, a large shipme nt of computer monitors arrived,\neach in its own large box; and since there are many different kinds of"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 513})","('type', 'Document')"
"('page_content', ""monitors in the shipment, the boxes do not all have the same\ndimensions. A bunch of people spent some time in the morning trying\nto figure  out how to store all these things, realizing of course that less\nspace would be taken up if some of the boxes could be nested  inside\nothers.\nSuppose each box i is a rectangular parallelepipe d with side\nlengths equal to (i1, i2,i3); and suppose each side length is strictly\nbetween half a meter and one meter . Geometrically , you know what it\nmeans for one box to nest inside  another: It's possible if you can rotate\nthe smaller so that it fits inside the larger in each dimension. Formally ,\nwe can say that box i with dimensions (i1, i2, i3) nests  inside box; with\ndimensions ( j1,J2, j3) if there is a permutation a, b,c of the dimensions\n{1,2,3} so that ia < j1, and ib < j2, and ic < j3. Of course, nesting is\nrecursive: If i nests in j, and; nests in k, then by putting i inside j inside\nk, only box k is visible. We say that a nesting arrangement  for a set of\nn boxes is a sequence of operations in which a box i is put inside\nanother box; in which it nests; and if there were already boxes  nested\ninside i, then these end up inside j as well. (Also notice the following:\nSince the side lengths of i are more than half a meter each, and since\nthe side lengths of j are less than a meter each, box i will take up more\nthan half of each dimension of j, and so after i is put inside j, nothing\nelse can be put inside j.) We say that a box k is visible  in a nesting\narrangement if the sequence of operations does not result in its ever\nbeing put inside another box.\nHere is the problem faced by the people at WebExodus: Since\nonly the visible boxes are taking up any space, how should a nesting\narrangement be chosen so as to minimize the number  of visible boxes?\nGive a polynomial-time algorithm to solve this problem.\nExample.  Suppose there are three boxes with dimensions (.6, .6, .6),\n(.75, .75, .75), and (.9, .7, .7). The first box can be put into either of the\nsecond or third boxes; but in any nesting arrangement, both the second\nand third boxes will be visible.  So the minimum possible number of\nvisible boxes is two, and one solution that achieves this is to nest the\nfirst box inside the second.\n32. Given a graph G = (V, E), and a natural number k, we can define a\nrelation \n  on pairs  of vertices of G as follo ws. If x, y ∊  V, we say that"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 514})","('type', 'Document')"
"('page_content', ""if there exist k mutually edge-disjoint paths from x to y in G. \nIs it true that for every G and every k ≥ 0, the relation \n  is\ntransitive? That is, is it always the case that if \n  and \n  then we\nhave \n  Give a proof or a counterexample.\n33. Let G = (V, E) be a directed graph, and suppose that for each node v,\nthe number of edges into v is equal to the number of edges out of v.\nThat is, for all v, \n \nLet x, y be two nodes of G, and suppose that there exist k mutually\nedge-disjoint paths from x to y. Under these conditions, does it follow\nthat there exist k mutually edge-disjoint paths from y to x? Give a\nproof or a counterexample with explanation.\n34. Ad hoc networks,  made up of low-powered wireless devices, have been\nproposed for situations like natural disasters in which the coordinators\nof a rescue effort might want to monitor conditions in a hard-to-reach\narea. The idea is that a large collection of these wireless devices could\nbe dropped into such an area from an airplane and then configured into\na functioning network.  \nNote that we're talking about (a) relatively inexpensive devices\nthat are (b) being dropped from an airplane into (c) dangerous\nterritory; and for the combina tion of reasons (a), (b), and (c), it\nbecomes necessa ry to include provisions for dealing with the failure of\na reasonable number of the nodes.\nWe'd like it to be the case that if one of the devices v detects that\nit is in danger of failing, it should transmit a representation of its\ncurrent state to some other device in the network. Each device has a\nlimited transmitting range-say it can communicate with other devices\nthat lie within d meters of it. Moreover , since we don't want it to try\ntransmitting its state to a device that has already failed, we should\ninclude some redundancy: A device v should have a set of k other\ndevices that it can potentially contact, each within d meters of it. We'll\ncall this a back-up set  for device v.\n(a) Suppose you're given a set of n wireless devices, with positions\nrepresented by an (x, y) coordinate pair for each. Design an algorithm"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 515})","('type', 'Document')"
"('page_content', ""that determines whether it is possible to choose a back-up set for each\ndevice (i.e., k other devices, each within d meters), with the further\nproperty that, for some paramet er 5, no device appears in the back-up\nset of more than b other devices. The algorithm should output the\nback-up sets themselves, provided they can be found.\n(b) The idea that, for each pair of devices v and w, there's a strict\ndichotomy between being “in range” or “out of range” is a simplified\nabstraction. More accurately , there's a power decay function f(·) that\nspecifies, for a pair of devices at distance δ, the signal strength f(δ) that\nthey'll be able to achieve on their wireless connection. (We'll assume\nthat f(δ) decreases with increasing δ.)\nWe might want to build this into our notion of back-up sets as\nfollows: among the k devices in the back-up set of v, there should be at\nleast one that can be reached with very high signal strength, at least\none other that can be reached with moderately high signal strength,\nand so forth. More concretely , we have values P1 ≥ p2 ≥ … ≥ pk, so\nthat if the back-up set for v consists of devices at distances d1 ≤ d2 ≤ …\n≤ dk, then we should have f(dj) ≥ Pj for each j.\nGive an algorithm that determin es whether it is possible to choose\na back-up set for each device subject to this more detailed condition,\nstill requiring that no device should appear in the back-up set of more\nthan b other devices. Again, the algorithm should output the back-up\nsets themselves, provided they can be found.\n35. You're designing an interactive image segmentation tool that works as\nfollows. You start with the image segmentation setup described in\nSection 7.10, with n pixels, a set of neighboring pairs, and parameters\n{ai}, {bi}, and {pi}. We will make two assum ptions about this\ninstance. First, we will suppose that each of the parameters {ai}, {bi},\nand { pij} is a nonnegative integer between 0 and d, for some number d.\nSecond, we will suppose that the neighbor relation among the pixels\nhas the property  that each pixel is a neighbor of at most four other\npixels (so in the resulting graph, there are at most four edges  out of\neach node).  \nYou first perform an initial segmentation  (A0,B0) so as to maxim ize the\nquantity q(A0,B0). Now , this might result in certain pixels being\nassigned to the background when the user knows that they ought to be"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 516})","('type', 'Document')"
"('page_content', 'in the foreground. So, when presented with the segmentation, the user\nhas the option of mouse-click ing on a particular pixel vh thereby\nbringing it to the foreground. But the tool should not simply bring this\npixel into the foreground; rather , it should compute a segmentation\n(A1,B1) that maximize s the quantity q(A1,B1) subject to the condition\nthat v1 is in the foreground.  (In practice, this is useful for the following\nkind of operatio n: In segmenting a photo of a group of people, perhaps\nsomeone is holding a bag that has been accidentally labeled as part of\nthe background. By clicking on a single pixel belonging to the bag,\nand recomputing an optimal segmentation subject to the new\ncondition, the whole bag will often become part of the foreground.)\nIn fact, the syste m should allow the user to perform a sequence of\nsuch mouse-clicks v1,v2, …,vt; and after mouse-click vt, the system\nshould produce a segmentation (A,B) that maximizes the quantity\nq(Al,Bl) subject to the condition that all of v1,v2, …,vt are in the\nforeground.\nGive an algorithm that perfor ms these operations so that the\ninitial segmentation is computed within a constant factor of the time\nfor a single maximum flow, and then the interaction with the user is\nhandled in O(dn) time per mouse-click.\n(Note:  Solved Exercise 1 from this chapter is a useful primitive\nfor doing this. Also, the symm etric operation of forcing a pixel to\nbelong to the background can be handled by analogous means, but you\ndo not have to work this out here.)\n36. We now consider a different variation of the image segme ntation\nproblem in Section 7.10. We will develop a solution to an image\nlabeling  problem, where the goal is to label each pixel with a rough\nestimate of its distance from the camera (rather than the simple\nforeground/backgr ound  labeling used in the text). The possible labels\nfor each pixel will be 0,1,2, …, M for some integer M. \nLet G = (V,E) denote the graph whose nodes are pixels, and edges\nindicate neighboring pairs of pixels. A labeling  of the pixels is a\npartition of V into sets A0, A1, …, AM, where Ak is the set of pixels that\nis labeled with distance k for k = 0, …, M. We will seek a labeling of\nminimum cost; the cost will come from two types of terms. By analogy\nwith the foreground/background  segmentation problem, we will have')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 517})","('type', 'Document')"
"('page_content', 'an assignment cost:  for each pixel i and label k, the cost ai,k is the cost\nof assigning label k to pixel  i. Next, if two neighboring pixels  (i,j) ∊ E\nare assigned different labels, there will be a separation  cost. In Section\n7.10, we used a separation penalty Pij. In our current problem, the\nseparation cost will also depend on how far the two pixels are\nseparated; specif ically , it will be proportional to the difference in value\nbetween their two labels.\nThus the overall cost q′ of a labeling is defined as follows:\nFigur e 7.30 The set of nodes corresponding to a single pixel i in\nExercise 36 (shown together with the source s and sink t).\n \nThe goal of this problem is to develop a polynomial-tim e\nalgorithm that finds the optima l labeling given the graph G and the\npenalty parameters ai,k and Pij. The algorithm will be based on\nconstructing a flow network, and we will start you off on design ing the\nalgorithm by providing a portion of the construction.\nThe flow netwo rk will have a source s and a sink t. In addition,\nfor each pixel i ∊ V we will have nodes vi,k in the flow netw ork for k =\n1, …, M, as shown in Figure 7.30 . (M = 5 in the example in the figure.)\nFor notational convenience, the nodes vi,o and vi,M+1  will refer to\ns and t, respectively , for any choice of i ∊ V.\nWe now add edges (vl,k, vi,k+1) with capacity ai,k for k = 0, …,M;\nand edges ( vi,k+1, vi,k) in the opposite direction with very large capacity\nL. We will refer to this collection of nodes and edges as the chain\nassociated with pixel i.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 518})","('type', 'Document')"
"('page_content', ""Notice that if we make this very large capacity L large enough,\nthen there will be no minimum cut (A, B) so that an edge of capacity L\nleaves the set A (How large do we have to make  it for this to happen?).\nHence, for any minimum cut (A,B), and each pixel i, there will be\nexactly one low-capacity edge in the chain associated with i that leaves\nthe set A (You should check that if there were two such edges, then a\nlarge-capacity edge would also have to leave the set A)\nFinally , here's the question: Use the nodes and edges defined so\nfar to complete the construction  of a flow network with the property\nthat a minimum-cost labeling can be efficiently computed from a\nminimum s-t cut. You should prove that your construction has the\ndesired property , and show how to recover the minimum-cost labeling\nfrom the cut.\n37. In a standard minimum s-t cut problem, we assume that all capacities\nare nonnegative; allowing an arbitrary set of positive and negative\ncapacities results in a problem that is computationally much more\ndifficult. Howe ver, as we'll see here, it is possible to relax the\nnonnegativity requirement a little and still have a problem that can be\nsolved in polynomial time.  \nLet G = (V, E) be a directed graph, with source s ∊ V, sink t ∊ V,\nand edge capacities { ce}. Suppose that for every edge e that has neither\ns nor t as an endpoint, we have ce ≥ 0. Thus ce can be negative for\nedges e that have at least one end equal to either s or t. Give a\npolynomial-time algorithm to find an s-t cut of minimum value in such\na graph. (Despite the new nonnegativity requirements, we still define\nthe value of an s-t cut ( A, B) to be the sum of the capacities of all edges\ne for which the tail of e is in A and the head of e is in B.)\n38. You're working with a large database of employee records. For the\npurposes of this question, we'll picture the database as a two-\ndimensional table T with a set Rofm  rows and a set C of n columns; the\nrows correspond to individual employees, and the columns correspond\nto dif ferent attributes.  \nTo take a simple example, we may have four columns labeled\nname, phone number , start date, manager's name\nand a table with five employees as shown here."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 519})","('type', 'Document')"
"('page_content', ""Given a subset S of the columns , we can obtain a new, smaller\ntable by keeping only the entries that involve columns from S. We will\ncall this new table the projection  of T onto S, and denote it by T[S]. For\nexample, if S = {name, start date}, then the projection T[S] would be\nthe table consisting of just the first and third columns.\nThere's a different operation on tables that is also useful, which is\nto permute  the columns. Given a permutation p of the columns, we can\nobtain a new table of the same size as T by simply reordering the\ncolumns accordi ng to p. We will call this new table the permutation  of\nT by p, and denote it by Tp.\nAll of this comes into play for your particular application, as\nfollows. You have k different subsets of the columns S1,S2, …,Sk that\nyou're going to be working with a lot, so you'd like to have  them\navailable in a readily accessible  format. One choice would be to store\nthe k projections T[S1], T[S2], …, T[Sk], but this would take up a lot of\nspace. In considering alternativ es to this, you learn that you may not\nneed to explicitly project onto each subset, because the underlying\ndatabase system  can deal with a subset of the columns particularly\nefficiently if (in some order) the members of the subset constitute a\nprefix of the columns in left-to-right order . So, in our example, the\nsubsets {name, phone number} and {name, start date, phone number ,}\nconstitute prefixes (they're the first two and first three columns from\nthe left, respecti vely); and as such, they can be processed much more\nefficiently in this table than a subset such as {name, start date}, which\ndoes not constitute a prefix. (Again, note that a given subset Si does\nnot come with a specified order , and so we are interested in whether\nthere is some  order under which it forms a prefix of the columns.)\nSo here's the question: Given a parameter ℓ < k, can you find ℓ\npermutations of the columns p1,p2, …,pe so that for every one of the\ngiven subsets St (for i = 1,2, …, k), it's the case that the columns in Si"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 520})","('type', 'Document')"
"('page_content', ""constitute a prefix of at least one of the permuted tables Tp1,TP2, …,\nTpℓ? We'll say that such a set of permutations constitutes a valid\nsolution to the problem; if a valid solution exists, it means you only\nneed to store the ℓ permuted tables rather than all k projections. Give a\npolynomial-time algorithm to solve this problem; for instances on\nwhich there is a valid solution, your algorithm should return an\nappropriate set of ℓ permutations.\nExample.  Suppose the table is as above, the given subsets are\n  \nand ℓ = 2. Then there is a valid solution to the instance, and it could be\nachieved by the two permutations\n  \nThis way , S1 constitutes a prefix of the permuted table Tp1, and both S2\nand S3 constitute prefixes of the permuted table Tp2.\n39. You are consulting for an envir onmental statistics firm. They collect\nstatistics and publish the collec ted data in a book. The statistics are\nabout population s of different regions in the world and are recorded in\nmultiples of one million. Exam ples of such statistics would look like\nthe following table."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 521})","('type', 'Document')"
"('page_content', ""We will assume  here for simpli city that our data is such that all\nrow and column sums are integ ers. The Census Rounding Problem is\nto round all data to integers without changing any row or column sum.\nEach fractional  number can be rounded either up or down. For\nexample, a good rounding for our table data would be as follows.\n(a) Consider first the special case when all data are between 0 and 1.\nSo you have a matrix of fractional numbers between 0 and 1, and your\nproblem is to round each fraction that is between 0 and 1 to either 0 or\n1 without changing the row or column sums. Use a flow comp utation\nto check if the desired rounding is possible.\n(b) Consider the Census Rounding Problem as defined above, where\nrow and column sums are integers, and you want to round each\nfractional number α to either α or α. Use a flow computation to check\nif the desired rounding is possible.\n(c) Prove that the rounding we are looking for in (a) and (b) always\nexists.\n40. In a lot of numerical computations, we can ask about the “stability” or\n“robustness” of the answer . This kind of question can be asked for\ncombinatorial problems as well; here's one way of phrasing the\nquestion for the Minimum Spanning T ree Problem.  \nSuppose you are given a graph G = (V,E), with a cost ce on each\nedge e. We view the costs as quant ities that have been measured\nexperimentally , subject to possible errors in measurement. Thus, the\nminimum spann ing tree one computes for G may not in fact be the\n“real” minimum spanning tree.\nGiven error parameters ∊  > 0 and k > 0, and a specific edge e′ =\n(u, v), you would like to be able to make a claim of the following form.\n(*) Even if the cost of each edge were to be changed by at most  ∊ (either\nincreased or decreased), and the costs of k of the edges  other than e′ were further\nchanged to arbitrarily different values, the edge e′ would still not belong to any\nminimum spanning tree of G."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 522})","('type', 'Document')"
"('page_content', ""Such a property provides a type of guarantee that e′ is not likely to\nbelong to the minimum spanning tree, even assuming significant\nmeasurement error .\nGive a polynomial-time algorithm that takes G, e′, ∊, and k, and\ndecides whether or not property (*) holds for e′.\n41. Suppose you're managing a colle ction of processors and must schedule\na sequence of jobs over time.  \nThe jobs have the following characteristics. Each job j has an\narrival time aj when it is first available for processing, a length ℓj\nwhich indicates how much processing time it needs, and a deadline dj\nby which it must be finished. (We'll assume 0 < ℓj ≤ dj - aj.) Each job\ncan be run on any of the processors, but only on one at a time; it can\nalso be preempt ed and resumed from where it left off (possibly after a\ndelay) on another processor .\nMoreover , the collection of processors is not entirely static either:\nYou have an overall pool of k possibl e processors; but for each\nprocessor i, there is an interval of time [ti ti′] during which it is\navailable; it is unavailable at all other times.\nGiven all this data about job requirements and processor\navailability , you'd like to decide  whether the jobs can all be completed\nor not. Give a polynomial-time algorithm that either produces a\nschedule completing all jobs by their deadlines or reports (correctly)\nthat no such schedule exists. You may assume that all the parameters\nassociated with the problem are integers.\nExample.  Suppose we have two jobs J1 and J2. J1 arrives at time 0, is\ndue at time 4, and has length 3. J2 arrives at time 1, is due at time 3,\nand has length 2. We also have two processors P1 and P2. P1 is\navailable between times 0 and 4; P2 is available between times 2 and 3.\nIn this case, there is a schedule that gets both jobs done.\nAt time 0, we start job J1 on processor P1.\nAt time 1, we preempt J1 to start J2 on P1.\nAt time 2, we resume J1 on P2. (J2 continues processing on P1.)\nAt time 3, J2 completes by its deadline. P2 ceases to be available,\nso we move J1 back to P1 to finish its remaining one unit of"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 523})","('type', 'Document')"
"('page_content', 'processing there.\nAt time 4, J1 completes its processing on P1.\nNotice that there is no solution that does not involve preemption and\nmoving of jobs.\n42. Give a polynomial-time algorithm for the following minim ization\nanalogue of the Maximum-Flow Problem. You are given a directed\ngraph G = (V, E), with a source s ∊ V and sink t ∊ V, and numbers\n(capacities) ℓ(v,w) for each edge ( v, w) ∊ E. We define a flow f, and the\nvalue of a flow, as usual, requiring that all nodes except s and t satisfy\nflow conservation. However , the given numbers are lower bounds on\nedge flow-that is, they require that f(v, w) ≥ ℓ{v, w) for every edge (v,\nw) ∊ E, and there is no upper bound on flow values on edges.  \n(a) Give a polynomial-time algori thm that finds a feasible flow of\nminimum possible value.\n(b) Prove an analogue of the Max-Flow Min-Cut Theorem for this\nproblem (i.e., does min-flow = max-cut?).\n43. You are trying to solve a circula tion problem, but it is not feasible. The\nproblem has demands, but no capacity limits on the edges. More\nformally , there is a graph G = (V,E), and demands dv for each node v\n(satisfying Σv ∊Vdv = 0), and the problem is to decide if there is a flow f\nsuch that f(e) ≥ 0 and fin(v) - fout(v) = dv for all nodes v ∊ V. Note that\nthis problem can be solved via the circulation algorithm from Section\n7.7 by setting ce = ∞ for all edges e ∊ E. (Alternately , it is enough to\nset ce to be an extremely large number for each edge-say , larger than\nthe total of all positive demands dv in the graph.)  \nYou want to fix up the graph to make the problem feasible, so it\nwould be very useful to know why the problem is not feasible as it\nstands now. On a closer look, you see that there is a subset U of nodes\nsuch that there is no edge into U, and yet Σv ∊U dv > 0. You quickly\nrealize that the existence of such a set immediately implies that the\nflow cannot exist: The set U has a positive total demand, and so needs\nincoming flow, and yet U has no edges into it. In trying to evaluate\nhow far the problem is from being solvable, you wonder how big the\ndemand of a set with no incoming edges can be.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 524})","('type', 'Document')"
"('page_content', ""Give a polynomial-time algorithm to find a subset S ⊂ V of nodes\nsuch that there is no edge into S and for which Σv ∊s dv is as large as\npossible subject to this condition.\n44. Suppose we are given a directed  network G = (V,E) with a root node r\nand a set of terminals T ⊆ V. We'd like to disconnect many terminals\nfrom r, while cutting relatively few edges.  \nWe make this trade-of f precise as follows. For a set of edges F ⊂\nE, let q(F) denote the number of nodes v ∊ T such that there is no r-v\npath in the subgraph (V, E - F). Give a polynomial-time algorithm to\nfind a set F of edges that maximizes the quantity q(F) - |F|. (Note that\nsetting F equal to the empty set is an option.)\n45. Consider the following definitio n. We are given a set of n countries\nthat are engaged in trade with one another . For each country i, we have\nthe value si of its budget surplus; this number may be positive or\nnegative, with a negative number indicating a deficit. For each pair of\ncountries i, j, we have the total value eij of all exports from i to j; this\nnumber is always nonnegative. We say that a subset S of the countries\nis free-standing  if the sum of the budget surplus es of the countries in S,\nminus the total value of all exports from countries in S to coun tries not\nin S, is nonnegative.  \nGive a polynom ial-time algorithm that takes this data for a set of\nn countries and decides whether it contains a nonempty free-sta nding\nsubset that is not equal to the full set.\n46. In sociology , one often studies a graph G in which nodes represent\npeople and edges represent those  who are friends with each other . Let's\nassume for purposes of this question that friendship is symmetric, so\nwe can consider an undirected graph.  \nNow suppose we want to study this graph G, looking for a “close-\nknit” group of people. One way to formalize this notion would be as\nfollows. For a subset S of nodes, let e(S) denote the number of edges in\nS-that is, the number of edges that have both ends in S. We define the\ncohesiveness  of S as e(S)/|S|. A natural thing to search for would be a\nset S of people achieving the maximum cohesiveness.\n(a) Give a polynomial-time algorith m that takes a rational number α\nand determines whether there exists a set S with cohesiveness at least\nα."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 525})","('type', 'Document')"
"('page_content', '(b) Give a polynomial-time algorithm to find a set S of nodes with\nmaximum cohesiveness.\n47. The goal of this problem is to suggest variants of the Preflow -Push\nAlgorithm that speed up the practical running time without ruining its\nworst-case complexity . Recall that the algorithm maintains the\ninvariant that h(v) ≤ h(w) + 1 for all edges (v, w) in the residual graph\nof the current preflow . We proved that if f is a flow (not just a preflow)\nwith this invaria nt, then it is a maximum flow. Heights were monotone\nincreasing, and the running-time analysis depended on bounding the\nnumber of times nodes can increase their heights. Practical experience\nshows that the algorithm is almost always much faster than suggested\nby the worst case, and that the practical bottleneck of the algorithm is\nrelabeling nodes  (and not the nonsaturating pushes that lead to the\nworst case in the theoretical analysis). The goal of the problems  below\nis to decrease the number of relabelings by increasing heights faster\nthan one by one. Assume you have a graph G with n nodes, m edges,\ncapacities c, source s, and sink t. \n(a) The Preflow-Push Algorithm, as described in Section 7.4, starts by\nsetting the flow equal to the capacity ce on all edges e leaving the\nsource, setting the flow to 0 on all other edges, setting h(s) = n, and\nsetting h(v) = 0 for all other nodes v ∊ V. Give an O(m) procedure for\ninitializing node  heights that is better than the one we constructed in\nSection 7.4 . Your method should set the height of each node v to be as\nhigh as possible given the initial flow .\n(b) In this part we will add a new step, called gap relabeling,  to\nPreflow-Push, which will increase the labels of lots of nodes by more\nthan one at a time. Consider a preflow f and heights h satisfying the\ninvariant. A gap in the heights is an integer 0 < h < n so that no node\nhas height exact ly h. Assume h is a gap value, and let A be the set of\nnodes v with heights n > h(v) > h. Gap relabeling  is the process of\nchanging the heights of all nodes in A so they are equa l to n. Prove that\nthe Preflow-Push Algorithm with gap relabeling is a valid max-flow\nalgorithm. Note that the only new thing that you need to prove is that\ngap relabeling preserves the invariant above, that h(v) ≤ h(w) + 1 for\nall edges ( v, w) in the residual graph.\n(c) In Section 7.4 we proved that h(v) ≤ 2n - 1 throughout the\nalgorithm. Here we will have a variant that has h(v) ≤ n throughout.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 526})","('type', 'Document')"
"('page_content', 'The idea is that we “freeze” all nodes when they get to height n; that\nis, nodes at height n are no longer considered active , and hence are not\nused for push and relabel. This way, at the end of the algorit hm we\nhave a preflow and height function that satisfies the invariant above,\nand so that all excess is at height n. Let B be the set of nodes v so that\nthere is a path from v to t in the residual graph of the current preflow .\nLet A= V-B. Prove that at the end of the algorithm, (A,B) is a\nminimum-capacity s-t cut.\n(d) The algorithm in part (c) computes a minimum s-t cut but fails to\nfind a maximum flow (as it ends with a preflow that has excesses).\nGive an algorithm that takes the preflow f at the end of the algorithm\nof part (c) and converts it into a maximum flow in at most O(mn) time.\n(Hint:  Consider nodes with excess, and try to send the excess back to s\nusing only edges that the flow came on.)\n48. In Section 7.4 we considered  the Preflow-Push Algorithm, and\ndiscussed one particular selection rule for considering vertices. Here\nwe will explore a different selection rule. We will also consider\nvariants of the algorithm that terminate early (and find a cut that is\nclose to the minimum possible).  \n(a) Let f be any preflow . As f is not necessarily a valid flow, it is\npossible that the value fout(s) is much higher than the maximum-flow\nvalue in G. Show , however , that fin(t) is a lower bound on the\nmaximum-flow value.\n(b) Consider a preflow f and a compatible labeling h. Recall that the\nset A = {v: There is an s-v path in the resid ual graph Gf}, and B = V-A\ndefines an s-t cut for any preflow f that has a compatible labeling h.\nShow that the capacity of the cut ( A, B) is equal to c(A, B) = Σv ∊B ef(v).\nCombining (a) and (b) allows the algorithm to terminate early and\nreturn (A, B) as an approxi mately minimu m-capacity cut, assuming\nc(A, B) - fin(t) is sufficiently small. Next we consider an\nimplementation that will work on decreasing this value by trying to\npush flow out of nodes that have a lot of excess.\n(c) The scaling version of the Preflow-Push Algorithm maintains a\nscaling parameter Δ. We set Δ initially to be a large power of 2. The\nalgorithm at each step selects a node with excess at least Δ with as\nsmall a height as possible. When no nodes (other than t) have excess at')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 527})","('type', 'Document')"
"('page_content', 'least Δ, we divide Δ by 2, and continue. Note that this is a valid\nimplementation of the generic Preflow-Push Algorithm. The algorithm\nruns in phases. A single phase continues as long as Δ is unchanged.\nNote that Δ starts out at the largest capacity , and the algorithm\nterminates when  Δ = 1. So there are at most 0(log C) scaling phases.\nShow how to implement this variant of the algorithm so that the\nrunning time can be bounded by O(mn + n log C + K) if the algorithm\nhas K nonsaturating push operations.\n(d) Show that the number of nonsaturating push operations in the\nabove algorithm is at most O(n2 log C). Recall that O(log C) bounds\nthe number of scaling phases. To bound the number of nonsat urating\npush operations in a single scaling phase, consider the potential\nfunction Φ = Σv ∊V h(v)ef(v)/Δ. What is the effect of a nonsaturating\npush on Φ? Which operation(s) can make Φ increase?\n49. Consider an assignment problem  where we have a set of n stations that\ncan provide service, and there is a set of k requests  for service. Say, for\nexample, that the stations are cell towers and the requests are cell\nphones. Each request can be served by a given set of station s. The\nproblem so far can be represented by a bipartite graph G: one side is\nthe stations, the other the custom ers, and there is an edge (x,y) between\ncustomer x and station y if customer x can be served from station y.\nAssume that each station can serve at most one customer . Using a\nmax-flow computation, we can decide whether or not all customers\ncan be served, or can get an assignment of a subset of customers to\nstations maximizing the number of served customers.  \nHere we consider a version of the problem with an additional\ncomplication: Each customer offers a different amount of money for\nthe service. Let U be the set of customers, and assume that customer x\n∊ U is willin g to pay vx ≥ 0 for being served. Now the goal is to find a\nsubset X ⊂ U maximizing Σx ∊X vx such that there is an assignment of\nthe customers in X to stations.\nConsider the following greedy approach. W e process customers in\norder of decreasing value (breaking ties arbitrarily). When considering\ncustomer x the algorithm will either “promise” service to x or rejec t x\nin the following greedy fashion. Let X be the set of customers that so\nfar have been promised service . We add x to the set X if and only if')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 528})","('type', 'Document')"
"('page_content', ""there is a way to assign X u {x} to servers, and we reject x otherwise.\nNote that rejected customers will not be considered later. (This is\nviewed as an advantage: If we need to reject a high-paying customer ,\nat least we can tell him/her early .) However , we do not assign accepted\ncustomers to servers in a greedy fashion: we only fix the assig nment\nafter the set of accepted custome rs is fixed. Does this greedy approach\nproduce an optimal set of customers? Prove that it does, or provide a\ncounterexample.\n50. Consider the following scheduling problem. There are m machines,\neach of which can process jobs, one job at a time. The problem  is to\nassign jobs to machines (each job needs to be assigned to exactly one\nmachine) and order the jobs on machines so as to minimize a cost\nfunction. The machines run at different speeds, but jobs are identical in\ntheir processing needs. More formally , each machine i has a parameter\nℓi and each job requires ℓi time if assigned to machine i. \nThere are n jobs. Jobs have identical processing needs but\ndifferent levels of urgency . For each job j, we are given a cost function\nCj(t) that is the cost of completing job j at time t. We assume that the\ncosts are nonnegative, and monotone in t.\nA sched ule consists of an assign ment of jobs to machines, and on\neach machine the schedule gives the order in which the jobs are done.\nThe job assigned  to machine i as the first job will complete at time ℓ,\nthe second job at time 2ℓi and so on. For a schedule S, let ts(j) denote\nthe completion time of job j in this schedule. The cost of the schedule\nis cost(S) = Σicj(tsj)).\nGive a polynomial-time algorith m to find a schedule of minimum\ncost.\n51. Some friends of yours have grown tired of the game “Six Degrees of\nKevin Bacon” (after all, they ask, isn't it just breadth-first search ?) and\ndecide to invent a game with a little more punch, algorithm ically\nspeaking. Here's how it works.  \nYou start with a set X of n actresse s and a set Y of n actors, and\ntwo players P0 and P1. Player P0 names an actress x1 ∊ X, player P1\nnames an actor y1 who has appeared in a movie with x1, player P0\nnames an actres s x2 who has appeared in a movie with y1, and so on.\nThus, P0 and P1 collectively generate a sequence x1,y1,x2,y2,… such"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 529})","('type', 'Document')"
"('page_content', ""that each actor/actress in the sequence has costarred with the\nactress/actor immediately preceding. A player Pt (i = 0,1) loses when it\nis Pt's turn to move, and he/she cannot name a member of his/her set\nwho hasn't been named before.\nSuppose you are given a specif ic pair of such sets X and Y, with\ncomplete inform ation on who has appeared in a movie with whom. A\nstrategy  for P, in our setting , is an algorithm that takes a current\nsequence X1,y1,X2,y2, … and generates a legal next move for Pi\n(assuming it's Pi's turn to move).  Give a polyno mial-time algorithm\nthat decides which of the two players can force a win, in a particular\ninstance of this game.\nNotes and Further Reading\nNetwork flow emer ged as a cohesive subject through the work of Ford and\nFulkerson (1962). It is now a field of research in itself, and one can easily\ndevote an entire course to the topic; see, for example, the survey by\nGoldber g, Tardos, and Tarjan (1990) and the book by Ahuja , Magnanti,\nandOrlin (1993).\nSchrijver (2002) provides an interesting historical account of the early\nwork by Ford and Fulkerson on the flow problem. Lending further support\nto those of us who always felt that the Minimum-Cut Problem had a slightly\ndestructive overtone, this survey  cites a recently declassified U.S. Air Force\nreport to show that in the origina l motivating application for minimum cuts,\nthe network was a map of rail lines in the Soviet Union, and the goal was to\ndisrupt transportation through it.\nAs we mention in the text, the formulations of the Bipartite Matching\nand Disjoint Paths Problems predate the Maximum-Flow Problem by\nseveral decades; it was through the development of network flows that these\nwere all placed on a common methodological footing. The rich structure of\nmatchings in bipartite graphs has many independent discoverers; P. Hall\n(1935) and Konig (1916) are perhaps the most frequently cited. The\nproblem of finding edge-disjoint paths from a source to a sink is equivalent\nto the Maximum -Flow Problem with all capacities equal to 1; this special\ncase was solved (in essentially equivalent form) by Menger (1927)."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 530})","('type', 'Document')"
"('page_content', 'The Preflow-Push Maximum-Flow Algorithm is due to Goldber g\n(1986), and its efficient implementation is due to Goldber g and Tarjan\n(1986). High-pe rformance code for this and other network flow algorithms\ncan be found at a W eb site maintained by Andrew Goldber g.\nThe algorithm for image segme ntation using minimum cuts is due to\nGreig, Porteous, and Seheult (1989), and the use of minimu m cuts has\nbecome an active theme in computer vision research (see, e.g., Veksler\n(1999) and Kolmogorov and Zabih (2004) for overviews); we will discuss\nsome further extensions of this approach in Chapter 12. Wayne (2001)\npresents further results on baseball elimination and credits Alan Hoffman\nwith initially popularizing this example in the 1960s. Many further\napplications of network flows and cuts are discussed in the book by Ahuja,\nMagnanti, and Orlin (1993).\nThe problem of finding a minimum-cost perfect matching is a special\ncase of the Minimum-Cost Flow Problem,  which is beyond the scope of our\ncoverage here. There are a number of equivalent ways to state the\nMinimum-Cost Flow Problem; in one formulation, we are given a flow\nnetwork with both capacities ce and costs Ce on the edges; the cost of a flow\nf is equal to the sum of the edge costs weighted by the amount of flow they\ncarry , Σe Cef(e), and the goal is to produce a maximum flow of minimum\ntotal cost. The Minimum-Cost Flow Problem can be solved in polynomial\ntime, and it too has many applications; Cook et al. (1998) and Ahuja,\nMagnanti, and Orlin (1993) discuss algorithms for this problem.\nWhile network flow models routing problems that can be reduced to\nthe task of constructing a numb er of paths from a single source to a single\nsink, there is a more general, and harder , class of routing problem s in which\npaths must be simultaneously constructed between different pairs of senders\nand receivers. The relationship  among these classes of proble ms is a bit\nsubtle; we discuss this issue, as well as algorithms for some of these harder\ntypes of routing problems, in Chapter 1 1.\nNotes on the Exercises  Exercise 8 is based on a problem we learned from\nBob Bland; Exercise 16 is based on discussions with Udi Manber; Exercise\n25 is based on discussions with Jordan Erenrich; Exercise 35 is based on\ndiscussions with Yuri Boykov , Olga Veksler , and Ramin Zabih; Exercise 36\nis based  on results of Hiroshi Ishikawa and Davi Geiger , and of Boykov ,\nVeksler , and Zabih; Exercise 38 is based on a problem we learned from Al\nDemers; and Exercise 46 is based on a result of J. Picard and H. Ratlif f.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 531})","('type', 'Document')"
"('page_content', ""1 Our notion of flow models traffic as it goes through the network at a\nsteady rate. We have a single variable f(e) to denote the amount of flow on\nedge e. We do not model bursty  traffic, where the flow fluctuates over time.\n2 In fact, in an interesting retrospective written in 1981, Menger relates\nhis versi on of the story of how he first explained his theorem to König, one\nof the independent discoverers of Hall's Theorem. You might think that\nKönig, having thought a lot about these problems, would have immediately\ngrasped why Menger's generaliz ation of his theorem was true, and perhaps\neven considered it obvious. But, in fact, the opposite happened; König\ndidn't believe it could be right and stayed up all night searching for a\ncounterexample. The next day, exhausted, he sought out Menger and asked\nhim for the proof.\n3 In contrast to the field of data mining, which has motivated several of\nthe problems we considered earlier , we're talking here about actual mining,\nwhere you dig things out of the ground.\n4 The Austrian scientist Karl Landsteiner received the Nobel Prize in 1930\nfor his discovery of the blood types A, B, O, and AB."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 532})","('type', 'Document')"
"('page_content', 'Chapter 8')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 533})","('type', 'Document')"
"('page_content', ""NP and Computational Intractability\n8.1 Polynomial-T ime Reductions  \n8.2 Reductions via “Gadgets”: The Satisfiability Pr oblem  \n8.3 Efficient Certification and the Definition of NP  \n8.4 NP-Complete Pr oblems  \n8.5 Sequencing Pr oblems  \n8.6 Partitioning Pr oblems  \n8.7 Graph Coloring  \n8.8 Numerical Pr oblems  \n8.9 Co-NP and the Asymmetry of NP  \n8.10 A Partial T axonomy of Hard Pr oblems  \nSolved Exer cises  \nExer cises  \nNotes and Further Reading\nWe now arrive at a major transi tion point in the book. Up until now, we've\ndeveloped efficient algorithms for a wide range of problems and have even\nmade some progress on inform ally categorizing the problems that admit\nefficient solutions—for example, problems expressible as minimum cuts in\na graph, or problems that allow a dynamic programming formulation. But\nalthough we've often paused to take note of other problems that we don't\nsee how to solve, we haven't yet made any attempt to actually quantify or\ncharacterize the range of problems that can't be solved efficiently .\nBack when we were first layin g out the fundamental definitions, we\nsettled on polynomial time as our working notion of efficiency . One\nadvantage of using a concrete definition like this, as we noted earlier , is that\nit gives us the opportunity to prove mathematically that certa in problems\ncannot be solved by polynomial-time—and hence “ef ficient”—algorithms.\nWhen people began investigating computational complexity in earnest,\nthere was some initial progres s in proving that certain extremely hard\nproblems canno t be solved by efficient algorithms. But for many of the\nmost fundamental discrete computational problems—arising in"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 534})","('type', 'Document')"
"('page_content', ""optimization, artificial intelligen ce, combinatorics, logic, and elsewhere—\nthe question was too difficult to resolve, and it has remained  open since\nthen: We do not know of polynomial-time algorithms for these problems,\nand we cannot prove that no polynomial-time algorithm exists.\nIn the face of this formal ambiguity , which becomes incre asingly\nhardened as years pass, people  working in the study of complexity have\nmade significant progress. A large class of problems in this “gray area” has\nbeen characterized, and it has been proved that they are equiv alent in the\nfollowing sense : a polynomial-time algorithm for any one of them would\nimply the existence of a polyno mial-time algorithm for all of them. These\nare the NP-complete problems , a name that will make more sense as we\nproceed a little further . There are literally thousands of NP-complete\nproblems, arising in numerous areas, and the class seems to contain a large\nfraction of the fundamental problems whose complexity we can't resolve.\nSo the formulation of NP-co mpleteness, and the proof that all these\nproblems are equivalent, is a powerful thing: it says that all these open\nquestions are really a single  open question, a single type of complexity that\nwe don't yet fully understand.\nFrom a pragmatic point of view , NP-completeness essentially means\n“computationally hard for all practical purposes, though we can't prove it.”\nDiscovering that a problem is NP-complete provides a compelling reason to\nstop searching for an efficient algorithm—you might as well search for an\nefficient algorith m for any of the famous computational problems already\nknown to be NP-complete, for which many people have tried and failed to\nfind ef ficient algorithms.\n8.1 Polynomial-Time Reductions\nOur plan is to explore the space of computationally hard problems,\neventually arriv ing at a mathematical characterization of a large class of\nthem. Our basic technique in this exploration is to compare the relative\ndifficulty of different problems; we'd like to formally express  statements\nlike, “Problem X is at least as hard as problem Y.” We will formalize this\nthrough the notion of reduction : we will show that a particular problem X is\nat least as hard as some other problem Y by arguing that, if we had a “black"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 535})","('type', 'Document')"
"('page_content', ""box” capable of solving X, then we could also solve Y. (In other words, X is\npowerful enough to let us solve Y.)\nTo make this precise, we add the assumption that X can be solved in\npolynomial time directly to our model of computation. Suppose we had a\nblack box that could solve instances of a problem X; if we write down the\ninput for an instance of X, then in a single step, the black box will return the\ncorrect answer . We can now ask the following question:\n(*) Can arbitrary instances of problem Y be solved using a polynomial number of\nstandar d computational steps, plus a polynomial number of calls to a black box that\nsolves pr oblem X?\nIf the answer to this question is yes, then we write Y ≤P X; we read this as\n“Y is polynomial-t ime reducible to X,” or “X is at least as hard as Y (with\nrespect to polynomial time).” Note that in this definition, we still pay for the\ntime it takes to write down the input to the black box solving X, and to read\nthe answer that the black box provides.\nThis formulation of reducibility is very natural. When we ask about\nreductions to a problem X, it is as though we've supplemented our\ncomputational model with a piece of specialized hardware that solves\ninstances of X in a single step. We can now explore the question: How\nmuch extra power does this piece of hardware give us?\nAn important consequence of our definition of ≤P is the following.\nSuppose Y ≤P X and there actually exists  a polynomial-time algorithm to\nsolve X. Then our specialized black box for X is actually not so valuable;\nwe can replace it with a polynomial-time algorithm for X. Consider what\nhappens to our algorithm for problem Y that involved a polynomial number\nof steps plus a polynomial numb er of calls to the black box. It now becomes\nan algorithm that involves a polynomial number of steps, plus a polynomial\nnumber of calls to a subroutine that runs in polynomial time; in other\nwords, it has become a polyn omial-time algorithm. We have therefore\nproved the following fact.\n(8.1)  Suppose Y  ≤P X. If X can be solved in polynomial time, then Y can be solved in polynomial time.\nWe've made use of precisely this fact, implicitly , at a number of earlier\npoints in the book. Recall that we solved the Bipartite Matchi ng Problem\nusing a polynom ial amount of preprocessing plus the solution of a single"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 536})","('type', 'Document')"
"('page_content', ""instance of the Maximum-Flow Problem. Since the Maximum-Flow\nProblem can be solved in polynomial time, we concluded that Bipartite\nMatching could as well. Similarly , we solved the foreground/background\nImage Segmentation Problem using a polynomial amount of preprocessing\nplus the solution of a single instance of the Minimum-Cut Problem, with the\nsame consequences. Both of these can be viewed as direct applications of\n(8.1). Indeed, (8.1) summarizes a great way to design polynomial-time\nalgorithms for new problems: by reduction to a problem we already know\nhow to solve in polynomial time.\nIn this chapter , however , we will be using (8.1) to establi sh the\ncomputational intractability  of vario us problems. We will be engaged in the\nsomewhat subtle activity of relating the tractability of problems even when\nwe don't know how to solve either  of them in polynomial time. For this\npurpose, we will really be using the contrapositive of (8.1), which is\nsufficiently valuable that we'll state it as a separate fact.\n(8.2)  Suppose Y ≤P X. If Y cannot be solved in polynomia l time, then X cannot be solved in\npolynomial time.\nStatement (8.2) is transparently equivalent to (8.1), but it emphasizes\nour overall plan: If we have a problem Y that is known to be hard, and we\nshow that Y ≤P X, then the hardness has “spread”  to X; X must be hard or\nelse it could be used to solve Y.\nIn reality , given that we don't actually know whether the problems\nwe're studying can be solved in polynomial time or not, we'll be using ≤P to\nestablish relative levels of dif ficulty among problems.\nWith this in mind, we now establish some reducibilities among an\ninitial collection of fundamental hard problems.\nA First Reduction: Independent Set and Vertex\nCover\nThe Independent Set Problem,  which we introduced as one of our five\nrepresentative problems in Chapter 1, will serve as our first prototypical\nexample of a hard problem. We don't know a polynomial-time algorithm for\nit, but we also don't know how to prove that none exists."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 537})","('type', 'Document')"
"('page_content', ""Let's review the formulation of Independent Set, because we're going\nto add one wrinkle to it. Recall that in a graph G = (V, E), we say a set of\nnodes S ⊆ V is independent  if no two nodes in S are joined by an edge. It is\neasy to find small independent sets in a graph (for example, a single node\nforms an independent set); the hard part is to find a large independent set,\nsince you need to build up a large collection of nodes without ever\nincluding two neighbors. For example, the set of nodes {3, 4, 5} is an\nindependent set of size 3 in the graph in Figure 8.1, while the set of nodes\n{1,4, 5, 6} is a lar ger independent set.\nFigur e 8.1 A graph whose  largest independent set has size 4, and whos e\nsmallest vertex cover has size 3.\nIn Chapter 1 , we posed the problem of finding the largest independent\nset in a graph G. For purposes of our current exploration in terms of\nreducibility , it will be much more convenient to work with problems that\nhave yes/no answers only , and so we phrase Independent Set as follows.\nGiven a graph G and a number k, does G contain an independent set of size at least k?\nIn fact, from the point of view of polynomial-time solvability , there is not a\nsignificant difference between the optimization version  of the problem (find\nthe maximum size of an indepe ndent set) and the decision version  (decide,\nyes or no, whether G has an independent set of size at least a given k).\nGiven a method to solve the optimization version, we automat ically solve\nthe decision version (for any k) as well. But there is also a slightly less\nobvious converse to this: If we can solve the decision version of\nIndependent Set for every k, then we can also find a maximum independent\nset. For given a graph G on n nodes, we simply solve the decision version\nof Independent Set for each k; the largest k for which the answer is “yes” is\nthe size of the largest independent set in G. (And using binary search, we"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 538})","('type', 'Document')"
"('page_content', ""need only solve the decision version for O(log n) different values of k.) This\nsimple equivalen ce between decision and optimization will also hold in the\nproblems we discuss below .\nNow , to illustrate our basic strategy for relating hard problems to one\nanother , we consider another fundamental graph problem for which no\nefficient algorithm is known: Vertex Cover . Given a graph G = (V, E), we\nsay that a set of nodes S ⊆ V is a vertex cover  if every edge ∊ e E has at\nleast one end in S. Note the follow ing fact about this use of terminology: In\na vertex  cover , the vertices do the “covering,” and the edges are the objects\nbeing “covered.”  Now , it is easy to find large vertex covers in a graph (for\nexample, the full vertex set is one); the hard part is to find small ones. We\nformulate the V ertex Cover Problem as follows.\nGiven a graph G and a number k, does G contain a vertex cover of size at most k?\nFor example, in the graph in Figure 8.1, the set of nodes {1, 2, 6, 7} is a\nvertex cover of size 4, while the set {2, 3, 7} is a vertex cover of size 3.\nWe don't know how to solve either Independent Set or Vertex Cover in\npolynomial time; but what can we say about their relative difficulty? We\nnow show that they are equivalently hard, by establishing that Independent\nSet ≤PVertex Cover and also that Vertex Cover ≤P Independent Set. This\nwill be a direct consequence of the following fact.\n(8.3)  Let G = (V, E) be a graph. Then S is an independent set if and only if its complement V - S is a\nvertex cover .\nProof. First, suppose that S is an independ ent set. Consider an arbitrary\nedge e = (u,v).  Since S is independent, it cannot be the case that both u and\nv are in S; so one of them must be in V - S. It follows that every edge has at\nleast one end in V - S, and so V - S is a vertex cover .\nConversely , suppose that V - S is a vertex cover. Consider any two\nnodes u and v in S. If they were joined by edge e, then neither end of e\nwould lie in V - S, contradicting our assumption that V - S is a vertex cover .\nIt follows that no two nodes in S are joined by an edge, and so S is an\nindependent set.\n▪\n \nReductions in each direction between the two problems follow immediately"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 539})","('type', 'Document')"
"('page_content', ""from (8.3).\n(8.4)  Independent Set ≤ P Vertex Cover .\nProof. If we have a black box to solve Vertex Cover , then we can decide\nwhether G has an independent set of size at least k by asking the black box\nwhether G has a vertex cover of size at most n - k. ▪\n(8.5)  Vertex Cover ≤ P Independent Set.\nProof. If we have a black box to solve  Independent Set, then we can decide\nwhether G has a vertex cover of size at most k by asking the black box\nwhether G has an independent set of size at least n - k. ▪\nTo sum up, this type of analysis illustrates our plan in general:\nalthough we don't know how to solve either Independent Set or Vertex\nCover efficiently , (8.4) and (8.5) tell us how we could solve either given an\nefficient solution to the other , and hence these two facts establish the\nrelative levels of dif ficulty of these problems.\nWe now pursue this strategy for a number of other problems.\nReducing to a More General Case: Vertex Cover\nto Set Cover\nIndependent Set and Vertex Cover represent two different genres of\nproblems. Independent Set can be viewed as a packing pr oblem:  The goal is\nto “pack  in” as many vertices as possible, subject to conflicts (the edges)\nthat try to preven t one from doing this. Vertex Cover , on the other hand, can\nbe viewed as a covering pr oblem:  The goal is to parsimoniously “cover” all\nthe edges in the graph using as few vertices as possible.\nVertex Cover is a covering problem phrased specifically in the\nlanguage of graphs; there is a more general covering problem, Set Cover , in\nwhich you seek to cover an arbitrary set of objects using a collection of\nsmaller sets. W e can phrase Set Cover as follows.\nGiven a set U of n elements, a collection S1,… ,Sm of subsets of U, and a number k,\ndoes ther e exist a collection of at most k of these sets whose union is equal to all of U?"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 540})","('type', 'Document')"
"('page_content', 'Imagine, for example, that we have m availabl e pieces of software, and\na set U of n capabilities  that we would like our system to have. The ith piece\nof software includes the set Si ⊆ U of capabilities. In the Set Cover\nProblem, we seek to include a small number of these pieces of software on\nour system, with the property that our system will then have all n\ncapabilities.\nFigure 8.2  shows a sample  instance of the Set Cover Problem: The ten\ncircles represent the elements of the underlying set U, and the seven ovals\nand polygons represent the sets S1, S2,…, S7. In this instance, there is a\ncollection of three of the sets whose union is equal to all of U: We can\nchoose the tall thin oval on the left, together with the two polygons.\nFigur e 8.2  An instance of the Set Cover Problem.\nIntuitively , it feels like Vertex Cover is a special case of Set Cover: in\nthe latter case, we are trying to cover an arbitrary set using arbitrary subsets,\nwhile in the former case, we are specifically trying to cover  edges of a\ngraph using sets of edges incid ent to vertices. In fact, we can show the\nfollowing reduction.\n(8.6)  Vertex Cover ≤ P Set Cover .\nProof. Suppose we have access to a black box that can solve Set Cove r, and\nconsider an arbitrary instance of Vertex Cover , specified by a graph G = (V,')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 541})","('type', 'Document')"
"('page_content', ""E) and a number k. How can we use the black box to help us?\nOur goal is to cover the edges in E, so we formulate  an instance of Set\nCover in which the ground set U is equal to E. Each time we pick a vertex\nin the Vertex Cover Problem, we cover all the edges incident to it; thus, for\neach vertex i ∊ V, we add a set Si ⊆ U to our Set Cover instance, consisting\nof all the edges in G incident to i.\nWe now claim that U can be covered with at most k of the sets S1,…,Sn\nif and only if G has a vertex cover of size at most k. This can be proved\nvery easily . For if Si1, …, Siℓ are ℓ ≤ k sets that cover U, then every edge in\nG is incident to one of the vertices i1,…, iℓ, and so the set {i1,…, iℓ} is a\nvertex cover in G of size ℓ ≤ k. Conversely , if {i1,…, iℓ is a vertex cover in\nG of size ℓ ≤ k,  then the sets Si1, …, Siℓ cover U.\nThus, given our instance of Vertex Cover , we formulate the instance of\nSet Cover described above, and pass it to our black box. We answer yes if\nand only if the black box answers yes.\n(You can check that the instance of Set Cover pictured in Figure 8.2  is\nactually the one you'd get by following the reduction in this proof, starting\nfrom the graph in Figure 8.1 .) ▪\n \nHere is something worth notic ing, both about this proof and about the\nprevious reducti ons in (8.4) and (8.5). Although the definition of ≤P allows\nus to issue many  calls to our black box for Set Cover , we issued only one.\nIndeed, our algorithm for Vertex Cover consisted simply of encoding the\nproblem as a single instance of Set Cover and then using the answer to this\ninstance as our overall answer . This will be true of essentially all the\nreductions that we consider; they will consist of establishing Y ≤P X by\ntransforming our instance of Y to a single insta nce of X, invoking our black\nbox for X on this instance, and reporting the box's answer as our answer for\nthe instance of Y.\nJust as Set Cove r is a natural generalization of Vertex Cover , there is a\nnatural generalization of Indepen dent Set as a packing problem for arbitrary\nsets. Specifically , we define the Set Packing Pr oblem  as follows.\nGiven a set U of n elements, a collection  S1,… ,Smof subsets of U, and a number k,\ndoes there exist a collection of at least k of these sets with the property that no two of\nthem intersect?"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 542})","('type', 'Document')"
"('page_content', 'In other words, we wish to “pack” a large number of sets together , with the\nconstraint that no two of them are overlapping.\nAs an example of where this type of issue might arise, imagine that we\nhave a set U of n non-sharable resour ces, and a set of m software processes.\nThe ith process  requires the set Si ⊆ U of resources in order to run. Then the\nSet Packing Problem seeks a large collection of these processes  that can be\nrun simultaneously , with the property that none of their resource\nrequirements overlap (i.e., represent a conflict).\nThere is a natural analogue to (8.6), and its proof is almost the same as\nwell; we will leave the details as an exercise.\n(8.7)  Independent Set ≤ P Set Packing.\n8.2 Reductions via “Gadgets”: The Satisfiability\nProblem\nWe now introduce a somewhat more abstract set of problems , which are\nformulated in Boolean notation. As such, they model a wide range of\nproblems in which we need to set decision variables so as to satisfy a given\nset of constraints; such formali sms are common, for example, in artificial\nintelligence. After introducing these problems, we will relate them via\nreduction to the graph- and set-based problems that we have been\nconsidering thus far .\nThe SAT and 3-SAT Problems\nSuppose we are given a set X of n Boole an varia bles x1,…, xn; each can\ntake the value 0 or 1 (equivalen tly, “false” or “true”). By a term over X, we\nmean one of the variables xi or its negation \n . Finally , a clause  is simp ly a\ndisjunction of distinct terms')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 543})","('type', 'Document')"
"('page_content', '(Again, each \n .) We say the clause has length ℓ if\nit contains ℓ terms.\nWe now formalize what it means for an assignment of values to satisfy\na collec tion of clauses. A truth assignment  for X is an assignment of the\nvalue 0 or 1 to each xi; in other words, it is a function v :X → {0, 1}. The\nassignment v implicitly gives \n  the opposite truth value from xi. An\nassignment satisfies  a clause C if it causes C to evaluate to 1 under the rules\nof Boolean logic; this is equivale nt to requiring that at least one of the terms\nin C should receive the value 1. An assignment satisfies a collection of\nclauses C1,…, Ck if it causes all of the Ci to evaluate to 1; in other words, if\nit causes the conjunction\nto evaluate to 1. In this case, we will say that v is a satisfying\nassignment  with respect to C1,…,Ck; and that the set of clauses C1,…,Ck is\nsatisfiable.\nHere is a simple example. Suppose we have the three clauses\nThen the truth assignment v that sets all variables to 1 is not a satisfying\nassignment, because it does not satisfy the second of these clauses; but the\ntruth assignment v′ that sets all variables to 0 is a satisfying assignment.\nWe can now state the Satisfiability Pr oblem,  also referred to as SAT:\nGiven a set of clauses C 1,…, Ck over a set of variable s X = {x1,…, xn], does there exist\na satisfying truth assignment?\nThere is a special case of SAT that will turn out to be equivalently difficult\nand is somewhat easier to think  about; this is the case in which  all clauses\ncontain exactly three terms (corresponding to distinct variable s). We call\nthis problem 3-Satisfiability , or 3-SA T:')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 544})","('type', 'Document')"
"('page_content', 'Given a set of clauses C1,…, Ck, each of length 3, over a set of variables X = {x1,…,\nxn}, does ther e exist a satisfying truth assignment?\nSatisfiability and 3-Satisfiability are really fundamental combinatorial\nsearch problems ; they contain the basic ingredients of a hard computational\nproblem in very “bare-bones” fashion. We have to make n independent\ndecisions (the assignments for each xi) so as to satisfy a set of constraints.\nThere are several ways to satisfy  each constraint in isolation, but we have to\narrange our decisions so that all constraints are satisfied simultaneously .\nReducing 3-SAT to Independent Set\nWe now relate the type of comp utational hardness embodied in SAT and 3-\nSAT to the superficially differen t sort of hardness represented by the search\nfor independent sets and vertex covers in graphs. Specifically , we will show\nthat 3-SA T ≤P Indepen dent Set. The difficulty in proving a thing like this is\nclear; 3-SAT is about setting Boolean variables in the presence of\nconstraints, while Independent Set is about selecting vertices in a graph. To\nsolve an instanc e of 3-SA T using a black box for Independent Set, we need\na way to encode  all these Boole an constraints in the nodes and edges of a\ngraph, so that satisfiability corresponds to the existence of a large\nindependent set.\nDoing this illustrates a general principle for designing complex\nreductions Y ≤P X: building “gadgets” out of components in problem X to\nrepresent what is going on in problem Y.\n(8.8)  3-SA T ≤P Independent Set.\nProof. We have a black box for Independent Set and want to solve an\ninstance of 3-SA T consisting of variables X = {x1,…, xn} and clauses C1,…,\nCk.\nThe key to thinking about the reduction is to realize that there are two\nconceptually distinct ways of thinking about an instance of 3-SA T.\nFigur e 8.3  The reduction from 3-SA T to Independent Set.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 545})","('type', 'Document')"
"('page_content', 'One way to picture the 3-SA T instance was suggested earlier: You\nhave to make an independent 0/1 decision for each of the n variables,\nand you succeed if you manage to achieve one of three ways of\nsatisfying each clause.\nA different way to picture the same 3-SA T instance is as follows: You\nhave to choose one term from each clause, and then find a truth\nassignment that causes all these terms to evaluate to 1, thereby\nsatisfying all clauses. So you succeed if you can select a term from\neach clause in such a way that no two selected terms “conflict”; we say\nthat two terms conflict  if one is equal to a variable xi and the other is\nequal to its negation \n . If we avoid conflicting terms,  we can find a\ntruth assignment that makes the selected terms from each clause\nevaluate to 1.\nOur reduction will be based on this second view of the 3-SA T instance;\nhere is how we encode it using independent sets in a graph. First, construct\na graph G = (V, E) consisting of 3k nodes grouped into k triangles as shown\nin Figure 8.3 . That is, for i = 1, 2, …, k, we construct three vertices vi1, vi2,\nvi3 joined to one another by edges. We give each of these vertices a label ; vij\nis labeled with the jth term from the clause Ci of the 3-SA T instance.\nBefore proceeding, consider what the independent sets of size k look\nlike in this graph: Since two vertices cannot be selected from the same\ntriangle, they consist of all ways of choosing one vertex from each of the\ntriangles. This is implementing our goal of choosing a term in each clause\nthat will evaluate to 1; but we have so far not prevented ourselves from\nchoosing two terms that conflict.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 546})","('type', 'Document')"
"('page_content', ""We encode conflicts by adding some more edges to the graph: For each\npair of vertices whose labels correspond to terms that conflict, we add an\nedge between them. Have we now destroyed all the independent sets of size\nk, or does one still exist? It's not clear; it depends on whether we can still\nselect one node from each triangle so that no conflicting pairs of vertices\nare chosen. But this is precisely what the 3-SA T instance required.\nLet's claim, precisely , that the original 3-SA T instance is satisfiable if\nand only if the graph G we have constructed has an independent set of size\nat least k. First, if the 3-SA T instance is satisfiable, then each triangle in our\ngraph contains at least one node whose label evaluates to 1. Let S be a set\nconsisting of one such node from  each triangle. We claim S is independent;\nfor if there were  an edge between two nodes u,v ∊  S, then the labels of u\nand v would have to conflict; but this is not possible, since they both\nevaluate to 1.\nConversely , suppose our graph G has an indepen dent set S of size at\nleast k. Then, first of all, the size of S is exactly k, and it must consist of one\nnode from each triangle. Now , we claim that there is a truth assignment ν\nfor the variables in the 3-SA T instance with the property that the labels of\nall nodes in S evaluat e to 1. Here is how we could construct such an\nassignment ν. For each variable xi, if neithe r xi nor \n  appears as a label of a\nnode in S, then we arbitra rily set ν(xi) = 1. Otherwise , exactly one of xi or \nappears as a label of a node in S; for if one node  in S were labeled xi and\nanother were labeled \n , then there would be an edge between these two\nnodes, contradic ting our assumption that S is an independe nt set. Thus, if xi\nappears as a label of a node in S, we set ν(xi) = 1, and otherwise we set ν(xi)\n= 0. By constructing ν in this way , all labels of nodes in S will evaluate to 1.\nSince G has an independent set of size at least k if and only if the\noriginal 3-SA T instance is satisfiable, the reduction is complete. ▪\nSome Final Observations: Transitivity of\nReductions\nWe've now seen a number of different hard problems, of various flavors,\nand we've discovered that they are closely related to one another . We can\ninfer a number of additional relationships using the following fact: ≤P is a\ntransitive  relation."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 547})","('type', 'Document')"
"('page_content', ""(8.9)  If Z ≤ P Y, and Y ≤ P X, then Z ≤ P X.\nProof. Given a black box for X, we show how to solve an instance of Z;\nessentially , we just compose the two algorithms implied by Z ≤P Y and Y ≤P\nX. We run the algorithm for Z using a black box for Y; but each time the\nblack box for Y is called, we simulate  it in a polynomial number of steps\nusing the algorithm that solves instances of Y using a black box for X. ▪\nTransitivity can be quite useful. For example, since we have proved\n3-SA T ≤P Independent Set ≤P Vertex Cover ≤P Set Cover ,\nwe can conclude that 3-SA T ≤P Set Cover .\n8.3 Efficient Certification and the Definition of NP\nReducibility among problems was the first main ingredient in our study of\ncomputational intractability . The second ingredient is a characterization of\nthe class of problems that we are dealing with. Combining these two\ningredients, together with a powerful theorem of Cook and Levin, will yield\nsome surprising consequences.\nRecall that in Chapter 1, when we first encountered the Independent\nSet Problem, we asked: Can we say anything good  about it, from a\ncomputational point of view? And, indeed, there was something: If a graph\ndoes contain an independent set of size at least k, then we could give you an\neasy proof of this fact by exhibi ting such an independent set. Similarly , if a\n3-SA T instance is satisfiable, we can prove this to you by revealing the\nsatisfying assignment. It may be an enormously difficult task to actually\nfind such an assignm ent; but if we've done the hard work of finding one, it's\neasy for you to plug it into the clauses and check that they are all satisfied.\nThe issue here is the contrast between finding  a solution and checking\na proposed solution. For Indep endent Set or 3-SA T, we do not know a\npolynomial-time algorithm to find solutions; but checking  a proposed\nsolution to these problems can be easily done in polynomial time. To see\nthat this is not an entirely trivial issue, consider the problem we'd face if we\nhad to prove that a 3-SA T instance was not satisfia ble. What “evidence”\ncould we show that would convince you, in polynomial time, that the\ninstance was unsatisfiable?"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 548})","('type', 'Document')"
"('page_content', 'Problems and Algorithms\nThis will be the crux of our characterization; we now proceed to formalize\nit. The input to a computational  problem will be encoded as a finite binary\nstring s. We denote the length of a string s by |s|. We will identif y a decision\nproblem X with the set of strings on which the answer is “yes.” An\nalgorithm A for a decision problem receives  an input string s and returns the\nvalue “yes” or “no”—we will denote this returned value by A(s).  We say\nthat A solves  the problem X if for all strings s, we have A(s) = yes if and\nonly if s ∊ X.\nAs always, we say that A has a polynomial running time if there is a\npolynomial function p(·) so that for every input string s, the algorithm A\nterminates on s in at most O(p(|s|)) steps. Thus far in the book, we have\nbeen concerned with problems solvable in polynomial time. In the notation\nabove, we can express this as the set P of all problems X for which there\nexists an algorithm A with a polynomial running time that solves X.\nEfficient Certification\nNow , how should we formalize the idea that a solution to a problem can be\nchecked  efficiently , independently of whether it can be solved efficiently ? A\n“checking algorithm” for a problem X has a different  structure from an\nalgorithm that actually seeks to solve the problem; in order to “check” a\nsolution, we need the input string s, as well as a separate “certificate ” string\nt that contains the evidence that s is a “yes” instance of X.\nThus we say that B is an efficient certifier  for a problem X if the\nfollowing properties hold.\nB is a polynomial-time algorithm  that takes two input arguments s and\nt.\nThere is a polynomial function p so that for every  string s, we have s ∊\nX if and only if there exists a string t such that |t| ≤ p(|s|) and B(s, t) =\nyes.\nIt takes some time to really think through what this definition is saying. One\nshould view an efficient certif ier as approaching a problem X from a\n“managerial” point of view . It will not actually try to decide whether an')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 549})","('type', 'Document')"
"('page_content', 'input s belongs to X on its own. Rather , it is willing to efficiently evaluate\nproposed “proofs” t that s belongs to X—provided they are not too long—\nand it is a correct algorithm in the weak sense that s belongs to X if and only\nif there exists a proof that will convince it.\nAn efficient certifier B can be used as the core component of a “brute-\nforce” algorithm  for a problem X: On an input s, try all strings t of lengt h ≤\np(|s|), and see if B(s, t ) = yes for any of these strings. But the existence of B\ndoes not provide us with any clear way to design an efficient algorithm that\nactually solves X; after all, it is still up to us to find a string  t that will cause\nB(s, t ) to say “yes,” and there are exponentially many possibilities for t.\nNP: A Class of Problems\nWe define NP to be the set of all problems for which there exists an\nefficient certifier .1 Here is one thing we can observe immediately .\n(8.10)  \n .\nProof. Consider a problem \n ; this means that there is a polyn omial-time\nalgorithm A that solves X. To show that \n , we must show that there is\nan ef ficient certifier B for X.\nThis is very easy; we design B as follows. When presented with the\ninput pair (s, t), the certifier B simply returns the value A(s).  (Think of B as\na very “hands-o n” manager that ignores the proposed proof t and simply\nsolves the problem on its own.) Why is B an efficient certifier for X?\nClearly it has polynomial running time, since A does. If a string s ∊ X, then\nfor every t of lengt h at most p(|s|), we have B(s, t) = yes. On the other hand,\nif s ∉ X, then for every t of length at most p(|s|), we have B(s, t ) = no. ▪\nWe can easily check that the problems introduced in the first two\nsections belong  to NP: it is a matter  of determining how an efficient\ncertifier for each of them will make use of a “certificate” string t. For\nexample:\nFor the 3-Satisf iability Problem , the certificate t is an assignment of\ntruth values to the variables; the certifier B evaluates the given set of\nclauses with respect to this assignment.\nFor the Indepen dent Set Problem, the certificate t is the identity of a\nset of at least k vertices; the certifier B checks that, for these vertices,')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 550})","('type', 'Document')"
"('page_content', 'no edge joins any pair of them.\nFor the Set Cover Problem, the certificate t is a list of k sets from the\ngiven collection; the certifier checks that the union of these sets is\nequal to the underlying set U.\nYet we cannot prove that any of these problems require more than\npolynomial time to solve. Indeed, we cannot prove that there is any problem\nin NP that does not belong to P. So in place of a concrete theorem, we can\nonly ask a question:\n(8.11) Is ther e a pr oblem in  NP that does not belong to  P? Does  P = NP?\nThe question of whether P = NP is fundamental in the area of\nalgorithms, and it is one of the most famous problems in computer science.\nThe general belief is that P ≠ NP—and this is taken as a working  hypothesis\nthroughout the field—but there is not a lot of hard technical evidence for it.\nIt is more based on the sense that P = NP would be too amazing to be true.\nHow could there be a general transformation from the task of checking  a\nsolution to the much harder task of actually finding  a solution? How could\nthere be a general means for designing efficient algorithms, powerful\nenough to handle all these hard problems, that we have somehow failed to\ndiscover? More  generally , a huge amount of effort has gone  into failed\nattempts at designing polynomial-time algorithms for hard problems in NP;\nperhaps the most natural explanation for this consistent failure is that these\nproblems simply cannot be solved in polynomial time.\n8.4 NP-Complete Problems\nIn the absence of progress on the P = NP question, people have turned to a\nrelated but more approachable question: What are the hardest problems in\nNP? Polyn omial-time reducibility gives us a way of addressing this\nquestion and gaining insight into the structure of NP.\nArguably the most natural way to define a “hardest” problem X is via\nthe following two properties: (i) X ∊ NP; and (ii) for all Y ∊ NP, Y ≤P X. In\nother words, we require that every problem in NP can be reduced to X. We\nwill call such an X an NP-complete  problem.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 551})","('type', 'Document')"
"('page_content', ""The following fact helps to further reinforce our use of the term\nhardest.\n(8.12)  Suppose X is an NP-complete problem. Then X is solvable in polynomial time if and only if P\n= NP .\nProof. Clearly, if P = NP, then X can be solved in polynomial time since it\nbelongs to NP. Conversely , suppose that X can be solved in polynomial\ntime. If Y is any other problem in NP, then Y ≤P X, and so by (8.1), it\nfollows that Y can be solved in polynomial time. Hence NP ⊆ P; combined\nwith (8.10), we have the desired conclusion. ▪\nA crucial consequence of (8.12) is the following: If there is any\nproblem in NP that cannot be solved in polynomial time, then no NP-\ncomplete problem can be solved in polynomial time.\nCircuit Satisfiability: A First NP-Complete\nProblem\nOur definition of NP-completeness has some very nice properties. But\nbefore we get too carried away in thinking about this notion, we should stop\nto notice something: it is not at all obvious that NP-complete problems\nshould even exist.  Why couldn't there exist two incomparable problems X′\nand X″, so that there is no X ∊ NP with the proper ty that X′ ≤P X and X″ ≤P\nX? Why couldn't there exist an infinite sequence of problems X1, X2, X3,…\nin NP , each strictly harder than the previous one? T o prove a problem is NP-\ncomplete, one must show how it could encode any problem in NP. This is a\nmuch trickier matter than what we encountered in Sections 8.1 and 8.2,\nwhere we sought to encode specific, individual problems in terms of others.\nIn 1971, Cook and Levin independently showed how to do this for\nvery natural problems in NP. Maybe the most natural problem choice for a\nfirst NP-complete problem is the following Circuit Satisfiability Pr oblem.\nTo specify this problem, we need to make precise what we mean by a\ncircuit. Consider the standard Boolean operators that we used to defin e the\nSatisfiability Problem: ∧  (AND), ∨ (OR), and ¬ (NOT). Our definition of a\ncircuit is designed to represent  a physical circuit built out of gates that\nimplement these operators. Thus we define a circuit K to be a labeled,\ndirected acyclic graph such as the one shown in the example of Figure 8.4 ."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 552})","('type', 'Document')"
"('page_content', 'The sources in K (the nodes with no incoming edges) are labeled either\nwith one of the constants 0 or 1, or with the name of a distinct variable.\nThe nodes of the latter type will be referred to as the inputs  to the\ncircuit.\nEvery other node is labeled with one of the Boolean operators ∧ , ∨ , or\n¬; nodes labeled with ∧  or ∨  will have two incoming edges, and nodes\nlabeled with ¬ will have one incoming edge.\nThere is a single node with no outgoing edges, and it will represent the\noutput:  the result that is computed by the circuit.\nA circui t computes a function of its inputs in the following natural\nway. We imagin e the edges as “wires” that carry the 0/1 value  at the node\nthey emanate from. Each node v other than the sources will take the values\non its incoming edge(s) and apply the Boolean operator that labels it. The\nresult of this ∧ , ∨ , or ¬ operation will be passed along the edge(s) leaving v.\nThe overall value computed by the circuit will be the value computed at the\noutput node.\nFor example, consider the circuit in Figure 8.4. The leftmost two\nsources are preassigned the values 1 and 0, and the next three sources\nconstitute the inputs. If the inputs are assigned the values 1, 0,1 from left to\nright, then we get values 0,1,1 for the gates in the second row, values 1,1 for\nthe gates in the third row , and the value 1 for the output.\nFigur e 8.4 A circuit with three inputs, two additional sources that have\nassigned truth values, and one output.\nNow , the Circuit Satisfiability Problem is the following. We are given\na circuit as input, and we need to decide whether there is an assignment of')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 553})","('type', 'Document')"
"('page_content', ""values to the inputs that causes the output to take the value 1. (If so, we will\nsay that the given circuit is satisfiable,  and a satisfying assignment  is one\nthat results in an output of 1.) In our example, we have just seen—via the\nassignment 1, 0,1 to the inputs—that the circuit in Figure 8.4  is satisfiable.\nWe can view the theorem of Cook and Levin as saying the following.\n(8.13)  Circuit Satisfiability is NP-complete.\nAs discu ssed above, the proof of (8.13) requires that we consider an\narbitrary problem X in NP, and show that X ≤P Circuit Satisfiability . We\nwon't describe the proof of (8.13) in full detail, but it is actually not so hard\nto follow the basic idea that underlies it. We use the fact that any algorithm\nthat takes a fixed number n of bits as input  and produces a yes/no answer\ncan be represented by a circuit of the type we have just defined: This circuit\nis equivalent to the algorithm in the sense that its output is 1 on precisely\nthe inputs for which the algorithm outputs yes. Moreover , if the algorithm\ntakes a number of steps that is polynomial in n, then the circuit has\npolynomial size. This transform ation from an algorithm to a circuit is the\npart of the proof of (8.13) that we won't go into here, though it is quite\nnatural given the fact that algor ithms implemented on physica l computers\ncan be reduced to their operations on an underlying set of ∧ , ∨ , and ¬ gates.\n(Note that fixing the number of input bits is important, since it reflects a\nbasic distinction between algorithms and circuits: an algorithm typically has\nno trouble dealing with differen t inputs of varying lengths, but a circuit is\nstructurally hard-coded with the size of the input.)\nHow should we use this relation ship between algorithms and circuits?\nWe are trying to show that X ≤P Circuit Satisfiability—that is, given an\ninput s, we want to decide whether s ∊ X using a black box that can solve\ninstances of Circuit Satisfiability . Now , all we know about X is that it has an\nefficient certifier B(·,·). So to determine whether s ∊ X, for some specific\ninput s of lengt h n, we need to answ er the following question: Is there a t of\nlength p(n) so that B(s, t ) = yes?\nWe will answer  this question by appealing to a black box for Circuit\nSatisfiability as follows. Since we only care about the answer for a specific\ninput s, we view  B(·,·) as an algori thm on n + p(n) bits (the input s and the\ncertificate t), and we conve rt it to a polynomial-size circuit K with n + p(n)\nsources. The first n sources  will be hard-coded with the values of the bits in"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 554})","('type', 'Document')"
"('page_content', ""s, and the remaining p(n) sources will be labeled with variables representing\nthe bits of t; these latter sources will be the inputs to K.\nNow we simply observe that s ∊ X if and only if there is a way to set\nthe input bits to K so that the circuit produces an output of 1—in other\nwords, if and only if K is satisfiable. This establishes  that X ≤P Circuit\nSatisfiability , and completes the proof of (8.13).\nAn Example  To get a better sense for what's  going on in the proof of\n(8.13), we consider a simple, concrete example. Suppose we have the\nfollowing problem.\nGiven a graph G, does it contain a two-node independent set?\nNote that this problem belongs  to NP. Let's see how an instance of this\nproblem can be solved by constructing an equivalent instance  of Circuit\nSatisfiability .\nFollowing the proof outline above, we first consider an efficient\ncertifier for this problem. The input s is a graph on n nodes, which will be\nspecified by \n  bits: For each pair of nodes, there will be a bit saying\nwhether there is an edge joining  this pair. The certificate t can be specified\nby n bits: For each node, there will be a bit saying whether this node\nbelongs to the proposed independent set. The efficient certifier  now needs\nto check two things: that at least two of the bits in t are set to 1, and that no\ntwo bits in t are both set to 1 if they form the two ends of an edge (as\ndetermined by the corresponding bit in s).\nNow , for the specific input length n corresponding to the s that we are\ninterested in, we construct an equivalent circuit K. Suppos e, for example,\nthat we are interested in decidin g the answer to this problem for a graph G\non the three nodes u, v, w, in which v is joined to both u and w. This means\nthat we are concerned with an input of length n = 3. Figure 8.5 shows a\ncircuit that is equivalent to an efficient certifier for our problem on arbitrary\nthree-node graphs. (Essentially , the right-hand side of the circuit  checks that\nat least two node s have been selected, and the left-hand side checks that we\nhaven't selected  both ends of any edge.) We encode the edges of G as\nconstants in the first three sources, and we leave the remaining three\nsources (represe nting the choice of nodes to put in the indepen dent set) as\nvariables. Now  observe that this instance of Circuit Satisfiability is\nsatisfiable, by the assignment 1, 0, 1 to the inputs. This corresponds to"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 555})","('type', 'Document')"
"('page_content', 'choosing nodes u and w, which indeed form a two-node independent set in\nour three-node graph G.\nFigur e 8.5 A circuit to verify whether a 3-node graph contains a 2-node\nindependent set.\nProving Further Problems NP-Complete\nStatement (8.13 ) opens the door to a much fuller understand ing of hard\nproblems in NP: Once we have our hands on a first NP-complete problem,\nwe can discover many more via the following simple observation.\n(8.14)  If Y is an NP-complete problem, and X is a problem in NP with the property that Y ≤P X, then\nX is NP-complete.\nProof. Since X ∊ NP, we need only verify property (ii) of the definition. So\nlet Z be any problem in NP. We have Z ≤P Y, by the NP-completeness of Y,\nand Y ≤P X by assumption. By (8.9), it follows that Z ≤P X. ▪\nSo while proving (8.13) required the hard work of considering any\npossible proble m in NP, proving further problems NP-complete only\nrequires a reduction from a single problem already known to be NP-\ncomplete, thanks to (8.14).')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 556})","('type', 'Document')"
"('page_content', 'In earlie r section s, we have seen a number of reductions among some\nbasic hard problems. To estab lish their NP-completeness, we need to\nconnect Circuit Satisfiability to this set of problems. The easiest way to do\nthis is by relating it to the problem it most closely resembles, 3-\nSatisfiability .\n(8.15)  3-Satisfiability is NP-complete.\nProof. Clearly 3-Satisfiability is in NP, since we can verify in polynomial\ntime that a proposed truth assignment satisfies the given set of clauses. We\nwill prove that it is NP-complete via the reduction Circuit Satisfiability ≤p\n3-SA T.\nGiven an arbitrary instance of Circuit Satisfiability , we will first\nconstruct an equivalent instance  of SAT in which each clause contains at\nmost  three variables. Then we will convert this SAT instance to an\nequivalent one in which each clause has exactly  three variables. This last\ncollection of clauses will thus be an instance of 3-SA T, and hence will\ncomplete the reduction.\nSo consider an arbitrary circuit K. We associate a variable xv with each\nnode v of the circuit, to encode the truth value that the circuit holds at that\nnode. Now we will define the clauses of the SAT problem. First we need to\nencode the requirement that the circuit computes values correctly at each\ngate from  the input values. There will be three cases depending on the three\ntypes of gates.\nIf node v is labeled with ¬, and its only entering edge is from node u,\nthen we need to have \n . We guarantee this by adding two clauses\n(xv ∨ xu), and \n .\nIf node v is labeled with ∨ , and its two entering edges are from nodes\nu and w, we need to have xv = xu ∨ xw. We guarantee this by adding\nthe following clauses: \n , and \n .\nIf node v is labeled with ∧ , and its two entering edges are from nodes\nu and w, we need to have xv = xu ∧ xw. We guarantee this by adding\nthe following clauses: \n , and \n .\nFinally , we need to guarantee that the constants at the sources have\ntheir specified values, and that the output evaluates to 1. Thus, for a source')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 557})","('type', 'Document')"
"('page_content', ""v that has been labeled with a constant value, we add a clause with the\nsingle variable xv or \n , which forces xv to take the designated value. For the\noutput node o, we add the single-variable clause x0, which requires that o\ntake the value 1. This concludes the construction.\nIt is not hard to show that the SAT instance we just constructed is\nequivalent to the given instan ce of Circuit Satisfiability . To show the\nequivalence, we need to argue two things. First suppose that the given\ncircuit K is satisfiable. The satisfying assignment to the circuit inputs can be\npropagated to create values at all nodes in K (as we did in the example of\nFigure 8.4). This set of values clearly satisfies the SAT instance we\nconstructed.\nTo argue the other direction, we suppose that the SAT instan ce we\nconstructed is satisfiable. Consid er a satisfying assignment for this instance,\nand look at the values of the variables corresponding to the circuit K's\ninputs. We claim that these values constitute a satisfying assignment for the\ncircuit K. To see this, simply note that the SAT clauses ensure that the\nvalues assigned to all nodes of K are the same as what the circuit computes\nfor these  nodes.  In particular , a value of 1 will be assigned to the output,\nand so the assignment to inputs satisfies K.\nThus we have shown how to create a SAT instance that is equiva lent to\nthe Circuit Satisfiability Problem. But we are not quite done, since our goal\nwas to create an instance of 3-SAT, which requires that all clauses have\nlength exactly 3—in the instance  we constructed, some clauses have lengths\nof 1 or 2. So to finish the proof,  we need to convert this instance of SAT to\nan equivalent instance in which each clause has exactly three variables.\nTo do this, we create four new variables: z1, z2, z3, z4. The idea is to\nensure that in any satisfying assignment, we have z1 = z2 = 0, and we do this\nby adding the clauses \n , and \nfor each of i = 1 and i = 2. Note that there  is no way to satisfy all these\nclauses unless we set z1 = z2 = 0.\nNow consider a clause in the SAT instance we constructed that has a\nsingle term t (where the term t can be either a variable or the negation of a\nvariable). We replace each such term by the clause (t ∨ z1 ∨ z2). Similarly ,\nwe replace each clause that has two terms, say, (t ∨ t′), with the clause (t ∨\nt′ ∨ z1). The resulting 3-SA T formul a is clearly equivalent to the SAT"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 558})","('type', 'Document')"
"('page_content', 'formula with at most three variables in each clause, and this finishes the\nproof. ▪\n \nUsing this NP-completeness result, and the sequence of reductions\n3-SA T ≤P Independent Set ≤P Vertex Cover ≤P Set Cover ,\nsummarized earlier , we can use (8.14) to conclude the following.\n(8.16)  All of the following problems are NP-complete:  Indep endent Set, Set Packing, Vertex Cover,\nand Set Cover .\nProof. Each of these problems has the property that it is in NP and that 3-\nSAT (and hence Circuit Satisfiability) can be reduced to it. ▪\nGeneral Strategy for Proving New Problems NP-\nComplete\nFor most of the remainder of this chapter , we will take off in search of\nfurther NP-complete problems. In particular , we will discuss further genres\nof hard computa tional problem s and prove that certain examples of these\ngenres are NP-complete. As we suggested initially , there is a very practical\nmotivation in doing this: since it is widely believed that P ≠ NP, the\ndiscovery that a problem is NP-complete can be taken as a strong indication\nthat it cannot be solved in polynomial time.\nGiven a new problem X, here is the basic strategy for proving it is NP-\ncomplete.\n1. Prove that X ∊ NP.\n2. Choose a problem Y that is known to be NP-complete.\n3. Prove that Y ≤P X.\nWe noticed earlier that most of our reductions Y ≤P X consist of\ntransforming a given instance of Y into a single  instance of X with the same\nanswer . This is a particular way of using a black box to solve X; in\nparticular , it requires only a single invocation of the black box. When we\nuse this style of reduction, we can refine the strategy above to the following\noutline of an NP-completeness proof.\n1. Prove that X ∊ NP.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 559})","('type', 'Document')"
"('page_content', '2. Choose a problem Y that is known to be NP-complete.\n3. Consider an arbitrary instance sY of problem Y, and show how to\nconstruct, in polynomial time, an instance sX of problem X that\nsatisfies the following properties:\n(a) If sY is a “yes” instance of Y, then sX is a “yes” instance of X.\n(b) If sX is a “yes” instance of X, then sY is a “yes” instance of Y.\nIn other words, this establishes that sY and sX have the same answer .\nThere has been research aimed at understanding the distinction\nbetween polynom ial-time reduct ions with this special structure—asking the\nblack box a single question and using its answer verbatim—an d the more\ngeneral notion of polynomial-ti me reduction that can query the black box\nmultiple times. (The more restricted type of reduction is known as a Karp\nreduction,  while the more  general type is known as a Cook reduction  and\nalso as a polynomial-time Turing reduction. ) We will not be pursuing this\ndistinction further here.\n8.5 Sequencing Problems\nThus far we have seen proble ms that (like Independent Set and Vertex\nCover) have involved searching  over subsets of a collection of objects; we\nhave also seen problems that (like 3-SA T) have involved searching over 0/1\nsettings to a collection of variables. Another type of computationally hard\nproblem involves searching over the set of all permutations  of a collection\nof objects.\nThe Traveling Salesman Problem\nProbably the most famous such sequencing problem is the Traveling\nSalesman Problem.  Consider a salesman who must visit n cities labeled v1,\nv2,…, vn. The salesman starts in city v 1, his home, and wants to find a tour\n—an order in which to visit all the other cities and return home . His goal is\nto find a tour that causes him to travel as little total distance as possible.\nTo form alize this, we will take a very general notion of distance: for\neach ordered pair of cities (vi, vj), we will specify a nonnegative number')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 560})","('type', 'Document')"
"('page_content', 'd(vi, vj) as the distance  from vi to vj. We will not require the distance to be\nsymmetric (so it may happen that d(vi, vj) ≠ d(vj, vi)), nor will we require it\nto satisfy  the triangle inequality (so it may happen that d(vi, vj) plus d(vj, vk)\nis actual ly less than the “direct”  distance d(vi, vk)). The reason for this is to\nmake our formulation as gener al as possible. Indeed, Traveling Salesman\narises naturally in many applications where the points are not cities and the\ntraveler is not a salesman. For example, people have used Traveling\nSalesman formulations for problems such as planning the most efficient\nmotion of a robotic arm that drills holes in n points on the surface of a VLSI\nchip; or for serving I/O requests on a disk; or for sequencing the execution\nof n software modules to minimize the context-switching time.\nThus, given the set of distances,  we ask: Order the cities into a tour vi1,\nvi2, …, vin, with i1 = 1, so as to minimize the total distance  \n. The requirement i1 = 1 simply “orients” the tour so\nthat it starts at the home city, and the terms in the sum simply give the\ndistance from each city on the tour to the next one. (The last term in the\nsum is the distance required for the salesman to return home at the end.)\nHere is a decision version of the T raveling Salesman Problem.\nGiven a set of distances on n cities, and a bound D, is ther e a tour of length at most D?\nThe Hamiltonian Cycle Problem\nThe Traveling Salesman Problem has a natural graph-based analogue,\nwhich forms one of the fundam ental problems in graph theory . Given a\ndirected graph G = (V , E), we say that a cycle C in G is a Hamiltonian cycle\nif it visits each vertex exactly once. In other words, it constitutes a “tour” of\nall the vertices, with no repetitions. For example, the directed graph\npictured in Figure 8.6 has several Hamiltonian cycles; one visits the nodes\nin the order 1, 6, 4, 3, 2, 5, 1, while another visits the nodes in the order 1,\n2, 4, 5, 6, 3, 1.\nFigur e 8.6  A directed graph containing a Hamiltonian cycle.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 561})","('type', 'Document')"
"('page_content', ""The Hamiltonian Cycle Problem is then simply the following:\nGiven a dir ected graph G, does it contain a Hamiltonian cycle?\nProving Hamiltonian Cycle is NP-Complete\nWe now show that both these problems are NP-complete. We do this by\nfirst establishing the NP-completeness of Hamiltonian Cycle, and then\nproceeding to reduce from Hamiltonian Cycle to T raveling Salesman.\n(8.17)  Hamiltonian Cycle is NP-complete.\nProof. We first show that Hamiltonian Cycle is in NP. Given a directed\ngraph G = (V, E), a certificate that there is a solution would be the ordered\nlist of the vertices on a Ham iltonian cycle. We could then check, in\npolynomial time, that this list of vertices does contain each vertex exactly\nonce, and that each consecutive pair in the ordering is joined by an edge;\nthis would establish that the ordering defines a Hamiltonian cycle.\nWe now show that 3-SA T ≤P Ham iltonian Cycle. Why are we reducing\nfrom 3-SAT? Essentially , faced with Hamiltonian Cycle, we really have no\nidea what  to reduce from ; it's sufficiently different from all the problems\nwe've seen so far that there's no real basis for choosing. In such a situation,\none strategy is to go back to 3-SA T, since its combinatorial struc ture is very\nbasic. Of course, this strategy guarantees at least a certa in level of\ncomplexity in the reduction, since we need to encode variables and clauses\nin the language of graphs.\nSo consi der an arbitrary instance of 3-SA T, with variables x1,…, xn and\nclauses C1,…, Ck. We must show  how to solve it, given the ability to detect\nHamiltonian cycles in directed graphs. As always, it helps to focus on the\nessential ingredients of 3-SA T: We can set the values of the variables\nhowever we want, and we are given three chances to satisfy each clause."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 562})","('type', 'Document')"
"('page_content', ""We begin by describing a graph that contains 2n different Hamiltonian\ncycles that correspond very naturally to the 2n possible truth assignments to\nthe variables. After this, we will add nodes to model the constraints\nimposed by the clauses.\nWe construct n paths P1,…, Pn, where Pi consists of nodes vi1, vi2,…,\nvib for a quantity b that we take to be somewhat larger than the number of\nclauses k; say, b = 3k + 3. Ther e are edges from vij to vi,j+1 and in the other\ndirection from vi,j+1 to vij. Thus Pi can be traversed “left to right,” from vi1\nto vib, or “right to left,” from vib to vi1.\nFigur e 8.7  The reduction from 3-SA T to Hamiltonian Cycle: part 1.\nWe hook these paths together as follows. For each i = 1, 2, …, n - 1,\nwe define edges from vi1 to vi+1,1 and to vi+1,b. We also define edges from\nvib to vi+1,1 and to vi+1,b. We add two extra nodes s and t; we define edge s\nfrom s to v11 and v1b; from vn1 and vnb to t; and from t to s.\nThe constructio n up to this point is pictured in Figure 8.7. It's\nimportant to pause here and consider what the Hamiltonian cycles in our"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 563})","('type', 'Document')"
"('page_content', ""graph look like. Since only one edge leaves t, we know that any\nHamiltonian cycle \n  must use the edge (t, s). After entering s, the cycle \ncan then traverse P1 either left to right or right to left; regardless of what it\ndoes here, it can then traverse P2either left to right or right to left; and so\nforth, until it finishes traversing Pnand enters t. In other words , there are\nexactly 2n different Hamiltonian cycles, and they correspond to the n\nindependent choices of how to traverse each Pi.\nThis naturally models the n independent choices of how to set each\nvariables x1,…, xn in the 3-SA T instance. Thus we will identify each\nHamiltonian cycle uniquely with a truth assignment as follows: If \ntraverses Pi left to right, then xi is set to 1; otherwise, xi is set to 0.\nNow we add nodes to model the clauses; the 3-SA T instance will turn\nout to be satisfiable if and only if any Hamiltonian cycle survives. Let's\nconsider , as a concrete example, a clause\nIn the language of Hamiltonian cycles, this clause says, “The cycle\nshould traverse P1 left to right; or it should traverse P2 right to left; or it\nshould traverse P3 left to right.” So we add a node  c1, as in Figure 8.8, that\ndoes just this. (Note that certa in edges have been eliminated from this\ndrawing, for the sake of clarity .) For some value of ℓ, node c1 will have\nedges from v1ℓ, v2,ℓ+1, and v3ℓ; it will have edges to v1,ℓ+1, v2,ℓ, and v3, ℓ+1.\nThus it can be easily spliced into any Hamiltonian cycle that traverses P1\nleft to right by visiting node c1 between v1ℓ and v1, ℓ+1; similarly , c1 can be\nspliced into any Hamiltonian cycle that traverses P2 right to left, or P3 left\nto right. It canno t be spliced into a Hamiltonian cycle that does not do any\nof these things.\nMore generally , we will define a node cj for each clause Cj. We will\nreserve node positions 3j and 3j + 1 in each path Pi for variables that\nparticipate in clause Cj. Suppose clause Cj contains a term t. Then if t = xi,"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 564})","('type', 'Document')"
"('page_content', 'we will add edges ( vi,3j, cj) and ( cj vi,3j +1); if \n , we will add edges (vi, 3j +\n1, cj) and ( cj, vi, 3j).\nThis completes the construction of the graph G. Now, followin g our\ngeneric outline for NP-completeness proofs, we claim that the 3-SA T\ninstance is satisfiable if and only if G has a Hamiltonian cycle.\nFirst suppose there is a satisfyin g assignment for the 3-SA T instance.\nThen we define a Hamiltonian cycle following our informal plan above. If\nxi is assig ned 1 in the satisfying assignment, then we traverse the path Pi\nleft to right; otherwise we traverse Pi right to left. For each clause Cj since it\nis satisfied by the assignment, there will be at least one path Pi in whic h we\nwill be going in the “correct” direction relative to the node cj and we can\nsplice it into the tour there via edges incident on vi,3j and vi,3j+1.\nConversely , suppose that there is a Hamiltonian cycle \n  in G. The\ncrucial thing to observe is the following. If \n enters a node cj on an edge\nfrom vi,3j, it must depart on an edge to vi,3j+1. For if not, then vi,3j+1 will\nhave only one unvisited neighbor left, namely , vi,3j+2 and so the tour will not\nbe able to visit this node and still maintain the Hamiltonia n property .\nSymmetrically , if it enters from vi,3j+1, it must depart immediately to vi,3j.\nThus, for each node cj, the nodes immediately before  and after cj in the\ncycle \n  are joined by an edge e in G; thus, if we remove cj from the cycle\nand insert this edge e for each j, then we obtain a Hamiltonian cycle \n ′ on\nthe subgraph G - {c1,…, ck}. This is our original subgraph, before we added\nthe clause nodes; as we noted above, any Hamiltonian cycle in this\nsubgraph must traverse each Pi fully in one direction or the other. We thus\nuse \n ′ to define the following truth assignment for the 3-SA T instance. If \n′\ntraverses Pi left to right, then we set xi = 1; otherwise we set xi = 0. Since\nthe larger cycle \n  was able to visit each clause node cj, at least one of the\npaths was traversed in the “corr ect” direction relative to the node cj, and so\nthe assignment we have defined satisfies all the clauses.\nFigur e 8.8  The reduction from 3-SA T to Hamiltonian Cycle: part 2.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 565})","('type', 'Document')"
"('page_content', 'Having established that the 3-SA T instance is satisfiable if and only if\nG has a Hamiltonian cycle, our proof is complete. ▪\nProving Traveling Salesman is NP-Complete\nArmed with our basic hardness result for Hamiltonian Cycle, we can move\non to show the hardness of T raveling Salesman.\n(8.18)  Traveling Salesman is NP-complete.\nProof. It is easy to see that Traveling Salesman is in NP: The certificate is a\npermutation of the cities, and a certifier checks that the length of the\ncorresponding tour is at most the given bound.\nWe now show that Hamiltonian Cycle ≤P Traveling Salesman. Given a\ndirected graph G = (V, E), we define the following instance of Traveling')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 566})","('type', 'Document')"
"('page_content', ""Salesman. We have a city vi′ for each node vi of the graph G. We define\nd(vi′,vj′) to be 1 if there is an edge (vi,vj) in G, and we define it to be 2\notherwise.\nNow we claim that G has a Hamilton ian cycle if and only if there is\ntour of length at most n in our Traveling Salesman instance. For if G has a\nHamiltonian cycle, then this ordering of the corresponding cities defines a\ntour of length n. Convers ely, suppose there is a tour of length at most n. The\nexpression for the length of this tour is a sum of n terms, each of which is at\nleast 1; thus it must be the case that all the terms are equal to 1. Hence each\npair of nodes in G that correspond  to consecutive cities on the tour must be\nconnected by an edge; it follow s that the ordering of these corresponding\nnodes must form a Hamiltonian cycle. ▪\n \nNote that allowing asymmetric  distances in the Traveling Salesman\nProblem (d(vi′,vj′) ≠ d(vj,vi) played  a crucial role; since the graph in the\nHamiltonian Cycle instance is directed, our reduction yielded a Traveling\nSalesman instance with asymmetric distances.\nIn fact, the analo gue of the Hamiltonian Cycle Problem for undirected\ngraphs is also NP-complete; although we will not prove this here, it follows\nvia a not-too-dif ficult reduction from directed Hamiltonian Cycle. Using\nthis undirected Hamiltonian Cycle Problem, an exact analogue of (8.18) can\nbe used to prove that the Traveling Salesman Problem with symmetric\ndistances is also NP-complete.\nOf course, the most famous special case of the Traveling Salesman\nProblem is the one in which the distances are defined by a set of n points in\nthe plane. It is possible to reduce Hamiltonian Cycle to this special case as\nwell, though this is much trickier .\nExtensions: The Hamiltonian Path Problem\nIt is also sometimes useful to think about a variant of Hamilton ian Cycle in\nwhich it is not necessary to return to one's starting point. Thus, given a\ndirected graph G = (V, E), we say that a path P in G is a Hamiltonian path  if\nit contai ns each vertex exactly once. (The path is allowed to start at any\nnode and end at any node, provi ded it respects this constraint.) Thus such a\npath consists of distinct nodes vi1, vi2,…, vin in order, such that they\ncollectively constitute the entire vertex set V; by way of contrast with a"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 567})","('type', 'Document')"
"('page_content', 'Hamiltonian cycle, it is not necessary for there to be an edge from vin back\nto vi1. Now , the Hamiltonian Path Pr oblem  asks:\nGiven a dir ected graph G, does it contain a Hamiltonian path?\nUsing the hardness of Hamiltonian Cycle, we show the following.\n(8.19)  Hamiltonian Path is NP-complete.\nProof. First of all, Hamiltonian Path is in NP: A certificate could be a path\nin G, and a certifier could then check that it is indeed a path and that it\ncontains each node exactly once.\nOne way to show that Hamiltonian Path is NP-complete is to use a\nreduction from 3-SA T that is almost identical to the one we used for\nHamiltonian Cycle: We construc t the same graph that appears in Figure 8.7,\nexcept  that we do not include an edge from t to s. If there is any\nHamiltonian path in this modified graph, it must begin at s (since s has no\nincoming edges)  and end at t (since t has no outgoing edges). With this one\nchange, we can adapt the argument used in the Hamiltonian Cycle reduction\nmore or less word for word to argue that there is a satisfying assignment for\nthe instance of 3-SA T if and only if there is a Hamiltonian path.\nAn alternate way to show that Hamiltonian Path is NP-comple te is to\nprove that Hamiltonian Cycle ≤P Hamilto nian Path. Given an instance of\nHamiltonian Cycle, specified by a directed graph G, we construct a graph\nG′ as follows. We choose an arbitrary node v in G and replace it with two\nnew nodes v′ and v″. All edges out of v in G are now out of v′; and all edges\ninto v in G are now into v″. More precisely , each edge (v, w) in G is\nreplaced by an edge ( v′, w); and each edge ( u, v) in G is repla ced by an edge\n(u, v″). This completes the construction of G′.\nWe claim that G′ contains a Hamiltonian path if and only if G contains\na Hamiltonian cycle. Indeed, suppose C is a Hamiltonian cycle in G, and\nconsider traversing it beginning and ending at node v. It is easy to see that\nthe same  ordering of nodes form s a Hamiltonian path in G′ that begins at v′\nand ends at v″. Conversely , suppose P is a Hamiltonian path in G′. Clearly\nP must begin at v′ (since v′ has no incoming edges) and end at v″ (since v″\nhas no outgoing  edges). If we replace v′ and v″ with v, then this ordering of\nnodes forms a Hamiltonian cycle in G. ▪')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 568})","('type', 'Document')"
"('page_content', '8.6 Partitioning Problems\nIn the next two sections, we consider two fundamental partitioning\nproblems, in which we are searching over ways of dividing a collection of\nobjects into subsets. Here we show the NP-completeness of a problem that\nwe call 3-Dimensional Matching . In the next section we consider Graph\nColoring ,a problem that involves partitioning the nodes of a graph.\nThe 3-Dimensional Matching Problem\nWe begin by discussing the 3-Dimensional Matching Problem, which can\nbe motivated as a harder version of the Bipartite Matching Problem that we\nconsidered earlier . We can view the Bipartite Matching Problem in the\nfollowing way: We are given two sets X and Y, each of size n, and a set P of\npairs drawn from  X × Y. The question is: Does there exist a set of n pairs in\nP so that each element in X ∪ Y is contained in exactly one of these pairs?\nThe relation to Bipartite Matching is clear: the set P of pairs  is simply the\nedges of the bipartite graph.\nNow Bipartite Matching is a problem we know how to solve in\npolynomial time. But things get much more complicated when we move\nfrom ordered pairs to ordered triples. Consider the following 3-Dimensional\nMatching Problem:\nGiven disjo int sets X, Y, and Z, each of size n, and given a set T ⊆ X × Y × Z of ordered\ntriples, does there exist a set of n triples in T so that each element of X ∪ Y ∪ Z is\ncontained in exactly one of these triples?\nSuch a set of triples is called a perfect thr ee-dimensional matching.\nAn interesting thing about 3-Dimensional Matching, beyond its\nrelation to Bipartite Matching, is that it simultaneously forms a special case\nof both Set Cover and Set Packing: we are seeking to cover  the ground set X\n∪ Y ∪ Z with a collection of disjoint  sets. More concretely , 3-Dimensional\nMatching  is a special case of Set Cover  since we seek to cover the ground\nset U = X ∪ Y ∪ Z using at most n sets from a given collection (the triples).\nSimilarly , 3-Dimensional Matching is a special case of Set Packing, since\nwe are seeking n disjoint subsets of the ground set U = X ∪ Y ∪ Z.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 569})","('type', 'Document')"
"('page_content', ""Proving 3-Dimensional Matching Is NP-Complete\nThe arguments above can be turned quite easily into proofs that 3-\nDimensional Matching ≤P Set Cover and that 3-Dimensional Matching ≤P\nSet Packing. But this doesn't help us establish the NP-completeness of 3-\nDimensional Matching, since these reductions simply show that 3-\nDimensional Matching can be reduced to some very hard problems. What\nwe need to show  is the other direction: that a known NP-complete problem\ncan be reduced to 3-Dimensional Matching.\n(8.20)  3-Dimensional Matching is NP-complete.\nProof. Not surprisingly , it is easy to prove that 3-Dimensional Match ing is\nin NP. Given a collect ion of triples T ⊂X ×Y ×Z, a certificate that there is a\nsolution could be a collection of triples T′ ⊆ T. In polynomial time, one\ncould verify that each element in X ∪Y ∪Z belongs to exactly one of the\ntriples in T′.\nFor the reduction, we again return all the way to 3-SA T. This is\nperhaps a little more curious than in the case of Hamiltonian Cycle, since 3-\nDimensional Matching is so closely related to both Set Pack ing and Set\nCover; but in fact the partitioning requirement is very hard to encode using\neither of these problems.\nThus, consider an arbitrary instance of 3-SA T, with n variables x1, …,\nxn and k clauses C1, …, Ck. We will show how to solve it, given the ability\nto detect perfect three-dimensional matchings.\nThe overall strategy in this reduction will be similar (at a very high\nlevel) to the approach we followed in the reduction from 3-SA T to\nHamiltonian Cycle. We will first design gadgets that encode the\nindependent choices involved in the truth assignment to each variable; we\nwill then add gadgets that encode the constraints imposed by the clauses. In\nperforming this construction, we will initially describe all the elements in\nthe 3-Dimensional Matching instance simply as “elements,” without trying\nto specify for each one whether it comes from X, Y,or Z. At the end, we will\nobserve that they naturally decompose into these three sets.\nHere is the basic gadget associated with variable xi. We define\nelements Ai = {ai1, ai2, …, ai,2k} that constitute the core of the gadget; we"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 570})","('type', 'Document')"
"('page_content', 'define elements Bi = {bi1, …, bi,2k} at the tips of the gadget. For each j = 1,\n2, …, 2k, we define a triple tij = (aij, ai,j+1, bij), where we interpret addition\nmodulo 2k. Three of these gadgets are pictured in Figure 8.9. In gadget i,\nwe will call a triple tij even if j is even, and odd if j is odd. In an analogous\nway, we will refer to a tip bij as being either even or odd.\nThese will be the only triples that contain the elements in Ai, so we can\nalready say something about how they must be covered in any perfect\nmatching: we must either use all the even triples in gadget i, or all the odd\ntriples in gadget  i. This will be our basic way of encoding the idea that xi\ncan be set to either 0 or 1; if we select all the even triples, this will represent\nsetting xi = 0, and if we select all the odd triples, this will represent setting\nxi = 1.\nFigur e 8.9  The reduction from 3-SA T to 3-Dimensional Matching.\nHere is another way to view the odd/even decision, in terms of the tips\nof the gadget. If we decide to use the even triples, we cover the even tips of\nthe gadg et and leave the odd tips free. If we decide to use the odd triples,\nwe cover the odd tips of the gadget and leave the even tips free. Thus our\ndecision of how to set xi can be viewed as follows: Leaving the odd tips free\ncorresponds to 0, while leaving  the even tips free correspond s to 1. This\nwill actually be the more useful way to think about things in the remainder\nof the construction.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 571})","('type', 'Document')"
"('page_content', ""So far we can make this even/odd choice independently for each of the\nn variable gadgets. We now add elements to model the clauses and to\nconstrain the assignments we can choose. As in the proof of (8.17), let's\nconsider the example of a clause\nIn the language of three-dime nsional matchings, it tells us, “The\nmatching on the cores of the gadgets should leave the even tips of the first\ngadget free; or it should leave the odd tips of the second gadge t free; or it\nshould leave the even tips of the third gadget free.” So we add a clause\ngadget  that does precis ely this. It consi sts of a set of two core elements P1 =\n{p1, p1′}, and three triples that contain them. One has the form (p1, p1′, b1j)\nfor an even tip b1j; another includes p1, p1′, and an odd tip b2,j′; and a third\nincludes p1, p1′, and an even tip b3,j″. These are the only three triples that\ncover P1, so we know that one of them  must be used; this enforces the\nclause constraint exactly .\nIn general, for clause Cj, we create a gadget with two core elements Pj\n= {pj, pj′}, and we define three triples containing Pj as follows. Suppose\nclause Cj contains a term t. If t = xi, we define a triple (pj, pj′, bi,2j); if \n ,\nwe define a triple ( pj, pj′, bi,2j-1). Note that only clause gadget j makes use of\ntips bim with m = 2j or m = 2j - 1; thus, the clause gadgets will never\n“compete” with each other for free tips.\nWe are almost done with the construction, but there's still one problem.\nSuppose the set of clauses has a satisfying assignment. Then we make the\ncorresponding choices of odd/even for each variable gadget; this leaves at\nleast one free tip for each clause gadget, and so all the core elem ents of the\nclause gadgets get covered as well. The problem is that we haven't cover ed\nall the tips. We started with n · 2k = 2nk tips; the triples {tij }covered nk of\nthem; and the clause gadgets covered an additional k of them. This leaves ( n\n- 1)k tips left to be covered.\nWe handle this problem with a very simple trick: we add (n - 1)k\n“cleanup gadgets” to the construction. Cleanup gadget i consists of two core"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 572})","('type', 'Document')"
"('page_content', 'elements Qi = {qi, qi′}, and there is a triple (qi, qi, b) for every  tip b in every\nvariable gadget. This is the final piece of the construction.\nThus, if the set of clauses has a satisfying assignment, then we make\nthe corresponding choices of odd/even for each variable gadget; as before,\nthis leaves at least one free tip for each clause gadget. Using the cleanup\ngadgets to cover the remaining tips, we see that all core elem ents in the\nvariable, clause,  and cleanup gadgets have been covered, and all tips have\nbeen covered as well.\nConversely , suppose there is a perfect three-dimensional matching in\nthe insta nce we have constructed. Then, as we argued above, in each\nvariable gadget the matching chooses either all the even {tij }or all the odd\n{tij }. In the former case, we set xi = 0 in the 3-SA T instance; and in the\nlatter case, we set xi = 1. Now consider clause Cj; has it been satisfied?\nBecause the two core elements in Pj have been covered, at least one of the\nthree variable gadgets corresponding to a term in Cj made the “correct”\nodd/even decision, and this induces a variable assignment that satisfies Cj.\nThis concludes the proof, except for one last thing to worry about:\nHave we really constructed an instance of 3-Dimensional Matching? We\nhave a collectio n of elements, and triples containing certain of them, but\ncan the elements really be partitioned into appropriate sets X, Y, and Z of\nequal size?\nFortunately , the answer is yes. We can define X to be set of all aij with\nj even, the set of all pj, and the set of all qi. We can define Y to be set of all\naij with j odd, the set of all pj′, and the set of all qi′. Finally, we can define Z\nto be the set of all tips bij. It is now easy to check that each triple consists of\none element from each of X, Y, and Z. ▪\n8.7 Graph Coloring\nWhen you color a map (say, the states in a U.S. map or the countries on a\nglobe), the goal is to give neighboring regions different colors so that you\ncan see their common borders clearly while minimizing visual distraction\nby using only a few colors. In the middle of the 19th century , Francis\nGuthrie noticed that you could color a map of the counties of England this')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 573})","('type', 'Document')"
"('page_content', ""way with only four colors, and he wondered whether the same was true for\nevery map. He asked his broth er, who relayed the question to one of his\nprofessors, and thus a famous mathematical problem was born: the Four -\nColor Conjectur e.\nThe Graph Coloring Problem\nGraph coloring  refers to the same process on an undirected graph G, with\nthe nodes playing the role of the regions to be colored, and the edges\nrepresenting pairs that are neighbors. W e seek to assign a color  to each node\nof G so that if (u, v) is an edge, then u and v are assigned different colors;\nand the goal is to do this while using a small set of colors. More formally , a\nk-coloring  of G is a function f : V → {1,2, …, k} so that for every edge (u,\nv), we have f(u) ≠ f(v). (So the availa ble colors here are named 1, 2,…, k,\nand the function f represen ts our choice of a color  for each node.) If G has a\nk-coloring, then we will say that it is a k-colorable graph .\nIn contrast with the case of maps in the plane, it's clear that there's not\nsome fixed constant k so that every graph has a k-coloring: For example, if\nwe take a set of n nodes and join each pair of them by an edge, the resulting\ngraph needs n colors. However , the algorithmic version of the problem is\nvery interesting:\nGiven a graph G and a bound k, does G have a k-coloring?\nWe will refer to this as the Graph Coloring Problem ,oras k-Coloring  when\nwe wish to emphasize a particular choice of k.\nGraph Coloring turns out to be a problem with a wide range of\napplications. While it's not clear there's ever been much genuine demand\nfrom cartographers, the problem  arises naturally whenever one is trying to\nallocate resources in the presence of conflicts.\nSuppose, for example, that we have a collection of n process es on a\nsystem that can run multiple jobs concurrently , but certain pairs of jobs\ncannot be scheduled at the same time because they both need a\nparticular resour ce. Over the next k time steps of the system, we'd like\nto schedule each process to run in at least one of them. Is this possible?\nIf we construct a graph G on the set of processes, joining two by an\nedge if they have a conflict, then a k-coloring of G represents a"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 574})","('type', 'Document')"
"('page_content', ""conflict-free schedule of the processes: all nodes colored j can be\nscheduled in step j, and there will never be contention for any of the\nresources.\nAnother well-known application arises in the design of compilers.\nSuppose we are compiling a program and are trying to assig n each\nvariable to one of k register s. If two variables are in use at a common\npoint in time, then they cannot be assigned to the same register .\n(Otherwise one would end up overwriting the other .) Thus we can\nbuild a graph G on the set of variables, joining two by an edge if they\nare both in use at the same time.  Now a k-coloring of G corresponds to\na safe way of allocating variables to registers: All nodes colore d j can\nbe assigned to register j, since no two of them are in use at the same\ntime.\nA third application arises in wavelength assignment for wireless\ncommunication devices: We'd like to assign one of k transmitting\nwavelengths to each of n devices; but if two devices are sufficiently\nclose to each other , then they need to be assigned different\nwavelengths to prevent interfe rence. To deal with this, we build a\ngraph G on the set of devices, joining two nodes if they're close\nenough to interfere with each other; a k-coloring of this graph is now\nan assig nment of wavelengths so that any nodes assigned the same\nwavelength are far enough apart that interference won't be a problem.\n(Interestingly , this is an application of graph coloring where the\n“colors” being assigned to nodes are positions on the electromagnetic\nspectrum—in other words, under a slightly liberal interpretation,\nthey're actually colors.)\nThe Computational Complexity of Graph\nColoring\nWhat is the complexity of k-Coloring? First of all, the case k = 2 is a\nproblem we've already seen in Chapter 3. Recall, there, that we considered\nthe problem of determining whether a graph G is bipartite, and we showed\nthat this is equivalent to the following question: Can one color the nodes of\nG red and blue so that every edge has one red end and one blue end?"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 575})","('type', 'Document')"
"('page_content', 'But this latter question is precisely the Graph Coloring Problem  in the\ncase when there are k = 2 colors (i.e., red and blue) available. Thus we have\nargued that\n(8.21)  A graph G is  2-colorable if and only if it is bipartite.\nThis means we can use the algorithm from Section 3.4 to decide\nwhether an input graph G is 2-colorable in O(m + n) time, where n is the\nnumber of nodes of G and m is the number of edges.\nAs soon  as we move up to k = 3 colors, things become much harder .\nNo simple efficient algorithm for the 3-Coloring Problem suggests itself, as\nit did for 2-Colo ring, and it is also a very difficult problem to reason about.\nFor example, one might initially suspect that any graph that is not 3-\ncolorable will contain a “proof” in the form of four nodes that are all\nmutually adjacent (and hence would need four different colors)—but this is\nnot true. The graph in Figure 8.10, for instance, is not 3-colorab le for a\nsomewhat more subtle (though still explainable) reason, and it is possible to\ndraw much more complicated graphs that are not 3-colorable for reasons\nthat seem very hard to state succinctly .\nFigur e 8.10  A graph that is not 3-colorable.\nIn fact, the case of three colors is already a very hard problem,  as we\nshow now .\nProving 3-Coloring Is NP-Complete\n(8.22)  3-Coloring is NP-complete.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 576})","('type', 'Document')"
"('page_content', ""Proof. It is easy to see why the problem is in NP. Given G and k, one\ncertificate that the answer is yes is simply a k-coloring: One can verify in\npolynomial time that at most k colors are used, and that no pair of nodes\njoined by an edge receive the same color .\nLike the other problems in this section, 3-Coloring is a problem that is\nhard to relate at a superficial level to other NP-complete problems we've\nseen. So once again, we're going to reach all the way back to 3-SA T. Given\nan arbitr ary instance of 3-SA T, with variables x1, …, xn and clauses C1, …,\nCk, we will solve it using a black box for 3-Coloring.\nThe beginning of the reduction is quite intuitive. Perhaps the main\npower of 3-Coloring for encoding Boolean expressions lies in the fact that\nwe can associate graph nodes with particular terms, and by joining them\nwith edges we ensure that they get different colors; this can be used to set\none true and the other false. So with this in mind, we define nodes vi and \ncorresponding to each variable xi and its negation \n . We also define three\n“special nodes” T, F, and B, which we refer to as True, False , and Base .\nTo begin, we join each pair of nodes vi, \n to each other by an edge, and\nwe join both these nodes to Base . (This forms a triangle on vi, \n, and Base ,\nfor each i.) We also join True, False , and Base  into a triangle. The simple\ngraph G we have define d thus far is pictured in Figure 8.11, and it already\nhas some useful properties.\nFigur e 8.1 1 The beginning of the reduction for 3-Coloring."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 577})","('type', 'Document')"
"('page_content', ""In any 3-coloring of G, the nodes vi and \n  must get different colors,\nand both must be dif ferent from Base .\nIn any 3-coloring of G, the nodes True, False , and Base  must get all\nthree colors in some permutation . Thus we can refer to the three  colors\nas the True color , the False  color , and the Base  color , based on which\nof these three nodes gets which color . In particular , this means that for\neach i, one of vi or \n gets the True color , and the other gets the False\ncolor . For the remainder of the construction, we will consider the\nvariable xi to be set to 1 in the given instance of 3-SA T if and only if\nthe node vi gets assigned the True color .\nSo in summary , we now have a graph G in which any 3-coloring\nimplicitly determ ines a truth assignment for the variables in the 3-SA T\ninstance. W e now need to grow G so that only satisfying assignments can be\nextended to 3-colorings of the full graph. How should we do this?\nAs in other 3-SA T reductions, let's consider a clause like \n . In\nthe language of 3-colorings of G, it says,  “At least one of the nodes v1, \n,\nor v3 should get the True color .” So what we need is a little subgraph that\nwe can plug into G, so that any 3-coloring that extends into this subgraph\nmust have the property of assig ning the True color to at least one of v1, \n,\nor v3. It takes some experimentation to find such a subgraph, but one that\nworks is depicted in Figure 8.12 .\nFigur e 8.12  Attaching a subgraph to represent the clause \n ."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 578})","('type', 'Document')"
"('page_content', ""This six-node subgraph “attaches” to the rest of G at five existing\nnodes: True, False , and those corre sponding to the three terms in the clause\nthat we're trying to represent (in this case, v1, \n, and v3.) Now suppose that\nin some 3-coloring of G all three of v1, \n, and v3 are assigned the False\ncolor . Then the lowest two shaded nodes in the subgraph must receive the\nBase  color , the three shaded nodes above them must receive, respectively ,\nthe False , Base , and True colors, and hence there's no color that can be\nassigned to the topmost shaded node. In other words, a 3-coloring in which\nnone of v1, \n, or v3 is assigned the True color cannot be extended to a 3-\ncoloring of this subgraph.2\nFinally , and conversely , some hand-checking of cases shows that as\nlong as one of v1, \n, or v3 is assigned the True color , the full subgraph can\nbe 3-colored.\nSo from this, we can complete the construction: We start with the\ngraph G defined above, and for each clause in the 3-SA T instance, we attach\na six-node subgraph as shown in Figure 8.12 . Let us call the resulting graph\nG′.\nWe now claim that the given 3-SA T instance is satisfiable if and only if\nG′ has a 3-coloring. First, suppose that there is a satisfying assignment for\nthe 3-SA T instance. We define a coloring of G′ by first coloring Base , True,\nand False  arbitrarily with the three colors , then, for each i, assigning vi the\nTrue color if xi = 1 and the False  color if xi = 0. We then assign \n  the only\navailable color . Finally , as argued above, it is now possible to extend this 3-\ncoloring into each six-node clause subgraph, resulting in a 3-coloring of all\nof G′.\nConversely , suppose G′ has a 3-colorin g. In this coloring, each node vi\nis assigned either the True color or the False  color; we set the variable xi\ncorrespondingly . Now we claim  that in each clause of the 3-SA T instance,\nat least one of the terms in the clause has the truth value 1. For if not, then\nall three of the corresponding nodes has the False  color in the 3-coloring of\nG′ and, as we have seen above, there is no 3-coloring of the corresponding\nclause subgraph consistent with this—a contradiction. ▪\nWhen k > 3, it is very easy to reduce the 3-Coloring Problem to k-\nColoring. Essen tially , all we do is to take an instance of 3-Coloring,\nrepresented by a graph G, add k - 3 new nodes, and join these new nodes to\neach other and to every node in G. The resulting graph is k-colorable if and"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 579})","('type', 'Document')"
"('page_content', 'only if the origin al graph G is 3-colorable. Thus k-Coloring for any k > 3 is\nNP-complete as well.\nCoda: The Resolution of the Four-Color\nConjecture\nTo conc lude this section, we should finish off the story of the Four-Color\nConjecture for maps in the plane as well. After more than a hundred years,\nthe conjecture was finally proved by Appel and Haken in 1976. The\nstructure of the proof was a simple induction on the number of regions, but\nthe induction step involved nearly two thousand fairly complicated cases,\nand the verification of these cases had to be carried out by a computer . This\nwas not a satisfy ing outcome for most mathematicians: Hoping for a proof\nthat would yield  some insight into why the result was true, they instead got\na case analysis of enormous complexity whose proof could not be checked\nby hand . The problem of findin g a reasonably short, human-readable proof\nstill remains open.\n8.8 Numerical Problems\nWe now consider some computationally hard problems that involve\narithmetic operations on numbe rs. We will see that the intractability here\ncomes from the way in which some of the problems we have seen earlier in\nthe chapter can be encoded in the representations of very lar ge integers.\nThe Subset Sum Problem\nOur basic problem in this genre will be Subset Sum, a special case of the\nKnapsack Problem that we saw before in Section 6.4 when we covered\ndynamic programming. We can formulate a decision version of this\nproblem as follows.\nGiven natural numbers w 1, …, wn , and a tar get number W , is ther e a subset of  {w1, …,\nwn } that adds up to pr ecisely W?\nWe have  already  seen an algorit hm to solve this problem; why are we\nnow including it on our list of computationally hard problems? This goes')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 580})","('type', 'Document')"
"('page_content', 'back to an issue that we raised the first time we considered Subset Sum in\nSection 6.4. The algorithm we developed there has running time O(nW),\nwhich is reasonable when W is small, but becomes hopeless ly impractical\nas W (and the numbers wi) grow large. Consider , for exam ple, an instance\nwith 100 numbe rs, each of which is 100 bits long. Then the input is only\n100 × 100 = 10,000 digits, but W is now roughly 2100.\nTo phras e this more generally , since integers will typically be given in\nbit representation, or base-10 representation, the quantity W is really\nexponential  in the size of the input; our algorithm was not a polynomial-\ntime algorithm. (We referred to it as pseudo-polynomial , to indicate that it\nran in time polynomial in the magnitude of the input numbers, but not\npolynomial in the size of their representation.)\nThis is an issue  that comes up in many settings; for examp le, we\nencountered it in the context of network flow algorithms, where the\ncapacities had integer values. Other settings may be familiar to you as well.\nFor example, the security of a cryptosystem such as RSA is motivated by\nthe sense that factoring a 1,000-bit number is difficult. But if we considered\na running time of 21000 steps feasible, factoring such a number would not be\ndifficult at all.\nIt is worth pausing here for a moment and asking: Is this notion of\npolynomial time for numerical  operations too severe a restriction? For\nexample, given two natural numbers w1 and w2 represented in base- d\nnotation for some d > 1, how long does it take to add, subtract, or multiply\nthem? This is an issue we touched on in Section 5.5, where we noted that\nthe standard ways that kids in elementary school learn to perform these\noperations have (low-degree) polynomial running times. Addition and\nsubtraction (with carries) take O(log w1 + log w2) time, while the standard\nmultiplication algorithm runs in O(log w1 · log w2) time. (Recall that in\nSection 5.5 we discussed the design of an asymptotically faster\nmultiplication algorithm that elementary schoolchildren are unlikely to\ninvent on their own.)\nSo a basic question is: Can Subset Sum be solved by a (genuinely)\npolynomial-time algorithm? In other words, could there be an algorithm\nwith running time polynomial in n and log W? Or polynomial in n alone?\nProving Subset Sum Is NP-Complete')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 581})","('type', 'Document')"
"('page_content', 'The following result suggests that this is not likely to be the case.\n(8.23)  Subset Sum is NP-complete.\nProof. We first show that Subset Sum is in NP. Given natural numbers w1,\n…, wn, and a target W, a certificate that there is a solution would be the\nsubset wi1, …, wik that is purported to add up to W. In polynomial time, we\ncan compute the sum of these numbers and verify that it is equal to W.\nWe now reduce a known NP-co mplete problem to Subset Sum. Since\nwe are seeking a set that adds up to exactly  a given  quantity  (as opposed to\nbeing bounded above or below by this quantity), we look for a\ncombinatorial problem that is based on meeting an exact  bound. The 3-\nDimensional Matching Problem is a natural choice; we show that 3-\nDimensional Matching ≤P Subset Sum. The trick will be to encode the\nmanipulation of sets via the addition of integers.\nSo consider an instance of 3-Dimensional Matching specified by sets\nX, Y, Z, each of size n, and a set of m triples T ⊆ X × Y × Z. A common way\nto represent sets is via bit-vectors : Each entry in the vector corresponds to a\ndifferent element, and it holds a 1 if and only if the set contains that\nelement. We adopt this type of approach for representing each triple t = (xi,\nyj, zk) ∊ T: we construct a number wt with 3n digits that has a 1 in positions\ni, n + j, and 2n + k, and a 0 in all other positions. In other words, for some\nbase d > 1, wt = di-1 + dn+j-1 + d2n+k-1.\nNote how taking the union of triples almost  corresponds to integer\naddition: The 1s fill in the places where there is an element in any of the\nsets. But we say almost  because addition includes carries : too many 1s in\nthe same  column will “roll over” and produce a nonzero entry  in the next\ncolumn. This has no analogue in the context of the union operation.\nIn the present situation, we handle this problem by a simple trick. We\nhave only m number s in all, and each has digits equal to 0 or 1; so if we\nassume that our numbers are written in base d = m + 1, then there will be no\ncarries at all.\nThus we construct the following instance of Subset Sum. For each\ntriple t = (xi, yj, zk) ∊ T, we construct a number wt in base m + 1 as defined\nabove. We defin e W to be the numbe r in base m + 1 with 3n digits, each of\nwhich is equal to 1, that is, \n .')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 582})","('type', 'Document')"
"('page_content', 'We claim  that the set T of triples contains a perfect three-dimensional\nmatching if and only if there is a subset of the numbers {wt} that adds up to\nW. For suppose there is a perfect three-dimensional matching consisting of\ntriples t1, …, tn. Then in the sum wt1 + … + wtn, there is a singl e 1 in each\nof the 3 n digit positions, and so the result is equal to W.\nConversely , suppose there exists a set of numbers wt1, …, wtk that adds\nup to W. Then since each wti has three 1s in its representation, and there are\nno carries, we know that k = n. It follows that for each of the 3n digit\npositions, exactly one of the wti has a 1 in that position. Thus, t1, …, tk\nconstitute a perfect three-dimensional matching. ▪\nExtensions: The Hardness of Certain Scheduling\nProblems\nThe hardness of Subset Sum can be used to establish the hardness of a\nrange of scheduling problems—including some that do not obviously\ninvolve the addition of numbe rs. Here is a nice example, a natural (but\nmuch harder) generalization of a scheduling problem we solved in Section\n4.2 using a greedy algorithm.\nSuppose we are given a set of n jobs that must be run on a single\nmachine. Each job i has a release time ri when it is first available for\nprocessing; a deadline di by whic h it must be completed; and a processing\nduration ti. We will assume  that all of these parameters are natural number s.\nIn order to be completed, job i must be allocated a contiguous slot of ti time\nunits somewhere in the interval [ ri, di]. The machine can run only one job at\na time. The question is: Can we schedule all jobs so that each completes by\nits deadline? We will call this an instance of Scheduling with Release Times\nand Deadlines .\n(8.24)  Scheduling with Release T imes and Deadlines is NP-complete.\nProof. Given an instance of the problem, a certificate that it is solvable\nwould be a specification of the starting time for each job. We could then\ncheck that each job runs for a distinct interval of time, between its release\ntime and deadline. Thus the problem is in NP.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 583})","('type', 'Document')"
"('page_content', 'We now show that Subset Sum is reducible to this scheduling problem.\nThus, consider an instance of Subset Sum with numbers w1, …, wn and a\ntarget W. In constructing an equivalent scheduling instance, one is struck\ninitially by the fact that we have so many parameters to manage: release\ntimes, deadlines, and durations. The key is to sacrifice most of this\nflexibility , produ cing a “skeletal” instance of the problem that still encodes\nthe Subset Sum Problem.\nLet \n . We define jobs 1,2,…, n; job i has a release time of 0,\na deadline of S + 1, and a duration of wi. For this set of jobs, we have the\nfreedom to arrange them in any order , and they will all finish on time.\nWe now further constrain the instance so that the only way to solve it\nwill be to group together a subset of the jobs whose durati ons add up\nprecisely to W. To do this, we define an (n + 1)st job; it has a release time of\nW, a deadline of W + 1, and a duration of 1.\nNow consider any feasible solution to this instance of the scheduling\nproblem. The (n + 1)st job must be run in the interval [W, W + 1]. This\nleaves S available time units between the common release time and the\ncommon deadline; and there are S time units worth of jobs to run. Thus the\nmachine must not have any idle time, when no jobs are running. In\nparticular , if jobs i1, …, ik are the ones that run before time W, then the\ncorresponding numbers wi1, …, wik in the Subset Sum instance add up to\nexactly W.\nConversely , if there are numbers wi1, …, wik that add up to exactly W,\nthen we can schedule these before job n + 1 and the remainder after job n +\n1; this is a feasible solution to the scheduling instance. ▪\nCaveat: Subset Sum with Polynomially Bounded\nNumbers\nThere is a very common source of pitfalls involving the Subset Sum\nProblem, and while it is closely connected to the issues we have been\ndiscussing alread y, we feel it is worth discussing explicitly . The pitfall is the\nfollowing.\nConsider the special case of Subset Sum, with n input numbers, in which W is bounded\nby a polynomial function of n. Assuming  P ≠ NP, this special case is  not NP-complete.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 584})","('type', 'Document')"
"('page_content', ""It is not NP-com plete for the simple reason that it can be solved in time\nO(nW), by our dynamic programming  algorithm from Section 6.4; when W\nis bounded by a polynomial function of n, this is a polynomial-time\nalgorithm.\nAll this is very clear; so you may ask: Why dwell on it? The reason is\nthat there is a genre of problem that is often wrongly claimed to be NP-\ncomplete (even in published papers) via reduction from this special case of\nSubset Sum. Here is a basic example of such a problem, which we will call\nComponent Gr ouping .\nGiven a graph G that is not connected, and a number k, does there exist a subset of its\nconnected components whose union has size exactly k?\nIncorr ect Claim.  Component Grouping is NP-complete.\nIncorr ect Proof. Component Grouping is in NP, and we'll skip the\nproof of this. We now attempt to show that Subset Sum ≤P Component\nGrouping. Given an instance of Subset Sum with numbers w1, …, wn and\ntarget W, we construct an instance of Component Grouping as follows. For\neach i,we construct a path Pi of lengt h wi. The graph G will be the union of\nthe paths P1, …, Pn, each of which is a separate connected component. We\nset k = W. It is clear that G has a set of connected components whose union\nhas size k if and only if some subset of the numbers w1, …, wn adds up to\nW. ▪\n \nThe error here is subtle; in particular , the claim in the last sentence is\ncorrect. The problem is that the construction described abov e does not\nestablish that Subset Sum ≤P Component Grouping, becaus e it requires\nmore than polyn omial time. In constructing the input to our black box that\nsolves Component Grouping, we had to build the encoding of a graph of\nsize w1 + … + wn, and this takes time exponential in the size of the input to\nthe Subset Sum instance. In effect, Subset Sum works with the numbers w1,\n…, wn in a very compa ct representation, but Component Grouping does not\naccept “compact” encodings of graphs.\nThe problem is more fundament al than the incorrectness of this proof;\nin fact, Component Grouping is a problem that can be solved in polynomial\ntime. If n1, n2, …, nc denote the sizes of the connected components of G, we"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 585})","('type', 'Document')"
"('page_content', ""simply use our dynamic programming algorithm for Subset Sum to decide\nwhether some subset of these numbers {ni} adds up to k. The running time\nrequired for this is O(ck); and since c and k are both bound ed by n, this is\nO(n2) time.\nThus we have discovered a new polynomial-time algorithm by\nreducing in the other direction, to a polynomial-time solvable special case\nof Subset Sum.\n8.9 Co-NP and the Asymmetry of NP\nAs a further perspective on this general class of problems, let's return to the\ndefinitions underlying the class NP. We've seen that the notion of an\nefficient certifie r doesn't suggest a concrete algorithm for actually solving\nthe problem that's better than brute-force search.\nNow here's another observation: The definition of efficient\ncertification, and hence of NP, is fundamentally asymmetric . An input\nstring s is a “yes” instance if and only if there exists a short t so that B(s, t)\n= yes. Negating  this statement, we see that an input string s is a “no”\ninstance if and only if for all  short t, it's the case that B(s, t) = no.\nThis relates closely to our intuit ion about NP: When we have  a “yes”\ninstance, we can provide a short proof of this fact. But when we have a “no”\ninstance, no correspondingly short proof is guaranteed by the definition; the\nanswer is no simply because there is no string that will serve as a proof. In\nconcrete terms, recall our question from Section 8.3 : Given an unsatisfiable\nset of clauses, what evidence could we show to quickly convince you that\nthere is no satisfying assignment?\nFor every proble m X, there is a natural complementary  problem \n : For\nall input strings s, we say s ∊ \n if and only if s ∉ X. Note that if X ∊ P,\nthen \n  ∊ P, since from an algorithm A that solves X, we can simply produce\nan algorithm A that runs \n  and then flips its answer .\nBut it is far from clear that if X ∊ NP, it shou ld follow  that \n  ∊ NP.\nThe problem \n , rather , has a different property: for all s, we have s ∊ \n if\nand only if for all t of length at most p(|s|), B(s, t) = no. This is a\nfundamentally different definition, and it can't be worked aroun d by simply\n“inverting” the output of the efficient certifier B to produ ce \n. The problem"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 586})","('type', 'Document')"
"('page_content', ""is that the “exists t” in the definitio n of NP has become a “for all t,” and this\nis a serious change.\nThere is a class of problems parallel to NP that is designed to model\nthis issue; it is called, naturally enough, co-NP. A problem X belongs to co-\nNP if and only if the complementary problem \n  belongs to NP. We do not\nknow for sure that NP and co- NP are dif ferent; we can only ask\n(8.25)  Does NP  = co- NP?\nAgain, the widespread belief is that NP ≠ co-NP: Just because the\n“yes” instances of a problem have short proofs, it is not clear why we\nshould believe that the “no” instances have short proofs as well.\nProving NP ≠ co-NP would be an even bigger step than proving P ≠\nNP, for the following reason:\n(8.26)  If NP ≠ co- NP, then P ≠ NP.\nProof. We'll actually prove the contrapositive statement: P = NP implies NP\n= co-NP. Essentially , the point is that P is closed under complementation;\nso if P = NP, then NP would be close d under complementation as well.\nMore formally , starting from the assumption P = NP , we have\nand\nHence it would follow that NP ⊆ co-NP and co-NP ⊆ NP, whence NP =\nco-NP. ▪\nGood Characterizations: The Class NP ∩ co-NP\nIf a problem X belongs to both NP and co- NP, then it has the following nice\nproperty: When  the answer is yes, there is a short proof; and when the"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 587})","('type', 'Document')"
"('page_content', ""answer is no, there is also a short proof. Thus problems that belong to this\nintersection NP ∩ co-NP are said to have a good characterization , since\nthere is always a nice certificate for the solution.\nThis notion corresponds directly to some of the results we have seen\nearlier . For example, consider the problem of determining whether a flow\nnetwork contain s a flow of value at least ν, for some quantity ν. To prove\nthat the answer is yes, we could simply exhibit a flow that achieves this\nvalue; this is consistent with the problem belonging to NP. But we can also\nprove the answer is no: We can exhibit a cut whose capacity is strictly less\nthan ν. This duality between “yes” and “no” instances is the crux of the\nMax-Flow Min-Cut Theorem.\nSimilarly , Hall's Theorem for matchings from Section 7.5 proved that\nthe Bipartite Perfect Matching Problem is in NP ∩ co-NP: We can exhibit\neither a perfect matching, or a set of vertices A ⊆ X such that the total\nnumber of neighbors of A is strictly less than | A|.\nNow , if a problem X is in P, then it belongs to both NP and co-NP;\nthus, P ⊆ NP ∩ co-NP. Interestingly , both our proof of the Max-Flow Min-\nCut Theorem and our proof of Hall's Theorem came hand in hand with\nproofs of the stronger results that Maximum Flow and Bipartite Matching\nare problems in P. Nevertheless, the good charact erizations themselves are\nso clean that formulating them separately still gives us a lot of conceptual\nleverage in reasoning about these problems.\nNaturally , one would like to know whether there's a problem that has a\ngood characterization but no polynomial-time algorithm. But this too is an\nopen question:\n(8.27)  Does  P = NP ∩ co- NP?\nUnlike questions (8.11) and (8.25), general opinion seems somewhat\nmixed on this one. In part, this is because there are many cases  in which a\nproblem was found to have a nontrivial good characterizatio n; and then\n(sometimes many years later) it was also discovered to have a polynomial-\ntime algorithm.\n8.10 A Partial Taxonomy of Hard Problems"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 588})","('type', 'Document')"
"('page_content', ""We've now reached the end of the chapter , and we've encounte red a fairly\nrich array of NP-complete problems. In a way, it's useful to know a good\nnumber of different NP-complete problems: When you encou nter a new\nproblem X and want to try proving it's NP-complete, you want to show Y ≤P\nX for some known  NP-complete problem Y—so the more options you have\nfor Y, the better .\nAt the same time, the more options you have for Y, the more\nbewildering it can be to try choosing the right one to use in a particular\nreduction. Of course, the whol e point of NP-completeness is that one of\nthese problems will work in your reduction if and only if any of them will\n(since they're all equivalent with respect to polynomial-time reductions);\nbut the reductio n to a given problem X can be much, much easier starting\nfrom some problems than from others.\nWith this in mind, we spend this concluding section on a review of the\nNP-complete problems we've come across in the chapter , grouped into six\nbasic genres. Together with this grouping, we offer some suggestions as to\nhow to choose a starting problem for use in a reduction.\nPacking Problems\nPacking problem s tend to have the following structure: You're given a\ncollection of objects, and you want to choose at least k of them; making\nyour life difficult is a set of conflicts among the objects, preventing you\nfrom choosing certain groups simultaneously .\nWe've seen two basic packing problems in this chapter .\nIndependent Set: Given a graph G and a number k, does G contain an\nindependent set of size at least k?\nSet Packing : Given a set U of n elements, a collection S1, …, Sm of\nsubsets of U, and a number k, does there exist a collection of at least k\nof these sets with the property that no two of them intersect?\nCovering Problems\nCovering proble ms form a natural contrast to packing problems, and one\ntypically recognizes them as having the following structure: you're given a\ncollection of objects, and you want to choose a subset that collectively"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 589})","('type', 'Document')"
"('page_content', ""achieves a certain goal; the challenge is to achieve this goal while choosing\nonly k of the objects.\nWe've seen two basic covering problems in this chapter .\nVertex Cover : Given a graph G and a number k, does G contain a\nvertex cover of size at most k?\nSet Cover : Given a set U of n elements, a collection S1, …, Sm of\nsubsets of U, and a number k, does there exist a collection of at most k\nof these sets whose union is equal to all of U?\nPartitioning Problems\nPartitioning problems involve a search over all ways to divide up a\ncollection of objects into subset s so that each object appears in exactly one\nof the subsets.\nOne of our two basic partitioning problems, 3-Dimensional Matching,\narises naturally whenever you have a collection of sets and you want to\nsolve a covering problem and a packing problem simultaneously: Choose\nsome of the sets in such a way that they are disjoint, yet completely cover\nthe ground set.\n3-Dimensional Matching : Given disjoint sets X, Y, and Z, each of size\nn, and given a set T ⊆ X × Y × Z of ordered triples, does there exist a\nset of n triples in T so that each element of X ∪ Y ∪ Z is conta ined in\nexactly one of these triples?\nOur other basic partitioning problem, Graph Coloring, is at work\nwhenever you're seeking to partition objects in the presence of conflicts,\nand conflicting objects aren't allowed to go into the same set.\nGraph Coloring : Given a graph G and a bound k, does G have a k-\ncoloring?\nSequencing Problems"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 590})","('type', 'Document')"
"('page_content', 'Our first three types of problems have involved searching over subsets of a\ncollection of objects. Another type of computationally hard problem\ninvolves searching over the set of all permutations  of a collection of\nobjects.\nTwo of our basic sequencing problems draw their difficulty from the\nfact that you are required to order n objects , but there are restrict ions\npreventing you from placing certain objects after certain others.\nHamiltonian Cycle : Given a directed graph G, does it contain a\nHamiltonian cycle?\nHamiltonian Path : Given a directed graph G, does it contain a\nHamiltonian path?\nOur third basic sequencing problem is very similar; it softens these\nrestrictions by simply imposing a cost for placing one object after another .\nTraveling Salesman : Given a set of distances on n cities, and a bound\nD, is there a tour of length at most D?\nNumerical Problems\nThe hardness of the numerical problems considered in this chapter flowed\nprincipally from  Subset Sum, the special case of the Knapsack Problem that\nwe considered in Section 8.8 .\nSubset Sum : Given natural numbers w1, …, wn, and a target number W,\nis there a subset of { w1, …, wn} that adds up to precisely W?\nIt is natural to try reducing from Subset Sum whenev er one has a problem\nwith weighted objects and the goal is to select objects conditioned on a\nconstraint on the total weight of the objects selected. This, for example, is\nwhat happened in the proof of (8.24), showing that Scheduling with Release\nTimes and Deadlines is NP-complete.\nAt the same time, one must heed the warning that Subset Sum only\nbecomes hard with truly large integers; when the magnitudes of the input\nnumbers are bounded by a polynomial function of n, the problem is\nsolvable in polynomial time by dynamic programming.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 591})","('type', 'Document')"
"('page_content', ""Constraint Satisfaction Problems\nFinally , we considered basic constraint satisfaction problems, including\nCircuit Satisfiability , SAT, and 3-SA T. Among these, the most useful for the\npurpose of designing reductions is 3-SA T.\n3-SA T: Given a set of clauses C1, …, Ck, each of length 3, over a set of\nvariables X = {x1, …, xn }, does there exist a satisfying truth\nassignment?\nBecause of its expressive flexibility , 3-SA T is often a useful starting\npoint for reductions where none of the previous five categories seem to fit\nnaturally onto the problem being considered. In designing 3-SA T\nreductions, it helps to recall the advice given in the proof of (8.8), that there\nare two distinct ways to view an instance of 3-SA T: (a) as a search over\nassignments to the variables, subject to the constraint that all clauses must\nbe satisf ied, and (b) as a search over ways to choose a single term (to be\nsatisfied) from each clause, subject to the constraint that one mustn't choose\nconflicting terms from different clauses. Each of these perspectives on 3-\nSAT is useful, and each forms the key idea behind a large number of\nreductions.\nSolved Exercises\nSolved Exercise 1\nYou're consulting for a small high-tech company that maintains a high-\nsecurity computer system for some sensitive work that it's doing. To make\nsure this system is not being used for any illicit purposes, they've set up\nsome logging software that records the IP addresses that all their users are\naccessing over time. We'll assume that each user accesses at most one IP\naddress in any given minute; the software writes a log file that records, for\neach user u and each minute m, a value I(u, m) that is equal to the IP"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 592})","('type', 'Document')"
"('page_content', ""address (if any) accessed by user u during minute m. It sets I(u, m) to the\nnull symbol ⊥  if u did not access any IP address during minute m.\nThe company management just learned that yesterday the system was\nused to launch a complex attack on some remote sites. The attack was\ncarried out by accessing t distinct  IP addresses over t consecutive minutes:\nIn minute 1, the attack accessed address i1; in minu te 2, it accessed address\ni2; and so on, up to address it in minute t.\nWho could have been responsible for carrying out this attack? The\ncompany checks  the logs and finds to its surprise that there's no single user\nuwho accessed each of the IP addresses involved at the appropria te time; in\nother words, there's no uso that I(u, m) = im for each minute mfrom 1 to t.\nSo the question becomes: What if there were a small coalition of kusers\nthat collectively  might have carried out the attack? We will say a subset Sof\nusers is a suspicious coalition if, for each minute mfrom 1 to t, there is at\nleast one user u ∊ S for whic h I(u, m) = im. (In other words, each IP address\nwas accessed at the appropriate time by at least one user in the coalition.)\nThe Suspicious Coalition Problem asks: Given the collection of all\nvalues I(u, m), and a number k, is there a suspicious coalition of size at most\nk?\nSolution  First of all, Suspicious Coalition is clearly in NP: If we were\nto be shown a set S of users, we could check that S has size at most k, and\nthat for each minute m from 1 to t, at least one of the users in S accessed the\nIP address im.\nNow we want to find a known NP-complete problem and reduce it to\nSuspicious Coalition. Although Suspicious Coalition has lots of features\n(users, minutes, IP addresses), it's very clearly a covering problem\n(following the taxonomy described in the chapter): We need to explain all t\nsuspicious accesses, and we're allowed a limited number of users (k) with\nwhich to do this. Once we've decided it's a covering problem, it's natural to\ntry reducing Vertex Cover or Set Cover to it. And in order to do this, it's\nuseful to push most of its compl icated features into the background, leaving\njust the bare-bones features that will be used to encode Vertex Cover or Set\nCover .\nLet's focus on reducing Vertex Cover to it. In Vertex Cover , we need to\ncover every edge, and we're only allowed k nodes. In Suspicious Coalition,\nwe need to “cov er” all the accesses, and we're only allowed k users. This"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 593})","('type', 'Document')"
"('page_content', ""parallelism strongly suggests that, given an instance of Vertex Cover\nconsisting of a graph G = (V, E) and a bound k, we should construct an\ninstance of Suspicious Coalition in which the users represent the nodes of G\nand the suspicious accesses represent the edges.\nSo suppose the graph G for the Vertex Cover instance has m edges e1,\n…, em, and ej= (vj, wj). We construct an instance of Suspicious Coalition as\nfollows. For each node of G we construct a user, and for each edge et= (vt,\nwt) we construct a minute t. (So there will be m minutes total.) In minute t,\nthe users associated with the two ends of etaccess an IP address it, and all\nother users access nothing. Finally , the attack consists of accesses to\naddresses i1, i2, …, im in minutes 1,2,…, m, respectively .\nThe following claim will establish that Vertex Cover ≤PSuspicious\nCoalition and hence will conclude the proof that Suspicious Coalition is\nNP-complete. Given how closel y our construction of the instance shadows\nthe original V ertex Cover instance, the proof is completely straightforward.\n(8.28)  In the instance constructed, there is a suspicious coalition of size at most k if and only if the\ngraph G contains a vertex cover of size at most k.\nProof. First, suppose that G contain s a vertex cover C of size at most  k.\nThen consider the corresponding  set S of users  in the instance of Susp icious\nCoalition. For each t from 1 to m, at least one element of C is an end of the\nedge et, and the corresponding user in S accessed the IP address it. Hence\nthe set S is a suspicious coalition.\nConversely , suppose that there is a suspicious coalition S of size at\nmost k, and consider the corresponding set of nodes C in G. For each t from\n1 to m, at least one user in S accessed the IP address it, and the\ncorresponding node in C is an end of the edge et. Hence the set C is a vertex\ncover .\nSolved Exercise 2\nYou've been asked to organize a freshman-level seminar that will meet once\na week during the next semester . The plan is to have the first portion of the\nsemester consist  of a sequence of ℓ guest lectures by outside speakers, and"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 594})","('type', 'Document')"
"('page_content', ""have the second  portion of the semester devoted to a sequence of p hands-\non projects that the students will do.\nThere are n options for speakers overall, and in week number i (for i =\n1,2, …, ℓ) a subset Li of these speakers is available to give a lecture.\nOn the other hand, each project requires that the students have seen\ncertain background material in order for them to be able to complete the\nproject successfully . In particular , for each project j (for j = 1,2, …, p), there\nis a subset Pjof relevant speakers so that the students need to have seen a\nlecture by at least one of the speakers in the set Pj in order to be able to\ncomplete the project.\nSo this is the problem: Given these sets, can you select exact ly one\nspeaker for each of the first ℓ weeks of the seminar , so that you only choose\nspeakers who are available in their designated week, and so that for each\nproject j, the students will have seen at least one of the speakers in the\nrelevant set Pj? We'll call this the Lectur e Planning Pr oblem .\nTo make this clear , let's consider the following sample instance.\nSuppose that ℓ = 2, p = 3, and there are n = 4 speakers that we denote A, B,\nC, D. The availability of the speakers is given by the sets L1 = {A, B, C}\nand L2 ={A, D}. The relevant speakers for each project are given by the sets\nP1 ={B, C}, P2 = {A, B, D}, and P3 = {C, D}. Then the answer to this\ninstance of the problem is yes, since we can choose speaker B in the first\nweek and speaker D in the second week; this way, for each of the three\nprojects, students will have seen at least one of the relevant speakers.\nProve that Lecture Planning is NP-complete.\nSolution  The problem is in NP since, given a sequence of speakers, we can\ncheck (a) all speakers are avail able in the weeks when they're scheduled,\nand (b) that for each project, at least one of the relevant speake rs has been\nscheduled.\nNow we need to find a known NP-complete problem that we can\nreduce to Lecture Planning. This is less clear -cut than in the previous\nexercise, becaus e the statement of the Lecture Planning Prob lem doesn't\nimmediately map into the taxonomy from the chapter .\nThere is a useful intuitive view of Lecture Planning, however , that is\ncharacteristic of a wide range  of constraint satisfaction problems. This\nintuition is captured, in a strikingly picturesque way, by a description that"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 595})","('type', 'Document')"
"('page_content', ""appeared in the New Yorker  of the lawyer David Boies's cross-examination\nstyle:\nDuring a cross-exami nation, David takes a friendly walk down the hall with you while\nhe's quietly  closing doors. They get to the end of the hall and David turns on you and\nthere's no place to go. He's closed all the doors.3\nWhat does constraint satisfaction have to do with cross-examination?\nIn Lecture Planning, as in many  similar problems, there are two conceptual\nphases. There's a first phase in which you walk through a set of choices,\nselecting some and thereby closing the door on others; this is followed by a\nsecond phase in which you find out whether your choices have left you with\na valid solution or not.\nIn the case of Lecture Planning, the first phase consists of choosing a\nspeaker for each week, and the second phase consists of verifying that\nyou've picked a relevant speaker for each project. But there are many NP-\ncomplete proble ms that fit this description at a high level, and so viewing\nLecture Planning this way helps us search for a plausible reduction. We will\nin fact describe two reductions, first from 3-SA T and then from Vertex\nCover . Of course, either one of these by itself is enough to prove NP-\ncompleteness, but both make for useful examples.\n3-SA T is the canonical example of a problem with the two-phase\nstructure describ ed above: We first walk through the variables, setting each\none to true or false; we then look over each clause and see whether our\nchoices have satisfied it. This parallel to Lecture Planning already suggests\na natural reduction showing that 3-SA T ≤P Lecture Planning: We set things\nup so that the choice of lecturers sets the variables, and then the feasibility\nof the projects represents the satisfaction of the clauses.\nMore concretely , suppose we are given an instance of 3-SA T\nconsisting of clauses C1, …, Ck over the variables x1, x2, …, xn. We\nconstruct an instance of Lecture  Planning as follows. For each variable xi,\nwe create two lecturers zi and zi′ that will correspond to xi and its negation.\nWe begin with n weeks of lectu res; in week i, the only two lecturers\navailable are zi and zi′. Then there is a sequence of k projects; for project j,\nthe set of releva nt lecturers Pj consists of the three lecturers corresponding\nto the terms in clause Cj. Now , if there is a satisfying assignment ν for the 3-"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 596})","('type', 'Document')"
"('page_content', 'SAT instance, then in week i we choose the lecturer among zi, zi′ that\ncorresponds to the value assign ed to xi by ν; in this case, we will select at\nleast one speaker from each relevant set Pj. Conversely , if we find a way to\nchoose speakers  so that there is at least one from each relevant set, then we\ncan set the variables xi as follows: xi is set to 1 if zi is chosen, and it is set to\n0 if zi′ is chosen. In this way, at least one of the three variables in each\nclause Cj is set in a way that satisfies it, and so this is a satisfyi ng\nassignment. This concludes the reduction and its proof of correctness.\nOur intuitive view of Lecture Planning leads naturally to a reduction\nfrom Vertex Cover as well. (What we describe here could be easily\nmodified to work from Set Cover or 3-Dimensional Matching too.) The\npoint is that we can view Vertex Cover as having a similar two-phase\nstructure: W e first choose a set of k nodes from the input graph, and we then\nverify for each edge that these choices have covered all the edges.\nGiven an input to Vertex Cover , consisting of a graph G =(V, E) and a\nnumber k, we create a lecturer zv for each node v. We set ℓ = k, and define\nL1 = L2 = … = Lk = {zv: v ∊ V}. In other words, for the first k weeks, all\nlecturers are available. After this, we create a project j for each edge ej =(v,\nw), with set Pj = {zv, zw}.\nNow , if there is a vertex cover S of at most k nodes, then consider the\nset of lecturers ZS = {zv: v ∊S}. For each project Pj, at least one of the\nrelevant speakers belongs to ZS, since S covers all edges in G. Moreover , we\ncan schedule all the lecturers in ZS during the first k weeks. Thus it follows\nthat there is a feasible solution to the instance of Lecture Planning.\nConversely , suppose there is a feasible solution to the instance of\nLecture Planning, and let T be the set of all lecturers who speak in the first k\nweeks. Let X be the set of nodes in G that correspond to lecturers in T. For\neach project Pj, at least one of the two relevan t speakers appears in T, and\nhence at least one end of each edge ej is in the set X. Thus X is a vertex\ncover with at most k nodes.\nThis concludes the proof that V ertex Cover ≤P Lecture Planning.\nExercises')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 597})","('type', 'Document')"
"('page_content', ""1. For each of the two questions below , decide whether the answer is (i)\n“Yes,” (ii) “No,” or (iii) “Unk nown, because it would resolve the\nquestion of whether P = NP.” Give a brief explanation of your answer . \n(a) Let's define the decision version of the Interval Scheduling\nProblem from Chapter 4 as follows: Given a collection of intervals on\na time-line, and a bound k, does the collection contain a subset of\nnonoverlapping intervals of size at least k? \nQuestion: Is it the case that Interval Scheduling ≤ P Vertex Cover?  \n \n(b) Questi on: Is it the case that Independent Set ≤P Interval\nScheduling?\n2. A store trying to analyze the behavior of its customers will often\nmaintain a two-dimensional array A, where the rows correspond to its\ncustomers and the columns correspond to the products it sells. The\nentry A[i, j] specifies the quantity of product j that has been purchased\nby customer i.\nHere's a tiny example of such an array A.\nliquid detergent beer diapers cat litter\nRaj 0 6 0 3\nAlanis 2 3 0 0\nChelsea 0 0 0 7\nOne thing that a store might want to do with this data is the\nfollowing. Let us say that a subset S of the customers is divers  e if no\ntwo of the of the customers in S have ever bought the same product\n(i.e., for each product, at most one of the customers in S has ever\nbought it). A diverse set of customers can be useful, for example, as a\ntarget pool for market research.\nWe can now define the Diverse Subset Problem as follows: Given\nan m × n array A as defined above, and a number k ≤ m, is there a\nsubset of at least k of customers that is diverse ?\nShow that Diverse Subset is NP-complete.\n3. Suppose you're helping to organize a summer sports camp, and the\nfollowing problem comes up. The camp is supposed to have at least\none counselor who's skilled at each of the n sports covered by the\ncamp (baseball , volleyball, and so on). They have receiv ed job"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 598})","('type', 'Document')"
"('page_content', ""applications from m potenti al counselors. For each of the n sports,\nthere is some subset of the m applicants qualified in that sport. The\nquestion is: For a given number k < m, is it possible to hire at most k of\nthe counselors and have at least one counselor qualified in each of the\nn sports? W e'll call this the Ef ficien t Recruitin g Problem.\nShow that Ef ficient Recruiting is NP-complete.\n4. Suppose you're consulting for a group that manages a high-\nperformance real-time system in which asynchronous processe s make\nuse of shared resources. Thus the system has a set of n processe  s and a\nset of m resour ces. At any given point in time, each process specifies a\nset of resources that it requests to use. Each resource might be\nrequested by many processes at once; but it can only be used by a\nsingle process at a time. Your job is to allocate resources to processes\nthat request them . If a process is allocated all the resources it requests,\nthen it is active ; otherwise it is blocked . You want to perform the\nallocation so that as many processes as possible are active. Thus we\nphrase the Resour c e Reservatio  n Proble m as follows: Given a set of\nprocesses and resources, the set of requested resources for each\nprocess, and a number k, is it possible  to allocate resources to\nprocesses so that at least k processes will be active?\nConsider the following list of problems, and for each proble m\neither give a polynomial-time algorithm or prove that the problem is\nNP-complete.  \n \n(a) The general Resource Reservation Problem defined above.  \n \n(b) The special case of the problem when k =2. \n \n(c) The special case of the problem when there are two types of\nresources—say , people and equipment—and each process requires at\nmost one resource of each type (In other words, each process requires\none specific person and one specific piece of equipment.)  \n \n(d) The special case of the problem when each resource is reque sted\nby at most two processes.\n5. Consider a set A = {a1,…,an} and a collection B1,B2,…,Bm of subsets\nof A (i.e., Bi ⊆ A for each i)."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 599})","('type', 'Document')"
"('page_content', ""We say that a set H ⊆A is a hitting set for the collection\nB1,B2,…,Bm if H contains at least one element from each Bi—that is, if\nH ∩ B i is not empty for each i (so H “hits” all the sets Bi).\nWe now define the Hitting Set Pr oblem  as follows. W e are given a\nset A = {a1,…,an}, a collection B1,B2,…,Bm of subsets of A, and a\nnumber k. We are asked: Is there a hittin g set H ⊆ A for B1,B2,…,Bm\nso that the size of H is at most k?\nProve that Hitting Set is NP-complete.\n6. Consider an instance of the Satisfiability Problem, specified by clauses\nC1,…,Ck over a set of Boolean variables x1,…,xn. We say that the\ninstance is monoton  e if each term in each clause consists of a\nnonnegated variable; that is, each term is equal to xi, for some i, rather\nthan \n . Monot one instances of Satisfiability are very easy to solve:\nThey are always satisfiable, by setting each variable equal to 1.\nFor example, suppose we have the three clauses\nThis is monotone, and indeed the assignment that sets all three\nvariables to satisfies all the clauses. But we can observe that this is not\nthe only satisfying assignment; we could also have set x1 and x2 to 1,\nand x3 to 0. Indeed, for any monotone instance, it is natural to ask how\nfew variables we need to set to 1in order to satisfy it.\nGiven a monotone instance of Satisfiability , together with a\nnumber k, the problem of Monoton  e Satisfiabilit  y wit h Fe w Tru e\nVariable  s asks: Is there a satisfying assignment for the instance in\nwhich at most k variables are set to 1? Prove this problem is NP-\ncomplete.\n7. Since the 3-Dimensional Matching Problem is NP-complete, it is\nnatural to expect that the corresponding 4-Dimensional Matching\nProblem is at least as hard. Let us define 4-Dimensiona  l Matchin  g as\nfollows. Given sets W, X, Y, and Z, each of size n, and a collection C of\nordered 4-tuples of the form (wi, xj, yk, zℓ), do there exist n 4-tuples\nfrom C so that no two have an element in common?\nProve that 4-Dimensional Matching is NP-complete.\n8. Your friends' preschool-age daughter Madison has recently learned to\nspell some simp le words. To help encourage this, her parents got her a"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 600})","('type', 'Document')"
"('page_content', ""colorful set of refrigerator magnets featuring the letters of the alphabet\n(some number of copies of the letter A, some number of copies of the\nletter B, and so on), and the last time you saw her the two of you spent\na while arranging the magnets to spell out words that she knows.\nSomehow with you and Madison, things always end up getting\nmore elaborate than originally planned, and soon the two of you were\ntrying to spell out words so as to use up all the magnets in the full set\n—that is, picking words that she knows how to spell, so that once they\nwere all spelled out, each magnet was participating in the spelling of\nexactly one of the words. (Multiple copies of words are okay here; so\nfor example, if the set of refrigerator magnets includes two copies each\nof C, A, and T, it would be okay to spell out CA T twice.)\nThis turned out to be pretty difficult, and it was only later that you\nrealized a plausible reason for this. Suppose we consider a general\nversion of the problem of Usin  g U p Al l th e Refrigerato  r Magnets ,\nwhere we replace the English alphabet by an arbitrary collection of\nsymbols, and we model Madison's vocabulary as an arbitrary set of\nstrings over this collection of symbols. The goal is the same as in the\nprevious paragraph.\nProve that the problem of Using  Up All the Refrigerator Magnets\nis NP-complete.\n9. Consider the following problem. You are managing a communication\nnetwork, modele d by a directed  graph G = (V,E). There  are c user s\nwho are interested in making use of this network. User i (for each i =\n1,2,…, c) issues a reques  t to reserve a specific path P i in G on which\nto transmit data.\nYou are interested in accepting as many of these path requests as\npossible, subject  to the following restriction: if you accept both Pi and\nPj, then Pi and Pj cannot share any nodes.\nThus, the Path Selection Problem  asks: Given a directed graph G\n= (V,E), a set of requests P1, P2, …,Pc—each of which must be a path\nin G —and a number k, is it possible to select at least k of the paths so\nthat no two of the selected paths share any nodes?\nProve that Path Selection is NP-complete.\n10. Your friends at WebExodus have recently been doing some consulting\nwork for compa nies that maintain large, publicly accessible Web sites"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 601})","('type', 'Document')"
"('page_content', ""— contractual issues prevent them from saying which ones—and\nthey've come across the following Strategi  c Advertisin  g Problem .\nA comp any comes to them with the map of a Web site, whic h\nwe'll model as a directed graph G = (V,E). The company also provides\na set of t trail s typically followed by users of the site; we'll model\nthese trails as directed paths P1, P2,…,Pt in the graph G (i.e., each Pi is\na path in G).\nThe company wants WebExodus to answer the following question\nfor them : Given  G, the paths {Pi}, and a number k, is it possible to\nplace advertisements on at most k of the nodes in G, so that each path\nPi includes at least one node containing an advertisement? We'll call\nthis the Strategic  Advertising Problem, with input G, {Pi : i = 1,…, t},\nand k.\nYour friends figure that a good algorithm for this will make them\nall rich; unfortunately , things are never quite this simple.  \n \n(a) Prove that Strategic Advertising is NP-complete.\n \n(b) Your friends at WebExodus forge ahead and write a pretty fast\nalgorithm S that produces yes/n o answers to arbitrary instances of the\nStrategic Advertising Problem. You may assume that the algorithm S is\nalways correct.\nUsing the algorithm S as a black box, design an algorithm that\ntakes input G, {Pi}, and k as in part (a), and does one of the following\ntwo things:  \n \n– Outputs a set of at most k nodes in G so that each path Pi includes at\nleast one of these nodes, o r \n \n– Outpu ts (correctly) that no such set of at most k nodes exists. Your\nalgorithm shoul d use at most a polynomial number of steps, together\nwith at most a polynomial number of calls to the algorithm S.\n11. As some people remember , and many have been told, the idea of\nhypertext predates the World Wide Web by decades. Even hypertext\nfiction is a relatively old idea: Rather than being constrained by the\nlinearity of the printed page, you can plot a story that consists of a"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 602})","('type', 'Document')"
"('page_content', ""collection of interlocked virtual “places” joined by virtual “passages.”4\nSo a piece of hypertext fiction is really riding on an underlying\ndirected graph; to be concrete (though narrowing the full range of what\nthe domain can do), we'll model this as follows.\nLet's view the structure of a piece of hypertext fiction as a\ndirected graph G = (V, E). Each node u ∊ V contains some text; when\nthe reader is currently at u, he or she can choose to follow any edge out\nof u; and if the reader chooses e = (u, v), he or she arrives next at the\nnode v. There is a start node s ∊ V where the reader begins, and an end\nnode t ∊ V; when the reader first reaches t, the story ends. Thus any\npath from s to t is a valid plo t of the story . Note that, unlike one's\nexperience using a Web browser , there is not necessarily a way to go\nback; once you've gone from u to v, you might not be able to ever\nreturn to u.\nIn this way, the hypertext structure defines a huge number of\ndifferent plots on the same underlying content; and the relatio nships\namong all these possibilities can grow very intricate. Here's a type of\nproblem one encounters when reasoning about a structure like this.\nConsider a piece of hypertext fiction built on a graph G = (V, E) in\nwhich there are certain crucial themati  c elements  : love, death, war, an\nintense desire to major in computer science, and so forth. Each\nthematic element i is represented by a set T i ⊆ V consisting of the\nnodes in G at whic h this theme appears. Now , given a particular set of\nthematic elements, we may ask: Is there a valid plot of the story in\nwhich each of these elements is encountered? More concretely , given a\ndirected graph G, with start node s and end node t, and thematic\nelements represented by sets T1,T2,…,Tk, the Plo t Fulfillmen  t Proble\nm asks: Is there a path from s to t that contains at least one node from\neach of the sets Ti?\nProve that Plot Fulfillment is NP-complete.\n12. Some friends of yours maintain a popular news and discussion site on\nthe Web, and the traffic has reached a level where they want to begin\ndifferentiating their visitors into paying and nonpaying customers. A\nstandard way to do this is to make all the content on the site available\nto custom ers who pay a monthly subscription fee; meanwhile, visitors"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 603})","('type', 'Document')"
"('page_content', ""who don't subscribe can still view a subset of the pages (all the while\nbeing bombarded with ads asking them to become subscribers).\nHere are two simple ways to control access for nonsubscriber s:\nYou could (1) designate a fixed subset of pages as viewable by\nnonsubscribers, or (2) allow any page in principle to be viewable, but\nspecify a maximum number of pages that can be viewed by a\nnonsubscriber in a single session . (We'll assume the site is able to track\nthe path followed by a visitor through the site.)\nYour friends are experimenting  with a way of restricting access\nthat is different from and more subtle than either of these two options.\nThey want nonsubscribers to be able to sample different sections  of the\nWeb site, so they designate certain subsets of the pages as constituting\nparticular zones —for example, there can be a zone for pages on\npolitics, a zone for pages on music, and so forth. It's possible for a\npage to belong to more than one zone. Now , as a nonsubscribin g user\npasses through the site, the access policy allows him or her to visit one\npage from each zone, but an attempt by the user to access a second\npage from the same zone later in the browsing session will be\ndisallowed. (Instead, the user will be directed to an ad suggesting that\nhe or she become a subscriber .)\nMore formally , we can model the site as a directed graph G =\n(V,E),in which the nodes represent Web pages and the edges represent\ndirected hyperli nks. There is a distinguished entr y nod e s ∊ V, and\nthere are zone s Z1,…,Zk ⊆ V. A path P taken by a nonsubscriber is\nrestricted to include at most one node from each zone Z i.\nOne issue with this more complicated access policy is that it gets\ndifficult to answer even basic questions about reachability , including:\nIs it possible for a nonsubscriber to visit a given node t? More\nprecisely , we define the Evasive Path Problem  as follows: Given G,\nZ1,…,Zk, s ∊ V, and a destination node t ∊  V, is there an s-t path in G\nthat includes at most one node from each zone Zi? Prove that Evasive\nPath is NP-complete.\n13. A combinatorial auction  is a particular mechanism developed by\neconomists for selling a collection of items to a collection of potential\nbuyers. (The Federal Communications Commission has studied this"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 604})","('type', 'Document')"
"('page_content', ""type of auction for assigning  stations on the radio spectr um to\nbroadcasting companies.)\nHere's a simple type of combin atorial auction. There are n items\nfor sale, labeled I1,…,In. Each item is indivisible and can only be sold\nto one person. Now , m different people place bids : The ith bid\nspecifies a subset Si of the items, and an offering price xi that the\nbidder is willing to pay for the items in the set Si, as a single unit.\n(We'll represent this bid as the pair ( Si, xi).)\nAn auctioneer now looks at the set of all m bids; she chooses to\naccep t  some of these bids and to rejec t  the others. Each  person whose\nbid i is accep ted gets to take all the items in the corresponding set Si.\nThus the rule is that no two accepted bids can specify sets that contain\na common item, since this would involve giving the same item to two\ndifferent people.\nThe auctioneer collects the sum of the offering prices of all\naccepted bids. (Note that this is a “one-shot” auction; there  is no\nopportunity to place further bids.) The auctioneer's goal is to collect as\nmuch money as possible.\nThus, the problem of Winner Determination for Combinatorial\nAuctions  asks: Given items I1,…,In, bids (S1,x1),…,( Sm, xm), and a\nbound B, is there a collection of bids that the auctioneer can accept so\nas to collect an amount of money that is at least B?\nExample.  Suppose an auctioneer decides to use this method to sell\nsome excess computer equipme nt. There are four items labeled “PC,”\n“monitor ,” “printer”, and “scanner”; and three people place bids.\nDefine\nand\nThe bids are ( S1,x1),(S2,x2),(S3,x3), and the bound B is equal to 2.\nThen the answer to this instance is no: The auctioneer can accept\nat most one of the bids (since any two bids have a desired item in\ncommon), and this results in a total monetary value of only 1.\nProve that the problem of W inner Determination in Combinatorial\nAuctions is NP-complete."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 605})","('type', 'Document')"
"('page_content', ""14. We've seen the Interval Scheduling Problem in Chapters 1  and 4. Here\nwe consider a computationally much harder version of it that we'll call\nMultipl e Interva l Scheduling . As before, you have a processor that is\navailable to run jobs over some period of time (e.g., 9 A.M. to 5 P.M).\nPeople submit jobs to run on the processor; the processor can only\nwork on one job at any single point in time. Jobs in this model,\nhowever , are more complicated than we've seen in the past: each job\nrequires a se t of intervals of time during which it needs to use the\nprocessor . Thus,  for example, a single job could require the processor\nfrom 10 A.M. to 11 A.M., and again from  2 P.M. to 3 P.M.. If you accept\nthis job, it ties up your processor during those two hours, but you could\nstill accept jobs that need any other time periods (including the hours\nfrom 1 1 A.M. to 2 A.M.).\nNow you're given a set of n jobs, each specified by a set of time\nintervals, and you want to answer the following question: For a given\nnumber k, is it possible to accept at least k of the jobs so that no two of\nthe accepted jobs have any overlap in time?\nShow that Multiple Interval Scheduling is NP-complete.\n15. You're sitting at your desk one day when a FedEx package arrives for\nyou. Inside is a cell phone that begins to ring, and you're not entirely\nsurprised to discover that it's your friend Neo, whom you haven't heard\nfrom in quite a while. Conversat ions with Neo all seem to go the same\nway: He starts out with some big melodramatic justification for why\nhe's calling, but in the end it always comes down to him trying  to get\nyou to voluntee r your time to help with some problem he needs to\nsolve.\nThis time, for reasons he can't go into (something having to do\nwith protecting an under ground city from killer robot probes), he and a\nfew associates need to monitor radio signals at various points on the\nelectromagnetic spectrum. Specifically , there are n different\nfrequencies that need monitoring, and to do this they have available a\ncollection of sensors .\nThere are two components to the monitoring problem.  \nA set L of m geographic locations at which sensors can be placed;\nand\nA set S of b interfe renc e sources, each of which  blocks certain\nfrequencies at certain locations. Specifically , each interferen ce"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 606})","('type', 'Document')"
"('page_content', ""source i is speci fied by a pair (Fi, Li), where Fi is a subset of the\nfrequencies and Li is a subset of the locations; it signifies that\n(due to radio interference) a sensor placed at any location in the\nset Li will not be able to receive signals on any frequency in the\nset Fi.\nWe say that a subset L′ ⊆ L of locations is sufficien t if, for each\nof the n frequencies j, there is some location in L′ where frequency j is\nnot blocked by any interference source. Thus, by placing a sensor at\neach location in a sufficient set, you can successfully monitor each of\nthe n frequencies.\nThey have k sensors, and hence they want to know whether there\nis a sufficient set of locations of size at most k. We'll call this an\ninstance of the Nearb y Electr omagneti c Observatio n Problem  :\nGiven frequencies, locations, interference sources, and a parameter k,\nis there a suf ficient set of size at most k?\nExample.  Suppose we have four frequencies {f1,f2,f3,f4}and four\nlocations {ℓ1,ℓ2,ℓ3,ℓ4}. There are three interference sources, with\nThen there is a sufficient set of size 2: We can choose locations ℓ2\nand ℓ4 (since f1 and f2 are not blocked at ℓ4, and f3 and f4 are not\nblocked at ℓ2).\nProve that Nearby Electromagnetic Observation is NP-complete.\n16. Consider the problem of reasoni ng about the identity of a set from the\nsize of its intersections with other sets. You are given a finite set U of\nsize n, and a collection A1,…,Am of subsets of U. You are also given\nnumbers c1,…,cm. The question is: Does there exist a set X ⊂ U so that\nfor each i =1,2,…, m, the cardinality of X ∩ Ai is equal to ci? We will\ncall this an instance of the Intersectio n Infer enc e Problem , with input\nU, {Ai}, and { ci}.\nProve that Intersection Inference is NP-complete.\n17. You are given a directed graph G =(V, E) with weights we on its edges\ne ∊ E. The weights can be negative or positive. The Zero-Weight-Cycl"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 607})","('type', 'Document')"
"('page_content', ""e Proble m  is to decide if there is a simple cycle in G so that the sum of\nthe edge weights on this cycle is exactly 0. Prove that this problem is\nNP-complete.\n18. You've been asked to help some organizational theorists analyze data\non group decision-making. In particular , they've been lookin g at a\ndataset that consists of decisions made by a particular govern mental\npolicy committee, and they're trying to decide whether it's possible to\nidentify a small set of influential members of the committee.\nHere's how the committee works. It has a set M = {m1,…,mn} of n\nmembers, and over the past year it's voted on t different issues. On\neach issue, each member can vote either “Yes,” “No,” or “Abstain”;\nthe overall effect is that the committee presents an affirmative decision\non the issue if the number of “Yes” votes is strictly greater than the\nnumber of “No” votes (the “Abstain” votes don't count for either side),\nand it delivers a negative decision otherwise.\nNow we have a big table consisting of the vote cast by each\ncommittee member on each issue, and we'd like to consider the\nfollowing defini tion. We say that a subset of the members M′ ⊆ M is\ndecisiv e  if, had we looked just at the votes cast by the members in M′,\nthe committee's decision on ever y  issue would have been the same . (In\nother words, the overall outcome of the voting among the members in\nM′ is the same on every issue as the overall outcome of the votin g by\nthe entire committee.) Such a subset can be viewed as a kind of “inner\ncircle” that reflects the behavior of the committee as a whole.\nHere's the question: Given the votes cast by each member on each\nissue, and given a parameter k, we want to know whether there is a\ndecisive subset consisting of at most k members. We'll call this an\ninstance of the Decisiv e Subse t Pr oblem .\nExample.  Suppose we have four committee members and three issues.\nWe're looking for a decisive set of size at most k = 2, and the voting\nwent as follows.\nIssue # m1 m2 m3 m4\nIssue 1 Yes Yes Abstain No\nIssue 2 Abstain No No Abstain\nIssue 3 Yes Abstain Yes Yes"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 608})","('type', 'Document')"
"('page_content', ""Then the answer to this instance  is “Yes,” since members m1 and\nm3 constitute a decisive subset.\nProve that Decisive Subset is NP-complete.\n19. Suppose you're acting as a consultant for the port authority of a small\nPacific Rim nation. They're currently doing a multi-billion-dollar\nbusiness per year, and their revenue is constrained almost entirely by\nthe rate at which they can unload ships that arrive in the port.\nHandling hazard ous materials adds additional complexity to what\nis, for them, an already complic ated task. Suppose a convoy of ships\narrives in the morning and delivers a total of n cannisters, each\ncontaining a dif ferent kind of hazardous material. Standing on the dock\nis a set of m trucks, each of which can hold up to k containers.\nHere are two related problems, which arise from dif ferent types of\nconstraints that might be placed on the handling of hazardous\nmaterials.\nFor each of the two problems , give one of the following two\nanswers:  \nA polynomial-time algorithm to solve it; or\nA proof that it is NP-complete.\n \n \n(a) For each cannis ter, there is a specified subset of the trucks in which\nit may be safely  carried. Is there  a way to load all n cannisters into the\nm trucks so that no truck is overloaded, and each container goes in a\ntruck that is allowed to carry it?\n \n(b) In this dif ferent version of the problem, any cannister can be placed\nin any truck; however , there are certain pairs of cannisters that cannot\nbe placed together in the same truck. (The chemicals they conta in may\nreact explosively if brought into contact.) Is there a way to load all n\ncannisters into the m trucks so that no truck is overloaded, and no two\ncannisters are placed in the same truck when they are not supp osed to\nbe?\n20. There are many different ways  to formalize the intuitive problem of\nclustering , where the goal is to divide up a collection of objects into\ngroups that are “similar” to one another ."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 609})","('type', 'Document')"
"('page_content', ""First, a natural way to express the input to a clustering problem is\nvia a set of objects p1,p2,…,pn, with a nume rical distance d(pi,\npj)defined on each pair. (We require only that d(pi, pi) = 0; that d(pi, pj)\n> 0 for distinct pi and pj; and that distances are symmetric: d(pi, pj) =\nd(pj, pi).)\nIn Section 4.7, earlier in the book, we considered one reasonable\nformulation of the clustering problem: Divide the objects into k sets so\nas to maximiz e the minimum distance between  any pair of objects in\ndistinct clusters. This turns out to be solvable by a nice application of\nthe Minimum Spanning T ree Problem.\nA different but seemingly related way to formalize the clusterin g\nproblem would be as follows: Divide the objects into k sets so as to\nminimiz e the maximum distance between any pair of objects in the\nsame cluster . Note the change. Where the formulation in the previous\nparagraph sought clusters so that no two were “close together ,” this\nnew formulation  seeks clusters so that none of them is too “wide”—\nthat is, no cluster contains two points at a large distance from each\nother .\nGiven the similarities, it's perhaps surprising that this new\nformulation is computationally hard to solve optimally . To be able to\nthink about this in terms of NP-completeness, let's write it first as a\nyes/no decision problem. Given n objects p1,p2,…,pn with distances on\nthem as above, and a bound B, we define the Low-Diameter Clustering\nProblem  as follo ws: Can the objects be partitioned into k sets, so that\nno two points in the same set are at a distance greater than B from each\nother?\nProve that Low-Diameter Clustering is NP-complete.\n21. After a few too many days immersed in the popular entrepreneurial\nself-help book Min e You r Ow n Business , you've come to the\nrealization that you need to upgrade your office computing system.\nThis, however , leads to some tricky problems.\nIn configuring your new system, there are k component s that\nmust be selected: the operating system, the text editing software , the e-\nmail program, and so forth; each is a separate component. For the j\nthcomponent of the system, you have a set Aj of options; and a"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 610})","('type', 'Document')"
"('page_content', 'configuratio n of the system consists of a selection of one element\nfrom each of the sets of options A1,A2,…,Ak.\nNow the trouble arises because certain pairs of options from\ndifferent sets may not be comp atible. We say that option xi ∊ Ai and\noption xj ∊ Aj form an incompatibl e pai r if a single system cannot\ncontain them both. (For example , Linux (as an option for the operating\nsystem) and Microsoft Word (as an option for the text-editing\nsoftware) form an incompatible pair.) We say that a configuration of\nthe system is full y compatibl e if it consists of elements x1 ∊ A1, x2 ∊\nA2,…xk ∊ Ak such that none of the pairs ( xi, xj) is an incompatible pair .\nWe can now define the Full y Compatibl e Configuratio n (FCC)\nProblem . An instance of FCC consists of disjoint sets of options\nA1,A2,…,Ak, and a set P of incompatibl e pair s (x, y), where x and y\nare elem ents of different sets of options. The problem is to decide\nwhether there exists a fully compatible configuration: a selectio n of an\nelement from each option set so that no pair of selected elements\nbelongs to the set P.\nExample.  Suppose k =3, and the sets A1,A2,A3 denote options for the\noperating system, the text-editing software, and the e-mail program,\nrespectively . We have\nwith the set of incompatible pairs equal to\nThen the answer to the decision problem in this instance of FCC  is yes\n—for example, the choices Linux ∊  A1, emacs ∊  A2, rmail ∊  A3 is a\nfully compatible configuration according to the definitions above.\nProve that Fully Compatible Configuration is NP-complete.\n22. Suppose that someone gives you a black-box algorithm A that takes an\nundirected graph G = (V, E), and a number k, and behaves as follows.  \nIf G is not connected, it simply returns “ G is not connected.”.\nIf G is conn ected and has an indepe ndent set of size at least k, it\nreturns “yes.”.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 611})","('type', 'Document')"
"('page_content', ""If G is connected and does not have an independent set of size at\nleast k, it returns “no.”\nSuppose that the algorithm A runs in time polynomial in the size of G\nand k.\nShow how, using calls to A, you could then solve the Independent\nSet Problem in polynomial time: Given an arbitrary undirected graph\nG, and a number k, does G contain an independent set of size at least\nk?\n23. Given a set of finite binary strings S = {s1,…,sk}, we say that a string u\nis a concatenation  over S if it is equal to si1 si2 …sit for some indice s\ni1,…,it ∊ {1,…, k}.\nA friend of yours is considerin g the following problem: Given\ntwo sets of finite binary strings, A = {a1,…,am} and B = {b1,…,bn},\ndoes there exist any string u so that u is both a concatenation over A\nand a concatenation over B?\nYour friend announces, “At least the problem is in NP, since I\nwould just have to exhibit such a string u in order  to prove the answer\nis yes.” You point out (politely , of course) that this is a completely\ninadequate expla nation; how do we know that the shortest such string\nu doesn't have length exponential  in the size of the input, in which case\nit would not be a polynomial-size certificate?\nHowever , it turns out that this claim can be turned into a proof of\nmembership in NP. Specifically , prove the following statement.\nIf there is a string u that is a concatenation  over both A and B, then there is such\na string whose length is bounded by a polynomial in the sum of the lengths of the\nstrings in A  ∪B.\n24. Let G = (V, E) be a bipartite graph; suppose its nodes are partitioned\ninto sets X and Y so that each edge has one end in X and the other in Y.\nWe define an ( a, b)-skeleto n  of G to be a set of edges E′ ⊆  E so that at\nmost  a nodes in X are incident to an edge in E′, and at least b nodes in\nY are incident to an edge in E′.\nShow that, given a bipartite graph G and numbers a and b,\nitisNPcomplete to decide whether G has an ( a, b)-skeleton.\n25. For functions g1,…,gℓ, we define the function max( g1,…,gℓ) via"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 612})","('type', 'Document')"
"('page_content', ""Consider the following problem. You are given n piecewise\nlinear , continuous functions f1,…,fn defined  over the interval [0,t] for\nsome integer t. You are also given an integer B. You want to decide:\nDo there exist k of the functions fi1, …,fik so that\nProve that this problem is NP-complete.\n26. You and a friend have been trekking through various far-off parts of\nthe world and have accumulate d a big pile of souvenirs. At the time\nyou weren't really thinking about which of these you were planning to\nkeep and which your friend was going to keep, but now the time has\ncome to divide everything up.\nHere's a way you could go abou t doing this. Suppose there are n\nobjects, labeled 1,2,…, n, and object i has an agreed-upon value xi. (We\ncould think of this, for example, as a monetary resale value; the case in\nwhich you and your friend don't agree on the value is someth ing we\nwon't pursue here.) One reasonable way to divide things would  be to\nlook for a partitio n  of the objects into two sets, so that the total value\nof the objects in each set is the same.\nThis suggests solving the following Number Partitioning\nProblem . You are given positive integer s x1,…,xn; you want to decide\nwhether the numbers can be partitioned into two sets S1 and S2 with\nthe same sum:\nShow that Number Partitioning is NP-complete.\n27. Consider the following problem. You are given positive integers\nx1,…,xn, and numbers k and B. You want to know whether it is\npossible to partition  the numbers {xi} into k sets S1,…,Sk so that the\nsquared sums of the sets add up to at most B:\nShow that this problem is NP-complete.\n28. The following is a version of the Independent Set Problem. You are\ngiven a graph G = (V, E) and an integer k. For this problem, we will"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 613})","('type', 'Document')"
"('page_content', ""call a set I ⊂ V strongly independent  if, for any two nodes v, u ∊ I, the\nedge ( v, u) does not belon g to E, and there is also no path of two edges\nfrom u to v, that is, there is no node w such that both (u, w) ∊ E and\n(w, v) ∊ E. The Strongly Independent Set Problem is to decide whether\nG has a strongly independent set of size at least k.\nProve that the Strongly Independent Set Problem is NP-complete.\n29. You're configuring a large network of workstations, which we'll model\nas an undirected graph G; the nodes of G represent individual\nworkstations and the edges represent direct communication links. The\nworkstations all need access to a common core database , which\ncontains data necessary for basic operating system functions.\nYou could replic ate this database on each workstation; this would\nmake lookups very fast from any workstation, but you'd have to\nmanage a huge number of copies. Alternately , you could keep a single\ncopy of the database on one workstation and have the remaining\nworkstations issue requests for data over the network G; but this could\nresult in large delays for a works tation that's many hops away from the\nsite of the database.\nSo you decide to look for the following compromise: You want to\nmaintain a small number of copies, but place them so that any\nworkstation either has a copy of the database or is connected by a\ndirect link to a workstation that has a copy of the database. In graph\nterminology , such a set of locations is called a dominating set .\nThus we phrase the Dominating Set Problem  as follows. Given\nthe network G, and a number k, is there a way to place k copies of the\ndatabase at k different nodes so that every node either has a copy of the\ndatabase or is connected by a direct link to a node that has a copy of\nthe database?\nShow that Dominating Set is NP-complete.\n30. One thing that's not always apparent when thinking about traditional\n“continuous math” problems is the way discrete, combinatorial issues\nof the kind we're studying here can creep into what look like standard\ncalculus questions.\nConsider , for example, the traditional problem of minimizing a\none-variable function like f(x) = 3 + x - 3x2 over an interval  like x ∊ [0,\n1]. The derivativ e has a zero at x = 1/6, but this in fact is a maximum\nof the function, not a minimum; to get the minimum, one has to heed"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 614})","('type', 'Document')"
"('page_content', ""the standard warning to check the values on the boundary of the\ninterval as well. (The minimum is in fact achieved on the boundary , at\nx = 1.)\nChecking the boundary isn't such a problem when you have  a\nfunction in one variable; but suppose we're now dealing with the\nproblem of minimizing a functio n in n variables x1, x2, …, xn over the\nunit cube, where each of x1, x2, …, xn ∊ [0, 1]. The minimum may be\nachieved on the interior of the cube, but it may be achieved on the\nboundary; and this latter prospect is rather daunting, since the\nboundary consis ts of 2n “corners” (where each xi is equal to either 0 or\n1) as well as various pieces of other dimensions. Calculus book s tend\nto get suspicious ly vague around here, when trying to describe how to\nhandle multivariable minimization problems in the face of this\ncomplexity .\nIt turns out there's a reason for this: Minimizing an n -variable\nfunction over the unit cube in n dimensions is as hard as an NP-\ncomplete problem. To make this concrete, let's consider the special\ncase of polynomials with integer coefficients over n variables x1, x2,\n…, xn. To review some terminology , we say a monomial  is a product of\na real-number coefficient c and each variable xi raised to some\nnonnegative integer power ai; we can write this as \n . (For\nexample, 2x12x2x4\n3 is a monomial.) A polynomial  is then a sum of a\nfinite set of monomials. (For example, \n  is a\npolynomial.)\nWe defin e the Multivariabl e Polynomial Mini mizatio n Problem\nas follows: Given a polynomial in n variables with integer coefficients,\nand given an integer bound B, is there a choice of real numbers x1, x2,\n…, xn ∊ [0, 1] that causes the polynomial to achieve a value that is ≤\nB?\nChoose a problem Y from this chap ter that is known to be NP-\ncomplete and show that\n31. Given an undirected graph G = (V, E),a feedback set is a set X ⊆ V\nwith the property that G - X has no cycles. The Undir ecte d Feedback"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 615})","('type', 'Document')"
"('page_content', ""Set Pr oblem  asks: Given G and k, does G contain a feedba ck set of size\nat most k? Prove that Undirected Feedback Set is NP-complete.\n32. The mapping of genomes involves a large array of difficult\ncomputational problems. At the most basic level, each of an or ganism's\nchromosomes can be viewed as an extremely long string (generally\ncontaining millions of symbols) over the four-letter alphabet {A, C, G,\nT}. One family of approaches to genome mapping is to generate a\nlarge number of short, overlapping snippets from a chromosome, and\nthen to infer the full long string representing the chromosome from this\nset of overlapping substrings.\nWhile we won't go into these string assembly problems in full\ndetail, here's a simplified problem that suggests some of the\ncomputational difficulty one encounters in this area. Suppose we have\na set S = {s1,s2,…,sn} of short DNA strings over a q -letter alphabet;\nand each string si has length 2ℓ, for some number ℓ ≥ 1. We also have\na library  of additional strings T = {t1,t2,…,tm} over the same alphabet;\neach of these also has length 2ℓ. In trying to assess whether the string\nsb might come directly after the string sa in the chromosome, we will\nlook to see whether the library T contains a string tk so that the first ℓ\nsymbols in tk are equal to the last ℓ symbols in sa, and the last ℓ\nsymbols in tk are equal to the first ℓ symbols in sb. If this is possible,\nwe will say that t k corroborate s the pair (sa, sb). (In other words, tk\ncould be a snippet of DNA that straddled the region in which sb\ndirectly followed sa.)\nNow we'd like to concatenate all the strings in S in some order ,\none after the other with no overlaps, so that each consecutive pair is\ncorroborated by some string in the library T. That is, we'd like to order\nthe strings in S as si1, si2, …,sin, where i1,i2,…,in is a permutation of\n{1,2,…, n}, so that for each j =1,2,…, n -1, there is a string tk that\ncorroborates the pair (sij, sij+1). (The same string tk can be used for\nmore than one consecutive pair in the concatenation.) If this is\npossible, we will say that the set S has a perfect assembly .\nGiven sets S and T, the Perfect Assembly Problem  asks: Does S\nhave a perfect assembly with respect to T? Prove  that Perfect\nAssembly is NP-complete."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 616})","('type', 'Document')"
"('page_content', ""Example.  Suppos e the alphabet is {A, C, G, T}, the set S = {AG, TC,\nTA}, and the set T = {AC, CA, GC, GT} (so each string has length 2ℓ\n=2). Then the answer to this instance of Perfect Assembly is yes: We\ncan conc atenate the three strings in S in the order TCAGT A (so si1 =s2,\nsi2 =s1, and si3 =s3). In this order , the pair (si1, si2) is corroborated by\nthe string CA in the library T, and the pair (si2, si3) is corroborated by\nthe string GT in the library T.\n33. In a barter econ omy, people trade goods and services directly , without\nmoney as an intermediate step in the process. Trades happen when\neach party views the set of goods they're getting as more valuable than\nthe set of goods  they're giving in return. Historically , societies tend to\nmove from barter -based to money-based economies; thus various\nonline systems that have been experimenting with barter can be\nviewed as intentional attempts  to regress to this earlier form of\neconomic interaction. In doing this, they've rediscovered some of the\ninherent difficulties with barter relative to money-based systems. One\nsuch difficulty is the complexity of identifying opportunities for\ntrading, even when these opportunities exist.\nTo model this complexity , we need a notion that each perso n\nassigns a value  to each object in the world, indicating how much this\nobject would be worth to them. Thus we assume there is a set of n\npeople p1,…,pn, and a set of m distinct objects a1,…,am. Each object is\nowned by one of the people. Now each person pi has a valuation\nfunction vi, defined so that vi(aj) is a nonnegative number that specifies\nhow much object aj is worth to pi —the larger the number , the more\nvaluable the object is to the person. Note that everyone assigns a\nvaluation to each object, including the ones they don't currently\npossess, and different people can assign very different valuations to the\nsame object.\nA two-person trade is possible in a system like this when there are\npeople pi and pj, and subsets of objects Ai and Aj possessed by pi and\npj, respectively , so that each person would prefer the objects in the\nsubset they don't currently have. More precisely , \npi's total valuation  for the objects in Aj exceeds  his or her total\nvaluation for the objects in Ai, and."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 617})","('type', 'Document')"
"('page_content', ""pj 's total valuation for the objects in Ai exceeds  his or her total\nvaluation for the objects in Aj.\n(Note that Ai doesn't have to be all the objects possessed by pi (and\nlikewise for Aj); Ai and Aj can be arbitrary subsets of their possessions\nthat meet these criteria.)\nSuppose you are given an instan ce of a barter economy , specified\nby the above data on people's valuations for objects. (To prevent\nproblems with representing real numbers, we'll assume that each\nperson's valuation for each object is a natural number .) Prove that the\nproblem of determining whethe r a two-person trade is possible is NP-\ncomplete.\n34. In the 1970s, researchers including Mark Granovetter and Thomas\nSchelling in the mathematical social sciences began trying to develop\nmodels of certain kinds of collective human behaviors: Why do\nparticular fads catch on while others die out? Why do particular\ntechnological innovations achie ve widespread adoption, while  others\nremain focused on a small group of users? What are the dynamics by\nwhich rioting and looting behavior sometimes (but only rarely)\nemer ges from a crowd of angry  people? They proposed that these are\nall examples of cascad e processes, in which an individu al's behavior is\nhighly influenced by the behaviors of his or her friends, and so if a few\nindividuals instigate the process, it can spread to more and more\npeople and eventually have a very wide impact. We can think of this\nprocess as being like the spread of an illness, or a rumor , jumpin g from\nperson to person.\nThe most basic version of their models is the following. There is\nsome underlying behavio r (e.g., playing ice hockey , owning a cell\nphone, taking part in a riot), and at any point in time each person is\neither an adopte r of the behavior or a nonadopter . We represent the\npopulation by a directed graph G = (V, E) in which the nodes\ncorrespond to people and there is an edge (v, w) if person v has\ninfluence over the behavior of person w : If person v adopts the\nbehavior , then this helps induce person w to adopt it as well. Each\nperson w also has a given threshol d θ(w) ∊ [0, 1], and this has the\nfollowing meaning: At any time when at least a θ(w) fractio n of the"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 618})","('type', 'Document')"
"('page_content', ""nodes with edges to w are adopters of the behavior , the node w will\nbecome an adopter as well.\nNote that nodes  with lower thresholds are more easily convinced\nto adopt the behavior , while nodes with higher thresholds are more\nconservative. A node w with threshold θ( w) = 0 will adopt the behavior\nimmediately , with no inducement from friends. Finally , we need a\nconvention about nodes with no incoming edges: We will say that they\nbecome adopters  if θ(w) = 0, and cannot become adopters if they have\nany lar ger threshold.\nGiven an instance of this model, we can simulate the spread of the\nbehavior as follows.\nNote that this process terminates, since there are only n individuals\ntotal, and at least one new person becomes an adopter in each iteration.\nNow , in the last few years, researchers in marketing and data\nmining have looked at how a model like this could be used to\ninvestigate “word-of-mouth” effects in the success of new products\n(the so-called vira l marketin g phenomenon). The idea here is that the\nbehavior we're concerned with is the use of a new product; we may be\nable to convince a few key people in the population to try out this\nproduct, and hope to trigger as lar ge a cascade as possible.\nConcretely , suppose we choose a set of nodes S ⊆ V and we reset\nthe thres hold of each node in S to 0. (By convincing them to try the\nproduct, we've ensured that they're adopters.) We then run the process\ndescribed above , and see how large the final set of adopters is. Let's\ndenote the size of this final set of adopters by f(S) (note that we write it\nas a function of S, since it natural ly depends on our choice of S). We"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 619})","('type', 'Document')"
"('page_content', ""could think of f(S) as the influenc e of the set S, since it captures how\nwidely the behavior spreads when “seeded” at S.\nThe goal, if we're marketing a product, is to find a small set S\nwhose influence f (S) is as large as possible. We thus define the\nInfluence Maximization Problem  as follows: Given a directed graph G\n=(V, E), with a thresho ld value at each node, and parameters k and b, is\nthere a set S of at most k nodes for which f(S) ≥ b?\nProve that Influence Maximization is NP-complete.\nExample.  Suppose our graph G =(V, E) has five nodes {a, b, c, d, e},\nfour edges (a, b), (b, c), (e, d), (d, c), and all node thresholds equal to\n2/3. Then the answer to the Influence Maximization instance defined\nby G, with k = 2 and b = 5, is yes: We can choose S = {a, e}, and this\nwill cause the other three nodes to become adopters as well. (This is\nthe only choice of S that will work here. For example, if we choose S =\n{a, d}, then b and c will become adopters, but e won't; if we choose S\n= {a, b}, then none of c, d, or e will become adopters.)\n35. Three of your friends work for a large computer -game company , and\nthey've been working hard for several months now to get their proposal\nfor a new game, Droid Trader! , approved by higher management. In\nthe process, they've had to endure all sorts of discouraging comments,\nranging from “You're really going to have to work with Marketing on\nthe name” to “Why don't you emphasize the parts where people get to\nkick each other in the head?”\nAt this point, though, it's all but certain that the game is really\nheading into production, and your friends come to you with one final\nissue that's been worrying them: What if the overall premise of the\ngame is too simple, so that players get really good at it and become\nbored too quickly?\nIt takes you a while, listening to their detailed description of the\ngame, to figure out what's going on; but once you strip away the space\nbattles, kick-bo xing interludes, and Stars-W ars-inspired pseudo-\nmysticism, the basic idea is as follows. A player in the game controls a\nspaceship and is trying to make  money buying and selling droids on\ndifferent planets. There are n different types of droids and k different\nplanets. Each planet p has the following properties: there are s(j, p) ≥\n0droids of type j available for sale, at a fixed price of x(j, p) ≥ 0 each,\nfor j = 1, 2,…, n; and there is a demand for d (j, p) ≥ 0 droids of type j,"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 620})","('type', 'Document')"
"('page_content', ""at a fixed price of y(j, p) ≥ 0 each. (We will assume that a planet does\nnot simultaneously have both a positive supply and a positive demand\nfor a single type of droid; so for each j, at least one of s (j, p) or d (j, p)\nis equal to 0.)\nThe player begins on planet s with z units of money and must end\nat planet t; there is a directed acyclic graph G on the set of planets,\nsuch that s -t paths in G correspond to valid routes by the player . (G is\nchosen to be acyclic to prevent arbitrarily long games.) For a given s -t\npath P in G, the player can engage in transactions as follows.\nWhenever the player arrives at a planet p on the path P, she can buy up\nto s (j, p) droids of type j for x (j, p) units of money each (provided she\nhas sufficient money on hand) and/or sell up to d (j, p) droids of type j\nfor y (j, p) units of money each (for j = 1,2,…, n). The player's final\nscore is the total amount of money she has on hand when she arrives at\nplanet t. (There are also bonus points based on space battles and kick-\nboxing, which we'll ignore for the purposes of formulating this\nquestion.)\nSo basically , the underlying problem is to achieve a high score. In\nother words, given an instance of this game, with a directed acyclic\ngraph G on a set of planets, all the other parameters described above,\nand also a target bound B, is there a path P in G and a sequence of\ntransactions on P so that the player ends with a final score that is at\nleast B? We'll call this an instance of the High-Scor e-on-Dr oid-T rader\n! Problem , or HSoDT! for short.\nProve that HSoDT! is NP-complete, thereby guaranteeing\n(assuming P ≠= NP) that there isn't a simple strategy for racking up\nhigh scores on your friends' game.\n36. Sometimes you can know peopl e for years and never really understand\nthem. Take your friends Raj and Alanis, for example. Neither of them\nis a morning person, but now they're getting up at 6 AM every day to\nvisit local farmers' markets, gathering fresh fruits and vegetables for\nthe new health-food restaurant they've opened, Chez Alanisse.\nIn the course of trying to save money on ingredients, they'v e\ncome across the following thorny problem. There is a large set of n\npossible raw ingredients they could buy, I1,I2,…,In (e.g., bundles of\ndandelion greens, jugs of rice vinegar , and so forth). Ingredient Ij must\nbe purchased in units of size s (j) grams (any purchase must be for a"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 621})","('type', 'Document')"
"('page_content', ""whole number of units), and it costs c (j) dollars per unit. Also, it\nremains safe to use for t (j) days from the date of purchase.\nNow , over the next k days, they want  to make a set of k different\ndaily specials, one each day. (The order in which they schedule the\nspecials is up to them.) The ith daily special uses a subset Si ⊆\n{I1,I2,…,In} of the raw ingredients. Specifically , it requires a (i, j)\ngrams of ingredient Ij. And there's a final constraint:  The restaurant's\nrabidly loyal customer base only remains rabidly loyal if they're  being\nserved the freshest meals available; so for each daily speci al, the\ningredients Si are partitioned into two subsets: those that must be\npurchased on the very day when the daily special is being offered, and\nthose that can be used any day while they're still safe. (For example,\nthe mesclun-bas il salad special needs to be made with basil that has\nbeen purchased that day; but the arugula-basil pesto with Cornell dairy\ngoat cheese special can use basil that is several days old, as long as it\nis still safe.)\nThis is where the opportunity  to save money on ingredien ts\ncomes up. Often, when they buy a unit of a certain ingredient Ij, they\ndon't need the whole thing for the special they're making that day.\nThus, if they can follow up quickly with another special that uses Ij but\ndoesn't require it to be fresh that day, then they can save money  by not\nhaving to purch ase Ij again. Of course, scheduling the basil recipes\nclose together may make it harder to schedule the goat cheese recipes\nclose together , and so forth— this is where the complexity comes in.\nSo we define the Daily Special Scheduling Problem as follows:\nGiven data on ingredients and recipes as above, and a budget x, is there\na way to schedu le the k daily specials so that the total money spent on\ningredients over the course of all k days is at most x?\nProve that Daily Special Scheduling  is NP-complete.\n37. There are those who insist that the initial working title for Episode\nXXVII of the Star Wars series was “P = NP”—but this is surely\napocryphal. In any case, if you're so inclined, it's easy to find NP-\ncomplete problems lurking just below the surface of the original Star\nWars movies.\nConsider the problem faced by Luke, Leia, and friends as they\ntried to make their way from the Death Star back to the hidden Rebel"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 622})","('type', 'Document')"
"('page_content', ""base. We can view the galaxy as an undirected graph G = (V, E), where\neach node is a star system and an edge (u, v) indicates that one can\ntravel directly from u to v. The Death Star is represented by a node s,\nthe hidden Rebel base by a node t. Certain edges in this graph\nrepresent longer distances than others; thus each edge e has an integer\nlength ℓe ≥ 0. Also, certa in edges represent routes that are more heavily\npatrolled by evil Imperial spacecraft; so each edge e also has an integer\nrisk re ≥ 0, indicating the expected amount of damage incurred from\nspecial-ef fects-intensive space battles if one traverses this edge.\nIt would  be safest to travel through the outer rim of the galaxy ,\nfrom one quiet upstate star system to another; but then one's ship\nwould run out of fuel long before getting to its destination. Alter nately ,\nit would  be quickest to plunge through the cosmopolitan core of the\ngalaxy; but then there would be far too many Imperial spacecraft to\ndeal with. In general, for any path P from s to t, we can define its total\nlength  to be the sum of the lengths of all its edges; and we can define\nits total risk  to be the sum of the risks of all its edges.\nSo Luke, Leia, and company are looking at a complex type of\nshortest-path problem in this graph: they need to get from s to t along a\npath whose total length and total risk are both reasona bly small. In\nconcrete terms, we can phrase the Galacti c Shortest-Path Problem  as\nfollows: Given a setup as above , and integer bounds L and R, is there  a\npath from s to t whose total length is at most L, an d whose total risk is\nat most R?\nProve that Galactic Shortest Path is NP-complete.\n38. Consider the following version of the Steiner Tree Problem, which\nwe'll refer to as Graphical Steiner Tree. You are given  an undirected\ngraph G = (V, E), a set X ⊆ V of vertices, and a number k. You want to\ndecide whether there is a set F ⊆ E of at most k edges so that in the\ngraph ( V, F), X belongs to a single connected component.\nShow that Graphical Steiner T ree is NP-complete.\n39. The Directed Disjoin t Paths Problem  is defined as follows. We are\ngiven a directed graph G and k pairs of nodes (s1,t1),(s2,t2),…,( sk, tk).\nThe problem is to decide whether there exist node-disjoint paths\nP1,P2,…,Pk so that Pi goes from si to ti.\nShow that Directed Disjoint Paths is NP-complete."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 623})","('type', 'Document')"
"('page_content', '40. Consider the following problem that arises in the design of\nbroadcasting schemes for networks. We are given a directed graph G =\n(V, E), with a design ated node r ∊ V and a designated set of “target\nnodes” T ⊆ V - {r}. Each node v has a switching time sv, which is a\npositive integer .\nAt time 0, the node r generates a message that it would like every\nnode in T to receive. To accomplish this, we want to find a scheme\nwhereby r tells some of its neighbors (in sequence), who in turn tell\nsome of their neighbors, and so on, until every node in T has received\nthe message. More formally , a broadcast scheme  is defined as follows.\nNode r may send a copy of the messag e to one of its neighbors at time\n0; this neighbor will receive the message at time 1. In general, at time t\n≥0, any node v that has already  received the message may send a copy\nof the message to one of its neighbors, provided it has not sent a copy\nof the message in any of the time steps t -sv +1,t -sv +2,…, t -1. (This\nreflects the role of the switching time; v needs a pause of sv -1 steps\nbetween success ive sendings of the message. Note that if sv =1, then\nno restriction is imposed by this.)\nThe completion time of the broadca st scheme is the minimum\ntime t by which all nodes in T have received the message. The\nBroadcast Time Problem  is the following: Given the input described\nabove, and a bound b, is there a broadcast scheme with completion\ntime at most b?\nProve that Broadcast T ime is NP-complete.\nExample.  Suppos e we have a directed graph G =(V, E), with V = {r, a,\nb, c}; edges (r, a), (a, b), (r, c); the set T = {b, c}; and switching time\nsv =2for each v ∊V. Then a broadcast scheme with minimum\ncompletion time would be as follows: r sends the messa ge to a at time\n0; a sends the messa ge to b at time 1; r sends the messa ge to c at time\n2; and the scheme completes at time 3when c receive s the message.\n(Note that a can send the message as soon as it receives it at time 1,\nsince this is its first sending of the message; but r cannot send the\nmessage at time 1since sr = 2 and it sent the message at time 0.)\n41. Given a directed graph G, a cycle cover  is a set of node-disjoint cycles\nso that each node of G belongs to a cycle. The Cycle Cover Problem\nasks whether a given directed graph has a cycle cover .')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 624})","('type', 'Document')"
"('page_content', ""(a) Show that the Cycle Cover Problem can be solved in polynom ial\ntime. ( Hint:  Use Bipartite Matching.)  \n \n(b) Suppose we require each cycle to have at most three edges. Show\nthat determining whether a graph G has such a cycle cover is NP-\ncomplete.\n42. Suppose you're consulting for a company in northern New Jersey that\ndesigns communication networks, and they come to you with the\nfollowing proble m. They're studying a specific n-node communication\nnetwork, modele d as a directed graph G = (V, E). For reasons of fault\ntolerance, they want to divide up G into as many virtual “domains” as\npossible: A domain  in G is a set X of node s, of size at least 2, so that\nfor each pair of nodes u, v ∊ X there are directed paths from u to v and\nv to u that are contained entirely in X.\nShow that the following Domain Decomposition Problem  is NP-\ncomplete. Given  a directed graph G = (V, E) and a number k, can V be\npartitioned  into at least k sets, each of which is a domain?\nNotes and Further Reading\nIn the notes to Chapter 2, we described some of the early work on\nformalizing computational efficiency using polynomial time; NP-\ncompleteness evolved out of this work and grew into its central role in\ncomputer scienc e following the papers of Cook (1971), Levin (1973), and\nKarp (1972). Edmonds (1965) is credited with drawing particular attention\nto the class of problems in NP ∩ co-NP —those with “good\ncharacterizations.” His paper also contains the explicit conjecture that the\nTraveling Salesm an Problem cannot be solved in polynomial time, thereby\nprefiguring the P ≠ NP question. Sipser (1992) is a useful guide to all of\nthis historical context.\nThe book by Garey and Johnson  (1979) provides extensive material on\nNP-completeness and concludes with a very useful catalog of known NP-\ncomplete problems. While this catalog, necessarily , only covers what was\nknown at the time of the book's publication, it is still a very useful reference"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 625})","('type', 'Document')"
"('page_content', 'when one encounters a new problem that looks like it might be NP-\ncomplete. In the meantime, the space of known NP-complete problems has\ncontinued to expand dramatically; as Christos Papadimitriou said in a\nlecture, “Roughly 6,000 papers every year contain an NP-completeness\nresult. That means another NP-complete problem has been discovered since\nlunch.” (His lecture was at 2:00 in the afternoon.)\nOne can interpret NP-completeness as saying that each individual NP-\ncomplete proble m contains the entire complexity of NP hidden inside it. A\nconcrete reflect ion of this is the fact that several of the NP-complete\nproblems we discuss here are the subject of entire books: the Traveling\nSalesman is the subject of Lawler et al. (1985); Graph Coloring is the\nsubject of Jensen  and Toft (1995 ); and the Knapsack Problem is the subject\nof Martello and Toth (1990). NP-completeness results for scheduling\nproblems are discussed in the survey by Lawler et al. (1993).\nNotes on the Exercises  A number of the exercises illustrate further\nproblems that emer ged as parad igmatic examples early in the development\nof NP-completeness; these include Exercises 5, 26, 29, 31, 38, 39, 40, and\n41. Exercise 33 is based on discussions with Daniel Golovin, and Exercise\n34 is based on our work with David Kempe. Exercise 37 is an example of\nthe class  of Bicriteria Shortest-Path problems ; its motivating application\nhere was suggested by Maverick W oo.\n1 The act of searching for a string t that will cause an efficient certifier to\naccept the input  s is often viewed as a nondeterministic search over the\nspace of possible proofs t; for this reason, NP was named as an acronym for\n“nondeterministic polynomial time.”\n2 This argument actually gives considerable insight into how one comes up\nwith this subgraph in the first place. The goal is to have a node like the\ntopmost one that cannot receive any color . So we start by “plugging in”\nthree nodes corresponding to the terms, all colored False , at the bottom. For\neach one, we then work upward, pairing it off with a node of a known color\nto force the node above to have  the third color . Proceeding in this way, we\ncan arrive at a node that is forced to have any color we want. So we force\neach of the three different colors, starting from each of the three different\nterms, and then we plug all three  of these differently colored nodes into our\ntopmost node, arriving at the impossibility .\n3 Ken Auletta quoting Jef frey Blattner , The New Y orker , 16 August 1999.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 626})","('type', 'Document')"
"('page_content', '4 See, e.g., http://www .eastgate.com .')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 627})","('type', 'Document')"
"('page_content', 'Chapter 9')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 628})","('type', 'Document')"
"('page_content', 'PSPACE: A Class of Problems beyond NP\n9.1 PSP ACE  \n9.2 Some Hard Pr oblems in PSP ACE  \n9.3 Solving Quantified Pr oblems and Games in Polynomial Space  \n9.4 Solving the Planning Pr oblem in Polynomial Space  \n9.5 Pr oving Pr oblems PSP ACE-Complete  \nSolved Exer cises  \nExer cises  \nNotes and Further Reading\nThroughout the book, one of the main issues has been the notion of time as\na computational resource. It was this notion that formed the basis for\nadopting polynomial time as our workin g definition of efficiency; and,\nimplicitly , it underlies the distinction between P and NP . To some extent, we\nhave also been concerned with the space  (i.e., memory) requirements of\nalgorithms. In this chapter , we investigate a class of problems  defined by\ntreating space as the fundamen tal computational resource. In the process,\nwe deve lop a natural class of problems that appear to be even harder than\nNP and co-NP .\n9.1 PSPACE\nThe basic class we study is PSPACE, the set of all problems that can be\nsolved by an algorithm with polynomial space complexity— that is, an\nalgorithm that uses an amount of space  that is polynomial in the size of the\ninput.\nWe begin by considering the relationship of PSPACE to classes of\nproblems we have considered earlier . First of all, in polynom ial time, an\nalgorithm can consume only a polynomial amount of space; so we can say\n(9.1)  P ⊆ PSPACE.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 629})","('type', 'Document')"
"('page_content', ""But PSPACE is much broade r than this. Consider , for example,\nanalgorithm that just counts from 0 to 2n - 1 in base-2 notation. It simply\nneeds to implement an n-bit counter , which it maintains in exactly the same\nway one increments an odometer in a car. Thus this algorithm runs for an\nexponential amount of time, and then halts; in the process, it has used only\na polyn omial amount of space. Although this algorithm is not doing\nanything particularly interesting, it illustrates an important principle: Space\ncan be reused during a computation in ways that time, by definition, cannot.\nHere is a more striking application of this principle.\n(9.2) There is an algorithm that solves 3-SA T using only a polynomial amount of space.  \n \nProof. We simply use a brute-force algorithm  that tries all possible truth assignments; each\nassignment is plugged into the set of clauses to see if it satisfies them. The key is to implement this\nall in polynomial space.\nTo do this, we increment an n-bit counter from 0 to 2n — 1 just as described above. The values\nin the counter correspond to truth assignments in the following way: When the counter holds a value\nq, we interpret it as a truth assignment v that sets xi to be the value of the ith bit of q.\nThus we devote a polynomial amount of space to enumerating all possible truth assignments v.\nFor each truth assignm ent, we need only polynomial space to plug it into the set of clauses and see if\nit satisfies them. If it does satisfy the clauses, we can stop the algorithm immediately . If it doesn't, we\ndelete the intermedia te work involved in this “plugging in” operation and reuse this space for the\nnext truth assignmen t. Thus we spend only polynomial space cumulatively in checking all truth\nassignments; this completes the bound on the algorithm's space requirements. ▪\nSince 3-SA T is an NP-compl ete problem, (9.2) has a significant\nconsequence.\n(9.3) NP ⊆ PSPACE.  \n \nProof. Cons ider an arbitrary  problem Y in NP. Since Y ≤P 3-SA T, there is an algorithm that solves Y\nusing a polynomial number of steps plus a polynomial number of calls to a black box for 3-SA T.\nUsing the algorithm in (9.2) to implement this black box, we obtain an algorithm for Y that uses only\npolynomial space. ▪\nJust as with the class P, a probl em X is in PSPACE if and only if its\ncomplementary problem \n  is in PSPACE as well. Thus we can conclude\nthat co-NP ⊆ PSPACE. We draw what is known about the relationship s\namong these classes of problems in Figure 9.1 .\nGiven that PSPACE is an enormously large class of problems,\ncontaining both NP and co-NP, it is very likely that it contains problems\nthat cannot be solved in polynomial time. But despite this widespread"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 630})","('type', 'Document')"
"('page_content', ""belief, amazingly it has not been proven that p ≠ PSP ACE. Nevertheless, the\nnearly universal conjecture is that PSPACE contains problems that are not\neven in NP or co- NP.\nFigur e 9.1 The subset relationships among various classes of problems.\nNote that we don't know how to prove the conjecture that all of these\nclasses are dif ferent from one another .\n9.2 Some Hard Problems in PSPACE\nWe now survey some natural examples of problems in PSPACE  that are not\nknown—and not believed—to belong to NP or co- NP.\nAs was the case with NP, we can try understanding the structure of\nPSPACE by looking for complete problems —the hardest problems in the\nclass. We will say that a problem  X is PSPACE- complete  if (i) it belongs to\nPSPACE; and (ii) for all problems Y in PSP ACE, we have Y ≤P X.\nIt turns out, analogously to the case of NP, that a wide range of natural\nproblems are PSPACE-complete. Indeed, a number of the basic problems in\nartificial intelligence are PSPACE-complete, and we describe three genres\nof these here.\nPlanning"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 631})","('type', 'Document')"
"('page_content', ""Planning problems  seek to capture , in a clean way, the task of interacting\nwith a complex environment to achieve a desired set of goals. Canonical\napplications include large logistical operations that require the movement of\npeople, equipment, and materials. For example, as part of coordinating a\ndisaster -relief effort, we might decide that twenty ambulances are needed at\na particular high-altitude locati on. Before this can be accomplished, we\nneed to get ten snowplows to clear the road; this in turn requires emer gency\nfuel and snowpl ow crews; but if we use the fuel for the snowplows, then we\nmay not have enough for the ambulances; and … you get the idea. Military\noperations also require such reasoning on an enormous scale, and\nautomated planning techniques from artificial intelligence have been used\nto great ef fect in this domain as well.\nOne can see very similar issues at work in complex solitaire games\nsuch as Rubik's Cube or the fifteen-puzzle —a 4 × 4 grid with fifteen\nmovable tiles labeled 1, 2,…, 15, and a single hole,  with the goal of moving\nthe tiles around so that the numb ers end up in ascending order . (Rather than\nambulances and snowplows, we now are worried about things like getting\nthe tile labeled 6 one position to the left, which involves gettin g the 11 out\nof the way; but that involves moving the 9, which was actually in a good\nposition; and so on.) These toy problems can be quite tricky and are often\nused in artificial intelligence as a test-bed for planning algorithms.\nHaving said all this, how should we define the problem of planning in\na way that's general enough to include each of these examples? Both\nsolitaire puzzles and disaster -relief efforts have a number of abstract\nfeatures in common: There are a number of conditions  we are trying to\nachieve and a set of allowable operators  that we can apply to achieve these\nconditions. Thus we model the environment by a set \n  = {C1, …, Cn) of\nconditions:  A given state of the world is specified by the subset of the\nconditions that currently hold. We interact with the environment through a\nset {\n1, …, \nk} of operators.  Each operator \ni is specified by a prerequisite\nlist, containing a set of conditions that must hold for \ni to be invoked; an\nadd list, containing a set of conditions that will become true after \ni is\ninvoked; and a delete list, containing a set of conditions that will cease to\nhold after \ni is invok ed. For example, we could model the fifteen-puzzle by\nhaving a conditi on for each possible location of each tile, and an operator to"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 632})","('type', 'Document')"
"('page_content', 'move each tile between each pair of adjacent locations; the prerequisite for\nan operator is that its two locations contain the designated tile and the hole.\nThe problem we face is the following: Given a set \n0 of initial\nconditions,  and a set \n* of goal conditions,  is it possible to apply a sequence\nof operators beginning with \n0 so that we reach a situation in which\nprecisely the conditions in \n* (and no others) hold? We will call this an\ninstance of the Planning Pr oblem.\nQuantification\nWe have seen, in the 3-SA T problem, some of the difficulty in determining\nwhether a set of disjunctive clauses can be simultaneously satisfied. When\nwe add quantifiers, the problem appears to become even more dif ficult.\nLet Φ( x1,…, xn) be a Boolean formula of the form\nwhere each Ci is a disjunction of three terms (in other words, it is an\ninstance of 3-SA T). Assume for simplicity that n is an odd number, and\nsuppose we ask\nThat is, we wish to know whether there is a choice for x1, so that for both\nchoices of x2, there is a choice for x3, and so on, so that Φ is satisfied. We\nwill refer to this decision problem as Quantified 3-SA T (or, briefly , QSA T).\nThe original 3-SA T problem, by way of comparison, simply asked\nIn other words, in 3-SA T it was sufficient to look for a single setting of the\nBoolean variables.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 633})","('type', 'Document')"
"('page_content', ""Here's an example to illustrate the kind of reasoning that under lies an\ninstance of QSA T. Suppose that we have the formula\nand we ask\nThe answer to this question is yes: We can set x1 so that for both choices of\nx2, there is a way to set x3 so that Φ is satisfied. Specifically , we can set x1 =\n1; then if x2 is set to 1, we can set x3 to 0 (satisfying all clauses); and if x2 is\nset to 0, we can set x3 to 1 (again satisfying all clauses).\nProblems of this type, with a sequence of quantifiers, arise naturally as\na form of contingency planning —we wish to know whether there is a\ndecision we can make (the choice of x1) so that for all possible responses\n(the choice of x2) there is a decis ion we can make (the choice of x3), and so\nforth.\nGames\nIn 1996 and 1997, world chess champion Garry Kasparov was billed by the\nmedia as the defender of the human race, as he faced IBM's program Deep\nBlue in two chess matches. We needn't look further than this picture to\nconvince ourselves that compu tational game-playing is one of the most\nvisible successes of contemporary artificial intelligence.\nA large number  of two-player games fit naturally into the following\nframework. Players alternate moves, and the first one to achiev e a specific\ngoal wins. (For example, depending on the game, the goal could be\ncapturing the king, removing all the opponent's checkers, placing four\npieces in a row, and so on.) Moreover , there is often a natural, polynomial,\nupper bound on the maximum possible length of a game."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 634})","('type', 'Document')"
"('page_content', ""The Competitive Facility Location Problem that we introduced in\nChapter 1  fits naturally within this framew ork. (It also illustrates the way in\nwhich games can arise not just as pastimes, but through competitive\nsituations in everyday life.) Recall that in Competitive Facility Location, we\nare given a graph G, with a nonnegative value bi attached to each node i.\nTwo players alternately select nodes of G, so that the set of selected node s\nat all times forms an independent set. Player 2 wins if she ultimately selects\na set of nodes of total value at least B, for a given bound B; Player 1 wins if\nhe prevents this from happenin g. The question is: Given the graph G and\nthe bound B, is there a strategy by which Player 2 can force a win?\n9.3 Solving Quantified Problems and Games in\nPolynomial Space\nWe now discuss how to solve all of these problems in polynomi al space. As\nwe will see, this will be trickier—in one case, a lot trickie r—than the\n(simple) task we faced in showing that problems like 3-SA T and\nIndependent Set belong to NP.\nWe begin here with QSA T and Competitive Facility Location, and then\nconsider Planning in the next section.\n Designing an Algorithm for QSAT\nFirst let's show that QSA T can be solved in polynomial space.  As was the\ncase with 3-SA T, the idea will be to run a brute-force algorithm that reuses\nspace carefully as the computation proceeds.\nHere is the basic brute-force approach. To deal with the first quantifier\n∃x1, we consider both possible values for x1 in seque nce. We first set x1 = 0\nand see, recursively , whether the remaining portion of the formula evaluates\nto 1. We then set x1 = 1 and see, recursively , whether the remaining portion\nof the formula evaluates to 1. The full formula evaluates to 1 if and only if\neither  of these  recursi ve calls yields a 1—that's simply the definition of the\n∃ quantifier .\nThis is essentially a divide-and-conquer algorithm, which, given an\ninput with n variables, spawns two recursive calls on inputs with n - 1"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 635})","('type', 'Document')"
"('page_content', ""variables each. If we were to save all the work done in both these recursive\ncalls, our space usage S(n) would satisfy the recurrence\nwhere p(n) is a polynomial function. This would result in an exponential\nbound, which is too lar ge.\nFortunately , we can perform a simple optimization that greatly reduces\nthe space usage. When we're done with the case x1 = 0, all we really need to\nsave is the single bit that repres ents the outcome of the recurs ive call; we\ncan throw away all the other intermediate work. This is another example of\n“reuse”—we're reusing the space from the computation for x1 = 0 in order\nto compute the case x1 = 1.\nHere is a compact description of the algorithm."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 636})","('type', 'Document')"
"('page_content', 'Analyzing the Algorithm\nSince the recurs ive calls for the cases x1 = 0 and x1 = 1 overwrite the same\nspace, our space requirement S(n) for an n-variable problem is simply a\npolynomial in n plus the space requirement for one recursive call on an (n -\n1)-variable problem:\nwhere again p(n) is a polynomial function. Unrolling this recurrence, we get\nSince p(n) is a polynomial, so is n ·d p(n),  and hence our space usage is\npolynomial in n, as desired.\nIn summary , we have shown the following.\n(9.4) QSAT can be solved in polynomial space.\nExtensions: An Algorithm for Competitive\nFacility Location\nWe can determ ine which player has a forced win in a game such as\nCompetitive Facility Location by a very similar type of algorithm.\nSuppose Player 1 moves first. We consider all of his possible moves in\nsequence. For each of these moves, we see who has a forced win in the\nresulting game, with Player 2 moving first. If Player 1 has a forced win in\nany of them, then Player 1 has a forced win from the initial position. The\ncrucial point, as in the QSA T algorithm, is that we can reuse the space from\none candidate move to the next; we need only store the single bit\nrepresenting the outcome. In this way, we only consume a polynomial')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 637})","('type', 'Document')"
"('page_content', 'amount of space plus the space requirement for one recursiv e call on a\ngraph with fewer nodes. As in the case of QSA T, we get the recurrence\nfor a polynomial p(n).\nIn summary , we have shown the following.\n(9.5) Competitive Facility Location can be solved in polynomial space.\n9.4 Solving the Planning Problem in Polynomial\nSpace\nNow we consider how to solve the basic Planning Problem in polynomial\nspace. The issue s here will look quite different, and it will turn out to be a\nmuch more dif ficult task.\n The Problem\nRecall that we have a set of conditions  \n = {C1,…, Cn} and a set of\noperators  {\n1,…, \nk}. Each operator \ni has a prerequisite list Pi, an add list\nAi, and a delete list Di. Note that \ni can still be applied even if conditions\nother than those in Pi are present; and it does not affect conditions that are\nnot in Ai or Di.\nWe define a configuration  to be a subset  \n′ ⊆ \n; the state of the\nPlanning Problem at any given time can be identified with a unique\nconfiguration \n ′ consisting precisely of the cond itions that hold at that time.\nFor an initial configuration \n0 and a goal configuration \n*, we wish to\ndetermine wheth er there is a sequence of operators that will take us from \n0\nto \n*.\nWe can view our Planning instance in terms of a giant, implicitly\ndefined, directed  graph \n . There is a node of \n for each of the 2n possible')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 638})","('type', 'Document')"
"('page_content', ""configurations (i.e., each possible subset of \n); and there is an edge of \nfrom configuration \n ′ to configuration \n ″ if, in one step, one of the operators\ncan convert \n ′ to \n″. In terms of this graph, the Planning Problem has a very\nnatural formulation: Is there a path in \n from \n0 to \n*? Such a path\ncorresponds precisely to a sequence of operators leading from \n0 to \n*.\nIt's possible for a Planning insta nce to have a short solution (as in the\nexample of the fifteen-puzzle), but this need not hold in gene ral. That is,\nthere need not always be a short path in \n from \n0 to \n*. This should not be\nso surprising, since \n  has an exponen tial number of nodes. But we must be\ncareful in applying this intuition, since \n  has a special structure: It is defined\nvery compactly in terms of the n conditions and k operators.\n(9.6)  There are instances of the Planning Problem with n conditions and k operators for which there\nexists a solution, but the shortest solution has length  2n-1. \n \nProof. We give a simple example of such an instance; it essentially encodes the task of incrementing\nan n-bit counter from the all-zeros state to the all-ones state.\nWe have conditions C1, C2, …, Cn.\nWe have operators \n i for i = 1, 2,…, n.\n1 has no prerequisites or delete list; it simply adds C1.\nFor i > 1, \ni requires Cj for all j < i as prerequisites. Whe n invoked, it adds Ci and delete s Cj\nfor all j < i.\nNow we ask: Is there a sequence of operators that will take us from \n 0 = φ to \n* = {C1,C2,…,Cn}?\nWe claim the following, by induction on i:\nFrom any configurat ion that does not contain Cj for any j ≤ i, there exists a sequence of\noperators that reaches a configuration containing Cj for all j ≤ i; but any such sequence has at\nleast  2i - 1 steps.\nThis is clearly true for i = 1. For lar ger i, here's one solution.\nBy induction, achieve conditions { Ci-1,…, C1} using operators \n 1, …, \n i-1.\nNow invoke operator \n i, adding Ci but deleting everything else.\nAgain, by induction, achieve conditions {Ci-1, …, C1 using operators \n 1,…, \n i-1. Note that\ncondition Ci is preserved throughout this process.\nNow we take care of the other part of the inductive step—that any such sequence requires at\nleast 2i — 1 steps. So consider the first moment when Ciis added. At this step, Ci-1,…, C1 must have\nbeen present, and by induction, this must have taken at least 2i-1 — 1 steps. Ci can only be added by"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 639})","('type', 'Document')"
"('page_content', ""i, which deletes all Cj for j < i. Now we have to achieve conditions {Ci-1,…, C1} again; this will\ntake another 2i-1 — 1 steps, by induction, for a total of at least 2(2i-1 — 1) + 1 = 2i - 1 steps.\nThe overall bound now follows by applying this claim with i = n . ▪\nOf cours e, if every “yes” instanc e of Planning had a polynomial-length\nsolution, then Planning would be in NP—we could just exhibit the solution.\nBut (9.6) shows that the shortest solution is not necessarily a good\ncertificate for a Planning instance, since it can have a length that is\nexponential in the input size.\nHowever , (9.6) describes essen tially the worst case, for we have the\nfollowing match ing upper bound. The graph \n  has 2n nodes, and if there is a\npath from \n0 to \n*, then the shorte st such path does not visit any node more\nthan once. As a result, the short est path can take at most 2n — 1 steps after\nleaving \n0.\n(9.7)  If a Planni ng instanc e with n conditions has a solution, then it has one using at most 2n - 1\nsteps.\n Designing the Algorithm\nWe've seen that the shortest solution to the Planning Problem may have\nlength exponential in n, which is bad news: After all, this means that in\npolynomial space, we can't even store an explicit representation of the\nsolution. But this fact doesn't necessarily close out our hopes of solving an\narbitrary instance of Planning using only polynomial space. It's possible that\nthere could be an algorithm that decides the answer to an instance of\nPlanning without ever being able to survey the entire solution at once.\nIn fact, we now show that this is the case: we design an algori thm to\nsolve Planning in polynomial space.\nSome Exponential Approaches  To get some intuition about this problem,\nwe first consider the following brute-force algorithm to solve the Planning\ninstance. We build the graph \n  and use any graph connectivity  algorithm—\ndepth-first search or breadth-first search—to decide whether there is a path\nfrom \n0 to \n*.\nOf course, this algorithm is too brute-force for our purposes; it takes\nexponential space just to construct the graph \n . We could try an approach in"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 640})","('type', 'Document')"
"('page_content', 'which we never actually build \n , and just simul ate the behavior of depth-\nfirst search or breadth-first search on it. But this likewise is not feasible.\nDepth-first search crucially requires us to maintain a list of all the nodes in\nthe current path we are explori ng, and this can grow to exponential size.\nBreadth-first requires a list of all nodes in the current “frontier” of the\nsearch, and this too can grow to exponential size.\nWe seem stuck. Our problem is transparently equivalent to finding a\npath in \n, and all the standard path-find ing algorithms we know are too\nlavish in their use of space. Could there really be a fundamenta lly different\npath-finding algorithm out there?\n\xa0\nA More Space-Ef ficient Way to Construct Paths  In fact, there  is a\nfundamentally different kind of path-finding algorithm, and it has just the\nproperties we need. The basic idea, proposed by Savitch in 1970, is a clever\nuse of the divide-and-conquer principle. It subsequently inspired the trick\nfor reducing the space requirements in the Sequence Alignment Problem; so\nthe overall approach may remind you of what we discussed there, in Section\n6.7. Our plan, as before, is to find a clever way to reuse space, admittedly at\nthe expense of increasing the time spent. Neither depth-first  search nor\nbreadth-first search is nearly aggressive enough in its reuse of space; both\nneed to maintain a large history at all times. We need a way to solve half the\nproblem, throw away almost all the intermediate work, and then solve the\nother half of the problem.\nThe key is a procedure that we will call Path(\n1, \n2,L). It determines\nwhether there is a sequence of operators, consisting of at most L steps,  that\nleads from confi guration \n1 to configuration \n2. So our initial problem is to\ndetermine the result (yes or no) of Path(\n0, \n*, 2n). Breadth-first search can\nbe view ed as the following dynamic programming implementa tion of this\nprocedure: To determine Path(\n1, \n2, L), we first determ ine all \n′ for which\nPath(\n1, \n′, L - 1) holds; we then see, for each such \n ′, whether any operator\nleads directly from \n ′ to \n2.\nThis indicates some of the wastefulness, in terms of space, that\nbreadth-first search entails. We are generating a huge number of\nintermediate configurations just to reduce the parameter L by one. More\neffective would be to try determining whether there is any configuration \n ′\nthat could serve as the midpoint  of a path from  \n1 to \n2. We could first')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 641})","('type', 'Document')"
"('page_content', 'generate all possible midpoints \n ′. For each \n ′, we then check recursively\nwhether we can get from \n1 to \n′ in at most L/2 steps; and also whether we\ncan get from \n ′ to \n2 in at most L/2 steps. This involves two recursive calls,\nbut we care only about the yes/no outcome of each; other than this, we can\nreuse space from one to the next.\nDoes this really reduce the space usage to a polynomial amount? We\nfirst write down  the procedure carefully , and then analyze it. We will think\nof L as a power of 2, which it is for our purposes.\nAgain, note that this procedure solves a generalization of our original\nquestion, which simply asked for Path(\n0, \n*, 2n). This does mean, however ,\nthat we should remember to view L as an exponentially large parameter: log\nL = n.\n Analyzing the Algorithm')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 642})","('type', 'Document')"
"('page_content', ""The following claim therefore implies that Planning can be solved in\npolynomial space.\n(9.8)  Path(\n 1, \n2, L) returns “yes” if and only if there is a sequence of operators of length at most L\nleading fr om \n1 to \n2. Its space usage is polynomial in n, k, and  log L.\n \nProof. The correctness follo ws by induction on L. It clearly holds when  L = 1, since all operators are\nconsidered explicitly . Now consider a larger value of L. If there is a sequence of operators from \n 1 to\n2, of length L′ ≤ L, then there is a configuration \n ′ that occurs at position ⌈L′/2 ⌉ in this sequence. By\ninduction, Path(\n 1, \n′, ⌈L/2 ⌉) and Path(\n ′, \n2, ⌈L/2 ⌉) will both return “yes,” and so Path(\n 1, \n2, L)\nwill return “yes.” Conversely , if there is a configuration \n ′ so that Path(\n 1, \n′, ⌈L/2 ⌉) and Path(\n ′, \n2,\n⌈L/2 ⌉) both return “yes,” then the inducti on hypothesis implies that there exist corresponding\nsequences of operators; concatenating these two sequences, we obtain a sequence of operators from \n1 to \n 2 of length at most L.\nNow we consider the space requirements. Aside from the space spent inside recursive calls, each\ninvocation of Path involves an amount of space polynomial in n, k, and log L. But at any given point\nin time, only a single recursive call is active, and the intermediate work from all other recursive calls\nhas been deleted. Thus, for a polynomial function p, the space requirement S(n, k, L) satisfies the\nrecurrence\nUnwinding the recurrence for O(log L) levels, we obtain the bound S(n,k,L ) = O(log L · p(n, k, log\nL)), which is a polynomial in n, k, and log L. ▪\nIf dynam ic programming has an opposite, this is it. Back when we\nwere solving problems by dynamic programming, the fundamental principle\nwas to save all the intermediate  work, so you don't have to recompute it.\nNow that conser ving space is our goal, we have just the opposite priorities:\nthrow away all the intermediate  work, since it's just taking up space and it\ncan always be recomputed.\nAs we saw when  we designed the space-ef ficient Sequence Alignment\nAlgorithm, the best strategy often lies somewhere in between, motivated by\nthese two approaches: throw away some of the intermediate work, but not\nso much that you blow up the running time.\n9.5 Proving Problems PSPACE-Complete"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 643})","('type', 'Document')"
"('page_content', ""When we studied NP, we had to prove a first problem NP-complete directly\nfrom the definition of NP. After Cook and Levin did this for Satisfiability ,\nmany other NP-complete problems could follow by reduction.\nA simila r sequence of events followed for PSPACE, shortly after the\nresults for NP. Recall that we defined PSPACE-completeness, by direct\nanalogy with NP-completeness, in Section 9.1. The natural analogue of\nCircuit Satisfiability and 3-SA T for PSPACE is played by QSA T, and\nStockmeyer and Meyer (1973) proved\n(9.9) QSAT is PSP ACE-complete.\nThis basic PSPACE-complete problem can then serve as a good “root”\nfrom which to discover other PSPACE-complete problems. By strict\nanalogy with the case of NP, it's easy to see from the definition that if a\nproblem Y is PSPACE-complete, and a problem X in PSPACE has the\nproperty that Y <P X, then X is PSP ACE-complete as well.\nOur goal in this section is to show an example of such a PSPACE-\ncompleteness proof, for the case of the Competitive Facility Location\nProblem; we will do this by reducing QSA T to Competit ive Facility\nLocation. In addition to establi shing the hardness of Competitive Facility\nLocation, the reduction also gives a sense for how one goes about showing\nPSPACE-completeness results for games in general, based on their close\nrelationship to quantifiers.\nWe note that Planning can also be shown to be PSPACE-complete by a\nreduction from QSA T, but we will not go through that proof here.\nRelating Quantifiers and Games\nIt is actually not surprising at all that there should be a close relation\nbetween quantifiers and games. Indeed, we could have equivalently defined\nQSA T as the problem of decidin g whether the first player has a forced win\nin the following Competitive 3-SA T game. Suppose we fix a formula Φ(x1,\n…, xn) consisting, as in QSA T, of a conjunction of length-3 clauses . Two\nplayers alternate  turns picking values for variables: the first player picks the\nvalue of x1, then the second player picks the value of x2, then the first player\npicks the value of x3, and so on. We will say that the first player wins if"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 644})","('type', 'Document')"
"('page_content', 'Φ(x1, …, xn) ends up evalua ting to 1, and the second player wins if it ends\nup evaluating to 0.\nWhen does the first player have a forced win in this game (i.e., when\ndoes our instance of Competitive 3-SA T have a yes answer)? Precisely\nwhen there is a choice for x1 so that for all choices of x2 there is a choice  for\nx3 so that … and so on, resulting in Φ(x1,…, xn) evaluating to 1. That is, the\nfirst player has a forced win if and only if (assuming n is an odd number)\nIn other words, our Competitiv e 3-SA T game is directly equiv alent to the\ninstance of QSA T defined by the same Boolean formula Φ, and so we have\nproved the following.\n(9.10) QSAT ≤P Competitive 3-SA T and Competitive 3-SA T <P QSA T.\nProving Competitive Facility Location is\nPSPACE-Complete\nStatement (9.10)  moves us into the world of games. We use this connection\nto establish the PSP ACE-completeness of Competitive Facility Location.\n(9.11) Competitive Facility Location is PSP ACE-complete.\n \nProof. We have already shown that Competitive Facility Location is in PSPACE. To prove it is\nPSPACE-complete, we now show that Competitive 3-SA T ≤P Competitive Facility Location.\nCombined with the fact that QSA T ≤P Competitive 3-SA T, this will show that QSA T ≤P Competitive\nFacility Location and hence will establish the PSP ACE-completeness result.\nWe are given an instance of Competitive 3-SA T, defined by a formula Φ. Φ is the conjunction of\nclauses\neach Cj has length 3 and can be written Cj = tj1 ∨ tj2 ∨ tj3. As before, we will assume that there is\nan odd number n of variables. We will also assume, quite naturally , that no clause contains both a\nterm and its negatio n; after all, such a clause would be automatically satisfie d by any truth')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 645})","('type', 'Document')"
"('page_content', ""assignment. We must show how to encode this Boolean structure in the graph that underlies\nCompetitive Facility Location.\nWe can picture the instance of Competitive 3-SA T as follows. The players alternately select\nvalues in a truth assignment, beginning and ending with Player 1; at the end, Player 2 has won if she\ncan select a clause Cj in which none of the terms has been set to 1. Player 1 has won if Player 2\ncannot do this.\nIt is this notion that we would like to encode in an instance of Competitive Facility Location:\nthat the players alternately make a fixed number of moves, in a highly constrained fashion, and then\nthere's a final chance by Player 2 to win the whole thing. But in its general form, Competitive\nFacility Location looks much more wide-o pen than this. Whereas the players in Com petitive 3-SA T\nmust set one variable at a time, in order , the players in Competitive Facility Locati on can jump all\nover the graph, choosing nodes wherever they want.\nOur fundamental trick, then, will be to use the values bi on the nodes to tightly constrain where\nthe players  can move, under any “reasonable” strategy . In other words, we will set things up so that if\nthe either of the players deviates from a particular narrow course, he or she will lose instantly .\nAs with our more complicated NP-completeness reductions in Chapter 8, the constr uction will\nhave gadgets to represent assignments to the variables, and further gadgets to repres ent the clauses.\nHere is how we encode the variables. For each variable xi, we define two nodes  vi, v′t in the graph G,\nand include an edge (vi, vi′), as in Figure 9.2. Selecting vi will represent setting xi = 1; selecting vi\nwill represent xi = 0. The constraint that the chosen variables must form an independent set naturally\nprevents both vi and v′i from being chosen. At this point, we do not define any other edges.\nFigur e 9.2  The reduction from Competitive 3-SA T to Competitive Facility Location.\nHow do we get the players to set the variables in order—first x1, then x2, and so forth? W e place\nvalues on v1 and v′1 so high that Player 1 will lose instantly if he does not choose them. We place\nsomewhat lower values on v2 and v′2, and contin ue in this way. Specifically , for a value c ≥ k  + 2, we\ndefine the node values bvi and bv′i to be c1+n-i. We defin e the bound that Player 2 is trying to\nachieve to be"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 646})","('type', 'Document')"
"('page_content', 'Let\'s pause, before worrying about the clauses, to consider the game played on this graph. In the\nopening move of the game, Player 1 must select one of V1 or v′1 (thereby obliterating the other one);\nfor if not, then Playe r 2 will immediately select one of them on her next move, winning instantly .\nSimilarly , in the second move of the game, Player 2 must select one of v2 or v′2. For otherwise,\nPlayer 1 will select one on his next move; and then, even if Player 2 acquired all the remaining nodes\nin the graph, she would not be able to meet the bound B. Continuing by induction in this way, we see\nthat to avoid an immediate loss, the player making the ith move  must select one of vi or v′i Note that\nour choice of node values has achieved precisely what we wanted: The players must set the variables\nin order . And what is the outcome on this graph? Player 2 ends up with a total of value of cn-1 +\nc""~3 + … + c2 = B - 1: she has lost by one unit!\nWe now complete the analogy with Competitive 3-SA T by giving Player 2 one final move on\nwhich she can try to win. For each clause Cj, we define  a node cj with value  bcj = 1 and an edge\nassociated with each of its terms as follows. If t = xi, we add an edge ( cj, vi); if t = \n , we add an edge\n(cj, vi). In other words, we join cj to the node that represents the term t.\nThis now defines the full graph G. We can verify that, because their values are so small, the\naddition of the clause nodes did not change the property that the players will begin by selecting the\nvariable nodes { vi, v′i} in the correct order . However , after this is done, Player 2 will win if and only\nif she can select a clause node cj that is not adjacent to any selected variabl e node—in other words, if\nand only the truth assignment defined alternately by the players failed to satisfy some clause.\nThus Player 2 can win the Competitive Facility Location instance we have defined if and only if\nshe can win the original Competitive 3-SA T instance. The reduction is complete. ▪\nSolved Exercises\nSolved Exercise 1\nSelf-avoiding walks  are a basic object of study in the area of statistical\nphysics; they can be defined as follows. Let L denote the set of all points in\nR2 with integer coordinates. (We can think of these as the “grid points” of\nthe plane.) A self-avoiding walk W of length n is a sequence of points\n(p1,p2, …,pn) drawn from L so that\n\xa0\n(i) p1 = (0, 0). ( The walk starts at the origin. )\n(ii) No two of the points are equal. ( The walk “avoids” itself. )\n(iii) For each i = 1, 2,…, n - 1, the points pi and pi+1 are at distance 1 from\neach other . (The walk moves between neighboring points in L. )')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 647})","('type', 'Document')"
"('page_content', 'Self-avoiding walks (in both two and three dimensions) are used in\nphysical chemistry as a simple geometric model for the possible\nconformations of long-chain polymer molecules. Such molecules can be\nviewed as a flexible chain of beads that flops around, adopting different\ngeometric layouts; self-avoiding walks are a simple combinatorial\nabstraction for these layouts.\nA famous unsolved problem in this area is the following. For a natural\nnumber n ≥ 1, let A(n) denote the number of distinct self-avoiding walks of\nlength n. Note that we view walks as sequences  of points rather than sets; so\ntwo walks can be distinct even if they pass through the same set of points,\nprovided that they do so in different orders. (Formally , the walks (p1,p2,\n…,pn) and (q1, q2,…, qn) are distinct if there is some i (1 ≤ i ≤ n) for which\npi ≠ qi.) See Figure 9.3 for an example. In polymer models based on self-\navoiding walks, A(n) is directly related to the entropy of a chain molecule,\nand so it appears in theories concerning the rates of certain metabolic and\norganic synthesis reactions.\nFigur e 9.3 Three distinct  self-avoiding walks of length 4. Note that\nalthough walks  (a) and (b) involve the same set of points, they are\nconsidered different walks because they pass through them in a different\norder .')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 648})","('type', 'Document')"
"('page_content', 'Despite its importance, no simpl e formula is known for the value A(n).\nIndeed, no algorithm is known for computing A(n) that runs in time\npolynomial in n.\n1. Show that A(n) ≥ 2n-1 for all natural numbers n ≥ 1.\n2. Give an algorith m that takes a number n as input, and outputs A(n) as a\nnumber in binary notation, using space (i.e., memory) that is\npolynomial in n.\n(Thus the runnin g time of your algorithm can be exponential, as long\nas its space usage is polynomial. Note also that polynomial  here means\n“polynomial in n,” not “polynom ial in log n.” Indee d, by part (a), we see\nthat it will take at least n - 1 bits to write the value of A(n), so clearly n - 1\nis a lower bound on the amount of space you need for produci ng a correct\nanswer .)')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 649})","('type', 'Document')"
"('page_content', ""Solution  We consider part (b) first. One's first thought is that enumerating\nall self-avoiding  walks sounds like a complicated prospect; it's natural to\nimagine the search as growing a chain starting from a single bead, exploring\npossible conform ations, and backtracking when there's no way to continue\ngrowing and remain self-avoiding. You can picture attenti on-grabbing\nscreen-savers that do things like this, but it seems a bit messy to write down\nexactly what the algorithm would be.\nSo we back up; polynomial space is a very generous bound, and we\ncan afford to take an even more brute-force approach. Suppose that instead\nof trying  just to enumerate all self-avoiding walks of length n, we simply\nenumerate all walks of length n, and then check which ones turn out to be\nself-avoiding. The advantage of this is that the space of all walks is much\neasier to describe than the space of self-avoiding walks.\nIndeed, any walk ( p1, p2, …, pn) on the set L of grid points in the plane\ncan be described  by the sequence of directions it takes. Each step from pi to\npi+1 in the walk can be viewed as moving in one of four directions: north,\nsouth, east, or west. Thus any walk of length n can be mapped to a distinct\nstring of length n - 1 over the alphabet {N, S, E, W}. (The three walks in\nFigure 9.3 would be ENW , NES, and EEN .) Each such string corresponds\nto a walk of length n, but not all such strings correspond to walks that are\nself-avoiding: for example, the walk NESW revisits the point (0, 0).\nWe can use this encoding of walks for part (b) of the question as\nfollows. Using a counter in base 4, we enumerate all strings of length n - 1\nover the alphabe t {N, S, E, W}, by viewing this alphabet equivalently as {0,\n1, 2, 3}. For each such string, we construct the corresponding walk and test,\nin polyn omial space, whether it is self-avoiding. Finally , we increment a\nsecond counter A (initialized to 0) if the current walk is self-avoiding. At\nthe end of this algorithm, A will hold the value of A(n).\nNow we can bound the space used by this algorithm as follow s. The\nfirst counter , which enumerates strings, has n - 1posi tions, each of which\nrequires two bits (since it can take four possible values). Similarly , the\nsecond counter holding A can be incremented at most 4n-1 times, and so it\ntoo needs at most 2n bits. Finally , we use polynomial space to check\nwhether each generated walk is self-avoiding, but we can reuse the same\nspace for each walk, and so the space needed for this is polynomial as well."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 650})","('type', 'Document')"
"('page_content', ""The encoding scheme also provides a way to answer part (a). We\nobserve that all walks that can be encoded using only the letters  {N, E} are\nself-avoiding, since they only move up and to the right in the plane. As\nthere are 2n-1 strings of length n - 1 over these two letters, there are at least\n2n-1 self-avoiding walks; in other words, A{n) > 2n-1.\n(Note that we argued earlier that our encoding technique also provides\nan upper bound, showing immediately that A(n) < 4n-1.)\nExercises\n1. Let's consider a special case of Quantified 3-SA T in which the\nunderlying Boolean formula has no negated variables. Specifically , let\nΦ(x1, …,xn) be a Boolean formula of the form  \n \nwhere each Ci is a disjunction of three terms. We say Φ is monotone  if\neach term in each clause consists of a nonnegated variable-that is, each\nterm is equal to xi, for some i, rather than \n . \nWe define Monotone QSA T to be the decision problem  \n \nwhere the formula Φ is monotone.  \nDo one of the following two things: (a) prove that Monotone QSAT is\nPSPACE-complete; or (b) give an algorithm to solve arbitrary\ninstances of Monotone QSA T that runs in time polynomial in n. (Note\nthat in (b), the goal is polynomial time,  not just polynomial space.)"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 651})","('type', 'Document')"
"('page_content', ""2. Consider the following word game, which we'll call Geography . You\nhave a set of names of places, like the capital cities of all the countries\nin the world. The first player begins the game by naming the capital\ncity c of the country the players are in; the second player must then\nchoose a city c′ that starts with the letter on which c ends; and the\ngame continues  in this way, with each player alternately choo sing a\ncity that starts with the letter on which the previous one ende d. The\nplayer who loses is the first one who cannot choose a city that hasn't\nbeen named earlier in the game.  \nFor example, a game played in Hungary would start with “Bud apest,”\nand then it could continue (for example), “Tokyo, Ottawa, Ankara,\nAmsterdam, Moscow , Washington, Nairobi.”  \nThis game is a good test of geographical knowledge, of course, but\neven with a list of the world's capitals sitting in front of you, it's also a\nmajor strategic challenge. Which word should you pick next, to try\nforcing your opponent into a situation where they'll be the one who's\nultimately stuck without a move?  \nTo highlight the strategic aspect, we define the following abstract\nversion of the game, which we call Geography on a Graph . Here, we\nhave a directed graph G = (V, E), and a designated start node s ∊ V.\nPlayers alternate  turns starting from s; each player must, if possible,\nfollow an edge out of the current node to a node that hasn't been\nvisited before. The player who loses is the first one who cannot move\nto a node that hasn't been visited earlier in the game. (There is a direct\nanalogy to Geography , with nodes corresponding to words.) In other\nwords, a player loses if the game is currently at node v, and for edges\nof the form ( v, w), the node w has already been visited.  \nProve that it is PSPACE-complete to decide whether the first player\ncan force a win in Geography on a Graph .\n3. Give a polynomial-time algorithm to decide whether a player has a\nforced win in Geography on a Graph , in the special case when the\nunderlying graph G has no directed cycles (in other words, when G is a\nDAG).\nNotes and Further Reading"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 652})","('type', 'Document')"
"('page_content', ""PSPACE is just one example of a class of intractable problems beyond NP;\ncharting the landscape of compu tational hardness is the goal of the field of\ncomplexity theory . There are a number of books that focus on complexity\ntheory; see, for example, Papadimitriou (1995) and Savage (1998).\nThe PSPACE-co mpleteness of QSA T is due to Stockmeyer and Meyer\n(1973).\nSome basic PSPACE-completeness results for two-player games can\nbe found in Schaefer (1978) and in Stockmeyer and Chandra (1979). The\nCompetitive Facility Location Problem that we consider here is a stylized\nexample of a class of problems studied within the broader area of facility\nlocation ; see, for example, the book edited by Drezner (1995) for surveys of\nthis topic.\nTwo-player games have provide d a steady source of difficult questions\nfor researchers in both mathematics and artificial intelligence. Berlekamp,\nConway , and Guy (1982) and Nowakowski (1998) discuss some of the\nmathematical questions in this area. The design of a world-champion-level\nchess program was for fifty years the foremost applied challenge problem in\nthe field of computer game-playing. Alan Turing is known to have worked\non devising algorithms to play chess, as did many leading  figures in\nartificial intelligence over the years. Newborn (1996) gives a readable\naccount of the history of work on this problem, covering the state of the art\nup to a year before IBM's Deep Blue finally achieved the goal of defeating\nthe human world champion in a match.\nPlanning is a fundamental problem in artificial intelligence; it features\nprominently in the text by Russe ll and Norvig (2002) and is the subject of a\nbook by Ghallab, Nau, and Traverso (2004). The argument that Planning\ncan be solved in polynomial space is due to Savitch (1970), who was\nconcerned with issues in complexity theory rather than the Planning\nProblem per se.\nNotes on the Exercises  Exercise 1 is based on a problem we learned from\nMaverick Woo and Ryan Williams; Exercise 2 is based on a result of\nThomas Schaefer ."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 653})","('type', 'Document')"
"('page_content', 'Chapter 10')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 654})","('type', 'Document')"
"('page_content', ""Extending the Limits of Tractability\n10.1 Finding Small V ertex Covers  \n10.2 Solving NP-Hard Pr oblems on T rees \n10.3 Coloring a Set of Cir cular Ar cs \n10.4 T ree Decompositions of Graphs  \n10.5 Constructing a T ree Decomposition  \nSolved Exer cises  \nExer cises  \nNotes and Further Reading\nAlthough we started the book by studying a number of techniques for\nsolving problems efficiently , we've been looking for a while at classes of\nproblems—NP-complete and PSPACE-complete problems—fo r which no\nefficient solution is believed to exist. And because of the insights we've\ngained this way, we've implici tly arrived at a two-pronged approach to\ndealing with new computational  problems we encounter: We try for a while\nto develop an efficient algorithm ; and if this fails, we then try to prove it\nNP-complete (or even PSPACE-complete). Assuming one of the two\napproaches work s out, you end up either with a solution to the problem (an\nalgorithm), or a potent “reason” for its difficulty: It is as hard as many of\nthe famous problems in computer science.\nUnfortunately , this strategy will only get you so far. If there is a\nproblem that people really want your help in solving, they won't be\nparticularly satisfied with the resolution that it's NP-hard1 and that they\nshould give up on it. They'll still want a solution that's as good as possible,\neven if it's not the exact, or optimal, answer . For example, in the\nIndependent Set Problem, even if we can't find the largest independent set\nin a graph, it's still natural to want to compute for as much time as we have\navailable, and output as lar ge an independent set as we can find.\nThe next few topics in the book  will be focused on different aspects of\nthis notion. In Chapters 11 and 12, we'll look at algorithms that provide\napproximate answers with guaranteed error bounds in polynomial time;"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 655})","('type', 'Document')"
"('page_content', ""we'll also consid er local search heuristics  that are often very effective in\npractice, even when we are not able to establish any provable guarantees\nabout their behavior .\nBut to start, we explore some situations in which one can exactly solve\ninstances of NP-complete problems with reasonable efficiency . How do\nthese situations arise? The point is to recall the basic message of NP-\ncompleteness: the worst-case instances of these problems are very difficult\nand not likely to be solvable in polynomial time. On a particular  instance,\nhowever , it's possible that we are not really in the “worst case”— maybe, in\nfact, the instance  we're looking at has some special structure that makes our\ntask easier . Thus the crux of this chapter is to look at situations in which it\nis possib le to quantify some precise senses in which an instance may be\neasier than the worst case, and to take advantage of these situations when\nthey occur .\nWe'll look at this principle in several concrete settings. First we'll\nconsider the Vertex Cover Problem, in which there are two natural “size”\nparameters for a problem instan ce: the size of the graph, and the size of the\nvertex cover being sought. The NP-completeness of Vertex Cover suggests\nthat we will have to be exponen tial in (at least) one of these parameters; but\njudiciously choosing which one can have an enormous effect on the running\ntime.\nNext we'll explore the idea that many NP-complete graph problems\nbecome polynom ial-time solvab le if we require the input to be a tree. This\nis a concrete illustration of the way in which an input with “special\nstructure” can help us avoid many of the dif ficulties that can make the worst\ncase intractable. Armed with this insight, one can generalize the notion of a\ntree to a more general class of graphs—those with small tree-width —and\nshow that many NP-complete problems are tractable on this more general\nclass as well.\nHaving said this, we should stress that our basic point remains the\nsame as it has always been: Exponential algorithms scale very badly . The\ncurrent chapter represents ways of staving off this problem that can be\neffective in various settings, but there is clearly no way around it in the\nfully general case. This will motivate our focus on approximation\nalgorithms and local search in subsequent chapters."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 656})","('type', 'Document')"
"('page_content', ""10.1 Finding Small Vertex Covers\nLet us briefly recall the Vertex Cover Problem, which we saw in Chapter 8\nwhen we covered NP-completeness. Given a graph G = (V, E) and an\ninteger k, we would like to find a vertex cover of size at most k—that is, a\nset of nodes S ⊆ V of size |S| ≤ k, such that every  edge e ⊆ E has at least\none end in S.\nLike many NP-complete decision problems, Vertex Cover comes with\ntwo parameters: n, the number of nodes in the graph, and k, the allowable\nsize of a vertex cover . This means that the range of possible running-time\nbounds is much richer , since it involves the interplay betwee n these two\nparameters.\n The Problem\nLet's consider this interaction between the parameters n and k more closely .\nFirst of all, we notice that if k is a fixed const ant (e.g., k = 2 or k = 3), then\nwe can solve Vertex Cover in polynomial time: We simply try all subsets of\nV of size k, and see whether  any of them constitute a vertex cover . There are\n(nk) subsets, and each takes time O(kn)  to check whether it is a vertex cover ,\nfor a total time of O(kn (n\nk)) = O(knk+1). So from this we see that the\nintractability of Vertex Cover only sets in for real once k grows as a\nfunction of n.\nHowever , even for moderately small values of k, a running time of\nO(knk+1) is quite  impractical. For examp le, if n = 1,000 and k = 10, then on\na computer executing a million high-level instructions per second, it would\ntake at least 1024 seconds  to decide if G has a k-node vertex cover—which\nis severa l orders of magnitude larger than the age of the universe. And this\nis for a small value of k, where the problem was supposed to be more\ntractable! It's natural to start asking whether we can do something that is\npractically viable when k is a small constant.\nIt turns out that a much better algorithm can be developed, with a\nrunning-time bound of O(2k · kn). There are two things worth noticing\nabout this. First, plugging in n = 1,000 and k = 10, we see that our computer\nshould be able to execute the algorithm in a few seconds. Second, we see\nthat as k grows, the running time is still increasing very rapidly; it's simply"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 657})","('type', 'Document')"
"('page_content', 'that the exponential dependence  on k has been move d out of the exponent\non n and into a separate function. From a practical point of view , this is\nmuch more appealing.\n Designing the Algorithm\nAs a first obser vation, we notice that if a graph has a small vertex cover ,\nthen it cannot have very many edges. Recall that the degree of a node is the\nnumber of edges that are incident to it.\n(10.1)  If G = (V, E) has n nodes, the maximum degree of any node is at most d, and there is a vertex\ncover of size at most k, then G has at most kd edges.\n \nProof. Let S be a vertex cover in G of size k′ ≤ k.  Every edge in G has at least one end in S; but each\nnode in S can cover at most d edges. Thus there can be at most k′d ≤ kd  edges in G. ▪\nSince the degree of any node in a graph can be at most n - 1, we have\nthe following simple consequence of (10.1).\n(10.2) If G = (V , E) has n nodes and a vertex cover of size k, then G has at most k(n  - 1) ≤ kn edges.\nSo, as a first step in our algorit hm, we can check if G contains more\nthan kn edges; if it does, then we know that the answer to the decision\nproblem—Is there a vertex cover of size at most k?—is no. Havin g done\nthis, we will assume that G contains at most kn edges.\nThe idea behind the algorithm is conceptually very clean. We begin by\nconsidering any edge e = (u, v) in G. In any k-node vertex cover S of G, one\nof u or v must belong to S. Suppose that u belongs to such a vertex cover S.\nThen if we delete u and all its incid ent edges, it must be possible to cover\nthe remaining edges by at most k - 1 nodes. That is, defining G–{u} to be\nthe graph obtained by deleting u and all its incid ent edges, there must be a\nvertex cover of size at most k - 1 in G–{u}. Similarly , if v belongs to S, this\nwould imply there is a vertex cover of size at most k - 1 in G–{v}.\nHere is a concrete way to formulate this idea.\n(10.3) Let e = (u, v) be any edge of G. The graph  G has a vertex cover of size at most k if and only if\nat least one of the graphs G–{u} and G–{v} has a vertex cover of size at most k  - 1.\n \nProof. First,  supp ose G has a verte x cover S of size at most k. Then S contains at least one of u or v;\nsuppose that it contains u. The set S–{u} must cover all edges that have neither end equal to u.\nTherefore S–{u} is a vertex cover of size at most k - 1 for the graph G–{u}.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 658})","('type', 'Document')"
"('page_content', 'Conversely , suppose that one of G–{u}  and G–{v} has a vertex cover of size at most k - 1—\nsuppose in particular that G–{u } has such a vertex cover T. Then the set T ∪ {u} covers all edges in\nG, so it is a vertex cover for G of size at most k. ▪\nStatement (10.3) directly establishes the correctness of the following\nrecursive algorithm for deciding whether G has a k-node vertex cover .\n Analyzing the Algorithm\nNow we bound the running time of this algorithm. Intuitively , we are\nsearching a “tree of possibilities”; we can picture the recursive execution of\nthe algorithm as giving rise to a tree, in which each node corresponds to a\ndifferent recursive call. A node corresponding to a recursive call with\nparameter k has, as children, two nodes corresponding to recursive calls\nwith parameter k - 1. Thus the tree has a total of at most 2k+1 nodes. In each\nrecursive call, we spend O(kn ) time.\nThus, we can prove the following.\n(10.4)  The running time of the Vertex Cover Algorithm on an n-node graph, with parameter k, is\nO(2k · kn).\nWe could also prove this by a recurrence as follows. If T(n, k ) denotes\nthe running time on an n-node graph with parameter k, then T(·, ·) satisfies\nthe following recurrence, for some absolute constant c:')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 659})","('type', 'Document')"
"('page_content', 'By induction on k ≥ 1, it is easy to prove that T(n, k) ≤ c · 2kkn. Indeed, if\nthis is true for k - 1, then\nIn summary , this algorithm is a powerful improvement on the simple\nbrute-force approach. However , no exponential algorithm can scale well for\nvery long, and that includes this one. Suppose we want to know whether\nthere is a vertex cover with at most 40 nodes, rather than 10; then, on the\nsame machine as before, our algorithm will take a significant  number of\nyears to terminate.\n10.2 Solving NP-Hard Problems on Trees\nIn Section 10.1  we designed an algorithm for the Vertex Cover Problem that\nworks well when the size of the desired vertex cover is not too large. We\nsaw that finding  a relatively small vertex cover is much easier than the\nVertex Cover Problem in its full generality .\nHere we consider special cases of NP-complete graph problems  with a\ndifferent flavor—not when the natural “size” parameters are small, but\nwhen the input graph is structurally “simple.” Perhaps the simplest types of\ngraphs are trees. Recall that an undirected graph is a tree if it is connected\nand has no cycle s. Not only are trees structurally easy to understand, but it\nhas been  found that many NP-hard graph problems can be solved efficiently\nwhen the underlying graph is a tree. At a qualitative level, the reason for\nthis is the following: If we consider a subtree of the input rooted at some\nnode v, the solution to the problem restricted to this subtree only “interacts”')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 660})","('type', 'Document')"
"('page_content', ""with the rest of the tree through v. Thus, by consi dering the different ways\nin which v might figure in the overall solution, we can essentially decoupl e\nthe problem in v's subtree from the problem in the rest of the tree.\nIt takes some amount of effort to make this general approach precise\nand to turn it into an efficient algorithm. Here we will see how to do this for\nvariants of the Independent Set Problem; however , it is importan t to keep in\nmind that this principle is quite general, and we could equally well have\nconsidered many other NP-complete graph problems on trees.\nFirst we will see that the Indepe ndent Set Problem itself can be solved\nby a greedy algorithm on a tree. Then we will consider the generalization\ncalled the Maximum-W eight Independent Set Problem , in which nodes have\nweight, and we seek an independent set of maximum weight. We'll see that\nthe Maximum-W eight Independent Set Problem can be solved on trees via\ndynamic program ming, using a fairly direct implementation of the intuition\ndescribed above.\nA Greedy Algorithm for Independent Set on Trees\nThe starting point of our greedy  algorithm on a tree is to conside r the way a\nsolution looks from the perspec tive of a single edge; this is a variant on an\nidea from Section 10.1 . Specifically , consider an edge e = (u, v) in G. In any\nindependent set S of G, at most one of u or v can belong to S. We'd like to\nfind an edge e for which we can greedily decide which of the two ends to\nplace in our independent set.\nFor this we exploit a crucial property of trees: Every tree has at least\none leaf—a node of degree 1. Consider a leaf v, and let (u, v) be the unique\nedge incident to v. How might we “greedily” evaluate the relative benefits\nof including u or v in our independent set S? If we include v, the only other\nnode that is directly “blocked” from joining the independent set is u. If we\ninclude u, it block s not only v but all the other nodes joined to u as well.  So\nif we're trying to maximize the size of the independent set, it seems that\nincluding v should be better than, or at least as good as, including u.\n(10.5)  If T = (V,E) is a tree and v is a leaf of the tree, then there exists a maximum-size independent\nset that contains v .\n \nProof. Consider a maximum-size independent set S, and let e = (u, v) be the unique edge incident to\nnode v. Clearly , at least one of u or v is in S; for if neither is present, then we could add v to S, thereby"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 661})","('type', 'Document')"
"('page_content', ""increasing its size. Now, if v ∊ S, then we are done; and if u ∊ S, then we can obtain another\nindependent set S′ of the same size by deleting u from S and inserting v. ▪\nWe will use (10.5) repeatedly to identify and delete nodes that can be\nplaced in the independent set. As we do this deletion, the tree T may\nbecome disconn ected. So, to handle things more cleanly , we actually\ndescribe our algorithm for the more general case in which the underlying\ngraph is a forest— a graph in which each connected component is a tree.\nWe can view the problem of finding a maximum-size independent set for a\nforest as really being the same as the problem for trees: an optim al solution\nfor a forest is simply the union of optimal solutions for each tree\ncomponent, and we can still use (10.5) to think about the problem in any\ncomponent.\nSpecifically , suppose we have a forest F; then (10.5) allows us to make\nour first decision in the following greedy way. Consider again an edge e =\n(u, v), where v is a leaf. We will include node v in our independent set S,\nand not include node u. Given this decision, we can delete the node v (since\nit's already been included) and the node u (since it cannot be included) and\nobtain a smaller  forest. We conti nue recursively on this smaller forest to get\na solution.\n(10.6)  The above algorithm finds a maximum-siz e independent set in forests (and hence in trees as\nwell).\nAlthough (10.5) was a very simple fact, it really represents an application of\none of the design principles for greedy algorithms that we saw in Chapter 4 :\nan exchange argument.  In particular , the crux of our Independent Set\nAlgorithm is the observation that any solution not containing a particular"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 662})","('type', 'Document')"
"('page_content', ""leaf can be “transformed” into a solution that is just as good and contains\nthe leaf.\nTo implement this algorithm so it runs quickly , we need to maintain\nthe current forest F in a way that allows us to find an edge incident to a leaf\nefficiently . It is not hard to implement this algorithm in linear time: We\nneed to maintain the forest in a way that allows us to do so on one iteration\nof the While loop in time proportional to the number of edges deleted when\nu and v are removed.\nThe Greedy Algorithm on More General Graphs  The greedy algorithm\nspecified above is not guaranteed to work on general graphs, because we\ncannot be guara nteed to find a leaf in every iteration. However , (10.5) does\napply to any graph: if we have an arbitrary graph G with an edge (u, v) such\nthat u is the only neighbor of v, then it's always safe to put v in the\nindependent set, delete u and v, and iterate on the smaller graph.\nSo if, by repeate dly deleting degree-1 nodes and their neighbors, we're\nable to eliminat e the entire graph, then we're guaranteed to have found an\nindependent set of maximum size—even if the original graph was not a\ntree. And even if we don't manage to eliminate the whole graph, we may\nstill succeed in running a few iterations of the algorithm in succession,\nthereby shrinking the size of the graph and making other appro aches more\ntractable. Thus our greedy algorithm is a useful heuristic to try\n“opportunistically” on arbitrary graphs, in the hope of maki ng progress\ntoward finding a lar ge independent set.\nMaximum-Weight Independent Set on Trees\nNext we turn to the more comp lex problem of finding a maxim um-weight\nindependent set. As before, we assume that our graph is a tree T = (V, E).\nNow we also have a positive weight wv associated with each node v ∊ V.\nThe Maximum-W eight Independent Set Problem  is to find an independent\nset S in the graph T = (V, E) so that the total weight ∑v ∊SWv is as large as\npossible.\nFirst we try the idea we used before to build a greedy solution for the\ncase without weights. Consider  an edge e = (u, v), such that v is a leaf.\nIncluding v blocks fewer nodes from entering the independent set; so, if the\nweight of v is at least as large as the weight of u, then we can indeed make a\ngreedy decision just as we did in the case without weights. However , if wv"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 663})","('type', 'Document')"
"('page_content', ""< wu, we face a dilemma: We acquire more weight by including u, but we\nretain more options down the road if we include v. There seems to be no\neasy way to resolve this locally , without considering the rest of the graph.\nHowever , there is still somethin g we can say. If node u has many neigh bors\nv1, v2, … that are leaves, then we should make the same decision for all of\nthem: Once we decide not to include u in the independent set, we may as\nwell go ahead and include all its adjacent leaves. So for the subtree\nconsisting of u and its adjacent leaves, we really have only two\n“reasonable” solutions to consider: including u, or including all the leaves.\nWe will use these ideas to design a polynomial-time algorithm  using\ndynamic progra mming. As we recall, dynamic programming allows us to\nrecord a few different solutions, build these up through a sequence of\nsubproblems, and thereby decide only at the end which of these possibilities\nwill be used in the overall solution.\nThe first issue to decide for a dynamic programming algorithm is what\nour subproblems will be. For Maximum-W eight Independent Set, we will\nconstruct subpro blems by rooting  the tree T at an arbitrary node r; recall\nthat this is the operation of “orienting” all the tree's edges away from r.\nSpecifically , for any node u ≠ r, the parent p(u) of u is the node adjacent to\nu along the path from the root r. The other neighbors of u are its children,\nand we will use childr en(u) to denote the set of children of u. The node u\nand all its descendants form a subtree Tu whose root is u.\nWe will base our subproblems on these subtrees Tu. The tree Tr is our\noriginal problem. If u ≠ r is a leaf, then Tu consists of a single node. For a\nnode u all of whose children are leaves, we observe that Tu is the kind of\nsubtree discussed above.\nTo solve the problem by dynamic programming, we will start at the\nleaves and gradually work our way up the tree. For a node u, we want to\nsolve the subproblem associated with the tree Tu after we have solved the\nsubproblems for all its children. To get a maximum-weight independent set\nS for the tree Tu, we will consider two cases: Either we include the node u\nin S or we do not. If we include u, then we cann ot include any of its\nchildren; if we do not include u, then we have the freedom to include or\nomit these children. This suggests that we should define two subproblems\nfor each subtree  Tu: the subproblem  OPTin(u) will denote the maximum"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 664})","('type', 'Document')"
"('page_content', ""weight of an independent set of Tu that includes u, and the subproblem\nOPTout(u) will denote the maximum weight of an independent set of Tu that\ndoes not include u.\nNow that we have our subproblems, it is not hard to see how to\ncompute these values recursivel y. For a leaf u ≠ r, we have OPTout(u) = 0\nand OPTin(u) = wu. For all other nodes u, we get the following recurrenc e\nthat defines OPTout(u) and OPTin(u) using the values for u's children.\n(10.7) For a node u that has childr en, the following r ecurr ence defines the values of the subpr oblems:\nOPT in(u) = \nOPT out(u) = \nUsing this recurrence, we get a dynamic programming algorithm by\nbuilding up the optimal solution s over larger and larger subtrees. We define\narrays Mout[u] and Min[u], which hold the values OPTout(u) and OPTin(u),\nrespectively . For building up solutions, we need to process all the children\nof a node before we process the node itself; in the terminol ogy of tree\ntraversal, we visit the nodes in post-or der."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 665})","('type', 'Document')"
"('page_content', ""This gives us the value of the maximum-weight independent set. Now ,\nas is standard in the dynamic programming algorithms we've seen before,\nit's easy to recover an actual independent set of maximum weight by\nrecording the decision we make for each node, and then tracing back\nthrough these decisions to determine which nodes should be included. Thus\nwe have\n(10.8) The above algorithm finds a maximum-weight independent set in tr ees in linear time.\n10.3 Coloring a Set of Circular Arcs\nSome years back, when telecommunications companies began focusing\nintensively on a technology known as wavelength-division multiplexing,\nresearchers at these companies developed a deep interest in a previously\nobscure algorithmic question: the problem of coloring a set of circular arcs.\nAfter explaining how the connection came about, we'll develop an\nalgorithm for this problem. The algorithm is a more complex variation on\nthe them e of Section 10.2: We approach a computationally hard problem\nusing dynamic programming,  building up solutions over a set of\nsubproblems that only “interact” with each other on very small pieces of the\ninput. Having to worry about only this very limited interaction serves to\ncontrol the complexity of the algorithm.\n The Problem\nLet's start with some backgroun d on how network routing issue s led to the\nquestion of circular -arc coloring. W avelength-division multiplexing (WDM)\nis a methodology that allows multiple communication streams to share a\nsingle portion of fiber-optic cable, provided that the streams are transmitted\non this cable using different wavelengths. Let's model the underlying\ncommunication network as a graph G = (V, E), with each communication\nstream consisti ng of a path Pi in G; we imagine data flowing along this\nstream from one endpoint of Pi to the other. If the paths Pi and Pj share\nsome edge in G, it is still possible to send data along these two streams\nsimultaneously as long as they are routed using different wavelengths.  So"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 666})","('type', 'Document')"
"('page_content', ""our goal is the following: Given a set of k availab le wave lengths (labeled\n1,2,…, k), we wish to assign a wavelength to each stream Pi in such a way\nthat each pair of streams that share an edge in the graph are assigned\ndifferent wavelengths. We'll refer to this as an instance of the Path Coloring\nProblem,  and we'll call a solution to this instance—a legal assignment  of\nwavelengths to paths—a k-coloring.\nThis is a natural  problem that we could consider as it stands; but from\nthe point of view  of the fiber-optic routing context, it is useful to make one\nfurther simplification. Many applications of WDM take place on networks\nG that are extrem ely simple in structure, and so it is natural to restrict the\ninstances of Path Coloring by making some assumptions about this\nunderlying netw ork structure. In fact, one of the most impor tant special\ncases in practice  is also one of the simplest: when the underlying network is\nsimply a ring; that is, it can be modeled using a graph G that is a cycle on n\nnodes.\nThis is the case we will focus on here: We are given a graph G = (V, E)\nthat is a cycle on n nodes, and we are given a set of paths P1,…, Pm on this\ncycle. The goal, as above, is to assign one of k given wavelengths to each\npath Pi so that overlapping paths receive different wavelengths. We will\nrefer to this as a valid  assignment of wavelengths to the paths. Figure 10.1\nshows a sample  instance of this problem. In this instance, there is a valid\nassignment using k = 3 wavelengths, by assigning wavelength 1 to the paths\na and e, wavelength 2 to the paths b and f, and wavelength 3 to the paths c\nand d. From the figure, we see that the underlying cycle network can be\nviewed as a circle, and the paths as arcs on this circle; hence we will refer to\nthis special case of Path Coloring as the Circular -Arc Coloring Pr oblem .\nFigur e 10.1  An insta nce of the Circular -Arc Coloring Problem with six arcs\n(a, b, c, d, e, f ) on a four -node cycle."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 667})","('type', 'Document')"
"('page_content', ""The Complexity of Circular-Arc Coloring  It's not hard to see that Circular -\nArc Coloring can be directly reduced to Graph Coloring. Given  an instance\nof Circu lar-Arc Coloring, we define a graph H that has a node zi for each\npath Pi, and we connect nodes zi and zj in H if the paths Pi and Pj share an\nedge in G. Now, routing all streams using k wavelengths is simply the\nproblem of coloring H using at most k colors. (In fact, this problem is yet\nanother applicat ion of graph coloring in which the abstract “colors,” since\nthey encode dif ferent wavelengths of light, are actually colors.)\nNote that this doesn't imply that Circular -Arc Coloring is NP-co mplete\n— all we've done is to reduce it to a know n NP-co mplete problem, which\ndoesn't tell us anything about its difficulty . For Path Coloring  on general\ngraphs, in fact, it is easy to reduce from Graph Coloring to Path Coloring,\nthereby establishing that Path Coloring is NP-complete. However , this\nstraightforward reduction does not work when the underlying graph is as\nsimple as a cycle. So what is the complexity of Circular -Arc Coloring?"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 668})","('type', 'Document')"
"('page_content', ""It turns out that Circular -Arc Coloring can be shown to be NP-\ncomplete using a very complica ted reduction. This is bad news for people\nworking with optical networks, since it means that optimal wavelength\nassignment is unlikely to be efficiently solvable. But, in fact, the known\nreductions that show Circular -Arc Coloring is NP-complete all have the\nfollowing interesting property: The hard instances of Circular -Arc Coloring\nthat they produc e all involve a set of available wavelengths that is quite\nlarge. So, in particular , these reductions don't show that the Circular -Arc\nColoring is hard in the case when the number of wavelengths is small; they\nleave open the possibility that for every fixed, constant  number of\nwavelengths k, it is possible to solve the wavelength assignment problem in\ntime polynomial in n (the size of the cycle) and m (the number of paths). In\nother words, we could hope for a running time of the form we saw for\nVertex Cover in Section 10.1 : O(f(k) · p(n, m)), where f(·) may be a rapidly\ngrowing function but p(·, ·) is a polynomial.\nSuch a running time would be appealing (assuming f(·) does not grow\ntoo outrageously), since it would make wavelength assignment potentially\nfeasible when the number of wavelengths is small. One way to appreciate\nthe challenge in obtaining such a running time is to note the following\nanalogy: The general Graph Coloring Problem is already hard for three\ncolors. So if Circular -Arc Coloring were tractable for each fixed  number of\nwavelengths (i.e., colors) k, it would  show that it's a special case of Graph\nColoring with a qualitatively dif ferent complexity .\nThe goal of this section is to design an algorithm with this type of\nrunning time, O(f(k)·p(n,m)).  As suggested at the beginning of the section,\nthe algorithm itself builds on the intuition we developed in Section 10.2\nwhen solving Maximum-W eight Independent Set on trees. There the\ndifficult search inherent in finding a maximum-weight independent set was\nmade tractable by the fact that for each node v in a tree T, the problems in\nthe components of T - {v} became completely decoupled once we decided\nwhether or not to include v in the independent set. This is a specific\nexample of the general principle of fixing a small set of decisions, and\nthereby separati ng the problem into smaller subproblems that can be dealt\nwith independently .\nThe analogous idea here will be to choose a particular point on the\ncycle and decide how to color the arcs that cross over this point; fixing"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 669})","('type', 'Document')"
"('page_content', ""these degrees of freedom allows  us to define a series of smaller and smaller\nsubproblems on the remaining arcs.\n Designing the Algorithm\nLet's pin down some notation we're going to use. We have a graph G that is\na cycle on n nodes; we denote the nodes by v1, v2, …, vn, and there is an\nedge (vi, vi+1) for each i, and also an edge (vn, v1). We have a set of paths\nP1, P2, …, Pm in G, we have a set of k available colors; we want to color the\npaths so that if Pi and Pj share an edge, they receive dif ferent colors.\nA Simple Special Case: Inter val Coloring  In order to build up to an\nalgorithm for Circular -Arc Coloring, we first briefly conside r an easier\ncoloring problem : the problem of coloring intervals on a line. This can be\nviewed as a special case of Circular-Arc Coloring in which the arcs lie only\nin one hemisphere; we will see that once we do not have difficulties from\narcs “wrapping around,” the problem becomes much simpler . So in this\nspecial case, we are given a set of intervals, and we must label each one\nwith a number in such a way that any two overlapping intervals receive\ndifferent labels.\nWe have actually seen exactly this problem before: It is the Interval\nPartitioning (or Interval Colorin g) Problem for which we gave  an optimal\ngreedy algorithm at the end of Section 4.1 . In addition to showing that there\nis an efficient, optimal algorithm for coloring intervals, our analysis in that\nearlier section revealed a lot about the structure of the problem.\nSpecifically , if we define the depth  of a set of intervals to be the maximum\nnumber that pass over any single point, then our greedy algorithm from\nChapter 4 showed  that the minimum number of colors needed is always\nequal to the depth. Note that the number of colors required is clearly at least\nthe depth, since intervals contai ning a common point need different colors;\nthe key here is that one never needs a number of colors that is greater than\nthe depth.\nIt is interesting that this exact  relationship between the number of\ncolors and the depth does not hold for collections of arcs on a circle. In\nFigure 10.2 , for example, we see a collection of circular arcs that has depth\n2 but needs three colors. This is a basic reflection of the fact that in trying to\ncolor a collectio n of circular arcs, one encounters “long-range” obstacles\nthat render the problem much more complex than the coloring problem for"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 670})","('type', 'Document')"
"('page_content', 'intervals on a line. Despite this, we will see that thinking about the simpler\nproblem of coloring intervals will be useful in designing our algorithm for\nCircular -Arc Coloring.\nTransforming to an Interval Coloring Problem  We now retur n to the\nCircular -Arc Coloring Problem. For now, we will consider a special case of\nthe problem in which, for each edge e of the cycle, there are exactly k paths\nthat contain e. We will call this the uniform-depth  case. It turns out that\nalthough this special case may seem fairly restricted, it contains essentially\nthe whole complexity of the problem; once we have an algorithm for the\nuniform-depth case, it will be easy to translate this to an algor ithm for the\nproblem in general.\nFigur e 10.2  A collection of circular arcs needing three colors, even though\nat most two arcs pass over any point of the circle.\nThe first step in designing an algorithm will be to transform the\ninstance into a modified form of Interval Coloring: We “cut” the cycle by\nslicing through the edge (vn, v1), and then “unroll” the cycle into a path G′.\nThis process is illustrated in Figure 10.3. The sliced-and-unrolled graph G′\nhas the same nodes as G, plus two extra ones where the slicing occurred: a\nnode v0 adjacent to v1 (and no other nodes), and a node vn+1 adjacent to vn\n(and no other nodes). Also, the set of paths has changed slight ly. Suppose\nthat P1,P2, …,Pk are the paths that contained the edge (vn, v1) in G. Each of')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 671})","('type', 'Document')"
"('page_content', ""these paths Pi has now been sliced into two, one that we'll label P′t (starting\nat v0) and one that we'll label P″i (ending at vn+1).\nNow this is an instance of Interval Coloring, and it has depth k. Thus,\nfollowing our discussion above about the relation between depth and colors,\nwe see that the intervals\ncan be colored using k colors. So are we done? Can we just translate this\nsolution into a solution for the paths on G?\nIn fact, this is not so easy; the problem is that our interval coloring\nmay well not have given the paths P′t and P″i the same color . Since these\nare two pieces of the same path Pi on G, it's not clear how to take the\ndiffering colors of P′i and P″i and infer from this how to color Pi on G. For\nexample, having  sliced open the cycle in Figure 10.3(a) , we get the set of\nintervals picture d in Figure 10.3(b) . Suppose we compute a coloring so that\nthe intervals in the first row get the color 1, those in the second row get the\ncolor 2, and those in the third row get the color 3. Then we don't have an\nobvious way to figure out a color for a and c.\nFigur e 10.3 (a) Cutting through the cycle in an instance of Circular -Arc\nColoring, and then unrolling it so it becomes, in (b), a collection of intervals\non a line."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 672})","('type', 'Document')"
"('page_content', ""This suggests a way to formaliz e the relationship between the instance\nof Circular -Arc Coloring in G and the instance of Interval Coloring in G′.\n(10.9)  The paths in G can be k-color ed if and only if the paths in G can be k-color ed subject to the\nadditional r estriction that P′ i and P″ i receive the same color , for each i  = 1, 2, …, k.\n \nProof. If the paths in G can be k-colored, then we simply use these as the colors in G′, assigning each\nof P′i and P″i the color of Pi. In the resulting coloring, no two paths with the same color have an\nedge in common.\nConversely , suppose the paths in G′ can be k-colored subject to the additional restrictio n that P′i\nand P″i receive the same color , for each i = 1,2,…, k. Then  we assign path Pi (for i ≤ k) the common\ncolor of P′i and P″i; and we assign path Pj (for j > k) the color that Pj gets in G′. Again, under this\ncoloring, no two paths with the same color have an edge in common. ▪\nWe've now transformed our problem into a search for a coloring of the\npaths in G′ subject to the condition in (10.9): The paths P′i and P″i (for 1 ≤ i\n≤ k) should get the same color ."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 673})","('type', 'Document')"
"('page_content', ""Before proceeding, we introduce some further terminology that makes\nit easier to talk about algorithms for this problem. First, since the names of\nthe colors are arbitrary , we can assume that path P′i is assig ned the color i\nfor each i = 1, 2,…, k. Now, for each edge ei = (vi, vi+1), we let Si denote the\nset of paths that contain this edge. A k-coloring of just the paths in Si has a\nvery simple structure: it is simply a way of assigning exactly  one of the\ncolors {1,2,…, k} to each of the k paths in Si. We will think of such a k-\ncoloring as a one-to-one function f : Si → {1, 2,…, k}.\nHere's the crucial definition: We say that a k-coloring f of Si and a k-\ncoloring g of Sj are consistent  if there is a single k-coloring of all the paths\nthat is equal to f on Si, and also equal to g on Sj. In other words, the k-\ncolorings f and g on restricted parts of the instance could both arise from a\nsingle k-coloring of the whole instance.  We can state our problem in terms\nof consi stency as follows: If f′ denotes  the k-coloring of S0 that assigns\ncolor i to P′i, and f″ denotes the k-coloring of Sn that assigns color i to P″i,\nthen we need to decide whether f′ and f″ are consistent.\n\xa0\nSearching for an Acceptable Interval Coloring  It is not clear  how to\ndecide the consistency of f′ and f″ directly . Instea d, we adopt a dynamic\nprogramming approach by building up the solution through a series of\nsubproblems.\nThe subproblems are as follows: For each set Si, working in order over\ni = 0,1, 2, …, n, we will compute the set Fi of all k-colorings on Si that are\nconsistent with f′. Once we have computed Fn, we need  only check whether\nit contains f″ in order to answer our overall question: whether f′ and f″ are\nconsistent.\nTo start the algorithm, we define F0 = {f′}: Since f′ determines a color\nfor every interval in S0, clearly no other k-coloring of S0 can be consistent\nwith it. Now suppose we have computed F0,F1, …, Fi; we show how to\ncompute Fi+1 from Fi.\nRecall that Si consists of the paths containing the edge ei = (vi, vi+1),\nand Si+1 consists of the paths containing the next consecutive edge ei+1 =\n(vi+1, vi+2). The paths in Si and Si+1 can be divided into three types:"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 674})","('type', 'Document')"
"('page_content', 'Those that contain both ei and ei+1. These lie in both Si and Si+1.\nThose that end at node vi+1. These lie in Si but not Si+1.\nThose that begin at node vi+1. These lie in Si+1 but not Si.\nNow , for any coloring f ∊ Fi, we say that a coloring g of Si+1 is an\nextension  of f if all the paths in Si ∩ Si+1 have the same colors with respect\nto f and g. It is easy to check that if g is an extension of f, and f is consistent\nwith f, then so is g. On the other hand, suppose some coloring g of Si+1 is\nconsistent with f′; in other words, there is a coloring h of all paths that is\nequal to f′ on S0 and is equal to g on Si+1. Then, if we consider the colors\nassigned by h to paths in Si, we get a coloring f ∊ Fi, and g is an extension\nof f.\nThis proves the following fact.\n(10.10) The set F i+1 is equal to the set of all extensions of k-colorings in F i.\nSo, in order to compute Fi+1, we simply need to list all extensions of\nall color ings in Fi. For each f ∊ Fi, this means that we want a list of all\ncolorings g of Si+1 that agree with f on Si ∩ Si+1. To do this, we simply list\nall possible ways of assigning the colors of Si — Si+1 (with respect to f) to\nthe paths in Si+1—Si. Mer ging these lists for all f ∊ Fi then gives us Fi+1.\nThus the overall algorithm is as follows.\nFigure 10.4 shows the results of executi ng this algorithm on the\nexample of Figure 10.3. As with all the dynamic programming algorithms')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 675})","('type', 'Document')"
"('page_content', 'we have seen in this book, the actual coloring can be computed  by tracing\nback through the steps that built up the sets F1, F2,…, Fn.\nFigur e 10.4 The execution of the coloring algorithm. The initial coloring f\nassigns color 1 to a′, color 2 to b′, and color 3 to c′. Above each edge ei (for\ni > 0) is a table representing the set of all consistent colorings in Fi: Each\ncoloring is represented by one of the columns in the table. Since the\ncoloring f″(a″) = 1, f″(b″) = 2, and f″(c″) = 3 appears in the final table, there\nis a solution to this instance.\nWe will discuss the running time of this algorithm in a moment . First,\nhowever , we show how to remove the assumption that the input instance\nhas uniform depth.\n\xa0\nRemoving the Uniform-Depth Assumption  Recall that the algorithm we\njust designed assumes that for each edge e, exactly k paths contain e. In\ngeneral, each edge may carry a different number of paths, up to a maximum\nof k. (If there were an edge contained in k + 1 paths, then all these paths\nwould need a different color , and so we could immediately conclude that\nthe input instance is not colorable with k colors.)\nIt is not hard to modify the algorithm directly to handle the general\ncase, but it is also easy to reduce the general case to the uniform-depth case.\nFor each edge ei that carries only ki < k paths, we add k - ki paths that\nconsist only of the single edge ei. We now have a uniform-depth  instance,\nand we claim\n(10.1 1) The original instance can be color ed with k colors if and only if the modified instance\n(obtained by adding single-edge paths) can be color ed with k colors.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 676})","('type', 'Document')"
"('page_content', 'Proof. Clearly , if the modified instance has a k-coloring, then we can use this same k-coloring for the\noriginal instance (simply ignoring the colors it assigns to the single-edge paths that we added).\nConversely , suppose the original instance has a k-coloring f. Then we can constr uct a k-coloring of\nthe modified instance by starting with f and considering the extra single-edge paths one at a time,\nassigning any free color to each of these paths as we consider them. ▪\n Analyzing the Algorithm\nFinally , we bound the running time of the algorithm. This is dominated by\nthe time to compute the sets F1, F2,…, Fn. To build one of these sets Fi+1,\nwe need  to consider each coloring f ∊ Fi, and list all permutations of the\ncolors that f assigns to paths  in Si — Si+1. Since Si has k paths, the numb er\nof colorings in Fi is at most k!. Listing all permutations of the colors that f\nassigns to Si — Si+1 also involves enumerating a set of size ℓ!, where ℓ ≤ k\nis the size of Si—Si+1.\nThus the total time to compute Fi+1 from one Fi has the form O(f(k) )\nfor a function f(·) that depends only on k. Over the n iterations of the outer\nloop to compute  F1, F2, …, Fn, this gives a total running time of O(f(k) · n),\nas desired.\nThis concludes the description and analysis of the algorithm. We\nsummarize its properties in the following statement.\n(10.12)  The algorithm described in this section correctly determines whether a collection of paths on\nan n-node cycle can be color ed with k colors, and its running time is O(f(k) · n) for a function f(·) that\ndepends only on k.\nLooking back on it, then, we see that the running time of the algorithm\ncame from the intuition we described at the beginning of the section: For\neach i, the subproblems based on computing Fi and Fi+1 fit together along\nthe “narrow” interface consistin g of the paths in just Si and Si+1, each of\nwhich has size at most k. Thus the time needed to go from one to the other\ncould be made to depend only on k, and not on the size of the cycle G or on\nthe number of paths.\n* 10.4 Tree Decompositions of Graphs')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 677})","('type', 'Document')"
"('page_content', ""In the previous two sections, we've seen how particular NP-hard problems\n(specifically , Maximum-W eight  Independent Set and Graph Coloring) can\nbe solved when the input has a restricted structure. When you find yourself\nin this situation—able to solve  an NP-complete problem in a reasonably\nnatural special case—it's worth  asking why the approach doesn't work in\ngeneral. As we discussed in Sections 10.2 and 10.3, our algorithms in both\ncases were taking advantage of a particular kind of structure: the fact that\nthe input could be broken down into subproblems with very limited\ninteraction.\nFor exam ple, to solve Maximum-W eight Independent Set on a tree, we\ntook advantage of a special property of (rooted) trees: Once we decide\nwhether or not to include a node u in the independent set, the subp roblems\nin each subtree become completely separated; we can solve each as though\nthe others did not exist. We don't encounter such a nice situation in general\ngraphs, where there might not be a node that “breaks the communication”\nbetween subproblems in the rest of the graph. Rather , for the Independent\nSet Prob lem in general graphs,  decisions we make in one place seem to\nhave complex repercussions all across the graph.\nSo we can ask a weaker version of our question instead: For how\ngeneral a class of graphs can we use this notion of “limited interaction”—\nrecursively chop ping up the input using small sets of nodes —to design\nefficient algorithms for a problem like Maximum-W eight Independent Set?\nIn fact, there is a natural and rich class of graphs that supports this type\nof algor ithm; they are essentially “generalized trees,” and for reasons that\nwill become clear shortly , we will refer to them as graphs of bounded tree-\nwidth . Just as with trees, many NP-complete problems are tractab le on\ngraphs of bounded tree-width; and the class of graphs of bounded tree-\nwidth turns out to have consider able practical value, since it includes many\nreal-world netw orks on which NP-complete graph problems arise. So, in a\nsense, this type of graph serve s as a nice example of finding the “right”\nspecial case of a problem that simultaneously allows for ef ficient algorithms\nand also includes graphs that arise in practice.\nIn this section, we define tree-width and give the general appro ach for\nsolving problem s on graphs of bounded tree-width. In the next section, we\ndiscuss how to tell whether a given graph has bounded tree-width.\nDefining Tree-Width"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 678})","('type', 'Document')"
"('page_content', ""We now give a precise definitio n for this class of graphs that is designed to\ngeneralize trees. The definition is motivated by two considerations. First,\nwe want to find graphs that we can decompose into disconnected pieces by\nremoving a small number of nodes; this allows us to impleme nt dynamic\nprogramming algorithms of the type we discussed earlier . Second, we want\nto make  precise the intuition conveyed by “tree-like” drawings of graphs as\nin Figure 10.5(b) .\nWe want to claim that the graph G pictured in this figure is\ndecomposable in a tree-like way, along the lines that we've been\nconsidering. If we were to encounter G as it is drawn in Figure 10.5(a) , it\nmight not be immediately clear why this is so. In the drawing in Figure\n10.5(b) , howev er, we see that G is really composed of ten interlocking\ntriangles; and seven of the ten triangles have the property that if we delete\nthem, then the remainder of G falls apart into disconnected pieces that\nrecursively have this interlocking-triangle structure. The other three\ntriangles are attached at the extremities, and deleting them is sort of like\ndeleting the leaves of a tree.\nFigur e 10.5 Parts (a) and (b) depict the same graph drawn in different\nways. The drawing in (b) emph asizes the way in which it is composed of\nten interlocking triangles. Part (c) illustrates schematically how these ten\ntriangles “fit together .”\nSo G is tree-like if we view it not as being composed of twelve node s,\nas we usually would, but instead as being composed of ten triangles.\nAlthough G clearly contains many cycles, it seems, intuitively , to lack\ncycles when viewed at the level  of these ten triangles; and based on this, it\ninherits many of the nice decomposition properties of a tree."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 679})","('type', 'Document')"
"('page_content', ""We will want to represent the tree-like structure of these triangles by\nhaving each triangle correspond to a node in a tree, as show n in Figure\n10.5(c) . Intuitiv ely, the tree in this figure corresponds to this graph, with\neach node of the tree representing one of the triangles. Notice, however , that\nthe same nodes of the graph occur in multiple triangles, even in triangles\nthat are not adjacent in the tree structure; and there are edges between nodes\nin triangles very far away in the tree-structure—for example, the central\ntriangle has edges to nodes in every other triangle. How can we make the\ncorrespondence between the tree and the graph precise? We do this by\nintroducing the idea of a tree decomposition  of a graph G, so named\nbecause we will seek to decompose G according to a tree-like pattern.\nFormally , a tree decomposition of G = (V, E) consists of a tree T (on a\ndifferent node set from G), and a subset Vt ⊆V associated with each node t\nof T. (We will call these subsets Vt the “pieces” of the tree decomposition.)\nWe will sometim es write this as the ordered pair (T, {Vt : t ∊  T}). The tree\nT and the collecti on of pieces {Vt : t ∊ T} must satisfy the following three\nproperties.\n(Node Coverage ) Every node of G belongs to at least one piece Vt.\n(Edge Coverage ) For every edge e of G, there is some piece Vt\ncontaining both ends of e.\n(Coher ence) Let t1, t2, and t3 be three nodes of T such that t2 lies on the\npath from t1 to t3. Then, if a node v of G belongs to both Vt1 and Vt3, it\nalso belongs to Vt2.\nIt's worth checking that the tree in Figure 10.5(c)  is a tree decomposition of\nthe graph using the ten triangles as the pieces.\nNext consider the case when the graph G is a tree. We can build a tree\ndecomposition of it as follows. The decomposition tree T has a node tv for\neach node v of G, and a node te for each edge e of G. The tree T has an edge\n(tv, te) when v is an end of e. Finally, if v is a node, then we define the piece\nVtv = {v}; and if e = (u, v) is an edge, then we define the piece Vte = {u, v}.\nOne can now check that the three properties in the definition of a tree\ndecomposition are satisfied."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 680})","('type', 'Document')"
"('page_content', 'Properties of a Tree Decomposition\nIf we consider the definition more closely , we see that the Node Coverage\nand Edge Coverage Properties simply ensure that the collectio n of pieces\ncorresponds to the graph G in a minimal way. The crux of the definition is\nin the Coherenc e Property . While it is not obvious from its statement that\nCoherence leads to tree-like separation properties, in fact it does so quite\nnaturally . Trees have two nice separation properties, closely related to each\nother , that get used all the time. One says that if we delete an edge e from a\ntree, it falls apart into exactly two connected components. The other says\nthat if we delete a node t from a tree, then this is like deleting all the\nincident edges, and so the tree falls apart into a number of components\nequal to the degree of t. The Coherence Property is designed to guarantee\nthat separations of T, of both these types, corre spond naturally to\nseparations of G as well.\nIf T is a subgraph of T, we use GT′ to denote the subgraph of G induced\nby the nodes in all pieces associated with nodes of T′, that is, the set\n∪t ∊T′Vt.\nFirst consider deleting a node t of T.\n(10.13) Suppose that T -t has components T 1,…, Td. Then the subgraphs\nhave no nodes in common, and ther e are no edges between them.\n \nProof. We refer to Figure 10.6 for a general view of what the separation looks like. We first prove\nthat the subgraphs GTi—Vt do not share any nodes. Indeed, any such node v woul d need to belong to\nboth GTi—Vt and GTj—Vt for some i ≠ j, and so such a node v belongs to some piece Vx with x ∊ Tt,\nand to some piece Vy with y ∊ Tj. Since t lies on the x-y path in T, it follows  from the Coherence\nProperty that v lies in Vt and hence belongs to neither GTi—Vt nor GTj—Vt.\nNext we must show that there is no edge e = (u , v) in G with one end u in subgrap h GTi—Vt and\nthe other end v in GTj—Vt for some j ≠ i. If there were such an edge, then by the Edge Coverage\nProperty , there would need to be some piece Vx containing both u and v. The node x cannot be in both\nthe subgraphs Ti and Tj. Suppose by symmetry x ∉ Ti. Node u is in the subgraph GTi, so u must be')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 681})","('type', 'Document')"
"('page_content', ""in a set Vy for some y in Ti. Then the node u belongs to both Vx and Vy, and since t lies on the x-y\npath in T, it follows that u also belongs to Vt, and so it does not lie in GTi — V t as required. ▪\nFigur e 10.6 Separations of the tree T translate to separations of the graph\nG.\nProving the edge separation property is analogous. If we delete an\nedge (x,y) from T, then T falls apart into two components: X, containing x,\nand Y, containing y. Let's establish the corresponding way in which G is\nseparated by this operation.\nFigur e 10.7 Deleting an edge of the tree T translates to separation of the\ngraph G."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 682})","('type', 'Document')"
"('page_content', ""(10.14)  Let X and Y be the two components of T after the deletion of the edge (x,y). Then deleting the\nset V x ∩ Vy from V disconnects G into the two subgraphs GX—(Vx ∩ Vy) and GY—(Vx ∩ Vy) More\nprecisely , these two subgraphs do not share any nodes, and there is no edge with one end in each of\nthem.\n \nProof. We refer to Figure 10.7  for a general view of what the separation looks like. The proof of this\nproperty is analogous to the proof of (10.13 ). One first proves that the two subgraphs GX—(Vx ∩ Vy)\nand GY—(Vx ∩ Vy) do not share any nodes, by showing that a node v that belongs to both GX and\nGY must  belong to both Vx and to Vy, and hence  it does not lie in either GY—(Vx ∩ Vy) or GX—(Vx\n∩ Vy).\nNow we must show that there is no edge e = (u,v) in G with one end u in GX—(Vx ∩ Vy) and\nthe other end v in GY — (Vx ∩ Vy). If there were such an edge, then by the Edge Coverage Property ,\nthere would need to be some piece Vz containing both u and v. Suppose by symmet ry that z ∊ X.\nNode v also belongs to some piece Vw for w ∊ Y. Since x and y lie on the w-z path in T, it follows  that\nV belongs to Vx and Vy. Hence v ∊ Vx ∩ Vy, and so it does not lie in GY—(Vx ∩ Vy) as required. ▪\nSo tree decompositions are useful in that the separation properti es of T\ncarry over to G. At this point, one might think that the key question is:\nWhich graphs have tree decompositions? But this is not the point, for if we\nthink about it, we see that of course every graph has a tree decomposition.\nGiven any G, we can let T be a tree consis ting of a single node t, and let the\nsingle piece Vtbe equal to the entire node set of G. This easily satisfies the\nthree properties required by the definition; and such a tree decomposition is\nno more useful to us than the original graph.\nThe crucial point, therefore, is to look for a tree decomposition in\nwhich all the pieces are small.  This is really what we're trying to carry over"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 683})","('type', 'Document')"
"('page_content', 'from trees, by requiring that the deletion of a very small set of nodes breaks\napart the graph into disconnected subgraphs. So we define the width  of a\ntree decomposition (T, {Vt}) to be one less than the maximum size of any\npiece Vt:\nWe then define the tree-width  of G to be the minimum width of any tree\ndecomposition of G. Due to the Edge Coverage Property , all tree\ndecompositions must have pieces with at least two nodes, and hence have\ntree-width at least 1. Recall that our tree decomposition for a tree G has\ntree-width 1, as the sets Vt each have either one or two nodes. The\nsomewhat puzzl ing “-1” in this definition is so that trees turn out to have\ntree-width 1, rather than 2. Also, all graphs with a nontrivial tree\ndecomposition of tree-width w have separators of size w, since if (x, y) is an\nedge of the tree, then, by (10.14), deleting Vx ∩ Vy separates G into two\ncomponents.\nThus we can talk about the set of all graphs of tree-width 1, the set of\nall graphs of tree-width 2, and so forth. The following fact establishes that\ntrees are the only graphs with tree-width 1, and hence our definitions here\nindeed generalize the notion of a tree. The proof also provides a good way\nfor us to exercis e some of the basic properties of tree decompositions. We\nalso observe that the graph in Figure 10.5  is thus, accordin g to the notion of\ntree-width, a member of the next “simplest” class of graphs after trees: It is\na graph of tree-width 2.\n(10.15) A connected graph G has tr ee-width  1 if and only if it is a tr ee.\n \nProof. We have already seen that if G is a tree, then we can build a tree decomposition of tree-width\n1 for G.\nTo prove the converse , we first establish the following useful fact: If H is a subgraph of G, then\nthe tree-width of H is at most the tree-wi dth of G. This is simply because, given a tree decomposition\n(T, {Vt}) of G, we can define a tree decomposition of H by keeping the same underlying tree T and\nreplacing each piece Vt with Vt ∩ H. It is easy to check that the required three properties still hold.\n(The fact that certain pieces may now be equal to the empty set does not pose a problem.)\nNow suppose by way of contradiction that G is a connected graph  of tree-width 1 that is not a\ntree. Since G is not a tree, it has a subgraph consisting of a simple cycle C. By our ar gument from the\nprevious paragraph, it is now enough for us to argue that the graph C does not have tree-width 1.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 684})","('type', 'Document')"
"('page_content', ""Indeed, suppose it had a tree decompositio n (T, {Vt}) in which each piece had size at most 2. Choose\nany two edges (u, v) and (u′, v′) of C; by the Edge Coverage Property , there are pieces Vt and Vt,\ncontaining them. Now , on the path in T from t to t′ there must be an edge (x, y) such that the pieces\nVx and Vy are unequa l. It follows that |Vx ∩ Vy| ≤ 1. We now invoke (10.14): Defining X and Y to be\nthe components of T - (x, y) containing x and y, respectively , we see that deleting Vx ∩ Vy separates\nC into Cx — (V x ∩ Vy) and CY—(VX ∩ Vy). Neither of these two subgraphs can be empty , since one\ncontains {u, v} — (Vx ∩ Vy) and the other contains {u′, v′}—(Vx ∩ Vy). But it is not possible to\ndisconnect a cycle into two nonempty subgraphs by deleting a single node, and so this yields a\ncontradiction. ▪\nWhen we use tree decompo sitions in the context of dynamic\nprogramming algorithms, we would like, for the sake of ef ficiency , that they\nnot have  too many pieces. Here is a simple way to do this. If we are given a\ntree decomposition (T, {Vt}) of a graph G, and we see an edge (x,y) of T\nsuch that Vx ⊆ vy, then we can contract the edge (x,y) (folding the piece Vx\ninto the piece Vy) and obtain a tree decompositio n of G based on a smaller\ntree. Repeating this process as often as necessary , we end up with a\nnonredundant tree decomposition:  There is no edge (x,y) of the underlying\ntree such that Vx ⊆ Vy.\nOnce we've reached such a tree decomposition, we can be sure that it\ndoes not have too many pieces:\n(10.16)  Any nonr edundant tr ee decomposition of an n-node graph has at most n pieces.\n \nProof. We prove this by induction on n, the case n = 1 being clear . Let's  consider the case in which n\n> 1. Given  a nonredundant tree decomposition (T, {Vt}) of an n-node graph, we first identify a leaf t\nof T. By the nonredundancy condition, there must be at least one node in Vt that does not appear in\nthe neighboring piece, and hence (by the Coherence Property) does not appear in any other piece. Let\nU be the set of all such nodes in Vt. We now observe that by deleting t from T, and remo ving Vt from\nthe collection of pieces, we obtain a nonredundant tree decomposition of G—U. By our inductive\nhypothesis, this tree decomposition has at most n - |U| ≤ n - 1 pieces, and so (T, {Vt}) has at most n\npieces. ▪\nWhile (10.16) is very useful for making sure one has a small tree\ndecomposition, it is often easier in the course of analyzing a graph to start\nby build ing a redundant tree decomposition, and only later “condensing” it\ndown to a nonredundant one. For example, our tree decompo sition for a\ngraph G that is a tree built a redundant tree decomposition; it would not\nhave been as simple to directly describe a nonredundant one."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 685})","('type', 'Document')"
"('page_content', ""Having thus laid the groundwor k, we now turn to the algorithmic uses\nof tree decompositions.\nDynamic Programming over a Tree\nDecomposition\nWe bega n by claiming that the Maximum-W eight Independent Set could be\nsolved efficiently on any graph for which the tree-width was bounded. Now\nit's time to deliver on this promise. Specifically , we will develop an\nalgorithm that closely follows the linear -time algorithm for trees. Given an\nrz-node graph with an associated tree decomposition of width w, it will run\nin time O(f(w) · n), where f(·) is an exponential function that depends only\non the width w, not on the number of nodes n. And, as in the case of trees,\nalthough we are focusing on Maximum-W eight Independent Set, the\napproach here is useful for many NP-hard problems.\nSo, in a very concrete sense, the complexity of the problem has been\npushed off of the size of the graph and into the tree-width, which may be\nmuch smaller . As we mentioned earlier , large networks in the real world\noften have very small tree-width; and often this is not coincidental, but a\nconsequence of the structured or modular way in which they are designed.\nSo, if we encou nter a 1,000-node network with a tree decomposition of\nwidth 4, the approach discussed here takes a problem that would have been\nhopelessly intractable and makes it potentially quite manageable.\nOf course, this is all somewh at reminiscent of the Vertex Cover\nAlgorithm from Section 10.1. There we pushed the exponential complexity\ninto the paramet er k, the size of the vertex cover being sought. Here we did\nnot have  an obvious parameter other than n lying around, so we were forced\nto invent a fairly nonobvious one: the tree-width.\nTo design the algorithm, we recall what we did for the case of a tree T.\nAfter rooting T, we built the independent set by working our way up from\nthe leaves. At each internal node u, we enumerated the possibilities for what\nto do with u—include it or not include it—since once this decision was\nfixed, the problems for the dif ferent subtrees below u became independent.\nThe generalization for a graph G with a tree decomposition ( T, {Vt}) of\nwidth w looks very similar . We root the tree T and build the independent set\nby considering the pieces Vt from the leaves upward. At an internal node t\nof T, we confront the following basic question: The optimal independent set"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 686})","('type', 'Document')"
"('page_content', ""intersects the piece Vt in some subset U, but we don't know which set U it\nis. So we enum erate all the possibilities for this subset U—that is, all\npossibilities for which nodes to include from Vt and which to leave out.\nSince Vt may have size up to w + 1, this may be 2W+1 possibilities to\nconsider . But we now can exploit two key facts: first, that the quantity 2W+1\nis a lot more reasonable than 2n when w is much smaller than n; and second,\nthat once we fix a particular one of these 2W+1 possibilities—once we've\ndecided which nodes in the piece Vt to include—the separation properties\n(10.13) and (10.14) ensure that the problems in the different subtrees of T\nbelow t can be solved independently . So, while we settle for doing brute-\nforce search at the level of a single  piece, we have an algorithm that is quite\nefficient at the global level when the individual pieces are small.\n\xa0\nDefining the Subproblems  More precisely , we root the tree T at a node r.\nFor any node t, let Tt denote the subtree rooted at t. Recall that GTt denotes\nthe subgraph of G induced by the nodes in all pieces associated with nodes\nof Tt; for notational simplicity , we will also write this subgraph as Gt. For a\nsubset U of V, we use w(U)  to deno te the total weight of nodes in U; that is,\nw(U)  = ∑u ∊Uwu.\nWe define a set of subproblems for each subtree Tt, one corresponding\nto each possible subset U of Vt that may represent the intersec tion of the\noptimal solution  with Vt. Thus, for each independent set U ⊆ Vt, we write\nft(U) to denote the maximum weight  of an independent set S in Gt, subject\nto the requirement that S ∩ Vt = U. The quantity ft(U) is undefined if U is\nnot an independent set, since in this case we know that U cannot represent\nthe intersection of the optimal solution with Vt.\nThere are at most 2W+1 subproblems associated with each node t of T,\nsince this is the maximum possible number of independent subse ts of Vt. By\n(10.16), we can assume we are working with a tree decomposition that has\nat most n pieces, and hence there are a total of at most 2w+1n subproblems\noverall. Clearly , if we have the solutions to all these subproblems, we can\ndetermine the maximum weight of an independent set in G by looking at the\nsubproblems associated with the root r: We simply take the maximum, over\nall independent sets U ⊆ vr, of fr(U)."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 687})","('type', 'Document')"
"('page_content', ""Building Up Solutions  Now we must show how to build up the solutions to\nthese sub-problems via a recurrence. It's easy to get started: When t is a\nleaf, ft(U) is equal to w(U) for each independent set U ⊆ vt.\nNow suppose that t has children t1,…, td, and we have already\ndetermined the values of fti(W) for each child tt and each indepe ndent set W\n⊆ vt. How do we determine the value of ft(U) for an indepen dent set U ⊆\nVt?\nFigur e 10.8 The subproblem ft(U) in the subgraph Gt. In the optimal\nsolution to this subproblem, we consider independent sets Si in the\ndescendant subgraphs Gti, subject to the constraint that Si ∩ Vt = U ∩ Vti."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 688})","('type', 'Document')"
"('page_content', 'Let S be the maximum-weight indep endent set in Gt subject to the\nrequirement that S ∩ Vt = U; that is, w(S) = ft(U). The key is to understand\nhow this set S looks when intersected with each of the subgraphs Gti, as\nsuggested in Figure 10.8. We let Si denote the intersection of S with the\nnodes of Gti.\n(10.17) Si is a maxim um-weight independent set of Gti, subject to the constraint that Si ∩ Vt = U ∩\nVti.\n \nProof. Supp ose there were an independent set S′t of Gti with the property that S′i∩Vt = U ∩ Vti\nand w(S′i) > w(S i). Then  consider the set S′ = (S —Si) ∪ S′i. Clearly w(S′) > w(S).  Also , it is easy to')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 689})","('type', 'Document')"
"('page_content', 'check that S′ ∩ Vt = U.\nWe claim that S′ is an independent set in G; this will contradict our choice of S as the maximum-\nweight independent set in Gt subject to S ∩ Vt = U.  For suppo se S′ is not independent, and let e = (u,\nv) be an edge with both ends in S′. It cannot be that u and v both belong to S, or that they both belong\nto S′i, since these are both independent sets. Thus we must have u ∊ S — S′i and v ∊ S′i—S, from\nwhich it follows that u is not a node of Gti while v ∊ Gti — (Vt ∩ Vt). But then, by (10.14), there\ncannot be an edge joining u and v. ▪\nStatement (10.17) is exactly what we need to design a recurrence\nrelation for our subproblems. It says that the information needed to compute\nft(U) is implicit in the values already computed for the subtrees.\nSpecifically , for each child ti we need simply determine the value of the\nmaximum-weight independent set Si of Gti, subject to the constraint that Si\n∩ Vt = U  ∩ Vti. This constraint does not completely determine what Si ∩ Vti\nshould be; rather , it says that it can be any independent set Ui ⊆ vt such that\nUi ∩ Vt = U ∩ Vti. Thus the weight of the optimal Si is equal to\nFinally , the value of ft(U) is simp ly w(U) plus these maxima added over the\nd children of t—except that to avoid overcounting the nodes in U, we\nexclude them from the contribution of the children. Thus we have\n(10.18) The value of f t(U) is given by the following r ecurr ence:\nThe overall algorithm now just builds up the values of all the\nsubproblems from the leaves of T upward.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 690})","('type', 'Document')"
"('page_content', 'An actual independent set of maximum weight can be found, as usual,\nby tracing back through the execution.\nWe can determine the time required for computing ft(U) as follows:\nFor each of the d children ti, and for each independent set Ui in Vti, we\nspend time O(w) checki ng if Ui ∩ Vt = U ∩ Vt, to determine whether it\nshould be considered in the computation of (10.18).\nThis is a total time of O(2w+1wd) for ft(U); since there are at most 2W+1\nsets U associated with t, the total time spent on node t is O(4w+1wd).\nFinally , we sum this over all nodes t to get the total running time.  We\nobserve that the sum, over all nodes t, of the number of children of t is O(n),\nsince each node is counted as a child once. Thus the total running time is\nO(4w+1wn).\n* 10.5 Constructing a Tree Decomposition\nIn the previous section, we introduced the notion of tree decompositions\nand tree-width, and we discussed a canonical example of how to solve an\nNP-hard problem on graphs of bounded tree-width.\n The Problem')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 691})","('type', 'Document')"
"('page_content', ""There is still a crucial missing piece in our algorithmic use of tree-width,\nhowever . Thus far, we have simply provided an algorithm for Maximum-\nWeight Independent Set on a graph G, provided we have been given a low-\nwidth tree decomposition of G. What if we simply encounter G “in the\nwild,” and no one has been  kind enough to hand us a good tree\ndecomposition of it? Can we compute one on our own, and then proceed\nwith the dynamic programming algorithm?\nThe answer is basically yes, with some caveats. First we must warn\nthat, given a graph G, it is NP-hard to determine its tree-width. However ,\nthe situation for us is not actua lly so bad, because we are only interested\nhere in graphs for which the tree-width is a small constant. And, in this\ncase, we will describe an algorithm with the following guarant ee: Given a\ngraph G of tree-width less than w, it will produce a tree decomposition of G\nof width less than 4 w in time O(f(w) · mn ), where m and n are the number of\nedges and nodes of G, and f(·) is a function that depends only on w. So,\nessentially , when the tree-width is small, there's a reasonably fast way to\nproduce a tree decomposition whose width is almost as small as possible.\n Designing and Analyzing the Algorithm\nAn Obstacle to Low T ree-W idth The first step in designing an algorithm for\nthis problem is to work out a reasonable “obstacle” to a graph G having low\ntree-width. In other words, as we try to construct a tree decomposition of\nlow width for G = (V, E), might there be some “local” structure we could\ndiscover that will tell us the tree-width must in fact be lar ge?\nThe following idea turns out to provide us with such an obstacle. First,\ngiven two sets Y, Z ⊆ V of the same size, we say they are separable  if some\nstrictly smaller set can completely disconnect them—specifically , if there is\na set S ⊆ V such that |S < |Y| = |Z| and there is no path from Y — S to Z — S\nin G—S.  (In this definition, Y and Z need not be disjoint.) Next we say that a\nset X of nodes in G is w-linked  if |X| ≥ w and X does not contain separable\nsubsets Y and Z, such that | Y| = |Z| < w.\nFor later algorithmic use of w-linked sets, we make note of the\nfollowing fact.\n(10.19)  Let G= (V,E) have m edges, let X be a set of k nodes in G, and let w ≤ k be a given parameter .\nThen we can determ ine whether X is w-linked in time O(f(k) · m), wher e f(·) depends only on k."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 692})","('type', 'Document')"
"('page_content', 'Moreover , if X is not w-linked, we can return a proof of this in the form of sets Y, Z ⊆ X and S ∊ V\nsuch that | S| < |Y| = |Z| ≤ w and ther e is no path fr om Y -S to Z-S in G-S.\n \nProof. We are trying to decide whether X contains separable subsets Y and Z such that |Y| = |Z| < w.\nWe can first enumera te all pairs of sufficiently small subsets Y and Z; since X only has 2k subsets,\nthere are at most 4k such pairs.\nNow , for each pair of subsets Y, Z, we must determine whether they are separable. Let ℓ = |Y| =\n|Z| < w. But this is exactly the Max-Flow Min-Cut Theorem when we have an undirected graph with\ncapacities on the nodes: Y and Z are separable if and only there do not exist ℓ node-disjoint paths,\neach with one end in Y and the other in Z. (See Exercise 13 in Chapter 7  for the version of maximum\nflows with capacities on the nodes.) We can determine whether such paths exist using an algorithm\nfor flow with (unit) capacities on the nodes; this takes time O(ℓm) . ▪\nOne should imagine a w-linked set as being highly self-entwined—it\nhas no two small parts that can be easily split off from each other . At the\nsame time, a tree decomposition cuts up a graph using very small\nseparators; and so it is intuiti vely reasonable that these two structures\nshould be in opposition to each other .\n(10.20) If G contains a (w  + 1)- linked set of size at least 3w , then G has tr ee-width at least w .\n \nProof. Supp ose, by way of contradiction, that G has a (w + 1)-linked set X of size at least 3w, and it\nalso has a tree decomposition (T, {Vt}) of width less than w; in other words, each piece Vt has size at\nmost w. We may further assume that ( T, {Vt}) is nonredundant.\nThe idea of the proof is to find a piece Vt that is “centered” with respect to X, so that when some\npart of Vt is deleted from G, one smal l subset of X is separated from another . Since Vt has size at\nmost w, this will contradict our assumption that X is (w + 1)-linked.\nSo how do we find this piece Vt? We first root the tree T at a node r; using the same notation as\nbefore, we let Tt denote the subtree rooted at a node t, and write Gt for GTt. Now  let t be a node that\nis as far from the root r as possible, subject to the condition that Gt contains more than 2w nodes of\nX.\nClearly , t is not a leaf (or else Gt could contain at most w nodes of X); so let t1,…, td be the\nchildren of t. Note that since each ti is farther than t from the root, each subgraph Gti contains at most\n2w nodes of X. If there is a child ti so that Gt contains at least w nodes of X, then we can define Y to\nbe w nodes of X belonging to Gt, and Z to be w nodes of X belonging to G — Gti. Since (T, {Vt}) is\nnonredundant, S = V ti ∩ Vt has size at most w - 1; but by (10.14), deleting S disconnects Y—S  from Z\n— S.  This contradicts our assumption that X is (w + 1)-linked.\nSo we consider the case in which there is no child ti such that Gti contains at least w nodes of X;\nFigure 10.9 suggests the structur e of the argument in this case. We begin with the node set of Gt1,\ncombine it with Gt2, then Gt3, and so forth, until we first obtain a set of nodes containing more than\nw mem bers of X. This will clearly happen by the time we get to Gtd, since Gt contains more than 2w')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 693})","('type', 'Document')"
"('page_content', 'nodes of X, and at most w of them can belong to Vt. So suppose our process of combining Gt1, Gt2,\n… first yields more than w members of X once we reach index i ≤ d.  Let W denote the set of nodes in\nthe subgraphs Gt1, Gt2, …, Gti. By our stopping condition, we have |W ∩ X| > w. But since Gti\ncontains fewer than w nodes of X, we also have |W ∩ X| < 2w. Hence we can define  Y to be w + 1\nnodes of X belonging to W, and Z to be w + 1 nodes of X belonging to V — W. By (10.13), the piece\nVt is now a set of size at most w whose deletion disconnects Y — Vt from Z — Vt. Again this\ncontradicts our assumption that X is (w + 1)-linked, completing the proof. ▪\nFigur e 10.9  The final step in the proof of (10.20).\nAn Algorithm to Search for a Low-W idth Tree Decomposition  Building on\nthese ideas, we now give a greedy algorithm for constructing a tree\ndecomposition of low width. The algorithm will not precisely determine the\ntree-width of the input graph G = (V, E); rather , given a parameter w, either\nit will produce a tree decomposition of width less than 4w, or it will\ndiscover a (w + 1)-linked set of size at least 3w. In the latter case, this\nconstitutes a proof that the tree-width of G is at least w, by (10.20); so our\nalgorithm is essentially capable of narrowing down the true tree-width of G\nto within a facto r of 4. As discussed earlier , the running time will have the\nform O(f(w ) · mn), where m and n are the number of edges and nodes of G,\nand f(·) depends only on w.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 694})","('type', 'Document')"
"('page_content', ""Having worked with tree decompositions for a little while now, one\ncan start imagining what might be involved in constructing one for an\narbitrary input graph G. The process is depicted at a high level in Figure\n10.10 . Our goal is to make G fall apart into tree-like portions; we begin the\ndecomposition by placing the first piece Vt anywhere. Now , hopefully , G–Vt\nconsists of several disconnected components; we recursively move into\neach of these components, placing a piece in each so that it partially\noverlaps the piece Vt that we've already defined. We hope that these new\npieces cause the graph to break up further , and we thus continue in this way,\npushing forward with small sets while the graph breaks apart in front of us.\nThe key to making this algorithm  work is to argue the following: If at some\npoint we get stuck, and our small sets don't cause the graph to break up any\nfurther , then we can extract a large (w + 1)-lin ked set that proves the tree-\nwidth was in fact lar ge.\nFigur e 10.10  A schem atic view of the first three steps in the construction of\na tree decomposition. As each step produces a new piece, the goal is to\nbreak up the remainder of the graph into disconnected compone nts in which\nthe algorithm can continue iteratively .\nGiven how vagu e this intuition is, the actual algorithm follows it more\nclosely than you might expect. We start by assuming that there is no (w +\n1)-linked set of size at least 3w; our algorithm will produce a tree\ndecomposition provided this holds true, and otherwise we can stop with a\nproof that the tree-width of G is at least w. We grow  the underlying tree T of"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 695})","('type', 'Document')"
"('page_content', ""the deco mposition, and the pieces Vt, in a greedy fashion. At every\nintermediate stage of the algorithm, we will maintain the property that we\nhave a partial tree decomposition:  by this we mean that if U ⊆ V denotes\nthe set of node s of G that belong to at least one of the pieces already\nconstructed, then our current tree T and pieces Vt should form a tree\ndecomposition of the subgraph of G induced on U. We define the width of a\npartial tree deco mposition, by analogy with our definition for the width of a\ntree decomposition, to be one less than the maximum piece size. This\nmeans that in order to achieve our goal of having a width of less than 4w, it\nis enough to make sure that all pieces have size at most 4w.\nIf C is a connected component of G — U, we say that u ∊ U is a\nneighbor  of C if there is some node v ∊ C with an edge to u. The key\nbehind the algorithm is not to simply maintain a partial tree decomposition\nof width less than 4w, but also to make sure the following invariant is\nenforced the whole time:\nWhy is this invariant so useful? It's useful because it will let us add a new\nnode s to T and grow a new piece Vs in the component C, with the\nconfidence that s can be a leaf hanging off t in the larger partial tree\ndecomposition. Moreover , (*) requires there be at most 3w neighbors, while\nwe are trying to produce a tree decomposition of width less than 4u?; this\nextra w gives our new piece “room” to expand by a little as it moves into C.\nSpecifically , we now describe how to add a new node and a new piece\nso that we still have a partial tree decomposition, the invariant (*) is still\nmaintained, and the set U has grown strictly larger. In this way, we make at\nleast one node's worth of progress, and so the algorithm will terminate in at\nmost n iterations with a tree decomposition of the whole graph G.\nLet C be any compon ent of G - U, let X be the set of neighbors of U,\nand let Vt be a piece that, as guaranteed by (*), contains all of X. We know ,\nagain by (*), that X contains at most 3w nodes. If X in fact contains strictly\nfewer than 3w nodes, we can make progress right away: For any node v ∊\nCwe defin e a new piece Vs = X ∪ {v}, making s a leaf of t. Since all the\nedges from v into U have their ends in X, it is easy to confirm that we still\nhave a partial tree decomposition obeying (*), and U has grown.\nThus, let's suppose that X has exactly 3w nodes. In this case, it is less\nclear how to proceed; for example, if we try to create a new piece by\narbitrarily adding a node v ∊ C to X, we may end up with a compone nt of C"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 696})","('type', 'Document')"
"('page_content', ""- {v} (which may be all of C - {v}) whose neighbor set includes all 3w + 1\nnodes of X ⊃ {v}, and this would violate (*).\nThere's no simple way around this; for one thing, G may not actuall y\nhave a low-width tree decomposition. So this is precisely the place where it\nmakes sense to ask whether X poses a genuine obstacle to the tree\ndecomposition or not: we test whether X is a (w + 1)-lin ked set. By (10.19),\nwe can determine the answer to this in time O(f(w) · m), since |X| = 3w. If it\nturns out that X is (w + 1)-linked, then we are all done; we can halt with the\nconclusion that G has tree-width at least w, which was one acceptable\noutcome of the algorithm. On the other hand, if X is not ( w + 1)-linked, then\nwe end up with Y, Z ⊆ X and S ⊆ V such that |S| < |Y| = |Z| ≤ w + 1 and\nthere is no path from Y—S  to Z—S  in G—S.  The sets Y, Z, and S will now\nprovide us with a means to extend the partial tree decomposition.\nLet S′ consist of the nodes of S that lie in Y ∪ Z ∪ C. The situation is\nnow as pictured in Figure 10.1 1. We observe that S′ ∩ C is not empty: Y and\nZ each have edge s into C, and so if S′ ∩ C were empty , there would be a\npath from Y—S  to Z—S  in G—S  that started in Y, jumped immediately into\nC, traveled through C, and finally jumped back into Z. Also, | S′| ≤ |S| < w.\nFigur e 10.1 1 Adding a new piece to the partial tree decomposition.\nWe define a new piece Vs = X ∪ S′, making s a leaf of t. All the edges\nfrom S′ into U have their ends in X, and |X ∪ S′| ≤ 3w + w = 4w, so we still"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 697})","('type', 'Document')"
"('page_content', 'have a partial tree decomposition. Moreover , the set of nodes covered by\nour partial tree decomposition has grown, since S′ ∩ C is not empty . So we\nwill be done if we can show that the invariant (*) still holds. This brings us\nexactly the intuition we tried to capture when discussing Figure 10.10 : As\nwe add the new piece X ∪ S′, we are hoping that the component C breaks up\ninto further components in a nice way .\nConcretely , our partial tree decomposition now covers U ∪ S′; and\nwhere we previously had a component C of G - U, we now may have\nseveral components C′ ⊆ C of G—(U ∪ S′). Each of these components C′\nhas all its neighb ors in X ∪ S′; but we must additionally make sure there are\nat most 3w such neighbors, so that the invariant (*) continues to hold. So\nconsider one of these componen ts C. We claim that all its neighbors in X ∪\nS′ actually belong to one of the two subsets (X—Z ) ∪ S′ or (X — Y) ∪ S′,\nand each of these sets has size at most |X| ≤ 3w. For, if this did not hold,\nthen C′ would have a neighbor in both Y — S and Z — S, and hence there\nwould be a path, through C, from Y—S  to Z—S  in G—S.  But we have\nalready ar gued that there cannot be such a path. This establishes that (*) still\nholds after the addition of the new piece and completes the argument that\nthe algorithm works correctly .\nFinally , what is the running time of the algorithm? The time to add a\nnew piece to the partial tree decomposition is dominated by the time\nrequired to check whether X is (w + 1)-linked, which is O(f(w) · m). We do\nthis for at most n iterations, since we increase the number of nodes of G that\nwe cover in each iteration. So the total running time is O(f (w ) · mn).\nWe summarize the properties of our tree decomposition algorithm as\nfollows.\n(10.21) Given a graph G and a parameter w, the tree decomposition algorithm in this section does\none of the following two things:\nit produces a tr ee decomposition of width less than  4w, or\nit reports (corr ectly) that G does not have tr ee-width less than w .\nThe running time of the algorithm is O(f(w) · mn), for a function f(·) that depends only on w .\nSolved Exercises')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 698})","('type', 'Document')"
"('page_content', ""Solved Exercise 1\nAs we've seen, 3-SA T is often used to model complex planning and\ndecision-making problems in artificial intelligence: the variables represent\nbinary decisions to be made, and the clauses represent constraints on these\ndecisions. Syste ms that work with instances of 3-SA T often need to\nrepresent situations in which some decisions have been made while others\nare still undetermined, and for this purpose it is useful to introduce the\nnotion of a partial assignment  of truth values to variables.\nConcretely , given a set of Boolean variables X = {x1, x2,…, xn}, we say\nthat a partial assignment  for X is an assignment of the value 0, 1, or ? to\neach xi; in other words, it is a function p :X → {0,1, ?}. We say that a\nvariable xiis determined  by the partial assignment if it receives the value 0\nor 1, and undetermined  if it receives the value ?. We can think of a partial\nassignment as choosing a truth value of 0 or 1 for each of its determined\nvariables, and leaving the truth value of each undetermined variable up in\nthe air .\nNow , given a collection of clauses C1, …, Cm, each a disjunction of\nthree distinct terms, we may be interested in whether a partial assignment is\nsufficient to “force” the collect ion of clauses to be satisfied, regardless of\nhow we set the undetermined variables. Similarly , we may be interested in\nwhether there exists a partial assignment with only a few determined\nvariables that can force the collection of clauses to be satisfied; this small\nset of determined variables can be viewed as highly “influen tial,” since\ntheir outcomes alone can be enough to force the satisfaction of the clauses.\nFor example, suppose we are given clauses\nThen the partial  assignment that sets x1 to 1, sets x3 to 0, and sets all other\nvariables to ? has only two deter mined variables, but it forces the collection\nof clauses to be satisfied: No matter how we set the remaining four\nvariables, the clauses will be satisfied."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 699})","('type', 'Document')"
"('page_content', ""Here's a way to formalize this. Recall that a truth assignment  for X is\nan assignment of the value 0 or 1 to each xi; in other  words, it must select a\ntruth value for every  variable and not leave any variables undetermined. We\nsay that a truth assignment v is consistent  with a partial assignment p if each\nvariable that is determined in p has the same truth value in both p and v. (In\nother words, if p(xi) ≠?, then p(xi) = v(xi).) Finally , we say that a partial\nassignment p forces the collection of clauses C1, …, Cm if, for every truth\nassignment v that is consistent with p, it is the case that v satisfies C1,…,\nCm. (We will also call p a forcing partial assignment. )\nMotivated by the issues raised above, here's the question. We are given\na collection of Boolean variables X = {x1, x2,…, xn), a parameter b < n, and\na collection of clauses C1,…, Cm over the variables, where each clause is a\ndisjunction of three distinct terms. We want to decide whether there exists a\nforcing partial assignment p for X, such that at most b variables are\ndetermined by p. Give an algorith m that solves this problem with a running\ntime of the form O(f(b)·p(n, m)), where p(·) is a polynomial function, and\nf(·) is an arbitrary function that depends only on b, not on n or m.\nSolution  Intuitively , a forcing partial assignment must “hit” each clause in\nat least one place, since otherwise it wouldn't be able to ensure the truth\nvalue. Although this seems natural, it's not actually part of the definition\n(the definition just talks about truth assignments that are consistent with the\npartial assignment), so we begin by formalizing and proving this intuition.\n(10.22) A partial assignment p forces all clauses if and only if for each clause Ci, at least one of the\nvariables in C i is determined by p in a way that satisfies C i.\n \nProof. Clearly , if p determines at least one variable in each Ci in a way that satisfies it, then no matter\nhow we construct a full truth assignment for the remaining variables, all the clauses are already\nsatisfied. Thus any truth assignment consistent with p satisfies all clauses.\nNow , for the converse, suppose there is a clause Ci such that p does not determine any of the\nvariables in Ci in a way that satisfie s Ci. We want to show that p is not forcing, which , according to\nthe definition, requires us to exhibit a consistent truth assignment that does not satisfy all clauses. So\nconsider the following truth assignment v: v agrees with p on all determined variables, it assigns an\narbitrary truth value to each undetermined variable not appearing in Ci, and it sets each undetermined\nvariable in Ci in a way that fails to satisfy it. We observe that v sets each of the varia bles in Ci so as\nnot to satisfy it, and hence v is not a satisfying assignment. But v is consistent with p, and so it\nfollows that p is not a forcing partial assignment. ▪"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 700})","('type', 'Document')"
"('page_content', ""In view  of (10.22), we have a problem that is very much like the\nsearch for smal l vertex covers at the beginning of the chapter . There we\nneeded to find a set of nodes that covered all edges, and we were limited to\nchoosing at most k nodes. Here we need to find a set of variables that\ncovers all clauses (and with the right true/false values), and we're limited to\nchoosing at most b variables.\nSo let's try an analogue of the approach we used for finding a small\nvertex cover . We pick an arbitrary clause C, containing xi, xj, and xk (each\npossibly negated). We know from (10.22) that any forcing assignment p\nmust set one of these three variables the way it appears in C, and so we can\ntry all three of these possibilities. Suppose we set xi the way it appears in\nCℓ; we can then eliminate from the instance all clauses (including Cℓ) that\nare satisfied by this assignment to xi, and consider trying to satisfy what's\nleft. We call this smaller set of clauses the instance reduced by the\nassignment to xi. We can do the same for xj and xk. Since p must determine\none of these three variables the way they appear in Cℓ, and then still satisfy\nwhat's left, we have justified the following analogue of (10.3). (To make the\nterminology a bit easier to discuss, we say that the size of a partial\nassignment is the number of variables it determines.)\n(10.23)  There exists a forcing assignment of size at most b if and only if there is a forcing assignment\nof size at most b  - 1 on at least one of the instances r educed by the assignment to x i, xj, or x k.\nWe there fore have the following algorithm. (It relies on the boundary\ncases in which there are no clauses (when by definition we can declare\nsuccess) and in which there are clauses but b = 0 (in which case we declare\nfailure)."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 701})","('type', 'Document')"
"('page_content', ""To boun d the running time, we consider the tree of possibilities being\nsearched, just as in the algorithm for finding a vertex cover . Each recursive\ncall gives rise to three children in this tree, and this goes on to a depth of at\nmost b. Thus the tree has at most 1 + 3 + 32 + … + 3b ≤ 3b+1 nodes, and at\neach node we spend at most 0(m + n) time to produce the reduced\ninstances. Thus the total running time is O(3b(m + n)).\nExercises\n1. In Exercise 5 of Chapter 8, we claimed that the Hitting Set Problem\nwas NP-complete. To recap the definitions, consider a set A = {a1,…,\nan} and a collection B1, B2,…, Bm of subsets of A We say that a set H\n⊆ A is a hitting set for the collection B1, B2,…, Bm if H contains at\nleast one element from each Bi—that is, if H ∩ Bt is not empty for each\ni. (So H “hits” all the sets Bi.) \nNow suppose we are given an instance of this problem, and we'd like\nto determine whether there is a hitting set for the collection of size at"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 702})","('type', 'Document')"
"('page_content', ""most k. Furthermore suppose that each set Bt has at most c elements,\nfor a constant c. Give an algorithm that solves  this problem with a\nrunning time of the form O(f(c, k)·p(n, m)), where p(·) is a polynomial\nfunction, and f(·) is an arbitrary function that depends only on c and k,\nnot on n or m.\n2. The difficulty in 3-SA T comes from the fact that there are 2n possible\nassignments to the input variables x1,x2, …,xn, and there's no apparent\nway to search this space in polynomial time. This intuitive picture,\nhowever , might create the misleading impression that the fastest\nalgorithms for 3-SA T actually require time 2n. In fact, though it's\nsomewhat count erintuitive when you first hear it, there are algorithms\nfor 3-SA T that run in significantly less than 2n time in the worst case;\nin other words, they determine whether there's a satisfying assignment\nin less time than it would take to enumerate all possible settings of the\nvariables.  \nHere we'll develop one such algorithm, which solves instance s of 3-\nSAT in O(p(n)  · (√3)n) time for some  polynomial p(n).  Note that the\nmain term in this running time is (√3)n, which is bounded by 1.74n. \n(a) For a truth assignment Φ for the variables x1, x2,…, xn, we use\nΦ(xi) to deno te the value assigned by Φ to xi. (This can be either 0 or\n1.) If Φ and Φ′ are each truth  assignments, we define the distance\nbetween Φ and Φ′ to be the number of variables xi for which they\nassign different values, and we denote this distance by d(Φ, Φ′). In\nother words, d(Φ, Φ′) = |{ i: Φ(xi) ≠ Φ′( xi)}|. \nA basic building block for our algorithm will be the ability to answer\nthe following kind of question: Given a truth assignment Φ and a\ndistance d, we'd like to know whether  there exists a satisfying\nassignment Φ′ such that the distance from Φ to Φ′ is at most d.\nConsider the following algorithm, Explore(Φ, d), that attempts to\nanswer this question."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 703})","('type', 'Document')"
"('page_content', 'Prove that Expl ore(Φ, d) returns  “yes” if and only if there exists a\nsatisfying assign ment Φ′ such that the distance from Φ to Φ′ is at most\nd. Also, give an analysis of the running time of Explore(Φ, d) as a\nfunction of n and d. \n(b) Clearly any two assignments Φ and Φ′ have distance at most n\nfrom each other , so one way to solve the given instance of 3-SA T\nwould be to pick an arbitrary starting assignment Φ and then run\nExplore(Φ, n). However , this will not give us the running time we\nwant.  \nInstead, we will need to make several calls to Explore, from different\nstarting points Φ, and search each time out to more limited distances.\nDescribe how to do this in such a way that you can solve the instance\nof 3-SA T in a running time of only O(p(n)  · (√3)n).\n3. Suppose we are given a directed  graph G = (V,E), with V = {v1,v2,…,\nvn], and we want to decide whether G has a Hamiltonian path from v1\nto vn. (That is, is there a path in G that goes from v1 to vn, passing\nthrough every other vertex exactly once?)  \nSince the Hamiltonian Path Problem is NP-complete, we do not expect')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 704})","('type', 'Document')"
"('page_content', ""that there is a polynomial-time solution for this problem. However , this\ndoes not mean that all nonpolynomial-time algorithms are equally\n“bad.” For example, here's the simplest brute-force approach: For each\npermutation of the vertices, see if it forms a Hamiltonian path from v1\nto vn. This takes time roughly proportional to n!, which is about  3 ×\n1017 when n = 20.  \nShow that the Hamiltonian Path Problem can in fact be solved in time\nO(2n · p(n)),  where p(n) is a polynomial function of n. This is a much\nbetter algorithm  for moderate values of n; for example, 2n is only\nabout a million when n = 20.\n4. We say that a graph G = (V, E) is a triangulated cycle graph  if it\nconsists of the vertices and edge s of a triangulated convex n-gon in the\nplane-in other words, if it can be drawn in the plane as follows.  \nFigur e 10.12  A triangulated cycle graph: The edges form the boundary\nof a convex polygon together with a set of line segments that divide its\ninterior into triangles.\n \nThe vertices are all placed on the boundary of a convex set in the plane\n(we may assume on the boundary of a circle), with each pair of\nconsecutive vertices on the circle joined by an edge. The remaining\nedges are then drawn as straight line segments through the interior of\nthe circle, with no pair of edges crossing in the interior . We require the\ndrawing to have the following property . If we let S denote the set of all\npoints in the plane that lie on vertices or edges of the drawin g, then\neach bounded component of the plane after deleting S is bordered by\nexactly three edges. (This is the sense in which the graph is a"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 705})","('type', 'Document')"
"('page_content', '“triangulation.”)  \nA triangulated cycle graph is pictured in Figure 10.12 . \nProve that every triangulated cycle graph has a tree decomposi tion of\nwidth at most 2, and describe an efficient algorithm to construct such a\ndecomposition.\n5. The Minimum-Cost Dominating Set Problem  is specified by an\nundirected graph G = (V, E) and costs c(v) on the nodes v ∊V. A subset\nS ⊂ V is said to be a dominating set if all nodes u ∊V–S have an edge\n(u,v) to a node v in S. (Note the difference between dominating sets\nand vertex cove rs: in a dominating set, it is fine to have an edge (u, v)\nwith neither u nor v in the set S as long as both u and v have neighbors\nin S.) \n(a) Give a polynomial-time algorithm for the Dominating Set Problem\nfor the special case in which G is a tree.  \n(b) Give a polynomial-time algorithm for the Dominating Set Problem\nfor the special case in which G has tree-width 2, and we are also given\na tree decomposition of G with width 2.\n6. The Node-Disjoint Paths Proble m is given by an undirected graph G\nand k pairs of nodes (si, ti) for i = 1,…, k. The problem is to decide\nwhether there are node-disjoint paths Pi so that path Pi connects si to ti.\nGive a polyno mial-time algorithm for the Node-Disjoint Paths\nProblem for the special case in which G has tree-width 2, and we are\nalso given a tree decomposition T of G with width 2.\n7. The chromatic number  of a graph G is the minimum k such that it has\na k-coloring. As we saw in Chapter 8, it is NP-complete for k ≥ 3 to\ndecide whether a given input graph has chromatic number ≤ k. \n(a) Show that for every natural number w ≥ 1, there is a number k(w)\nso that the following holds. If G is a graph of tree-width at most w,\nthen G has chromatic number at most k(w).  (The point is that k(w)\ndepends only on w, not on the number of nodes in G.) \n(b) Given an undirected n-node graph G = (V,E) of tree-width at most\nw, show how to compute the chromatic number of G in time O(f(w) ·\np(n)),  where p() is a polynomial but f(·) can be an arbitrary function.\n8. Consider the class of 3-SA T instances in which each of the n variables\noccurs—counting positive and negated appearances combin ed—in\nexactly three clauses. Show that any such instance of 3-SA T is in fact')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 706})","('type', 'Document')"
"('page_content', 'satisfiable, and that a satisfying assignment can be found in\npolynomial time.\n9. Give a polynom ial-time algorithm for the following problem. We are\ngiven a binary tree T = (V, E) with an even number of nodes, and a\nnonnegative weight on each edge. We wish to find a partition of the\nnodes V into two sets of equal  size so that the weight of the cut\nbetween the two sets is as large as possible (i.e., the total weight of\nedges with one end in each set is as large as possible). Note that the\nrestriction that the graph is a tree is crucial here, but the assumption\nthat the tree is binary is not. The problem is NP-hard in general graphs.\nNotes and Further Reading\nThe first topic in this chapter , on how to avoid a running time of O(knk+1)\nfor Vertex Cover , is an examp le of the general theme of parameterized\ncomplexity : for problems with two such “size parameters” n and k, one\ngenerally prefer s running times of the form O(f(k ) · p(n)), where p(·) is a\npolynomial, rather than running times of the form O(nk). A body of work\nhas grow n up around this issue , including a methodology for identifying\nNP-complete problems that are unlikely to allow for such impro ved running\ntimes. This area is covered in the book by Downey and Fellows (1999).\nThe problem of coloring a collection of circular arcs was shown to be\nNP-complete by Garey , Johnson, Miller , and Papadimitriou (1980). They\nalso described how the algorithm  presented in this chapter follo ws directly\nfrom a construction due to Tucker (1975). Both Interval Coloring and\nCircular -Arc Coloring belong to the following class of problems: Take a\ncollection of geometric objects (such as intervals or arcs), define  a graph by\njoining pairs of objects that intersect, and study the problem of coloring this\ngraph. The book on graph coloring by Jensen and Toft (1995) includes\ndescriptions of a number of other problems in this style.\nThe importance of tree decompositions and tree-width was brought\ninto prominence  largely through the work of Robertson and Seymour\n(1990). The algorithm for constructing a tree decomposition described in\nSection 10.5  is due to Diestel et al. (1999). Further discussion of tree-width\nand its role in both algorithms and graph theory can be found in the survey')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 707})","('type', 'Document')"
"('page_content', 'by Reed (1997) and the book by Diestel (2000). Tree-width has also come\nto play an important role in inference algorithms for probabilistic models in\nmachine learning (Jordan 1998).\nNotes on the Exercises  Exercise 2 is based on a result of Uwe Schöning;\nand Exercise 8 is based on a problem we learned from Amit Kumar .\n1 We use the term NP-har d to mean “at least as hard as an NP-complete\nproblem.”W e avoid referring to optimization problems as NP-complete,\nsince technically this term applies only to decision problems.\n(*) At any stage in the execution of the algorithm, each component C of G-\nU has at most 3w neighbors, and there is a single piece Vt that contains all\nof them.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 708})","('type', 'Document')"
"('page_content', 'Chapter 11')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 709})","('type', 'Document')"
"('page_content', ""Approximation Algorithms\n11.1 Greedy Algorithms and Bounds on the Optimum: A Load\nBalancing Pr oblem  \n11.2 The Center Selection Pr oblem  \n11.3 Set Cover: A General Gr eedy Heuristic  \n11.4 The Pricing Method: V ertex Cover  \n11.5 Maximization via the Pricing Method: The Disjoint Paths Pr oblem  \n11.6 Linear Programming and Rounding: An Application to Vertex\nCover  \n*11.7 Load Balancing Revisited: A Mor e Advanced LP Application  \n11.8 Arbitrarily Good Appr oximations: The Knapsack Pr oblem  \nSolved Exer cises  \nExer cises  \nNotes and Further Reading\nFollowing our encounter with NP-completeness and the idea of\ncomputational intractability in general, we've been dealing with a\nfundamental question: How should we design algorithms for problems\nwhere polynomial time is probably an unattainable goal?\nIn this chapter , we focus on a new theme related to this question:\napproximation algorithms , which run in polynomial time and find solutions\nthat are guaranteed to be close to optimal. There are two key words to\nnotice in this definition: close  and guaranteed . We will not be seeking the\noptimal solutio n, and as a result, it becomes feasible to aim for a\npolynomial running time. At the same time, we will be interested in proving\nthat our algorith ms find solutions that are guaranteed to be close to the\noptimum. There  is something inherently tricky in trying to do this: In order\nto prove  an approximation guara ntee, we need to compare our solution with\n—and hence reason about—an optimal solution that is computationally very\nhard to find. This difficulty will be a recurring issue in the analysis of the\nalgorithms in this chapter ."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 710})","('type', 'Document')"
"('page_content', ""We will consider four general techniques for designing approximation\nalgorithms. We start with greedy algorithms , analogous to the kind of\nalgorithms we developed in Chapter 4 . These algorithms will be simple and\nfast, as in Chapter 4, with the chall enge being to find a greedy rule that\nleads to solutions provably close to optimal. The second gener al approach\nwe pursue is the pricing method . This approach is motivated by an\neconomic persp ective; we will consider a price one has to pay to enforce\neach constraint of the problem. For example, in a graph problem, we can\nthink of the nodes or edges of the graph sharing the cost of the solution in\nsome equitable way. The pricing method is often referred to as the primal-\ndual technique , a term inherit ed from the study of linear programming,\nwhich can also be used to motivate this approach. Our presentation of the\npricing method here will not assume familiarity with linear programming.\nWe will introduce linear progra mming through our third technique in this\nchapter , linear program ming and rounding , in which one exploits the\nrelationship between the compu tational feasibility of linear programming\nand the expressi ve power of its more difficult cousin, integer programming .\nFinally , we will describe a technique that can lead to extre mely good\napproximations: using dynamic programming on a rounded version of the\ninput.\n11.1 Greedy Algorithms and Bounds on the\nOptimum: A Load Balancing Problem\nAs our first topic in this chapter , we consider a fundam ental Load\nBalancing Problem  that arises when multiple servers need to process a set\nof jobs or reques ts. We focus on a basic version of the problem in which all\nservers are identical, and each can be used to serve any of the requests. This\nsimple problem is useful for illustrating some of the basic issues that one\nneeds to deal with in designing and analyzing approximation algorithms,\nparticularly the task of comparing an approximate solution with an\noptimum solutio n that we cann ot compute efficiently . Moreov er, we'll see\nthat the general issue of load balancing is a problem with many  facets, and\nwe'll explore some of these in later sections.\n The Problem"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 711})","('type', 'Document')"
"('page_content', 'We form ulate the Load Balancing Problem as follows. We are given a set of\nm machines M1, …, Mm and a set of n jobs; each job j has a processing time\ntj. We seek to assign each job to one of the machines so that the loads\nplaced on all machines are as “balanced” as possible.\nMore concretely , in any assignment of jobs to machines, we can let\nA(i) denote the set of jobs assigned to machine Mi; under this assignment,\nmachine Mi needs to work for a total time of  \n\xa0\nand we declare this to be the load on machine Mi. We seek to minimize a\nquantity known as the makespan ; it is simply the maximum load on any\nmachine, T = maxi Ti. Although we will not prove this, the scheduling\nproblem of finding an assignment of minimum makespan is NP-hard.\n Designing the Algorithm\nWe first consider a very simp le greedy algorithm for the problem. The\nalgorithm makes  one pass throu gh the jobs in any order; when it comes to\njob j, it assigns i to the machine whose load is smallest so far .\n\xa0\n\xa0\nGreedy-Balance:\nStart with no jobs assigned\nSet Ti = 0 and A(i) = Ø for all machines Mi\nFor j = 1, …, n\nLet Mi be a machine that achieves the minimum min k Tk\nAssign job j to machine Mi\nSet A(i) ← A(i) ∪ {j}\nSet Ti ← Ti + tj\nEndFor')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 712})","('type', 'Document')"
"('page_content', ""For example, Figure 11.1 shows the result of running this greedy\nalgorithm on a sequence of six jobs with sizes 2,3,4,6,2,2; the resulting\nmakespan is 8, the “height” of the jobs on the first machine. Note that this is\nnot the optimal solution; had the jobs arrived in a different order , so that the\nalgorithm saw the sequence of sizes 6,4,3,2,2,2, then it would have\nproduced an allocation with a makespan of 7.\nFigur e 11.1 The result of running the greedy load balancing algorithm on\nthree machines with job sizes 2, 3, 4, 6, 2, 2.\n Analyzing the Algorithm\nLet T denote the makespan of the resulting assignment; we want to show\nthat T is not much larger than the minimum possible makespan T*. Of\ncourse, in trying to do this, we immediately encounter the basic problem\nmentioned above: We need to compare our solution to the optimal value T*,\neven though we don't know what this value is and have no hope of\ncomputing it. For the analysis, therefore, we will need a lower bound  on the\noptimum—a quantity with the guarantee that no matter how good the\noptimum is, it cannot be less than this bound.\nThere are many possible lower bounds on the optimum. One idea for a\nlower bound is based on considering the total processing time ∑j tj. One of\nthe m machines must do at least a 1/m fraction of the total work, and so we\nhave the following."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 713})","('type', 'Document')"
"('page_content', ""(11.1) The optimal makespan is at least\n\xa0\n\xa0\nThere is a particular kind of case in which this lower bound is much\ntoo weak to be useful. Suppose we have one job that is extremely long\nrelative to the sum of all process ing times. In a sufficiently extreme version\nof this, the optim al solution will place this job on a machine by itself, and it\nwill be the last one to finish. In such a case, our greedy algorithm would\nactually produce  the optimal solution; but the lower bound in (11.1) isn't\nstrong enough to establish this.\nThis suggests the following additional lower bound on T*.\n\xa0\n\xa0\n(11.2) The optimal makespan is at least T * ≥ max j tj.\n\xa0\n\xa0\nNow we are ready to evaluate the assignment obtained by our greedy\nalgorithm.\n\xa0\n\xa0\n(11.3) Algorithm  Greedy-Balance produces an assignment of jobs to machines with makespan T ≤\n2T*.\nProof. Here is the overall plan for the proof. In analyzing an approximation algorithm, one compares\nthe solution obtained to what one knows about the optimum—in this case, our lowe r bounds (11.1)\nand (11.2). We consid er a machine Mi that attain s the maximum load T in our assignment, and we\nask: What was the last job j to be placed on Mi? If tj is not too large relative to most of the other jobs,\nthen we are not too far above the lower bound (11.1). And, if tj is a very large job, then we can use\n(11.2). Figure 1 1.2 shows the structure of this ar gument.\nFigur e 11.2 Accounting for the load on machine Mi in two parts: the last job to be added, and all the\nothers."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 714})","('type', 'Document')"
"('page_content', 'Here is how we can make this precise. When we assigned job j to Mi, the machine Mi had the\nsmallest load of any machine; this is the key property of our greedy algorithm. Its load just before\nthis assignment was Ti - tj, and since this was the smallest load at that moment, it follows that every\nmachine had load at least Tt - tj. Thus, adding up the loads of all machines, we have ∑k Tk ≥ m(Ti -\ntj), or equivalently , \n \nBut the value ∑k Tk;, is just the total load of all jobs ∑j tj (since every job is assigned to exactly one\nmachine), and so the quantity on the right- hand side of this inequality is exactly our lower bound on\nthe optimal value, from (1 1.1). Thus  \nNow we account for the remaining part of the load on Mi, which is just the final job j. Here we\nsimply use the other lower bound we have, (11.2), which says that tj ≤ T*. Adding up these two\ninequalities, we see that  \nSince our makespan T is equal to Tt, this is the result we want. ▪')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 715})","('type', 'Document')"
"('page_content', ""It is not hard to give an example in which the solution is indeed close\nto a factor of 2 away from optim al. Suppose we have m machines and n =\nm(m - 1) + 1 jobs. The first m(m - 1) = n - 1 jobs each require time tj = 1.\nThe last job is much larger; it requires time tn = m. What does our greedy\nalgorithm do with this sequence of jobs? It evenly balances the first n — 1\njobs, and then has to add the giant job n to one of them; the resulting\nmakespan is T = 2m - 1.\nFigur e 11.3 A bad example for the greedy balancing algorithm with m = 4.\nWhat does the optimal solution look like in this example? It assigns\nthe large job to one of the machines, say, M1, and evenly spreads the\nremaining jobs over the other m - 1 machines. This results in a makespan of\nm. Thus the ratio between the greedy algorithm's solution and the optimal\nsolution is (2m - 1)/m = 2 - 1/m, which is close to a factor of 2 when m is\nlarge.\nSee Figure 1 1.3 for a picture of this with m = 4; one has to admire the\nperversity of the construction, which misleads the greedy algorithm into\nperfectly balancing everything, only to mess everything up with the final\ngiant item.\nIn fact, with a little care, one can improve the analysis in (11.3) to\nshow that the greedy algorithm with m machines is within exactly this\nfactor of 2 - 1/m on every instance; the example above is really as bad as\npossible.\nExtensions: An Improved Approximation\nAlgorithm"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 716})","('type', 'Document')"
"('page_content', ""Now let's think about how we might develop a better approximation\nalgorithm—in other words, one for which we are always guaranteed to be\nwithin a factor strictly smaller than 2 away from the optimum. To do this, it\nhelps to think about the worst cases for our current approximation\nalgorithm. Our earlier bad exam ple had the following flavor: We spread\neverything out very evenly across the machines, and then one last, giant,\nunfortunate job arrived. Intuitively , it looks like it would help to get the\nlargest jobs arranged nicely first, with the idea that later , small jobs can only\ndo so much damage. And in fact, this idea does lead to a measurable\nimprovement.\nThus we now analyze the variant of the greedy algorithm that first\nsorts the jobs in decreasing order of processing time and then proceeds as\nbefore. We will prove that the resulting assignment has a makespan that is\nat most 1.5 times the optimum.\n\xa0\n\xa0\nSorted-Balance:\nStart with no jobs assigned\nSet Ti = 0 and A(i) = Ø for all machines Mi\nSort jobs in decreasing order of processing times tj\nAssume that t1 ≥ t2 ≥ … ≥ tn\nFor j = 1, …, n\nLet Mi be the machine that achieves the minimum min k Tk\nAssign job j to machine Mi\nSet A(i) ← A(i) ∪ {j}\nSet Ti ← Ti + tj\nEndFor\n\xa0\n\xa0\nThe improvement comes from the following observation. If we have\nfewer than m jobs, then the greedy solution will clearly be optimal, since it\nputs each job on its own machi ne. And if we have more than m jobs, then\nwe can use the following further lower bound on the optimum.\n\xa0\n\xa0\n(11.4) If ther e are mor e than m jobs, then T * ≥ 2 tm+1."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 717})","('type', 'Document')"
"('page_content', ""Proof. Consider only the first m + 1 jobs in the sorted order . They each take at least tm+1 time. There\nare m + 1 jobs and only m machines, so there must be a machine that gets assigned two of these jobs.\nThis machine will have processing time at least 2 tm+1. ▪\n\xa0\n\xa0\n(11.5) Algorithm  Sorted-Balance produces an assignment of jobs to machines with makespan  \n.\nProof. The proof  will be very similar to the analysis of the previous algorithm. As before, we will\nconsider a machine Mi that has the maximum load. If Mi only holds  a single job, then the schedule is\noptimal.\nSo let's assume that machine Mi has at least two jobs, and let tj be the last job assign ed to the\nmachine. Note that j ≥ m + 1, since the algorit hm will assign the first m jobs to m distinct machines.\nThus \n , where the second inequality is (1 1.4).\nWe now proceed as in the proof of (11.3), with the following single change. At the end of that\nproof, we had inequalities Ti - tj ≤ T* and tj ≤ T*, and we added them up to get the factor of 2. But in\nour case here, the second of these inequal ities is, in fact, \n ; so adding  the two inequalities\ngives us the bound\n▪\n11.2 The Center Selection Problem\nLike the problem in the previo us section, the Center Selection Problem,\nwhich we consid er here, also relates to the general task of allocating work\nacross multiple servers. The issue at the heart of Center Selection is where\nbest to place the servers; in order to keep the formulation clean and simple,\nwe will not incorporate the notion of load balancing into the problem. The\nCenter Selection Problem also provides an example of a case in which the\nmost natural greedy algorithm can result in an arbitrarily bad solution, but a\nslightly differen t greedy method is guaranteed to always result in a near-\noptimal solution.\n The Problem"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 718})","('type', 'Document')"
"('page_content', 'Consider the following scenario. We have a set S of n sites—say , n little\ntowns in upstate New York. We want to select k centers  for building large\nshopping malls. We expect that people in each of these n towns will shop at\none of the malls, and so we want to select the sites of the k malls to be\ncentral.\nLet us start by defining the input to our problem more formally . We are\ngiven an integer  k, a set S of n sites (correspon ding to the towns), and a\ndistance function . When we consider instances where the sites are points in\nthe plane, the distance function will be the standard Euclidean distance\nbetween points, and any point in the plane is an option for placing a center .\nThe algorithm we develop, howe ver, can be applied to more general notions\nof dista nce. In applications, distance sometimes means straight-line\ndistance, but can also mean the travel time from point s to point z, or the\ndriving distance (i.e., distance along roads), or even the cost of traveling.\nWe will allow any distance function that satisfies the following natural\nproperties.\ndist(s, s) = 0 for all s ∊ S\nthe distance is symmetric: dist(s, z) = dist(z, s) for all sites s, z ∊ S\nthe triangle inequality: dist(s, z) + dist(z, h) ≥ dist(s, h)\nThe first and third of these properties tend to be satisfied by essentially all\nnatural notions of distance. Although there are applications with\nasymmetric distances, most cases of interest also satisfy the second\nproperty . Our greedy algorithm  will apply to any distance function that\nsatisfies these three properties, and it will depend on all three.\nNext we have to clarify what we mean by the goal of wanti ng the\ncenters to be “central.” Let C be a set of centers. We assume that the people\nin a given town will shop at the closest mall. This suggests we define the\ndistance of a site s to the centers as dist(s, C) = minc ∊C dist(s, c). We say\nthat C forms an r-cover  if each site is within distance at most r from one of\nthe centers—that is, if dist(s, C) ≤ r for all sites s ∊ S. The minimum r for\nwhich C is an r-cover will be called the covering radius  of C and will be\ndenoted by r(C). In other words , the covering radius of a set of centers C is\nthe farthest that anyone needs to travel to get to his or her nearest center .\nOur goal will be to select a set C of k centers for which r(C) is as small as\npossible.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 719})","('type', 'Document')"
"('page_content', 'Designing and Analyzing the Algorithm\nDifficulties with a Simple Greedy Algorithm  We now discuss greedy\nalgorithms for this problem. As before, the meaning of “gree dy” here is\nnecessarily a little fuzzy; essentially , we consider algorithms that select sites\none by one in a myopic fashion—that is, choosing each withou t explicitly\nconsidering where the remaining sites will go.\nProbably the simplest greedy algorithm would work as follows. It\nwould put the first center at the best possible location for a single center ,\nthen keep adding centers so as to reduce the covering radius, each time, by\nas much as possible. It turns out that this approach is a bit too simplistic to\nbe ef fective: there are cases where it can lead to very bad solutions.\nTo see that this simple greedy approach can be really bad, consider an\nexample with only two sites s and z, and k = 2. Assume that s and z are\nlocated in the plane, with distance equal to the standard Euclidean distance\nin the plane, and that any point in the plane is an option for placing a center .\nLet d be the distance between s and z. Then the best location for a single\ncenter c1 is halfway between s and z, and the covering radius of this one\ncenter is r({c1}) = d/2. The greedy algorithm would start with c1 as the first\ncenter . No matter where we add a second center , at least one of s or z will\nhave the center c1 as closest, and so the covering  radius of the set of two\ncenters will still be d/2. Note  that the optimum solution with k = 2 is to\nselect s and z themsel ves as the centers. This will lead to a covering radius\nof 0. A more complex example illustrating the same problem can be\nobtained by having two dense “clusters” of sites, one around s and one\naround z. Here our proposed greedy algorithm would start by opening a\ncenter halfway between the clusters, while the optimum solution would\nopen a separate center for each cluster .\nKnowing the Optimal Radius Helps  In searching for an improved\nalgorithm, we begin with a useful thought experiment. Suppose for a minute\nthat someone told us what the optimum radius r is. Would this information\nhelp? That is, suppose we know  that there is a set of k centers C* with\nradius r(C*) ≤ r, and our job is to find some set of k centers C whose\ncovering radius is not much more than r. It turns out that finding a set of k\ncenters with covering radius at most 2 r can be done relatively easily .')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 720})","('type', 'Document')"
"('page_content', 'Figur e 11.4 Everything covered at radius r by c* is also covere d at radius\n2r by s.\nHere is the idea: We can use the existence of this solution C* in our\nalgorithm even though we do not know what C* is. Consider any site s ∊ S.\nThere must be a center c* ∊ C* that covers site s, and this center c* is at\ndistance at most r from s. Now our idea would be to take this site s as a\ncenter in our solution instead of c*, as we have no idea what c* is. We\nwould like to make s cover all the sites that c* covers in the unknown\nsolution C*. This is accomplished by expa nding the radius from r to 2r. All\nthe sites that were at distance at most r from center c* are at distance at\nmost 2r from s (by the triangle inequality). See Figure 11.4 for a simple\nillustration of this ar gument.\n\xa0\n\xa0\nS′ will represent the sites that still need to be covered\nInitialize S′ = S\nLet C = Ø\nWhile S′ ≠ Ø\nSelect any site s ∊ S′ and add s to C\nDelete all sites from S′ that are at distance at most 2 r from s\nEndWhile\nIf |C| ≤ k then\nReturn C as the selected set of sites\nElse\nClaim (correctly) that there is no set of k centers with covering radius at most r')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 721})","('type', 'Document')"
"('page_content', 'EndIf\n\xa0\n\xa0\nClearly , if this algorithm returns a set of at most k centers, then we\nhave what we wanted.\n\xa0\n\xa0\n(11.6) Any set of centers C r eturned by the algorithm has covering radius r (C) ≤ 2 r.\n\xa0\n\xa0\nNext we argue that if the algorithm fails to return a set of centers, then\nits conclusion that no set can have covering radius at most r is indeed\ncorrect.\n\xa0\n\xa0\n(11.7) Suppose the algorithm  selects more than k centers. Then, for any set C* of size at most k, the\ncovering radius is r (C*) > r.\nProof. Assume the opposite , that there is a set C* of at most k centers with covering  radius r(C*) ≤ r.\nEach center c ∊ C selected by the greedy algorithm is one of the original sites in S, and the set C* has\ncovering radius at most r, so there must be a center c* ∊ C* that is at most a distance of r from c—\nthat is, dist(c, c*) ≤ r. Let us say that such a center c* is close  to c. We want to claim that no center c*\nin the optimal solution C* can be close to two different centers in the greedy solution C. If we can do\nthis, we are done: each center c ∊ C has a close optimal center c* ∊ C*, and each of these close\noptimal centers is distinct. This will imply that |C*| ≥ |C|, and since |C| > k, this will contradict our\nassumption that C* contains at most k centers.\nSo we just need to show that no optimal center c* ∊ C can be close to each of two centers c, c′\n∊ C. The reason for this is pictured in Figure 11.5. Each  pair of centers c,c′ ∊ C is separated by a\ndistance of more than 2r, so if c* were within a distance of at most r from each, then this would\nviolate the triangle inequality , since dist(c, c*) + dist(c*, c′) ≥ dist(c, c′) > 2 r. ▪\n\xa0\n\xa0\nEliminating the Assumption That We Know the Optimal Radius  Now we\nreturn to the original question: How do we select a good set of k centers\nwithout  knowing what the optimal covering radius might be?\nIt is worth discu ssing two different answers to this question. First, there are\nmany cases in the design of approximation algorithms where it is\nconceptually useful to assume that you know the value achieved by an')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 722})","('type', 'Document')"
"('page_content', 'optimal solution . In such situations, you can often start with an algorithm\ndesigned under this assumption  and convert it into one that achieves a\ncomparable performance guarantee by simply trying out a range of\n“guesses” as to what the optim al value might be. Over the course of the\nalgorithm, this sequence of guesses gets more and more accurate, until an\napproximate solution is reached.\nFigur e 11.5 The crucial step in the analysis of the greedy algorithm that\nknows the optimal radius r. No center used by the optimal solution can lie\nin two different circles, so there must be at least as many optimal centers as\nthere are centers chosen by the greedy algorithm.\nFor the Center Selection Problem, this could work as follows. We can\nstart with some very weak initial guesses about the radius of the optimal\nsolution: We know it is greater than 0, and it is at most the maximum\ndistance rmax betwee n any two sites. So we could begin by splitting the\ndifference between these two and running the greedy algorithm we\ndeveloped above with this value of r = rmax/2. One of two things will\nhappen, according to the design of the algorithm: Either we find a set of k\ncenters with covering radius at most 2r, or we conclud e that there is no\nsolution with covering radius at most r. In the first case, we can afford to\nlower our guess on the radius of the optimal solution; in the second case, we\nneed to raise it. This gives us the ability to perform a kind of binary search\non the radius: in general, we will iteratively maintain values r0 < r1 so that\nwe know the optimal radius is greater than r0, but we have a solution of\nradius at most 2r1. From these values, we can run the above algorithm with')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 723})","('type', 'Document')"
"('page_content', 'radius r = (r0 + r1)/2; we will either conclude that the optimal solution has\nradius greater than r > r0, or obtain a solution with radius at most 2r = (r0 +\nr1) < 2r1. Either way, we will have sharp ened our estimates on one side or\nthe other , just as binary search  is supposed to do. We can stop when we\nhave estimates r0 and r1 that are close to each other; at this point, our\nsolution of radius 2r1 is close to being a 2-approxim ation to the optimal\nradius, since we know the optimal radius is greater than r0 (and hence close\nto r1).\nA Greedy Algorithm That Works For the specific case of the Center\nSelection Problem, there is a surprising way to get around the assumption of\nknowing the radius, without resorting to the general technique described\nearlier . It turns out we can run essentially the same greed y algorithm\ndeveloped earlier without knowing anything about the value of r.\nThe earlier greedy algorithm, armed with knowledge of r, repeatedly selects\none of the origin al sites s as the next center , making sure that it is at least 2r\naway from all previously selected sites. To achieve essentially the same\neffect without knowing r, we can simply  select the site s that is farthest\naway from all previously selected centers: If there is any site at least 2r\naway from all previously chosen centers, then this farthest site s must be\none of them. Here is the resulting algorithm.\n\xa0\n\xa0\nAssume k ≤ |S| (else define C = S)\nSelect any site s and let C = {s}\nWhile | C| < k\nSelect a site s ∊ S that maximizes dist(s,C)\nAdd site s to C\nEndWhile\nReturn C as the selected set of sites\n\xa0\n\xa0\n(11.8) This greedy algorithm returns a set C of k points such that r(C) ≤ 2r(C*), wher e C* is an\noptimal set of k points .\nProof. Let r = r(C*) denote the minimum possible radius of a set of k centers. For the proof, we\nassume that we obtain a set of k centers C with r(C) > 2 r, and from this we derive a contradiction.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 724})","('type', 'Document')"
"('page_content', 'So let s be a site that is more than 2r away from every center in C. Consider some intermediate\niteration in the execution of the algorithm, where we have thus far selected a set of centers C′.\nSuppose we are adding the center c′ in this iteration. We claim that c′ is at least 2r away from all sites\nin C′. This follows as site s is more than 2 r away from all sites in the larger set C, and we select a site\nc that is the farthest site from all previously selected centers. More formally , we have the following\nchain of inequalities:  \nIt follows that our greedy algorithm is a correct implementation of the first k iterations of the\nwhile loop of the previous algorithm, which knew the optimal radius r: In each iteration, we are\nadding a center at distance more than 2r from all previously selected centers. But the previous\nalgorithm would have  S′ ≠ Ø after selecting k centers, as it would have s ∊ S′, and so it would go on\nand select more than k centers and eventual ly conclude that k centers cannot have covering radius at\nmost r. This contradicts our choice of r, and the contradiction proves that r(C) ≤ 2 r. ▪\n\xa0\n\xa0\nNote the surprising fact that our final greedy 2-approximation\nalgorithm is a very simple modification of the first greedy algorithm that\ndid not work. Perhaps the most important change is simply that our\nalgorithm alway s selects sites as centers (i.e., every mall will be built in one\nof the little towns and not halfway between two of them).\n11.3 Set Cover: A General Greedy Heuristic\nIn this section we will consider a very general problem that we also\nencountered in Chapter 8, the Set Cover Problem. A number of important\nalgorithmic problems can be formulated as special cases of Set Cover , and\nhence an approximation algorithm for this problem will be widely\napplicable. We will see that it is possible to design a greedy algorithm here\nthat produces solutions with a guaranteed approximation factor relative to\nthe optimum, although this facto r will be weaker than what we saw for the\nproblems in Sections 1 1.1 and 11.2.\nWhile the greedy algorithm we design for Set Cover will be very\nsimple, the analysis will be more complex than what we encountered in the\nprevious two sections. There we were able to get by with very simple\nbounds on the (unknown) optimum solution, while here the task of\ncomparing to the optimum is more difficult, and we will need to use more')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 725})","('type', 'Document')"
"('page_content', 'sophisticated bounds. This aspect of the method can be viewed as our first\nexample of the pricing method , which we will explore more fully in the\nnext two sections.\n The Problem\nRecall from our discussion of NP-completeness that the Set Cover Problem\nis based on a set U of n elements and a list S1, …, Sm of subsets of U; we\nsay that a set cover  is a collection of these sets whose union is equal to all\nof U.\nIn the version of the problem we consider here, each set St has an\nassociated weight wi ≥ 0. The goal is to find a set cover C so that the total\nweight  \n\xa0\nis minim ized. Note that this problem is at least as hard as the decision\nversion of Set Cover we encountered earlier; if we set all wi = 1, then the\nminimum weight of a set cover is at most k if and only if there is a\ncollection of at most k sets that covers U.\n Designing the Algorithm\nWe will develop and analyze a greedy algorithm for this problem. The\nalgorithm will have the property  that it builds the cover one set at a time; to\nchoose its next set, it looks for one that seems to make the most progress\ntoward the goal. What is a natural way to define “progress” in this setting?\nDesirable sets have two properties: They have small weight wi, and they\ncover lots of elements. Neither of these properties alone, howeve r, would be\nenough for designing a good approximation algorithm. Instead, it is natural\nto combine these two criteria into the single measure wi/|Si|—that is, by\nselecting Si, we cover |Si| elements at a cost of wi, and so this ratio gives the\n“cost per element covered,” a very reasonable thing to use as a guide.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 726})","('type', 'Document')"
"('page_content', ""Of course, once some sets have already been selected, we are only\nconcerned with how we are doing on the elements still left uncovered. So\nwe will maintain the set R of rema ining uncovered elements and choose the\nset Si that minimizes wi/|Si ∩ R|.\n\xa0\n\xa0\nGreedy-Set-Cover:\nStart with R = U and no sets selected\nWhile R ≠ Ø\nSelect set Si that minimizes wi/|Si ∩ R|\nDelete set Si from R\nEndWhile\nReturn the selected sets\n\xa0\n\xa0\nAs an example of the behavio r of this algorithm, consider what it\nwould do on the instance in Figure 11.6. It would first choose the set\ncontaining the four nodes at the bottom (since this has the best weight-to-\ncoverage ratio, 1/4). It then chooses the set containing the two nodes in the\nsecond row, and finally it choo ses the sets containing the two individual\nnodes at the top. It thereby chooses a collection of sets of total weight 4.\nBecause it myopically chooses  the best option each time, this algorithm\nmisses the fact that there's a way to cover everything using a weight of just\n2 + 2ε, by selecting the two sets that each cover a full column.\n Analyzing the Algorithm\nThe sets selected  by the algorithm clearly form a set cover . The question we\nwant to address is: How much larger is the weight of this set cover than the\nweight w* of an optimal set cover?\nFigur e 11.6 An instance of the Set Cover Problem where the weights of sets\nare either 1 or 1 + ε for some small ε > 0. The greedy algorithm chooses sets\nof total weight 4, rather than the optimal solution of weight 2+ 2 ε."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 727})","('type', 'Document')"
"('page_content', ""As in Sections 11.1 and 11.2, our analysis will require a good lower\nbound on this optimum. In the case of the Load Balancing Problem, we\nused lower bounds that emer ged naturally from the statement of the\nproblem: the average load, and the maximum job size. The Set Cover\nProblem will turn out to be more subtle; “simple” lower bounds are not very\nuseful, and instead we will use a lower bound that the greedy algorithm\nimplicitly constructs as a byproduct.\nRecall the intuitive meaning of the ratio wi/|Si ∩ R| used by the\nalgorithm; it is the “cost paid” for covering each new element. Let's record\nthis cost paid for element s in the quantity cs. We add the following line to\nthe code immediately after selecting the set Si."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 728})","('type', 'Document')"
"('page_content', 'Define cs = wi/|Si ∩ R| for all s ∊ Si ∩ R\n\xa0\n\xa0\nThe values cs do not affect the behavior of the algorithm at all; we view\nthem as a bookkeeping device to help in our comparison with the optimum\nw*. As each set Si is selected, its weight is distrib uted over the costs cs of\nthe elements that are newly covered. Thus these costs completely account\nfor the total weight of the set cover , and so we have\n\xa0\n\xa0\n(11.9) If \n is the set cover obtained by  Greedy-Set-Cover , then ∑Si ∊\n wi = ∑s ∊Ucs.\n\xa0\n\xa0\nThe key to the analysis is to ask how much total cost any single  set Sk\ncan account for—in other words , to give a bound on ∑s ∊Skcs relative to the\nweight wk of the set, even for sets not selected by the greedy algorithm.\nGiving an upper bound on the ratio  \n\xa0\nthat holds for every set says, in effect, “To cover a lot of cost, you must use\na lot of weight. ” We know that the optimum solution must cover the full\ncost Σs ∊U cs via the sets it selects; so this type of bound will establish that it\nneeds to use at least a certain amount of weight. This is a lower bound on\nthe optimum, just as we need for the analysis.\nOur analysis will use the harmonic function')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 729})","('type', 'Document')"
"('page_content', 'To understand its asymptotic size as a function of n, we can interpre t it as a\nsum approximating the area under the curve y = 1/x. Figure 1 1.7 shows how\nit is naturally bounded above by \n , and bounded below by\n. Thus we see that H(n) = Θ(ln n).\nHere is the key to establishing a bound on the performance of the\nalgorithm.\n\xa0\n\xa0\n(11.10)  For every set S k, the sum  ∑S ∊Sk cs is at most H (|Sk|) · wk.\nProof. To simplif y the notation, we will assume that the elements of Sk are the first d = |Sk| elements\nof the set U; that is, Sk = {s1, …, sd}. Furthermore, let us assume that these elements are labeled in\nthe order in which they are assigned a cost csj by the greedy algorithm (with ties broken arbitrarily).\nThere is no loss of generality in doing this, since it simply involves a renaming of the elements in U.\nNow consider the iteration in which eleme nt Sj is covered  by the greedy algorithm, for some j ≤\nd. At the start of this iteration, Sj, Sj+1, …, Sd ∊ R by our labeling of the elements. This implies that\n|Sk ∩ R| is at least d - j + 1, and so the average cost of the set Sk is at most  \nNote that this is not necessarily an equality , since sj may be covered in the same iteration as some of\nthe other elements sj′ for j′ < j. In this iteration, the greedy algorithm selected a set Si of minimum\naverage cost; so this set Si has average cost at most that of Sk. It is the average cost of Si that gets\nassigned to sj, and so we have\nWe now simply add up these inequalities for all elements s ∊ Sk:\n▪')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 730})","('type', 'Document')"
"('page_content', ""Figur e 11.7 Upper and lower bounds for the Harmonic Function H(n).\nWe now comple te our plan to use the bound in (11.10) for comparing\nthe greedy algorithm's set cover to the optimal one. Letting d* = maxi |Si|\ndenote the maximum size of any set, we have the following approximation\nresult.\n\xa0\n\xa0\n(11.11) The set cover C selected by Greedy-Set-Cover has weight at most H(d*) times the optimal\nweight w *.\nProof. Let \n * denote the optimum set cover , so that w* = ∑Si ∊\n*wi. For each of the sets in \n*,\n(11.10) implies\nBecause these sets form a set cover , we have\n \nCombining these with (1 1.9), we obtain the desired bound:"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 731})","('type', 'Document')"
"('page_content', ""▪\n\xa0\n\xa0\nAsymptotically , then, the bound in (11.11) says that the greedy\nalgorithm finds a solution withi n a factor O(log d*) of optimal. Since the\nmaximum set size d* can be a constant fraction of the total number of\nelements n, this is a worst-case upper bound of O(log n). However ,\nexpressing the bound in terms of d* shows us that we're doing much better\nif the lar gest set is small.\nIt's interesting to note that this bound is essentially the best one possible,\nsince there are instances where the greedy algorithm can do this badly . To\nsee how such instances arise, consider again the example in Figure 11.6.\nNow suppose we generalize this so that the underlying set of elements U\nconsists of two tall columns with n/2 eleme nts each. There are still two sets,\neach of weight 1 + ε, for some small ε > 0, that cove r the columns\nseparately . We also create Θ(log  n) sets that generalize the structu re of the\nother sets in the figure: there is a set that covers the bottommos t n/2 nodes,\nanother that covers the next n/4, anoth er that covers the next n/8, and so\nforth. Each of these sets will have weight 1.\nNow the greedy algorithm will choose the sets of size n/2, n/4, n/8, …, in\nthe process producing a solution of weight Ω(log n). Choosing the two sets\nthat cover the columns separat ely, on the other hand, yields the optimal\nsolution, with weight 2 + 2ε. Throug h more complicated constructions, one\ncan stren gthen this to produce instances where the greedy algorithm incurs\na weight that is very close to H(n) times the optimal weight. And in fact, by\nmuch more complicated means, it has been shown that no polynomial-time\napproximation algorithm can achieve an approximation bound much better\nthan H(n) times optimal, unless P = NP .\n11.4 The Pricing Method: Vertex Cover"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 732})","('type', 'Document')"
"('page_content', 'We now turn to our second general technique for designing approximation\nalgorithms, the pricing method . We will introduce this technique by\nconsidering a version of the Vertex Cover Problem. As we saw in Chapter\n8, Vertex Cover is in fact a special case of Set Cover , and so we will begin\nthis section by considering the extent to which one can use reductions in the\ndesign of approximation algorithms. Following this, we will develop an\nalgorithm with a better approximation guarantee than the general bound that\nwe obtained for Set Cover in the previous section.\n The Problem\nRecall that a vertex cover  in a graph G = (V, E) is a set S ⊆ V so that each\nedge has at least one end in S. In the version of the problem we consider\nhere, each verte x i ∊ V has a weight  wi ≥ 0, with the weight of a set S of\nvertices denoted w(S) = ∑i ∊Swi. We would like to find a vertex cover S for\nwhich w(S) is minimum. When all weights are equal to 1, deciding if there\nis a vertex cover of weight at most k is the standard decision version of\nVertex Cover .\nApproximations via Reductions?  Before  we work on developing an\nalgorithm, we pause to discuss an interesting issue that arises: Vertex Cover\nis easily  reducib le to Set Cove r, and we have just seen an approximation\nalgorithm for Set Cover . What does this imply about the approximability of\nVertex Cover? A discussion of this question brings out some of the subtle\nways in which approximation results interact with polynomial-time\nreductions.\nFirst consider the special case in which all weights are equal to 1—that\nis, we are looking for a vertex cover of minimum size. We will call this the\nunweighted case. Recall  that we showed Set Cover to be NP-complete\nusing a reduction from the decision version of unweighted Vertex Cover .\nThat is,')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 733})","('type', 'Document')"
"('page_content', 'This reduction says, “If we had a polynomial-time algorithm that solves the\nSet Cover Problem, then we could use this algorithm to solve the Vertex\nCover Problem in polynomial time.” We now have a polynomial-time\nalgorithm for the Set Cover Problem that approximates the solution. Does\nthis imply that we can use it to formulate an approximation algorithm for\nVertex Cover?\n(11.12)  One can use the Set Cover appr oximation algorithm to give an H (d)-approximation algorithm\nfor the weighted V ertex Cover Pr oblem, wher e d is the maximum degr ee of the graph .\nProof. The proof is based on the reduction that showed Vertex Cover ≤P Set Cover , which also\nextends to the weight ed case. Consider an instance of the weighted Vertex Cover Problem, specified\nby a graph  G = (V, E). We define an instan ce of Set Cover as follows. The underlying set U is equal\nto E. For each node i, we define a set Si consisting of all edges incident to node i and give this set\nweight wi. Collections of sets that cover U now correspond precisely to vertex covers. Note that the\nmaximum size of any Si is precisely the maximum degree d.\nHence we can use the approximation algorithm for Set Cover to find a vertex cover whose\nweight is within a factor of H(d) of minimum. ▪\nThis H(d)-approximation is quite good when d is small; but it gets\nworse as d gets larger, approaching a bound that is logarithmic in the\nnumber of vertices. In the following, we will develop a stronger\napproximation algorithm that comes within a factor of 2 of optimal.\nBefore turning to the 2-approximation algorithm, we make the\nfollowing further observation: One has to be very careful when trying to use\nreductions for designing approximation algorithms. It worked in (11.12),\nbut we made sure to go through an argument for why it worked; it is not the\ncase that every polynomial-time reduction leads to a comparable\nimplication for approximation algorithms.\nHere is a cautio nary example. We used Independent Set to prove that\nthe V ertex Cover Problem is NP-complete. Specifically , we proved  \n\xa0\nwhich states that “if we had a polynomial-time algorithm that solves the\nVertex Cover Problem, then we could use this algorithm to solve the\nIndependent Set Problem in polynomial time.” Can we use an\napproximation algorithm for the minimum-size vertex cover to design a')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 734})","('type', 'Document')"
"('page_content', ""comparably good approximation algorithm for the maximum-size\nindependent set?\nThe answer is no. Recall that a set I of vertices is independent if and\nonly if its complement S = V - I is a vertex cover . Given a minimum-size\nvertex cover S*, we obtain a maximum-size independent set by taking the\ncomplement I* = V - S. Now suppose we use an approximation algorithm\nfor the Vertex Cover Problem to get an approximately minimum vertex\ncover S. The complement I = V - S is indee d an independent set—t here's no\nproblem there. The trouble is when we try to determine our approximation\nfactor for the Independent Set Problem; I can be very far from optimal.\nSuppose, for example, that the optimal vertex cover S* and the optimal\nindependent set I* both have size |V|/2. If we invok e a 2-approximation\nalgorithm for the Vertex Cover Problem, we may perfectly well get back the\nset S = V. But, in this case, our “approximately maximum independent set”\nI = V  - S has no elements.\n Designing the Algorithm: The Pricing Method\nEven though (11.12) gave us an approximation algorithm with a provable\nguarantee, we will be able to do better . Our approach forms a nice\nillustration of the pricing method  for designing approximation algorithms.\nThe Pricing Method to Minimize Cost The pricing method (also known as\nthe primal-dual method ) is motivated by an economic perspective. For the\ncase of the Vertex Cover Problem, we will think of the weights on the nodes\nas costs , and we will think of each edge  as having to pay for its “share” of\nthe cost of the vertex cover we find. We have actually just seen an analysis\nof this sort, in the greedy algorithm for Set Cover from Section 11.3; it too\ncan be thought of as a pricing  algorithm. The greedy algorithm for Set\nCover defined values cs, the cost the algorithm paid for covering element s.\nWe can think of cs as the element s's “share” of the cost. Statement (11.9)\nshows that it is very natural to think of the values cs as cost-shares, as the\nsum of the cost-shares ∑S ∊U cs is the cost of the set cover C returned by the\nalgorithm, ∑Si ∊Cwi. The key to proving that the algorithm is an H(d*)-\napproximation algorithm was a certain approximate “fairness” property for\nthe cost- shares: (11.10) shows that the elements in a set Sk are charged by at\nmost an H(|Sk|) factor more than the cost of covering them by the set Sk."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 735})","('type', 'Document')"
"('page_content', ""In this section, we'll develop the pricing technique through another\napplication, Vertex Cover . Again, we will think of the weight wi of the\nvertex i as the cost for using i in the cover. We will think of each edge e as a\nseparate “agent”  who is willing to “pay” something to the node that covers\nit. The algorithm will not only find a vertex cover S, but also determine\nprices pe ≥ 0 for each edge e ∊ E, so that if each edge e ∊ E pays the price\npe, this will in total approximately cover the cost of S. These prices pe are\nthe analogues of cs from the Set Cover Algorithm.\nThinking of the edges as agent s suggests some natural fairness rules\nfor prices, analogous to the property proved by (11.10). First of all,\nselecting a vertex i covers all edges  incident to i, so it would be “unfair” to\ncharge these incident edges in total more than the cost of vertex i. We call\nprices pe fair if, for each vertex i, the edges adjac ent to i do not have to pay\nmore than the cost of the vertex: ∑e=(i,j)Pe ≤ wi. Note that the property\nproved by (11.10) for Set Cover  is an approximate fairness cond ition, while\nin the Vertex Cover algorithm we'll actually use the exact fairn ess defined\nhere. A useful fact about fair prices is that they provide a lower bound on\nthe cost of any solution.\n\xa0\n\xa0\n(11.13)  For any vertex cover S*, and any nonnegative and fair prices p e, we have  ∑e ∊EPe ≤ w(S*).\nProof. Cons ider a vertex cover S*. By the definition of fairness, we have ∑e=(i,j) Pe ≤ wi for all\nnodes i ∊ S*. Adding these inequalities over all nodes in S*, we get\n \nNow the expression on the left-hand side is a sum of terms, each of which is some edge price pe.\nSince S* is a vertex cover , each edge e contributes at least one term pe to the left-hand side. It may\ncontribute more than one copy of pe to this sum, since it may be covered from both ends by S*; but\nthe prices are nonnegative, and so the sum on the left-hand side is at least as large as the sum of all\nprices pe. That is,"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 736})","('type', 'Document')"
"('page_content', 'Combining this with the previous inequality , we get\n  \nas desired.\n▪\n\xa0\n\xa0\nThe Algorithm  The goal of the approximation algorithm will be to find a\nvertex cover and to set prices at the same time. We can think of the\nalgorithm as being greedy in how it sets the prices. It then uses these prices\nto drive the way it selects nodes for the vertex cover .\nWe say that a node i is tight (or “paid for”) if ∑e=(i,j) Pe = wi.\n\xa0\n\xa0\nVertex-Cover -Approx( G, w):\nSet pe = 0 for all e ∊ E\nWhile there is an edge e = (i, j) such that neither i nor j is tight\nSelect such an edge e\nIncrease pe without violating fairness\nEndWhile\nLet S be the set of all tight nodes\nReturn S\n\xa0\n\xa0\nFor example, consider the execu tion of this algorithm on the instance\nin Figure 1 1.8. Initially , no node is tight; the algorithm decides to select the\nedge (a, b). It can raise the price paid by (a, b) up to 3, at which point the\nnode b becomes tight and it stops. The algorithm then selects the edge (a,\nd). It can only raise this price up to 1, since at this point the node a becomes\ntight (due to the fact that the weight of a is 4, and it is already incident to an\nedge that is paying 3). Finally , the algorithm selects the edge (c, d). It can\nraise the price paid by (c, d) up to 2, at which point d become s tight. We\nnow have a situation where all edges have at least one tight end, so the')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 737})","('type', 'Document')"
"('page_content', ""algorithm termin ates. The tight nodes are a, b, and d; so this is the resulting\nvertex cover . (Note that this is not the minimum-weight vertex  cover; that\nwould be obtained by selecting a and c.)\nFigur e 11.8 Parts (a)–(d) depict the steps in an execution of the pricing\nalgorithm on an instance of the weighted Vertex Cover Problem. The\nnumbers inside the nodes indicate their weights; the numbers annotating the\nedges indicate the prices they pay as the algorithm proceeds.\n Analyzing the Algorithm\nAt first sight, one may have the sense that the vertex cover S is fully  paid\nfor by the prices: all nodes in S are tight, and hence the edges adjacent to\nthe node i in S can pay for the cost of i. But the point is that an edge e can\nbe adjacent to more than one node in the vertex cover (i.e., if both ends of e\nare in the vertex cover), and hence e may have to pay for more than one\nnode. This is the case, for example, with the edges (a, b) and (a, d) at the\nend of the execution in Figure 1 1.8.\nHowever , notice that if we take edges for which both ends happened to\nshow up in the vertex cover , and we charge them their price twice, then\nwe're exactly paying for the vertex cover . (In the example, the cost of the"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 738})","('type', 'Document')"
"('page_content', ""vertex cover is the cost of nodes a, b, and d, which is 10. We can account\nfor this cost exactly by charging (a, b) and (a, d) twice, and (c, d) once.)\nNow , it's true that this is unfair to some edges, but the amount of unfairness\ncan be bounded : Each edge gets charged its price at most two times (once\nfor each end).\nWe now make this ar gument precise, as follows.\n\xa0\n\xa0\n(11.14)  The set S and prices p r eturned by the algorithm satisfy the inequality  w(S) ≤ ∑ e ∊E Pe.\nProof. All nodes in S are tight, so ∑ e=(i,j) Pe = wi for all i ∊ S. Adding over all nodes in S we get  \n \nAn edge e = (i,j) can be included in the sum on the right-hand side at most twice (if both i and j are in\nS), and so we get  \n \nas claimed. ▪\n\xa0\n\xa0\nFinally , this factor of 2 carries into an argument that yields the\napproximation guarantee.\n\xa0\n\xa0\n(11.15)  The set S returned by the algorithm is a vertex cover , and its cost is at most twice the\nminimum cost of any vertex cover .\nProof. First note that S is indeed a vertex cover. Suppose, by contradiction, that S does not cover\nedge e = (i, j). This implies that neither i nor j is tight, and this contradicts the fact that the While loop\nof the algorithm terminated.\nTo get the claimed approximation bound, we simply put together statement (11.14) with (11.13).\nLet p be the prices set by the algorithm, and let S* be an optimal vertex cover . By (11.14) we have 2\n∑e ∊E Pe ≥ w(S), and by (1 1.13) we have ∑ e ∊E Pe ≤ w(S*)."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 739})","('type', 'Document')"
"('page_content', ""In other words, the sum of the edge prices is a lower bound on the weight of any vertex cover ,\nand twice the sum of the edge prices is an upper bound on the weight of our vertex cover:\n▪\n\xa0\n\xa0\n11.5 Maximization via the Pricing Method: The\nDisjoint Paths Problem\nWe now continue the theme of pricing algorithms with a fundamental\nproblem that arises in network routing: the Disjoint Paths Problem . We'll\nstart out by developing a greedy algorithm for this problem and then show\nan improved algorithm based on pricing.\n The Problem\nTo set up the problem, it helps to recall one of the first applications we saw\nfor the Maximum -Flow Problem : finding disjoint paths in graphs, which we\ndiscussed in Chapter 7. There we were looking for edge-disjoint paths all\nstarting at a node s and ending at a node t. How crucial is it to the\ntractability of this problem that all paths have to start and end at the same\nnode? Using the technique from Section 7.7, one can extend this to find\ndisjoint paths where we are given a set of start nodes S and a set of\nterminals T, and the goal is to find edge- disjoint paths where paths may\nstart at any node in S and end at any node in T.\nHere, however , we will look at a case where each path to be routed has\nits own designated starting node and ending node. Specifically , we consider\nthe following Maximum Disjo int Paths Problem . We are given a directed\ngraph G, together with k pairs of nodes (s1, t1), (s2, t2), …, (sk, tk) and an\ninteger capacity c. We think of each pair (si, ti) as a routing request , which\nasks for a path from si to ti. A solution to this instance consists of a subset"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 740})","('type', 'Document')"
"('page_content', ""of the requests we will satisfy , I ⊆ {1, …, k}, together with paths that\nsatisfy them while not overloadi ng any one edge: a path Pi for i ∊ I so that\nPi goes from si to ti, and each edge is used by at most c paths. The problem\nis to find a solution with |I| as large as possible—that is, to satisfy as many\nrequests as possible. Note that the capacity c controls how much “sharing”\nof edges we allow; when c = 1, we are requiring the paths to be fully edge-\ndisjoint, while lar ger c allows some overlap among the paths.\nWe have  seen in Exercise 39 in Chapter 8 that it is NP-complete to\ndetermine wheth er all k routing requests can be satisfied  when the paths are\nrequired to be node-disjoint. It is not hard to show that the edge-disjoint\nversion of the problem (corresponding to the case with c = 1) is also NP-\ncomplete.\nThus it turns out to have been crucial for the application of efficient\nnetwork flow algorithms that the endpoints of the paths not be explicitly\npaired up as they are in Maximum Disjoint Paths. To develop this point a\nlittle further , suppose we attemp ted to reduce Maximum Disjoint Paths to a\nnetwork flow problem by defin ing the set of sources to be S = {s1, s2, …,\nsk}, defining the set of sinks to be T = {t1, t2, …, tk}, setting each edge\ncapacity to be c, and looking for the maximum possible number of disjoint\npaths starting in S and ending in T. Why wouldn't this work? The problem\nis that there's no way to tell the flow algorithm that a path starti ng at si ∊ S\nmust  end at ti ∊ T; the algorithm guarantees only that this path will end at\nsome  node in T. As a result, the paths that come out of the flow algorithm\nmay well not constitute a solution to the instance of Maximum Disjoint\nPaths, since they might not link a source st to its corresponding endpoint ti.\nDisjoint paths problems, where we need to find paths connecting\ndesignated pairs of terminal nodes, are very common in networking\napplications. Just think about paths on the Internet that carry streaming\nmedia or Web data, or paths through the phone network carrying voice\ntraffic.1 Paths sharing edges can interfere with each other , and too many\npaths sharing a single edge will cause problems in most applications. The\nmaximum allow able amount of sharing will differ from application to\napplication. Requiring the paths to be disjoint is the stronges t constraint,\neliminating all interference betw een paths. We'll see, however , that in cases\nwhere some sharing is allowed  (even just two paths to an edge), better\napproximation algorithms are possible."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 741})","('type', 'Document')"
"('page_content', ""Designing and Analyzing a Greedy Algorithm\nWe first consider a very simple algorithm for the case when the capacity c =\n1: that is, when the paths need to be edge-disjoint. The algorithm is\nessentially greedy , except that it exhibits a preference for short paths. We\nwill show that this simple algorithm is an O(√m)-approximation algorithm,\nwhere m = |E| is the number of edges in G. This may sound like a rather\nlarge factor of approximation, and it is, but there is a strong sense in which\nit is essentially the best we can do. The Maximum Disjoint Paths Problem is\nnot only NP-complete, but it is also hard to approximate: It has been shown\nthat unless P = NP, it is impossible for any polynomial-time algorithm to\nachieve an approximation bound  significantly better than O(√m) in arbitrary\ndirected graphs.\nAfter developing the greedy algorithm, we will consider a slightly\nmore sophisticated pricing algorithm for the capacitated version. It is\ninteresting to note that the pricing algorithm does much better than the\nsimple greedy algorithm, even when the capacity c is only slightly more\nthan 1.\nFigur e 11.9 A case in which it's crucial that a greedy algorithm for\nselecting disjoint paths favors short paths over long ones.\n\xa0\n\xa0\nGreedy-Disjoint-Paths:\nSet I = Ø\nUntil no new path can be found\nLet Pi be the shortest path (if one exists) that is edge-disjoint from previously selected paths,\nand connects some ( si, ti) pair that is not yet connected\nAdd i to I and select path Pi to connect si to ti\nEndUntil"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 742})","('type', 'Document')"
"('page_content', ""Analyzing the Algorithm  The algorithm clearly selects edge-disjoint paths.\nAssuming the graph G is connected, it must select at least one path. But\nhow does the number of paths selected compare with the maximum\npossible? A kind of situation we need to worry about is shown in Figure\n11.9: One of the paths, from s1 to t1, is very long, so if we select it first, we\neliminate up to Ω( m) other paths.\nWe now show that the greedy algorithm's preference for short paths\nnot only avoids the problem in this example, but in general it limits the\nnumber of other paths that a selected path can interfere with.\n\xa0\n\xa0\n(11.16)  The algorithm  Greedy-Disjoint-Paths is a (2√m + 1)-approximation algorithm for the\nMaximum Disjoint Paths Pr oblem .\nProof. Cons ider an optimal solution: Let I* be the set of pairs for which a path was selected in this\noptimum solution, and let P*i for i ∊ I* be the selected paths. Let I denote the set of pairs returned by\nthe algorithm, and let Pi for i ∊ I be the corresponding paths. We need to bound |I*| in terms of |I|.\nThe key to the analysis is to make a distin ction between short and long paths and to consider them\nseparately . We will call a path long if it has at least √m edges, and we will call it short  otherwise. Let\nI*s denote the set of indices in I* so that the correspo nding path P*i is short, and let Is denote the set\nof indices in I so that the corresponding path Pi is short.\nThe graph G has m edges, and each long path uses at least √m edges, so there can be at most √m\nlong paths in I*.\nNow consi der the short paths in I*. In order for I* to be much larger than I, there would have to\nbe many pairs that are connected in I* but not in I. Thus let us consider pairs that are connected by\nthe optimum using a short path, but are not connected by the greedy algorithm. Since the path P*i\nconnecting si and ti in the optimal solutio n I* is short, the greedy algorithm would have selected this\npath, if it had been available, before selecting any long paths. But the greedy algorithm did not\nconnect si and ti at all, and hence one of the edges e along the path P*i must  occu r in a path Pj that\nwas selected earlier by the greedy algorithm. W e will say that edge e blocks  the path P*i.\nNow the lengths of the paths selected by the greedy algorithm are monotone increasing, since\neach iteration has fewer options for choosing paths. The path Pj was select ed before considering P*i\nand hence it must be shorter: |Pj| ≤ |P*i| ≤ √m. So path Pj is short. Since the paths used by the\noptimum are edge-disjoint, each edge in a path Pj can block at most one path P*i. It follows that each\nshort path Pj blocks at most √ m paths in the optimal solution, and so we get the bound"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 743})","('type', 'Document')"
"('page_content', 'We use this to produc e a bound on the overall size of the optimal solution. To do this, we view\nI* as consisting of three kinds of paths, following the analysis thus far:  \nlong paths, of which there are at most √ m;\npaths that are also in I; and\nshort paths that are not in I, which we have just bounded by | Is|√m.\n \nPutting this all together , and using the fact that |I| ≥ 1 whenever at least one set of terminal pairs can\nbe connected, we get the claimed bound:  \n▪\n\xa0\n\xa0\nThis provides an approximatio n algorithm for the case when the\nselected paths have to be disjoint. As we mentioned earlier , the\napproximation bound of O(√m) is rather weak, but unless P = NP, it is\nessentially the best possible for the case of disjoint paths in arbitrary\ndirected graphs.\n Designing and Analyzing a Pricing Algorithm\nNot letting any two paths use the same edge is quite extreme; in most\napplications one can allow a few paths to share an edge. We will now\ndevelop an analogous algorithm, based on the pricing method, for the case\nwghere c > 1 paths may share any edge. In the disjoint case just consider ed,\nwe viewed all edges as equal and preferred short paths. We can think of this\nas a simple kind of pricing algor ithm: the paths have to pay for using up the\nedges, and each edge has a unit cost. Here we will conside r a pricing\nscheme in which edges are viewed as more expensive if they have been\nused already, and hence have less capacity left over. This will encourage the\nalgorithm to “spread out” its paths, rather than piling them up on any single\nedge. We will refer to the cost of an edge e as its length ℓe, and define the\nlength  of a path to be the sum of the lengths of the edges it contains: ℓ(P) =\n∑e ∊P ℓe. We will use a multiplicative parameter β to incre ase the length of\nan edge each time an additional path uses it.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 744})","('type', 'Document')"
"('page_content', ""Greedy-Paths-with-Capacity:\nSet I = Ø\nSet edge length ℓe = 1 for all e ∊ E\nUntil no new path can be found\nLet Pi be the shortest path (if one exists) so that adding Pi to\nthe selected set of paths does not use any edge more than c\ntimes, and Pi connects some ( si, ti) pair not yet connected\nAdd i to I and select path Pi to connect si to ti\nMultiply the length of all edges along Pi by β\nEndUntil\n\xa0\n\xa0\nAnalyzing the Algorithm  For the analysis we will focus on the simplest\ncase, when at most two paths may use the same edge—that is, when c = 2.\nWe'll see that, for this case, setting β = m1/3 will give the best approximation\nresult for this algorithm. Unlike the disjoint paths case (when c = 1), it is\nnot know n whether the approximation bounds we obtain here for c > 1 are\nclose to the best possible for polynomial-time algorithms in general,\nassuming P ≠ NP.\nThe key to the analysis in the disjoint case was to distinguish “short”\nand “long” paths. For the case when c = 2, we will consider a path Pi\nselected by the algorithm to be short  if the length is less than β2. Let Is\ndenote the set of short paths selected by the algorithm.\nNext we want to compare the number of paths selected with the\nmaximum possible. Let I* be an optimal solution and P*i be the set of paths\nused in this solution. As before , the key to the analysis is to consider the\nedges that block the selection of paths in I*. Long paths can block a lot of\nother paths, so for now we will focus on the short paths in Is. As we try to\ncontinue follow ing what we did in the disjoint case, we immediately run\ninto a difficulty , however . In that case, the length of a path in I* was simply\nthe number of edges it containe d; but here, the lengths are changing as the\nalgorithm runs, and so it is not clear how to define the length of a path in I*"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 745})","('type', 'Document')"
"('page_content', ""for purposes of the analysis. In other words, for the analysis, when should\nwe measure this length? (At the beginning of the execution? At the end?)\nIt turns out that the crucial moment in the algorithm, for purposes of\nour analysis, is the first point at which there are no short paths left to\nchoose. Let \n  be the length function at this point in the execution of the\nalgorithm; we'll use \n  to measure the length of paths in I*. For a path P, we\nuse \n (P) to deno te its length, ∑e ∊P \ne. We consider a path P*i in the optimal\nsolution I* short  if \n(P*i) < β2, and long otherwise. Let I*s denote the set of\nshort paths in I*. The first step is to show that there are no short paths\nconnecting pairs that are not connected by the approximation algorithm.\n\xa0\n\xa0\n(11.17)  Consider a sour ce-sink pair i  ∊ I* that is not connected by the approximation algorithm; that\nis, i ∉ I. Then  \n(P*i) ≥ β2.\nProof. As long as short paths are being selected, we do not have to worry about explicitly enforcing\nthe require ment that each edge be used by at most c = 2 paths: any edge e considered for selection by\na third path would already have length ℓ e = β2, and hence be long.\nConsider the state of the algorithm with length \n . By the argument in the previous paragrap h, we can\nimagine the algorithm having run up to this point without caring about the limit of c; it just selected a\nshort path whenever it could find one. Since the endpoints si, ti of P*i are not connected by the\ngreedy algorithm, and since there are no short paths left when the length function reaches \n , it must\nbe the case that path P*i has length at least β2 as measured by \n . ▪\n\xa0\n\xa0\nThe analysis in the disjoint case used the fact that there are only m\nedges to limit the number of long paths. Here we consider length \n, rather\nthan the number of edges, as the quantity that is being consume d by paths.\nHence, to be able to reason about this, we will need a bound on the total\nlength in the graph ∑e \ne. The sum of the lengths over all edges ∑e ℓe starts\nout at m (length 1 for each edge). Adding a short path to the solution Is can\nincrease the length by at most β3, as the selected path has length at most β2,\nand the lengths of the edges are increased by a β factor along the path. This\ngives us a useful comparison between the number of short paths selected\nand the total length."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 746})","('type', 'Document')"
"('page_content', '(11.18)  The set Is of short paths selected by the approximation algorithm, and the lengths \n , satisfy\nthe relation  ∑e \ne ≤ β3|Is| + m.\n\xa0\n\xa0\nFinally , we prove an approximation bound for this algorithm. We will\nfind that even though we have simply increased the number of paths\nallowed on each edge from 1 to 2, the approximation guarantee drops by a\nsignificant amount that essentially incorporates this change into the\nexponent: from O(m1/2) down to O(m1/3).\n\xa0\n\xa0\n(11.19) The algorithm  Greedy-Paths-with-Capacity , using β = m1/3, is a (4m1/3 + 1)-approximation\nalgorithm in the case when the capacity c = 2 .\nProof. We first bound |I* - I|. By (11.17), we have \n(P*) ≥ β2 for all i ∊ I* - I. Summing over all\npaths in I* - I, we get  \n \nOn the other hand, each edge is used by at most two paths in the solution I*, so we have  \nCombining these bounds with (1 1.18) we get  \n \nFinally , dividing through by β2, using | I| ≥ 1 and setting β = m1/3, we get that | I*| ≤ (4 m1/3 + 1)| I|. ▪')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 747})","('type', 'Document')"
"('page_content', ""The same algorithm also works for the capacitated Disjoint Path\nProblem with any capacity c > 0. If we choose β = m1/(c+1), then the\nalgorithm is a (2cm1/(c+1) + 1)-approximation algorithm. To extend the\nanalysis, one has to consider paths to be short if their length is at most βc.\n\xa0\n\xa0\n(11.20) The algorithm  Greedy-Paths-with-Capacity , using β = m1/c+1, is a (2cm1/(c+1) + 1-\napproximation algorithm when the the edge capacities ar e c.\n\xa0\n\xa0\n11.6 Linear Programming and Rounding: An\nApplication to Vertex Cover\nWe will start by introducing a powerful technique from operations research:\nlinear programming . Linear programming is the subject of entire courses,\nand we will not attempt to provide any kind of comprehensive overview of\nit here. In this section, we will introduce some of the basic ideas underlying\nlinear programming and show how these can be used to approximate NP-\nhard optimization problems.\nRecall that in Section 11.4 we developed a 2-approximation algorithm\nfor the weighted Vertex Cover Problem. As a first application for the linear\nprogramming technique, we'll give here a different 2-approximation\nalgorithm that is conceptually much simpler (though slower  in running\ntime).\nLinear Programming as a General Technique\nOur 2-approxim ation algorithm for the weighted version of Vertex Cover\nwill be based on linear programming. We describe linear programming here\nnot just to give the approximatio n algorithm, but also to illustra te its power\nas a very general technique.\nSo what is linear programming? To answer this, it helps to first recall,\nfrom linear algebra, the proble m of simultaneous linear equations. Using"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 748})","('type', 'Document')"
"('page_content', 'matrix-vector notation, we have a vector x of unknown real numbers, a\ngiven matrix A, and a given vector b; and we want to solve the equation Ax\n= b. Gaussian elimination is a well-known efficient algorithm for this\nproblem.\nThe basic Linear Programming  Problem can be viewed as a more\ncomplex version of this, with inequalities in place of equations.\nSpecifically , consider the problem of determining a vector x that satisfies Ax\n≥ b. By this notatio n, we mean that each coordinate of the vector Ax should\nbe great er than or equal to the corresponding coordinate of the vector b.\nSuch systems of inequalities define regions in space. For examp le, suppose\nx = (x1, x2) is a two-dimensional vector , and we have the four inequalities  \n\xa0\nThen the set of solutions is the region in the plane shown in Figure 1 1.10.\nGiven a region defined by Ax ≥ b, linear programming seeks to\nminimize a linear combination of the coordinates of x, over all x belonging\nto the region. Such a linear combination can be written ctx, where c is a\nvector of coefficients, and ctx denotes the inner product of two vectors.\nThus our standard form for Linear Programming, as an optimization\nproblem, will be the following.\n\xa0\n\xa0\nGiven an m × n matrix A, and vectors b ∊ Rm and c ∊ Rn, find a vector x ∊\nRn to solve the following optimization pr oblem:  \nctx is often called the objective function  of the linear program, and Ax ≥ b is\ncalled the set of constraints . For example, suppose we define the vector c to')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 749})","('type', 'Document')"
"('page_content', ""be (1.5,1) in the example in Figure 1 1.10; in other words , we are seeking  to\nminimize the quantity 1.5 x1 + x2 over the region defined by the inequalities.\nThe solution to this would be to choose the point x = (2, 2), where  the two\nslanting lines cross; this yields a value of ctx = 5, and one can check that\nthere is no way to get a smaller value.\nFigur e 11.10 The feasible region of a simple linear program.\nWe can phrase Linear Programming as a decision problem in the\nfollowing way .\nGiven a matrix A, vectors b and c, and a bound γ, does there exist x so that\nx ≥ 0, Ax ≥ b, and ctx ≤ γ?\nTo avoid issues related to how we represent real numbers, we will assume\nthat the coordinates of the vectors and matrices involved are integers.\nThe Computational Complexity of Linear Programming  The decision\nversion of Linear Programmin g is in 1NTP . This is intuitively very\nbelievable—we just have to exhibit a vector x satisfying the desired\nproperties. The one concern is that even if all the input numbers are\nintegers, such a vector x may not have integer coordina tes, and it may in\nfact require very large precision to specify: How do we know that we'll be\nable to read and manipulate it in polynomial time? But, in fact, one can"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 750})","('type', 'Document')"
"('page_content', ""show that if there is a solution, then there is one that is rational and needs\nonly a polynomial number of bits to write down; so this is not a problem.\nLinear Programming was also known to be in co-NP for a long time,\nthough this is not as easy to see. Students who have taken a linear\nprogramming course may notice that this fact follows from linear\nprogramming duality .2\nFor a long time, indeed, Linear Programming was the most famous\nexample of a problem in both NP and co-NP that was not known to have a\npolynomial-time solution. Then, in 1981, Leonid Khachiyan, who at the\ntime was a young researcher in the Soviet Union, gave a polyn omial-time\nalgorithm for the problem. After some initial concern in the U.S. popular\npress that this discovery might turn out to be a Sputnik-like  event in the\nCold War (it didn't), researchers settled down to understand exactly what\nKhachiyan had done. His initial algorithm, while polynomial-t ime, was in\nfact quite slow and impractical ; but since then practical polynomial-time\nalgorithms—so-called interior point methods —have also been developed\nfollowing the work of Narendra Karmarkar in 1984.\nLinear programming is an interesting example for another reason as\nwell. The most widely used algorithm for this problem is the simplex\nmethod . It works very well in practice and is competitive with polynomial-\ntime interior methods on real-world problems. Yet its worst-case running\ntime is known to be exponential; it is simply that this exponent ial behavior\nshows up in practice only very rarely . For all these reasons, linear\nprogramming has been a very useful and important example for thinking\nabout the limits of polynomial time as a formal definition of ef ficiency .\nFor our purposes here, though,  the point is that linear programming\nproblems can be solved in polynomial time, and very efficient algorithms\nexist in practice. You can learn a lot more about all this in courses on linear\nprogramming. The question we ask here is this: How can linear\nprogramming help us when we want to solve combinatorial problems such\nas Vertex Cover?\nVertex Cover as an Integer Program\nRecall that a vertex cover  in a graph G = (V, E) is a set S ⊆ V so that each\nedge has at least one end in S. In the weighted Vertex Cover Problem, each\nvertex i ∊ V has a weight wi ≥ 0, with the weight of a set S of vertices"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 751})","('type', 'Document')"
"('page_content', 'denoted \n . We would like to find a vertex cover S for which\nw(S) is minimum.\nWe now try to formulate a linear program that is in close\ncorrespondence with the Vertex Cover Problem. Thus we consider a graph\nG = (V, E) with a weight wi ≥ 0 on each node i. Linear programming is\nbased on the use of vectors of variables. In our case, we will have a decision\nvariable xi for each node i ∊ V to model the choice of whether to include\nnode i in the vertex cover; xi = 0 will indicate  that node i is not in the vertex\ncover , and xi = 1 will indicate that node i is in the vertex  cover . We can\ncreate a single n-dimensional vector x in which the ith coordinate\ncorresponds to the ith decision variable xi.\nWe use linear inequalities to encode the requirement that the selected\nnodes form a vertex cover; we use the objective function to enco de the goal\nof minimizing the total weight. For each edge (i, j) ∊ E, it must have one\nend in the vertex cover , and we write this as the inequality xi + xj ≥ 1.\nFinally , to express the minimization problem, we write the set of node\nweights as an n-dimensional vector w, with the ith coordinate corresponding\nto wi; we then seek to minimize wtx. In summary , we have formulated the\nVertex Cover Problem as follows.  \nWe claim that the vertex covers of G are in one-to-one correspondence\nwith the solutions x to this system of linear inequalities in which all\ncoordinates are equal to 0 or 1.\n\xa0\n\xa0\n(11.21)  S is a vertex cover in G if and only if the vector x, defined as xi = 1 for i ∊ S, and xi = 0 for i\n∉ S, satisfies the constraints in (VC.IP). Further , we have w (S) = wtx.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 752})","('type', 'Document')"
"('page_content', 'We can put this system into the matrix form we used for linear\nprogramming, as follows. We define a matrix A whose columns correspond\nto the nodes in V and whose rows  correspond to the edges in E; entry A[e, i]\n= 1 if node i is an end of the edge e, and 0 otherwise. (Note that each row\nhas exactly two nonzero entries.) If we use \n  to denote the vector with all\ncoordinates equa l to 1, and \n  to denote the vector with all coordinates equal\nto 0, then the system of inequalities above can be written as  \nBut keep in mind that this is not just an instance of the Linear Programming\nProblem: We have crucially required that all coordinates in the solution be\neither 0 or 1. So our formulation suggests that we should solve the problem  \n\xa0\nThis is an instance of the Linear  Programming Problem in which we require\nthe coordinates of x to take integer values; without this extra constraint, the\ncoordinates of x could be arbitrary real numbers. We call this problem\nInteger Programming , as we are looking for integer -valued solutions to a\nlinear program.\nInteger Program ming is considerably harder than Linear Programming;\nindeed, our discussion really constitutes a reduction from Vertex Cover to\nthe decision version of Intege r Programming. In other words, we have\nproved\n\xa0\n\xa0\n(11.22)  Vertex Cover ≤ P Integer Programming.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 753})","('type', 'Document')"
"('page_content', 'To show the NP-completeness of Integer Programming, we would still\nhave to establish  that the decisio n version is in NP. There is a complication\nhere, as with Linear Programmi ng, since we need to establish that there is\nalways a solutio n x that can be written using a polynomial number of bits.\nBut this can indeed be proven. Of course, for our purposes, the integer\nprogram we are dealing with is explicitly constrained to have solutions in\nwhich each coordinate is either 0 or 1. Thus it is clearly in NP, and our\nreduction from Vertex Cover establishes that even this special case is NP-\ncomplete.\nUsing Linear Programming for Vertex Cover\nWe have yet to resolve whether our foray into linear and integer\nprogramming will turn out to be useful or simply a dead end. Trying to\nsolve the integer programming problem (VC.IP) optimally is clearly not the\nright way to go, as this is NP-hard.\nThe way to make progress is to exploit the fact that Linear\nProgramming is not as hard as Integer Programming. Suppose we take\n(VC.IP) and modify it, dropping the requirement that each xi ∊ {0,1} and\nreverting to the constraint that each xi is an arbitrary real number between 0\nand 1. This gives us an instanc e of the Linear Programming Problem that\nwe could  call (VC.LP), and we can solve it in polynomial time: We can find\na set of values {x*} betwe en 0 and 1 so that x*i + x*j ≥ 1 for each edge (i,j),\nand \n  is minimized. Let x* denote this vector , and wLP = wtx* denote\nthe value of the objective function.\nWe note the following basic fact.\n\xa0\n\xa0\n(11.23) Let S* denote a vertex cover of minimum weight. Then w LP ≤ w(S*).\nProof. Vertex covers of G correspond to integer solutions of (VC.IP), so the minimum of \n over all integer x vectors is exactly the minimum-weight vertex\ncover . To get the minimum of the linear program (VC.LP), we allow x to take arbitrary real-number\nvalues—that is, we minimize over many more choices of x—and so the minimum of (VC.LP) is no\nlarger than that of (VC.IP). ▪')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 754})","('type', 'Document')"
"('page_content', 'Note that (11.23) is one of the crucial ingredients we need for an\napproximation algorithm: a good lower bound on the optimum, in the form\nof the ef ficiently computable quantity wLP.\nHowever , wLP can definitely be smaller than w(S*). For example, if the\ngraph G is a triangle and all weights are 1, then the minimum vertex cover\nhas a weight of 2. But, in a linear programming solution, we can set xi = ½\nfor all three vertices, and so get a linear programming solution of weight\nonly \n . As a more general example, consider a graph on n nodes in which\neach pair of nodes is connected by an edge. Again, all weights are 1. Then\nthe minimum vertex cover has weight n - 1, but we can find a linear\nprogramming solution of value n/2 by setting xi = ½ for all vertices i.\nSo the question is: How can solving this linear program help us\nactually find a near-optimal vertex cover? The idea is to work with the\nvalues x*i and to infer a vertex cover S from them. It is natural that if x*i =\n1 for some node i, then we should  put it in the vertex cover S; and if x*i = 0,\nthen we should leave it out of S. But what should we do with fractional\nvalues in between? What should we do if x*i = .4 or x*i = .5? The natural\napproach here is to round . Given a fracti onal solution {x*i}, we define  \n—that is, we round values at least ½ up, and those below ½\ndown.\n\xa0\n\xa0\n(11.24) The set S defined in this way is a vertex cover , and w (S) ≤ wLP.\nProof. First we argue that S is a vertex cover . Consider an edge e = (i,j). We claim  that at least one of\ni and j must be in S. Recall that one of our inequalities is xi + xj ≥ 1. So in any solution x* that\nsatisfies this inequality , either x*i ≥ ½ or x*j ≥ ½. Thus at least one of these two will be rounded up,\nand i or j will be placed in S.\nNow we consider the weight w(S) of this vertex cover . The set S only has vertices with x*i ≥ ½;\nthus the linear program “paid” at least ½wi for node i, and we only pay wi: at most twice as much.\nMore formally , we have the following chain of inequalities.  \n▪')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 755})","('type', 'Document')"
"('page_content', 'Thus we have a produced a vertex cover S of weight at most 2wLP. The\nlower bound in (11.23) showed that the optimal vertex cover has weight at\nleast wLP, and so we have the following result.\n\xa0\n\xa0\n(11.25)  The algorithm pr oduces a vertex cover S of at most twice the minimum possible weight .\n\xa0\n\xa0\n*11.7 Load Balancing Revisited: A More\nAdvanced LP Application\nIn this section we consider a more general load balancing problem. We will\ndevelop an approximation algor ithm using the same general outline as the\n2-approximation we just designed for Vertex Cover: We solve a\ncorresponding linear program, and then round the solution. However , the\nalgorithm and its analysis here will be significantly more complex than\nwhat was needed for Vertex Cover. It turns out that the instance of the\nLinear Programming Problem we need to solve is, in fact, a flow problem.\nUsing this fact, we will be able to develop a much deeper unde rstanding of\nwhat the fractio nal solutions to the linear program look like, and we will\nuse this underst anding in order to round them. For this problem, the only\nknown constant-factor approximation algorithm is based on rounding this\nlinear programming solution.\n The Problem\nThe problem we consider in this section is a significant, but natural,\ngeneralization of the Load Balancing Problem with which we began our\nstudy of approximation algorithms. There, as here, we have a set J of n\njobs, and a set M of m machines, and the goal is to assign each job to a\nmachine so that the maximum load on any machine will be as small as')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 756})","('type', 'Document')"
"('page_content', ""possible. In the simple Load Balancing Problem we considered earlier , each\njob j can be assigned to any machine i. Here, on the other hand, we will\nrestrict the set of machines that each job may consider; that is, for each job\nthere is just a subset of machines to which it can be assigned. This\nrestriction arises  naturally in a number of applications: for example, we\nmay be seeking to balance load while maintaining the property that each job\nis assigned to a physically nearby machine, or to a machine with an\nappropriate authorization to process the job.\nMore formally , each job j has a fixed given size tj ≥ 0 and a set of\nmachines Mj ⊆ M that it may be assigned to. The sets Mj can be completely\narbitrary . We call an assignment of jobs to machines feasible  if each job j is\nassigned to a machine i ∊ Mj. The goal is still to minimize the maximum\nload on any machine: Using Ji ⊆ J to denote the jobs assigned to a machine\ni ∊ M in a feasible assignment, and using \n  to denote the resulting\nload, we seek to minimize maxi Li. This is the definition of the Generalized\nLoad Balancing Pr oblem .\nIn addition to containing our initial Load Balancing Problem  as a\nspecial case (setting Mj = M for all jobs j), Gener alized Load Balancing\nincludes the Bipartite Perfect Matching Problem as another special case.\nIndeed, given a bipartite graph with the same number of nodes on each side,\nwe can view the nodes on the left as jobs and the nodes on the right as\nmachines; we define tj = 1 for all jobs j, and define Mj to be the set of\nmachine nodes i such that there is an edge (i, j) ∊ E. There is an assignment\nof maximum load 1 if and only if there is a perfect matching in the bipartite\ngraph. (Thus, network flow techniques can be used to find the optimum\nload in this special case.) The fact that Generalized Load Balancing\nincludes both these problems as special cases gives some indication of the\nchallenge in designing an algorithm for it.\n Designing and Analyzing the Algorithm\nWe now develop an approximation algorithm based on linear programming\nfor the Generalized Load Balan cing Problem. The basic plan is the same\none we saw in the previous section: we'll first formulate the problem as an\nequivalent linear program where  the variables have to take specific discrete\nvalues; we'll then relax this to a linear program by dropping this"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 757})","('type', 'Document')"
"('page_content', ""requirement on the values of the variables; and then we'll use the resulting\nfractional assignment to obtain an actual assignment that is close to optimal.\nWe'll need to be more careful than in the case of the Vertex Cover Problem\nin rounding the solution to produce the actual assignment.\n\xa0\n\xa0\nInteger and Linear Programming Formulations  First we formulate the\nGeneralized Load Balancing Problem as a linear program with restrictions\non the variable values. We use variables xij corresponding to each pair (i,j)\nof machine i ∊ M and job j ∊ J. Setting xij = 0 will indicate that job j is not\nassigned to machine i, while setting xij = tj will indicate that all the load tj of\njob j is assigned to machine i. We can think of x as a single vector with mn\ncoordinates.\nWe use linear inequalities to encode the requirement that each job is\nassigned to a machine: For each job j we require that \n . The load of\na machine i can then be expressed as \n . We require that xij = 0\nwhenever i ∉ Mj. We will use the objective function to encode the goal of\nfinding an assignment that minimizes the maximum load. To do this, we\nwill need one more variable, L, that will corres pond to the load. We use the\ninequalities \n  for all machines i. In summary , we have formulated\nthe following problem.\nFirst we claim that the feasible assignments are in one-to-one\ncorrespondence with the solutions x satisfying the above constraints , and, in\nan optimal solution to (GL.IP), L is the load of the correspo nding\nassignment."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 758})","('type', 'Document')"
"('page_content', '(11.26) An assignm ent of jobs to machines has load at most L if and only if the vector x, defined by\nsetting x ij = tj whenever job j is assigned to machine i, and xij = 0 otherwise, satisfies the constraints\nin (GL.IP), with L set to the maximum load of the assignment .\n\xa0\n\xa0\nNext we will consider the corre sponding linear program obtained by\nreplacing the requirement that each xij ∊ {0, tj} by the weaker requirement\nthat xij ≥ 0 for all j ∊ J and i ∊ Mj. Let (GL.LP) denote the resulting linear\nprogram. It would also be natural to add xij ≤ tj. We do not add these\ninequalities explicitly , as they are implied by the nonnegativity and the\nequation \n  that is required for each job j.\nWe immediately see that if there is an assignment with load at most L,\nthen (GL.LP) must have a solution with value at most L. Or, in the\ncontrapositive,\n\xa0\n\xa0\n(11.27) If the optimum value of (GL.LP) is L, then the optimal load is at least L* ≥ L .\n\xa0\n\xa0\nWe can use linear programmin g to obtain such a solution (x, L) in\npolynomial time. Our goal will then be to use x to create an assignment.\nRecall that the Generalized Load Balancing Problem is NP-hard, and hence\nwe cannot expect to solve it exactly in polynomial time. Instead, we will\nfind an assignm ent with load at most two times the minimum possible. To\nbe able to do this, we will also need the simple lower bound (11.2), which\nwe used already in the original Load Balancing Problem.\n\xa0\n\xa0\n(11.28) The optimal load is at least L * ≥ max j tj.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 759})","('type', 'Document')"
"('page_content', ""Rounding the Solution When There Are No Cycles  The basic idea is to\nround the xij values to 0 or tj. However , we cannot use the simple idea of\njust rounding large values up and small values down. The problem is that\nthe linea r programming solution may assign small fractions of a job j to\neach of the m machines, and hence for some jobs there may be no large xij\nvalues. The algorithm we develop will be a rounding of x in the weak sense\nthat each job j will be assigned  to a machine i with xij > 0, but we may have\nto round a few really small values up. This weak rounding already ensures\nthat the assignm ent is feasible, in the sense that we do not assign any job j\nto a machine i not in Mj (because if i ∉ Mj, then we have xij = 0).\nThe key is to understand what the structure of the fractional solution is\nlike and to show that while a few jobs may be spread out to many machines,\nthis cannot happen to too many jobs. To this end, we'll consider the\nfollowing bipartite graph G(x) = (V(x), E(x)): The nodes are V(x) = M ∪ J,\nthe set of jobs and the set of machines, and there is an edge (i, j) ∊ E(x) if\nand only if xij > 0.\nWe'll show that, given any solut ion for (GL.LP), we can obtain  a new\nsolution x with the same load L, such that G(x) has no cycles. This is the\ncrucial step, as we show that a solution x with no cycles can be used to\nobtain an assignment with load at most L + L*.\n\xa0\n\xa0\n(11.29)  Given a solution (x, L) of (GL.LP) such that the graph G(x) has no cycles, we can use this\nsolution x to obtain a feasible assignment of jobs to machines with load at most L + L* in O(mn)\ntime.\nProof. Since the graph G(x) has no cycles, each of its connected components is a tree. We can\nproduce the assignment by considering each component separately . Thus, consider one of the\ncomponents, which is a tree whose nodes correspond to jobs and machines, as shown in Figure 1 1.11.\nFirst, root the tree at an arbitrary node. Now consider a job j. If the node correspo nding to job j\nis a leaf of the tree, let machine node i be its parent. Since j has degree 1 in the tree G(x), machine i is\nthe only machine that has been assigned any part of job j, and hence we must have that xij = tj. Our\nassignment will assign such a job j to its only neighbor i. For a job j whose corresponding  node is not\na leaf in G(x), we assign j to an arbitrary child of the corresponding node in the rooted tree.\nThe metho d can clearly be implemented in O(mn) time (including the time to set up the graph\nG(x)). It defines a feasible assignment, as the linear program (GL.LP) required that xij = 0 whenever i\n∉ Mj. To finish the proof, we need to show that the load is at most L + L* . Let i be any machine, and\nlet Ji be the set of jobs assigned to machine i. The jobs assigned to machine i form a subset of the\nneighbors of i in G(x): the set Ji contains those childr en of node i that are leaves, plus possibly the"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 760})","('type', 'Document')"
"('page_content', 'parent p(i) of node i. To bound  the load, we consider the paren t p(i) separately . For all other jobs j ≠\np(i) assigned to i, we have xij = tj, and hence we can bound the load using the solution x, as follows.  \n \nusing the inequality bounding the load in (GL.LP). For the parent j = p(i) of node i, we use tj ≤ L* by\n(11.28). Adding the two inequalities, we get that \n , as claimed. ▪\n\xa0\n\xa0\nFigur e 11.11 An exam ple of a graph G(x) with no cycles,  where the squares\nare machines and the circles are jobs. The solid lines show the resulting\nassignment of jobs to machines.\nNow , by (11.27), we know that L ≤ L*, so a solution whose load is\nbounded by L + L* is also bound ed by 2L*—in other words, twice the\noptimum. Thus we have the following consequence of (1 1.29).')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 761})","('type', 'Document')"
"('page_content', ""(11.30)  Given a solution  (x, L) of (GL.LP) such that the graph G(x) has no cycles, then we can use\nthis solution x to obtain a feasible assignment of jobs to machines with load at most twice the\noptimum in O (mn) time.\n\xa0\n\xa0\nEliminating Cycles from the Linear Programming Solution  To wrap up\nour approximation algorithm, then, we just need to show how to convert an\narbitrary solutio n of (GL.LP) into a solution x with no cycles in G(x). In the\nprocess, we will also show how to obtain a solution to the linear program\n(GL.LP) using flow computation s. More precisely , given a fixed load value\nL, we show how to use a flow computation to decide if (GL. LP) has a\nsolution with value at most L. For this constr uction, consider  the following\ndirected graph G = (V, E) shown in Figure 11.12. The set of vertices of the\nflow graph G will be V = M ∪ J ∪ {v}, where v is a new node. The nodes j\n∊ J will be sources with supply tj, and the only demand node is the new\nsink v, which has demand \n . We'll think of the flow in this network as\n“load” flowing from jobs to the sink v via the machines. We add an edge (j,\ni) with infinite capacity from job j to machine i if and only if i ∊ Mj.\nFinally , we add an edge ( i, v) for each machine node i with capacity L.\nFigur e 11.12 The network flow computation used to find a solution to\n(GL.LP). Edges between the jobs and machines have infinite capacity ."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 762})","('type', 'Document')"
"('page_content', ""(11.31)  The solutions of this flow problem with capacity L are in one-to-one correspondence with\nsolutions of (GL.LP) with value L, wher e xij is the flow value along edge  (i,j), and the flow value on\nedge  (i, t) is the load  \n  on machine i .\n\xa0\n\xa0\nThis statement allows us to solve (GL.LP) using flow computations\nand a binary search for the optimal value L: we try success ive values of L\nuntil we find the smallest one for which there is a feasible flow .\nHere we'll use the understand ing we gained of (GL.LP) from the\nequivalent flow formulation to modify a solution x to eliminate all cycles\nfrom G(x). In terms of the flow we have just defined, G(x) is the undirected\ngraph obtained from G by ignoring the directions of the edges, deleting the\nsink v and all adjacent  edges, and also deleting all edges from J to M that do\nnot carry flow. We'll eliminate all cycles in G(x) in a sequence of at most\nmn steps, where the goal of a single step is to eliminate at least one edge\nfrom G(x) without increasing the load L or introducing any new edges."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 763})","('type', 'Document')"
"('page_content', ""(11.32) Let (x, L) be any solution to (GL.LP) and C be a cycle in G(x). In time linear in the length of\nthe cycle, we can modify the solution x to eliminate at least one edge from G(x) without increasing\nthe load or intr oducing any new edges .\nProof. Consider the cycle C in G(x). Recall that G(x) corresponds to the set of edges that carry flow\nin the solution x. We will modify the solution by augmenting  the flow along the cycle C, using\nessentially the procedure augment from Section 7.1 . The augmentation along a cycle will not change\nthe balance between incoming and outgoing flow at any node; rather , it will eliminate one backward\nedge from the residua l graph, and hence an edge from G(x). Assume that the nodes along the cycle\nare i1, j1, i2, j2, …, ik, jk, where iℓ is a machine node and jℓ is a job node. We'll modify the solution\nby decreasi ng the flow along all edges (jℓ, iℓ) and increasing the flow on the edges (jℓ, iℓ+1) for all ℓ\n= 1, …, k (where k + 1 is used to denote 1), by the same amount δ. This chan ge will not affect the\nflow conservation constraints. By setting \n , we ensure  that the flow remains feasible\nand the edge obtaining the minimum is deleted from G(x). ▪\n\xa0\n\xa0\nWe can use the algorithm conta ined in the proof of (11.32) repeatedly\nto eliminate all cycles from G(x). Initially , G(x) may have mn edges, so\nafter at most O(mn) iterations, the resulting soluti on (x, L) will have no\ncycles in G(x). At this point, we can use (11.30) to obtain a feasible\nassignment with at most twice the optimal load. W e summarize the result by\nthe following statement.\n\xa0\n\xa0\n(11.33) Given an instance of the Generalized Load Balancing Problem, we can find, in polynomial\ntime, a feasible assignment with load at most twice the minimum possible .\n\xa0\n\xa0\n11.8 Arbitrarily Good Approximations: The\nKnapsack Problem\nOften, when you talk to some one faced with an NP-hard optimization\nproblem, they're  hoping you can give them something that will produce a\nsolution within,  say, 1 percent of the optimum, or at least within a small\npercentage of optimal. Viewed from this perspective, the approximation"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 764})","('type', 'Document')"
"('page_content', ""algorithms we've seen thus far come across as quite weak: solutions within\na factor of 2 of the minimum for Center Selection and Vertex Cover (i.e.,\n100 percent more than optimal). The Set Cover Algorithm in Section 10.3  is\neven worse: Its cost is not even within a fixed constant factor of the\nminimum possible!\nHere is an important point underlying this state of af fairs: NP-complete\nproblems, as you well know , are all equivalent with respect to polynomial-\ntime solvability; but assuming P ≠ NP, they dif fer considerably in the extent\nto which their solutions can be efficiently approximated. In some cases, it is\nactually possible  to prove limits on approximability . For example, if P ≠\nNP, then the guara ntee provided by our Center Selection Algorith m is the\nbest possible for any polynomial-time algorithm. Similarly , the guarantee\nprovided by the Set Cover Algorithm, however bad it may seem, is very\nclose to the best possible, unless P = NP. For other problems, such as the\nVertex Cover Problem, the approximation algorithm we gave is essentially\nthe best known, but it is an open question whether there could be\npolynomial-time algorithms with better guarantees. We will not discuss the\ntopic of lower bounds on approximability in this book; while some lower\nbounds of this type are not so difficult to prove (such as for Center\nSelection), many are extremely technical.\n The Problem\nIn this section, we discuss an NP-complete problem for which it is possible\nto design a polynomial-time algorithm providing a very strong\napproximation. We will consider a slightly more general version of the\nKnapsack (or Subset Sum) Problem. Suppose you have n items that you\nconsider packing in a knapsack. Each item i = 1, …, n has two integer\nparameters: a weight Wi and a value Vi. Given a knaps ack capacity W, the\ngoal of the Knapsack Problem is to find a subset S of items of maximum\nvalue subject to the restriction that the total weight of the set should not\nexceed W. In other words, we wish to maximize \n  subject to the\ncondition \n .\nHow strong an approximation can we hope for? Our algorithm will\ntake as input the weights and values defining the problem and will also take\nan extra  parame ter ∊ , the desir ed precision. It will find a subset S whose\ntotal weight does not exceed W, with value \n  at most  a (1 + ε) factor"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 765})","('type', 'Document')"
"('page_content', ""below the maximum possible. The algorithm will run in polyn omial time\nfor any fixed  choice of ε > 0; however , the dependence on ε will not be\npolynomial. We call such an algorithm a polynomial-time approximation\nscheme .\nYou may ask: How could such a strong kind of approximation\nalgorithm be possible in polynomial time when the Knapsack Problem is\nNP-hard? With integer values, if we get close enough to the optimum value,\nwe must reach the optimum itself! The catch is in the nonpolynomial\ndependence on the desired precision: for any fixed choice of ε, such as ε =\n.5, ε = .2, or even ε = .01, the algor ithm runs in polynomial time, but as we\nchange ε to smal ler and smaller values, the running time gets larger. By the\ntime we make ε small enough to make sure we get the optimum value, it is\nno longer a polynomial-time algorithm.\n Designing the Algorithm\nIn Section 6.4 we considered algorithms for the Subset Sum Problem, the\nspecial case of the Knapsack Problem when vi = wi for all items i. We gave\na dynam ic programming algorithm for this special case that ran in O(nW)\ntime assuming the weights are integers. This algorithm naturall y extends to\nthe more genera l Knapsack Problem (see the end of Section 6.4 for this\nextension). The algorithm given in Section 6.4  works well when the weights\nare smal l (even if the values may be big). It is also possible to extend our\ndynamic progra mming algorithm for the case when the values are small,\neven if the weights may be big. At the end of this section,  we give a\ndynamic programming algorithm for that case running in time O(n2v*),\nwhere v* = maxi vi. Note that this algorithm does not run in polynomial\ntime: It is only pseudo-polynomial, because of its dependence on the size of\nthe values vi. Indeed , since we proved this problem to be NP-complete in\nChapter 8 , we don't expect to be able to find a polynomial-time algorithm.\nAlgorithms that depend on the values in a pseudo-polynomial way can\noften be used to design polynomial-time approximation schem es, and the\nalgorithm we develop here is a very clean example of the basic strategy . In\nparticular , we will use the dynamic programming algorithm with running\ntime O(n2v*) to design a polynomial-time approximation scheme; the idea\nis as follows. If the values are small integers, then v* is small and the\nproblem can be solved in polyno mial time already . On the other hand, if the"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 766})","('type', 'Document')"
"('page_content', ""values are large, then we do not have to deal with them exactly , as we only\nwant an approximately optimum solution. W e will use a rounding parameter\nb (whose value we'll set later) and will consider the values rounded to an\ninteger multiple of b. We will use our dynamic programming algorithm to\nsolve the proble m with the rounded values. More precisely , for each item i,\nlet its rounded value be \n . Note that the rounded and the original\nvalue are quite close to each other .\n\xa0\n\xa0\n(11.34) For each item i we have  \n .\n\xa0\n\xa0\nWhat did we gain by the roundin g? If the values were big to start with,\nwe did not make them any smaller. However , the rounded values are all\ninteger multiples of a common value b. So, instead of solving the problem\nwith the rounded values \n , we can chang e the units; we can divide all\nvalues by b and get an equivalent problem. Let \n.\n\xa0\n\xa0\n(11.35) The Knapsack Problem with values  \n and the scaled problem with values  \n have the same\nset of optim um solutio ns, the optimum values differ exactly by a factor of b, and the scaled values are\nintegral .\n\xa0\n\xa0\nNow we are ready to state our approximation algorithm. We will\nassume that all items have weight at most W (as items with weight wi > W\nare not in any solution, and hence can be deleted). We also assume for\nsimplicity that ε-1 is an integer .\n\xa0\n\xa0\nKnapsack-Approx( ε):\nSet b = (ε/(2n)) max i vi\nSolve the Knapsack Problem with values \n  (equivalently \n )\nReturn the set S of items found"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 767})","('type', 'Document')"
"('page_content', ""Analyzing the Algorithm\nFirst note that the solution found is at least feasible; that is, \n .\nThis is true as we have rounded only the values and not the weights. This is\nwhy we need the new dynamic programming algorithm describe d at the end\nof this section.\n\xa0\n\xa0\n(11.36) The set of items S returned by the algorithm has total weight at most W, that is \n.\n\xa0\n\xa0\nNext we'll prove that this algorithm runs in polynomial time.\n\xa0\n\xa0\n(11.37) The algorithm  Knapsack-Approx runs in polynomial time for any fixed  ε > 0.\nProof. Setting b and round ing item values can clearly be done in polynomial time. The time-\nconsuming part of this algorithm is the dynamic programming to solve the rounded problem. Recall\nthat for problems with integer values, the dynamic programming algorithm we use runs in time\nO(n2v*), where v* = max i vi.\nNow we are applying this algorithms for an instance in which each item i has weigh t wi and\nvalue \n . To determ ine the running time, we need to determine \n . The item j with maximum\nvalue vj = maxi vi also has maximum value in the rounded problem, so \n. Hence the overall running time of the algorithm is O(n3ε-1). Note\nthat this is polynomial time for any fixed ε > 0 as claimed; but the dependence on the desired\nprecision ε is not polynomial, as the running time includes ε-1 rather than log ε-1. ▪\n\xa0\n\xa0\nFinally , we need to consider the key issue: How good is the solution\nobtained by this algorithm? Statement (11.34) shows that the values \n  we\nused are close to the real values vi, and this sugg ests that the solution\nobtained may not be far from optimal."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 768})","('type', 'Document')"
"('page_content', '(11.38)  If S is the solution found by the Knapsack-Approx algorithm, and S* is any other solution\nsatisfying  \n , then we have  \n .\nProof. Let S* be any set satisfying  \n . Our algorithm finds the optimal solution with\nvalues \n , so we know that  \n \nThe rounded values \n  and the real values vi are quite close by (11.34), so we get the following chain\nof inequalities.  \n \nshowing that the value \n  of the solution we obtained is at most nb smaller than the maximum\nvalue possible. We wanted to obtain a relative error showing that the value obtained, \n , is at\nmost a (1 + ε) factor less than the maximum possible, so we need to compare nb to the value \n.\nLet j be the item with largest value; by our choice of b, we have vj = 2ε-1nb and \n . By our\nassumption that each item alone fits in the knapsack (wi ≤ W for all i), we have  \n. Finally , the chain of inequalities above says \n ,\nand thus \n . Hence \n , and so  \n▪\n\xa0\n\xa0\nThe New Dynamic Programming Algorithm for\nthe Knapsack Problem')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 769})","('type', 'Document')"
"('page_content', 'To solve a problem by dynamic programming, we have to define a\npolynomial set of subproblems. The dynamic programming algorithm we\ndefined when we studied the Knapsack Problem earlier uses subproblems of\nthe form opt(i, w): the subproble m of finding the maximum value of any\nsolution using a subset of the items 1, …, i and a knapsack of weight w.\nWhen the weights are large, this is a large set of problems. We need a set of\nsubproblems that work well when the values are reasonably small; this\nsuggests that we should use subproblems associated with values, not\nweights. We define our subproblems as follows. The subproblem is defined\nby i and a target value V, and \n (i, V) is the smallest knapsack weight W so\nthat one can obtain a solution using a subset of items {1, …, i] with value at\nleast V. We will have a subproblem for all i = 0, …, n and values  \n. If v* denotes maxi vi, then we see that the largest V can\nget in a subproblem is \n . Thus, assuming the values are integral,\nthere are at most O(n2v*) subproblems. None of these subproblems is\nprecisely the original instance of Knapsack, but if we have the values of all\nsubproblems \n (n, V) for \n , then the value of the original\nproblem can be obtained easily:  it is the largest value V such that \n (n, V)\n≤ W.\nIt is not hard to give a recurren ce for solving these subproblems. By\nanalogy with the dynamic programming algorithm for Subset Sum, we\nconsider cases depending on whether or not the last item n is included in the\noptimal solution \n .\n\xa0\nThese last two options can be summarized more compactly as')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 770})","('type', 'Document')"
"('page_content', 'This implies the following analogue of the recurrence (6.8) from Chapter 6 .\n\xa0\xa0\n(11.39)  If \n . Otherwise  \n.\n\xa0\n\xa0\nWe can then write down an analogous dynamic programming\nalgorithm.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 771})","('type', 'Document')"
"('page_content', ""(11.40)  Knapsack (n) takes O(n2v*) time and correctly computes the optimal values of the\nsubpr oblems .\n\xa0\n\xa0\nAs was done before, we can trace back through the table M containing\nthe optimal values of the subproblems, to find an optimal solution.\nSolved Exercises\nSolved Exercise 1\nRecall the Shortest-First greedy algorithm for the Interval Scheduling\nProblem: Given a set of intervals, we repeatedly pick the shortest interval I,\ndelete all the other intervals I′ that intersect I, and iterate.\nIn Chapter 4, we saw that this algorithm does not always produce a\nmaximum-size set of nonoverlapping intervals. However , it turns out to\nhave the following interesting approximation guarantee. If s* is the\nmaximum size of a set of nonov erlapping intervals, and s is the size of the\nset produced by the Shortest-First Algorithm, then s ≥ ½s* (that is,\nShortest-First is a 2-approximation).\nProve this fact.\nSolution  Let's first recall the example in Figure 4.1 from Chapter 4, which\nshowed that Shortest-First does not necessarily find an optimal set of\nintervals. The difficulty is clear: We may select a short interval j while\neliminating two longer flanking intervals i and i′. So we have done only half\nas well as the optimum.\nThe question is to show that Shortest-First  could never do worse than\nthis. The issues here are somew hat similar to what came up in the analysis\nof the greedy algorithm for the Maximum Disjoint Paths Problem in Section\n11.5: Each interval we select may “block” some of the intervals in an\noptimal solution, and we want to argue that by always selecting the shortest\npossible interva l, these blocking effects are not too severe. In the case of\ndisjoint paths, we analyzed the overlaps among paths essentially edge by\nedge, since the underlying graph there had an arbitrary structu re. Here we"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 772})","('type', 'Document')"
"('page_content', ""can benefit from the highly restricted structure of intervals on a line so as to\nobtain a stronger bound.\nIn order  for Shortest-First to do less than half as well as the optimum,\nthere would have to be a large optimal solution that overlaps with a much\nsmaller solution chosen by Shortest-First. Intuitively , it seems that the only\nway this could happen would be to have one of the intervals i in the optimal\nsolution nested completely inside one of the intervals j chosen by Shortest-\nFirst. This in turn would contradict the behavior of Shortest-First: Why\ndidn't it choose this shorter interval i that's nested inside j?\nLet's see if we can make this argument precise. Let A denote the set of\nintervals chosen by Shortest-First, and let \n  denote an optimal set of\nintervals. For each interval j ∊ A, consider the set of intervals in \n that it\nconflicts with. W e claim\n\xa0\n\xa0\n(11.41)  Each interval j  ∊ A conflicts with at most two intervals in  \n.\nProof. Assu me by way of contradiction that there is an interval in j ∊ A that conflicts with at least\nthree intervals in i1, i2, i3 ∊ O. These three intervals do not conflict with one another , as they are part\nof a single solution \n , so they are ordered sequentially in time. Suppose they are ordered with i1 first,\nthen i2, and then i3. Since interval j conflicts with both i1 and i3, the interv al i2 in between must be\nshorter than j and fit completely inside it. Moreover , since i2 was never  selected by Shortest-First, it\nmust have been available as an option when Shortest-First selected interval j. This is a contradiction,\nsince i2 is shorter than j. ▪\n\xa0\n\xa0\nThe Shortest-First Algorithm only terminates when every unselected\ninterval conflicts with one of the intervals it selected. So, in particular , each\ninterval in \n  is either included in A, or conflicts with an interval in A.\nNow we use the following accounting scheme to bound the number of\nintervals in \n. For each i ∊ \n, we have some  interval j ∊ A “pay” for i, as\nfollows. If i is also in A, then i will pay for itself. Otherwise, we arbitrarily\nchoose an interval j ∊ A that conflicts with i and have j pay for i. As we just\nargued, every interval in \n conflicts with some interval in A, so all intervals\nin \n will be paid for under this scheme. But by (11.41), each interval j ∊ A\nconflicts with at most two intervals in \n, and so it will only pay for at most\ntwo intervals. Thus, all intervals in \n are paid for by intervals in A, and in"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 773})","('type', 'Document')"
"('page_content', ""this process each interval in A pays at most twice. If follows that A must\nhave at least half as many intervals as \n .\n\xa0\n\xa0\nExercises\n1. Suppose you're acting as a consultant for the Port Authority of a small\nPacific Rim nation. They're currently doing a multi-billion-dollar\nbusiness per year, and their revenue is constrained almost entirely by\nthe rate at which they can unload ships that arrive in the port.  \nHere's a basic sort of problem they face. A ship arrives, with n\ncontainers of weight w1, w2, …, wn. Standing on the dock is a set of\ntrucks, each of which can hold K units of weight. (You can assum e that\nK and each wi is an integer .) You can stack multiple containers in each\ntruck, subject to the weight restriction of K; the goal is to minimize the\nnumber of trucks that are needed in order to carry all the containers.\nThis problem is NP-complete (you don't have to prove this).\nA greed y algori thm you might use for this is the following. Start\nwith an empty truck, and begin piling containers 1, 2, 3, … into it until\nyou get to a container that would overflow the weight limit . Now\ndeclare this truck “loaded” and send it off; then continue the process\nwith a fresh truck. This algorithm, by considering trucks one at a time,\nmay not achieve the most efficient way to pack the full set of\ncontainers into an available collection of trucks.\n(a) Give an example of a set of weights, and a value of K, where this\nalgorithm does not use the minimum possible number of trucks.\n(b) Show , however , that the number of trucks used by this algorithm is\nwithin a factor of 2 of the minimum possible number , for any set of\nweights and any value of K.\n2. At a lecture in a computational biology conference one of us attended\na few years ago, a well-known protein chemist talked about the idea of\nbuilding a “representative set” for a large collection of protein\nmolecules whos e properties we don't understand. The idea would be to"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 774})","('type', 'Document')"
"('page_content', ""intensively study the proteins in the representative set and thereby\nlearn (by inference) about all the proteins in the full collection.  \nTo be useful, the representative set must have two properties.\nIt should  be relatively small, so that it will not be too expensive to\nstudy it.\nEvery protein in the full collec tion should be “similar” to some\nprotein in the representative set. (In this way, it truly provides\nsome information about all the proteins.)\nMore concretely , there is a large set P of proteins. We define\nsimilarity on proteins by a distance function d: Given two proteins p\nand q, it returns a number d(p, q) ≥ 0. In fact, the function d(·, ·) most\ntypically used is the sequence alignment  measure, which we looked at\nwhen we studie d dynamic programming in Chapter 6. We'll assume\nthis is the distance being used here. There is a predefined distan ce cut-\noff Δ that's specified as part of the input to the problem; two proteins p\nand q are deemed to be “similar” to one another if and only if d(p, q) ≤\nΔ.\nWe say that a subset of P is a representative set if, for every\nprotein p, there is a protein q in the subset that is similar to it-that is,\nfor which d(p, q) ≤ Δ. Our goal is to find a representative set that is as\nsmall as possible.\n(a) Give a polynom ial-time algorithm that approximates the minim um\nrepresentative set to within a factor of O(log n). Specifically , your\nalgorithm should have the following property: If the minimum possible\nsize of a repre sentative set is s*, your algorithm  should return a\nrepresentative set of size at most O(s* log n).\n(b) Note the close similarity betw een this problem and the Center\nSelection Proble m-a problem for which we considered approxi mation\nalgorithms in Section 11.2. Why doesn't the algorithm described there\nsolve the current problem?\n3. Suppose you are given a set of positive integers A = {a1, a2, …, an}\nand a positive integer B. A subset S ⊆ A is called  feasible  if the sum of\nthe numbers in S does not exceed B:"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 775})","('type', 'Document')"
"('page_content', 'The sum of the numbers in S will be called the total sum  of S.\nYou would like to select a feasible subset S of A whose total sum\nis as lar ge as possible.\nExample.  If A = {8,2,4} and B = 11, then the optimal solution is the\nsubset S = {8,2}.\n(a) Here is an algorithm for this problem.\n \n \n \n \nGive an instance in which the total sum of the set S returned by\nthis algorithm is less than half the total sum of some other feasible\nsubset of A\n(b) Give a polynomial-time approximation algorithm for this probl em\nwith the following guarantee: It returns a feasible set S ⊆ A whose\ntotal sum is at least half as large as the maximum total sum of any\nfeasible set S′ ⊆ A Your algorithm should have a running time of at\nmost O( n log n).\n4. Consider an optimization versio n of the Hitting Set Problem defined as\nfollows. We are given a set A = {a1 …, an} and a collection B1, B2,…,\nBm of subsets of A. Also, each element ai ∊ A has a weight wi ≥ 0. The\nproblem is to find a hitting set H ⊆ A such that the total weight of the')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 776})","('type', 'Document')"
"('page_content', ""elements in H, that is, ∑ai ∊Hwi, is as small as possible. (As in Exercise\n5 in Chapter 8 , we say that H is a hitting set if H ∩ Bi is not empty for\neach i.) Let b = maxi |Bi| denote the maximum size of any of the sets\nB1, B2,…, Bm. Give a polynomial-time approximation algorithm for\nthis problem that finds a hitting set whose total weight is at most b\ntimes the minimum possible.  \n5. You are asked to consult for a business where clients bring in jobs each\nday for process ing. Each job has a processing time ti that is known\nwhen the job arrives. The compa ny has a set of ten machines, and each\njob can be processed on any of these ten machines.  \nAt the moment the business is running the simple Greedy-Balance\nAlgorithm we discussed in Section 11.1. They have been told that this\nmay not be the best approxima tion algorithm possible, and they are\nwondering if they should be afraid of bad performance. However , they\nare reluc tant to change the scheduling as they really like the simplicity\nof the current algorithm: jobs can be assigned to machines as soon as\nthey arrive, without having to defer the decision until later jobs arrive.\nIn particular , they have heard that this algorithm can produ ce\nsolutions with makespan as much as twice the minimum possible; but\ntheir experience with the algorithm has been quite good: They have\nbeen running it each day for the last month, and they have not\nobserved it to produce a make span more than 20 percent above the\naverage load, \nTo try understan ding why they don't seem to be encountering this\nfactor -of-two behavior , you ask a bit about the kind of jobs and loads\nthey see. You find out that the sizes of jobs range between 1 and 50,\nthat is, 1 ≤ ti ≤ 50 for all jobs i; and the total load ∑i ti is quite high\neach day: it is always at least 3,000.\nProve that on the type of inputs the company sees, the Greed y-\nBalance Algorit hm will always find a solution whose makespan is at\nmost 20 percent above the average load.\n6. Recall that in the basic Load Balancing Problem from Section 11.1,\nwe're interested  in placing jobs on machines so as to minimize the\nmakespan —the maximum  load on any one machine. In a number of\napplications, it is natural to consider cases in which you have access to\nmachines with different amounts of processing power , so that a given"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 777})","('type', 'Document')"
"('page_content', ""job may complete more quickly on one of your machines than on\nanother . The question then beco mes: How should you allocate jobs to\nmachines in these more heterogeneous systems?  \nHere's a basic model that expose s these issues. Suppose you have\na system that consists of m slow machin es and k fast machines. The\nfast machines can perform twice as much work per unit time as the\nslow machines. Now you're given a set of n jobs; job i takes time ti to\nprocess on a slow machine and time ½ti to proce ss on a fast machine.\nYou want to assign each job to a machine; as before, the goal is to\nminimize the makespan—that is the maximum, over all machines, of\nthe total processing time of jobs assigned to that machine.\nGive a polynomial-time algorithm that produces an assignment of\njobs to machines with a makespan that is at most three times the\noptimum.\n7. You're consultin g for an e-commerce site that receives a large number\nof visitors each day. For each visitor i, where i ∊ {1,2, …, n}, the site\nhas assigned a value vi, representing the expected revenue that can be\nobtained from this customer . \nEach visitor i is shown one of m possible ads A1, A2,…, Am as\nthey enter the site. The site wants a selection of one ad for each\ncustomer so that each  ad is seen, overall, by a set of customers of\nreasonably large total weight. Thus, given a selection of one ad for\neach customer , we will define the spread of this selection to be the\nminimum, over j = 1,2,…, m, of the total weight of all customers who\nwere shown ad Aj.\nExample  Suppose there are six customers with values 3,4,12,2,4,6,\nand there are m = 3 ads. Then, in this instance , one could achieve a\nspread of 9 by showing ad A1 to customers 1,2,4, ad A2 to customer 3,\nand ad A3 to customers 5 and 6.\nThe ultim ate goal is to find a selection of an ad for each custom er\nthat maximizes the spread. Unfortunately , this optimization problem is\nNP-hard (you don't have to prove this). So instead, we will try to\napproximate it.\n(a) Give a polynom ial-time algorithm that approximates the maxim um\nspread to within a factor of 2. That is, if the maximum spread is s, then\nyour algorithm should produce a selection of one ad for each customer"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 778})","('type', 'Document')"
"('page_content', ""that has spread at least s/2. In designing your algorithm, you may\nassume that no single customer has a value that is significantly above\nthe average; specifically , if \n  denotes the total value of all\ncustomers, then you may assume that no single customer has a value\nexceeding \n .\n(b) Give an example of an instan ce on which the algorithm you\ndesigned in part (a) does not find an optimal solution (that is, one of\nmaximum sprea d). Say what the optimal solution is in your sample\ninstance, and what your algorithm finds.\n8. Some friends of yours are working with a system that performs real-\ntime scheduling  of jobs on multiple servers, and they've come to you\nfor help in getting around an unfortunate piece of legacy code that\ncan't be changed.  \nHere's the situation. When a batch of jobs arrives, the syste m\nallocates them to servers using the simple Greedy-Balance Algorithm\nfrom Section 1 1.1, which provides an approximation to within a factor\nof 2. In the decade and a half since this part of the system was written,\nthe hardware has gotten faster to the point where, on the instanc es that\nthe system needs to deal with, your friends find that it's generally\npossible to compute an optimal solution.\nThe difficulty is that the people in charge of the system's interna ls\nwon't let them change the portion of the software that implements the\nGreedy-Balance Algorithm so as to replace it with one that finds the\noptimal solution. (Basically , this portion of the code has to interact\nwith so many other parts of the system that it's not worth the risk of\nsomething going wrong if it's replaced.)\nAfter grumbling about this for a while, your friends come up with\nan alternate idea. Suppose they could write a little piece of code that\ntakes the description of the jobs, computes an optimal solution (since\nthey're able to do this on the instances that arise in practice), and then\nfeeds the jobs to the Greedy-Balance Algorithm in an order that will\ncause it to allocate them optimally . In other words, they're hoping to\nbe able to reord er the input in such a way that when Greedy-B alance\nencounters the input in this order , it produces an optimal solution.\nSo their question to you is simply the following: Is this alwa ys\npossible? Their conjecture is,"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 779})","('type', 'Document')"
"('page_content', 'For every instance of the load balancing problem from Section 11.1, there exists\nan or der of the jobs so that when Gr eedy-Balance pr ocesses the jobs in this or der,\nit produces an assignment of jobs to machines with the minimum possible\nmakespan .\nDecide whether you think this conjecture is true or false, and give\neither a proof or a counterexample.\n9. Consider the following maxim ization version of the 3-Dimensional\nMatching Problem. Given disjoint sets X, Y, and Z, and given a set T ⊆\nX × Y × Z of ordered triples, a subset M ⊆ T is a 3-dimensional\nmatching  if each element of X ∪ Y ∪ Z is contained in at most one of\nthese triples. The Maximum 3-Dim ensional Matc hing Problem  is to\nfind a 3-dimensional matching M of maximum size. (The size of the\nmatching, as usual, is the number of triples it contains. You may\nassume | X| = |Y| = |Z| if you want.)  \nGive a polynom ial-time algorithm that finds a 3-dimension al\nmatching of size at least ⅓ times the maximum possible size.\n10. Suppose you are given an n × n grid graph G , as in Figure 1 1.13. \nAssociated with each node v is a weight w(v), which is a\nnonnegative integer. You may assume that the weights of all nodes are\ndistinct. Your goal is to choose an independent set S of nodes of the\ngrid, so that the sum of the weights of the nodes in S is as large as\npossible. (The sum of the weigh ts of the nodes in S will be called its\ntotal weight .)\nFigur e 11.13 A grid graph.\nConsider the following greedy algorithm for this problem.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 780})","('type', 'Document')"
"('page_content', 'The ""heaviest-first"" greedy algorithm:\nStart with S equal to the empty set\nWhile some node remains in G\nPick a node vi of maximum weight\nAdd vi to S\nDelete vi and its neighbors from G\nEndwhile\nReturn S\n \n \n(a) Let S be the independ ent set returned by the “heaviest-first” greedy\nalgorithm, and let T be any other independent set in G. Show that, for\neach node v ∊ T, either v ∊ S, or there is a node v′ ∊ S so that w(v) ≤\nw(v′) and v,v′) is an edge of G.\n(b) Show that the “heaviest-first” greedy algorithm returns an\nindependent set of total weight at least ¼ times the maximum total\nweight of any independent set in the grid graph G.\n11. Recall that in the Knapsack Problem, we have n items, each with a\nweight wi and a value vi. We also have a weight bound  W, and the\nproblem is to select a set of items S of highe st possi ble value subject to\nthe condition that the total weigh t does not exceed W—that is∑i ∊S wi ≤\nW. Here\'s  one way to look at the approximation algorithm that we\ndesigned in this chapter . If we are told there exists a subset \n  whose\ntotal weight is ∑i ∊\n wi ≤ W and whose total value is ∑i ∊\n vi = V for\nsome V, then our appro ximation algorithm can find a set A with total\nweight ∑i ∊A wi ≤ W and total value at least ∑i ∊A vi ≥ V/(1 + ∊ ). Thus\nthe algorithm approximates the best value, while keeping the weights\nstrictly under W. (Of course, returning the set \n  is always a valid\nsolution, but since the problem is NP-hard, we don\'t expect to always\nbe able to find \n  itself; the approximation bound of 1 + ∊  means that\nother sets A, with slightly less value, can be valid answers as well.)  \nNow , as is well known, you can always pack a little bit more for a\ntrip just by “sitting on your suitcase”—in other words, by slightly\noverflowing the allowed weight limit. This too suggests a way of\nformalizing the approximation question for the Knapsack Problem, but\nit\'s the following, dif ferent, formalization.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 781})","('type', 'Document')"
"('page_content', ""Suppose, as before, that you're given n items with weights and\nvalues, as well as parameters W and V; and you're told that there is a\nsubset \n  whose total weight is ∑i ∊\n wi ≤ W and whose total value is\n∑i ∊\n vi = V for some V. For a given fixed ∊  > 0, design  a polynomial-\ntime algorithm that finds a subset of items A such that ∑i ∊A wi ≤ (1 +\n∊) and ∑i ∊A vi ≥ V. In other words, you want A to achie ve at least as\nhigh a total value as the given bound V, but you're allowed to exceed\nthe weight limit W by a factor of 1 + ∊ .\nExample . Suppos e you're given four items, with weights and values as\nfollows:\n \nYou're also given W = 10 and V = 13 (since, indeed, the subset\nconsisting of the first three items has total weight at most 10 and has\nvalue 13). Finally , you're given  ∊  = .1. This means you need to find\n(via your approx imation algorith m) a subset of weight at most (1 + .1)\n* 10 = 11 and value at least 13. One valid solution would be the subset\nconsisting of the first and fourth  items, with value 14 ≥ 13. (Note that\nthis is a case where you're able to achieve a value strictly great er than\nV, since you're allowed to slightly overfill the knapsack.)\n12. Consider the following problem. There is a set U of n nodes, which we\ncan think of as users (e.g., these are locations that need to access a\nservice, such as a Web server). You would like to place servers at\nmultiple locations. Suppose you are given a set S possible sites that\nwould be willing  to act as locations for the servers. For each site s ∊ S,\nthere is a fee fs ≥ 0 for placing a server at that location. Your goal will\nbe to approximately minimize the cost while providing the service to\neach of the customers. So far this is very much like the Set Cover\nProblem: The places s are sets, the weight of set s is fs, and we want to\nselect a collection of sets that covers all users. There is one extra\ncomplication: Users u ∊ U can be served from multiple sites, but there\nis an associated cost dus for serving user u from site s. When the value"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 782})","('type', 'Document')"
"('page_content', ""dus is very high, we do not want to serve user u from site s; and in\ngeneral the service cost dus serves as an incentive to serve customers\nfrom “nearby” servers whenever possible.  \nSo here is the question, which we call the Facility Locatio n\nProblem: Given the sets U and S, and costs f and d, you need to select\na subset A ⊆ S at which to place servers (at a cost of ∑s ∊A fs), and\nassign each user u to the active server where it is cheapest to be served,\nmins ∊A dus. The goal is to minimize the overall cost ∑s ∊Afs + ∑u ∊U\nmins ∊A dus. Give an H(n)- approximation for this problem.\n(Note that if all service costs dus are 0 or infinity , then this\nproblem is exactly the Set Cover Problem: fs is the cost of the set\nnamed s, and dusis 0 if node u is in set s, and infinity otherwise.)\nNotes and Further Reading\nThe design of approximation algorithms for NP-hard problems is an active\narea of research, and it is the focus of a book of surveys  edited by\nHochbaum (1996) and a text by V azirani (2001).\nThe greedy algorithm for load balancing and its analysis is due to\nGraham (1966, 1969); in fact, he proved that when the jobs are first sorted\nin descending order of size, the greedy algorithm achieves an assignment\nwithin a factor \n  of optimal. (In the text, we give a simpler proof for the\nweaker bound of \n.) Using more complicated algorithms, even stronger\napproximation guarantees can be proved for this problem (Hochbaum and\nShmoys 1987; Hall 1996). The techniques used for these stronger load\nbalancing approximation algorithms are also closely related to the method\ndescribed in the text for designing arbitrarily good approximations for the\nKnapsack Problem.\nThe approximation algorithm for the Center Selection Problem follows\nthe approach of Hochbaum and Shmoys (1985) and Dyer and Frieze (1985).\nOther geometric  location problems of this flavor are discussed by Bern and\nEppstein (1996) and in the book of surveys edited by Drezner (1995).\nThe greedy algorithm for Set Cover and its analysis are due\nindependently to Johnson (1974), Lova'sz (1975), and Chvatal (1979)."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 783})","('type', 'Document')"
"('page_content', 'Further results for the Set Cover Problem are discussed in the survey by\nHochbaum (1996).\nAs mentioned in the text, the pricing method for designing\napproximation algorithms is also referred to as the primal-dual method  and\ncan be motivated using linear programming. This latter perspective is the\nsubject of the survey by Goemans and Williamson (1996). The pricing\nalgorithm to approximate the W eighted V ertex Cover Problem is due to Bar -\nYehuda and Even (1981).\nThe greedy algorithm for the disjoint paths problem is due to\nKleinber g and Tardos (1995); the pricing-based approximatio n algorithm\nfor the case when multiple paths can share an edge is due to Awerbuch,\nAzar , and Plotkin (1993). Algor ithms have been developed for many other\nvariants of the Disjoint Paths Problem; see the book of surveys edited by\nKorte et al. (1990) for a discuss ion of cases that can be solved optimally in\npolynomial time, and Plotkin (1995) and Kleinber g (1996) for surveys of\nwork on approximation.\nThe linear programming rounding algorithm for the Weighted Vertex\nCover Problem is due to Hochbaum (1982). The rounding algorithm for\nGeneralized Load Balancing is due to Lenstra, Shmoys, and Tardos (1990);\nsee the survey by Hall (1996) for other results in this vein. As discussed in\nthe text, these two results illustrate a widely used method for designing\napproximation algorithms: One sets up an integer programming formulation\nfor the problem , transforms it to a related (but not equivalent) linear\nprogramming problem, and then rounds the resulting solution. Vazirani\n(2001) discusses many further applications of this technique.\nLocal search and randomization are two other powerful techniques for\ndesigning approximation algorithms; we discuss these connections in the\nnext two chapters.\nOne topic that we do not cover in this book is inappr oximability . Just\nas one can prove that a given NP-hard problem can be approximated to\nwithin a certain factor in polynomial time, one can also sometimes establish\nlower bounds, showing that if the problem could be approximated to within\nbetter than some factor c in polynomial time, then it could be solved\noptimally , thereb y proving P = NP. There is a growing body of work that\nestablishes such limits to appro ximability for many NP-hard problems. In\ncertain cases, these positive and negative results have lined up perfectly to\nproduce an approximation threshold , establishing for certain problem s that')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 784})","('type', 'Document')"
"('page_content', ""there is a polyno mial-time approximation algorithm to within some factor c,\nand it is impossible to do better unless P = NP. Some of the early results on\ninapproximability were not very difficult to prove, but more recent work\nhas intro duced powerful techniques that become quite intricate . This topic\nis covered in the survey by Arora and Lund (1996).\nNotes on the Exercises  Exercises 4 and 12 are based on results of Dorit\nHochbaum. Exercise 11 is based on results of Sartaj Sahni, Oscar Ibarra,\nand Chul Kim, and of Dorit Hochbaum and David Shmoys.\n1 A researcher from the telec ommunications industry once gave the\nfollowing explanation for the distinction between Maximum Disjoint Paths\nand netw ork flow, and the broken reduction in the previous paragraph. On\nMother's Day, traditionally the busiest day of the year for telephone calls,\nthe phone company must solve an enormous disjoint paths problem:\nensuring that each source individual si is connected by a path through  the\nvoice network to his or her mother ti. Network flow algorithms, finding\ndisjoint paths between a set S and a set T, on the other hand, will ensure\nonly that each person gets their call through to somebody's  mother .\n2 Those of you who are familiar with duality may also notice that the\npricing method  of the previous sections is motiv ated by linear programming\nduality: the prices are exactly the variables in the dual linear program\n(which explains why pricing algorithms are often referred to as primal-dual\nalgorithms )."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 785})","('type', 'Document')"
"('page_content', 'Chapter 12')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 786})","('type', 'Document')"
"('page_content', 'Local Search\n12.1 The Landscape of an Optimization Pr oblem  \n12.2 The Metr opolis Algorithm and Simulated Annealing  \n12.3 An Application of Local Sear ch to Hopfield Neural Networks  \n12.4 Maximum-Cut Appr oximation via Local Sear ch \n12.5 Choosing a Neighbor Relation  \n* 12.6 Classification via Local Sear ch \n12.7 Best-Response Dynamics and Nash Equilibria  \nSolved Exer cises  \nExer cises  \nNotes and Further Reading\nIn the previous two chapters, we have considered techniques for dealing\nwith computatio nally intractable problems: in Chapter 10, by identifying\nstructured special cases of NP-hard problems, and in Chapter 11, by\ndesigning polynomial-time approximation algorithms. We now develop a\nthird and final topic related to this theme: the design of local search\nalgorithms .\nLocal search is a very general technique; it describes any algorithm\nthat “explores” the space of possible solutions in a sequential fashion,\nmoving in one step from a current solution to a “nearby” one. The\ngenerality and flexibility of this notion has the advantage that it is not\ndifficult to design a local searc h approach to almost any computationally\nhard problem; the counterbalan cing disadvantage is that it is often very\ndifficult to say anything precise or provable about the quality of the\nsolutions that a local search algorithm finds, and consequently very hard to\ntell whether one is using a good local search algorithm or a poor one.\nOur discussion of local search in this chapter will reflect these trade-\noffs. Local search algorithms are generally heuristics designed to find good,\nbut not necessarily optimal, solutions to computational problems, and we\nbegin by talking about what the search for such solutions looks like at a\nglobal level. A useful intuitive basis for this perspective comes from')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 787})","('type', 'Document')"
"('page_content', ""connections with energy minimization principles in physics, and we explore\nthis issue first. Our discussion for this part of the chapter will have a\nsomewhat different flavor from what we've generally seen in the book thus\nfar; here, we'll introduce some algorithms, discuss them quali tatively , but\nadmit quite frankly that we can't prove very much about them.\nThere are cases,  however , in which it is possible to prove properties of\nlocal search algorithms, and to bound their performance relative to an\noptimal solution . This will be the focus of the latter part of the chapter: We\nbegin by consid ering a case—the dynamics of Hopfield neural networks—\nin which local search provides the natural way to think about the underlying\nbehavior of a complex process; we then focus on some NP-ha rd problems\nfor which local search can be used to design efficient algorithms with\nprovable approximation guarantees. We conclude the chapter by discussing\na different type of local search: the game-theoretic notions of best-response\ndynamics and Nash equilibria, which arise naturally in the study  of systems\nthat contain many interacting agents.\n12.1 The Landscape of an Optimization Problem\nMuch of the core of local search  was developed by people thinking in terms\nof analogies with physics. Looking at the wide range of hard computational\nproblems that require the minimization of some quantity , they reasoned as\nfollows. Physica l systems are performing minimization all the time, when\nthey seek to minimize their potential energy. What can we learn from the\nways in which nature performs minimization? Does it suggest new kinds of\nalgorithms?\nFigur e 12.1 When the potential energy landscape has the structure of a\nsimple funnel, it is easy to find the lowest point."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 788})","('type', 'Document')"
"('page_content', ""Potential Energy\nIf the world really looked the way a freshman mechanics class suggests, it\nseems that it would consist entirely of hockey pucks sliding on ice and balls\nrolling down inclined surfaces. Hockey pucks usually slide because you\npush them; but why do balls roll downhill? One perspective that we learn\nfrom Newtonia n mechanics is that the ball is trying to minimize its\npotential ener gy. In particular , if the ball has mass m and falls a distance of\nh, it loses an amount of potential energy proportional to mh. So, if we\nrelease a ball from the top of the funnel-shaped landscape in Figure 12.1 , its\npotential ener gy will be minimized at the lowest point.\nIf we make the landscape a little more complicated, some extra  issues\ncreep in. Consider the “double funnel” in Figure 12.2 . Point A is lower than\npoint B, and so is a more desira ble place for the ball to come to rest. But if\nwe start the ball rolling from point C, it will not be able to get over the\nbarrier between the two funnels, and it will end up at B. We say that the ball\nhas become trapped in a local minimum : It is at the lowest point if one looks\nin the neighborhood of its current location; but stepping back and looking at\nthe whole landscape, we see that it has missed the global minimum .\nFigur e 12.2  Most landscapes are more comp licated than simple funnels; for\nexample, in this “double funne l,” there's a deep global minimum and a\nshallower local minimum."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 789})","('type', 'Document')"
"('page_content', 'Of course, enormously large physical systems must also try to\nminimize their energy. Consider , for example, taking a few grams of some\nhomogeneous substance, heating it up, and studying its behavior over time.\nTo capture the potential energy exactly , we would in principle need to\nrepresent the behavior of each atom in the substance, as it interacts with\nnearby atoms. But it is also useful to speak of the properties of the system\nas a whole—as an aggregate—and this is the domain of statistical\nmechanics. We will come back to statistical mechanics in a little while, but\nfor now we simply observe that our notion of an “ener gy landscape”\nprovides useful visual intuition  for the process by which even a large\nphysical system minimizes its energy. Thus, while it would in reality take a\nhuge number of dimensions to draw the true “landscape” that constrains the\nsystem, we can use one-dimensional “cartoon” representations to discuss\nthe distinction between local and global energy minima, the “funnels”\naround them, and the “height” of the ener gy barriers between them.\nTaking a molten material and trying to cool it to a perfect crystalline\nsolid is really the process of trying to guide the underlying collection of\natoms to its global potential energy minimum. This can be very difficult,\nand the large number of local minima in a typical energy landscape\nrepresent the pitfalls that can lead the system astray in its search for the\nglobal minimum . Thus, rather than the simple example of Figure 12.2,\nwhich simply contains a single wrong choice, we should be more worried\nabout landscapes with the schematic cartoon representation depicted in\nFigure 12.3. This can be viewed as a “jagged funnel,” in which there are\nlocal minima waiting to trap the system all the way along its journey to the\nbottom.\nFigur e 12.3 In a general energy landscape, there may be a very large\nnumber of local minima that make it hard to find the global minimum, as in\nthe “jagged funnel” drawn here.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 790})","('type', 'Document')"
"('page_content', ""The Connection to Optimization\nThis perspective on energy minimization has really been based on the\nfollowing core ingredients: The physical system can be in one of a large\nnumber of possible states; its energy is a function of its current state; and\nfrom a given state, a small pertu rbation leads to a “neighboring” state. The\nway in which these neighboring states are linked together , along with the\nstructure of the energy functio n on them, defines the underly ing energy\nlandscape.\nIt's from this perspective that we again start to think about\ncomputational minimization problems. In a typical such problem , we have a\nlarge (typically exponential-size) set \n of possi ble solutions. We also have a\ncost function c (·) that measures  the quality of each solution; for a solution S\n∊ \n, we write its cost as c(S). The goal is to find a solution S* ∊ \n for which\nc(S*) is as small as possible.\nSo far this is just the way we've thought about such problems all along.\nWe now add to this the notion of a neighbor relation  on solutions, to\ncapture the idea that one solution S′ can be obtained by a small modification\nof another solution S. We write S ~ S′ to denote that S′ is a neighboring\nsolution of S, and we use N(S) to denote the neighbor hood  of S, the set\n{S′:S~S′}. We will primarily be considering symmetric neighbor relations\nhere, though the basic points we discuss will apply to asymmetric neighbor\nrelations as well. A crucial point  is that, while the set \n of possible solutions\nand the cost function c(·) are provided by the specification of the problem,\nwe have the freedom to make up any neighbor relation that we want.\nA local search algorithm  takes this setup, including a neighbor\nrelation, and works according to the following high-level scheme. At all"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 791})","('type', 'Document')"
"('page_content', ""times, it maintains a current solution S ∊ \n. In a given step, it chooses a\nneighbor S′ of S, declares S′ to be the new current solution, and iterates.\nThroughout the execution of the algorithm, it remembers the minimum-cost\nsolution that it has seen thus far; so, as it runs, it gradually finds better and\nbetter solutions.  The crux of a local search algorithm is in the choice of the\nneighbor relatio n, and in the design of the rule for choosing a neighboring\nsolution at each step.\nThus one can think of a neighbor relation as defining a (generally\nundirected) graph on the set of all possible solutions, with edges joining\nneighboring pairs of solutions. A local search algorithm can then be viewed\nas performing a walk on this graph, trying to move toward a good solution.\nAn Application to the Vertex Cover Problem\nThis is still all somewhat vague  without a concrete problem to think about;\nso we'll use the Vertex Cover Problem as a running example here. It's\nimportant to keep in mind that, while Vertex Cover makes for a good\nexample, there are many other optimization problems that would work just\nas well for this illustration.\nThus we are given a graph G = (V, E); the set \n of possible solutions\nconsists of all subsets S of V that form vertex covers. Hence , for example,\nwe always have V ∊ \n. The cost c(S) of a vertex cover S will simply be its\nsize; in this way, minimizing the cost of a vertex cover is the same as\nfinding one of minimum size. Finally , we will focus our examples on local\nsearch algorithms that use a particularly simple neighbor relation: we say\nthat S ~ S′ if S′ can be obtained  from S by adding or deleting a single node.\nThus our local search algorithms will be walking through the space of\npossible vertex covers, adding or deleting a node to their current solution in\neach step, and trying to find as small a vertex cover as possible.\nOne useful fact about this neighbor relation is the following.\n(12.1)  Each vertex cover S has at most n neighboring solutions.\nThe reason is simply that each neighboring solution of S is obtained by\nadding or deleting a distinct node. A consequence of (12.1) is that we can\nefficiently exam ine all possible neighboring solutions of S in the process of\nchoosing which to select."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 792})","('type', 'Document')"
"('page_content', ""Let's think first about a very simple local search algorithm, whic h we'll\nterm gradient descent.  Gradient descent starts with the full vertex set V and\nuses the following rule for choosing a neighboring solution.\nLet S deno te the current solution. If there is a neighbor S′ of S with strictly lower cost,\nthen choose the neigh bor whose cost is as small as possible. Otherwise terminate the\nalgorithm.\nSo gradient descent moves strictly “downhill” as long as it can; once this is\nno longer possible, it stops.\nWe can see that gradient descent terminates precisely at solutions that\nare local minima:  solutions S such that, for all neighboring S′, we have c(S)\n≤ c(S′). This definition corresponds very naturally to our notion of local\nminima in energy landscapes: They are points from which no one-step\nperturbation will improve the cost function.\nHow can we visualize the behavior of a local search algorithm in terms\nof the kinds of energy landsca pes we illustrated earlier? Let's think first\nabout gradient descent. The easiest instance of Vertex Cover is surely an n-\nnode graph with no edges. The empty set is the optimal solution (since there\nare no edges to cover), and gradient descent does exception ally well at\nfinding this solution: It starts with the full vertex set V, and keeps delet ing\nnodes until there are none left. Indeed, the set of vertex covers for this edge-\nless graph corresponds naturally  to the funnel we drew in Figure 12.1: The\nunique local minimum is the global minimum, and there is a downhill path\nto it from any point.\nWhen can gradient descent go astray? Consider a “star graph” G,\nconsisting of nodes x1, y1, y2, …, yn-1, with an edge from x1 to each yi. The\nminimum vertex cover for G is the singleton set {x1}, and gradient descent\ncan reach this solution by successively deleting y1, …, yn-1 in any order .\nBut, if gradient  descent deletes the node x1 first, then it is immediately\nstuck: No node yi can be deleted without destroying the vertex cover\nproperty , so the only neighborin g solution is the full node set V, which has\nhigher cost. Thus the algorithm  has become trapped in the local minimum\n{y1, y2, …, yn-1}, which has very high cost relative to the global minimum.\nPictorially , we see that we're in a situation corresponding to the double\nfunnel of Figure 12.2. The deeper funnel correspo nds to the optimal\nsolution {x1}, while the shallower funnel corresponds to the inferior local"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 793})","('type', 'Document')"
"('page_content', ""minimum {y1,y2, …,yn-1}. Slidin g down the wrong portion of the slope at\nthe very beginning can send one into the wrong minimum. We can easily\ngeneralize this situation to one in which the two minima have any relative\ndepths we want. Consider , for example, a bipartite graph G with nodes x1,\nx2, …, xk and y1,y2,…,yℓ, where k < ℓ, and there is an edge from every node\nof the form xi to every node of the form yj. Then there are two local minima,\ncorresponding to the vertex covers {x1,…,xk} and {y1,…,yℓ}. Which one is\ndiscovered by a run of gradient descent is entirely determined by whether it\nfirst deletes an element of the form xi or yj.\nWith more complicated graphs, it's often a useful exercise to think\nabout the kind of landscape they induce; and conversely , one sometimes\nmay look at a landscape and consider whether there's a graph that gives rise\nto something like it.\nFor example, what kind of graph might yield a Vertex Cover instance\nwith a landscape like the jagged funnel in Figure 12.3? One such graph is\nsimply an n-node path, where n is an odd number , with nodes labeled V1,\nv2, …, vn in order . The unique minimum vertex cover S* consis ts of all\nnodes vi where i is even. But there are many local optima. For example,\nconsider the vertex cover {v2, v3, v5, v6, v8, v9, …} in which every third\nnode is omitted. This is a verte x cover that is significantly larger than S*;\nbut there's no way to delete any node from it while still covering all edges.\nIndeed, it's very hard for gradient descent to find the minimum vertex cover\nS* starting  from the full vertex set V: Once it's deleted just a single node vi\nwith an even value of i, it's lost the chance to find the global optimum S*.\nThus the even/odd parity distin ction in the nodes captures a plethora of\ndifferent wrong turns in the local search, and hence gives the overall funnel\nits jagged character . Of course, there is not a direct correspondence between\nthe ridges in the drawing and the local optima; as we warned above, Figure\n12.3 is ultimately just a cartoon rendition of what's going on.\nBut we see that even for graphs that are structurally very simple,\ngradient descent is much too straightforward a local search algorithm. We\nnow look at some more refined local search algorithms that use the same\ntype of neighbor relation, but include a method for “escaping”  from local\nminima."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 794})","('type', 'Document')"
"('page_content', ""12.2 The Metropolis Algorithm and Simulated\nAnnealing\nThe first idea for an improved local search algorithm comes from the work\nof Metropolis, Rosenbluth, Rosenbluth, Teller, and Teller (1953). They\nconsidered the problem of simulating the behavior of a phys ical system\naccording to principles of statistical mechanics. A basic model from this\nfield asserts that the probability of finding a physical system in a state with\nenergy E is proportional to the Gibbs-Boltzmann function e-E/(kT), where T >\n0 is the temperature and k > 0 is a constant. Let's look at this function. For\nany temperature T, the function is monotone decreasing in the energy E, so\nthis states that a physical system is more likely to be in a lower energy state\nthan in a high energy state. Now let's consider the effect of the temperature\nT. When T is small, the probability for a low-ener gy state is significantly\nlarger than the probability for a high-ener gy state. However , if the\ntemperature is large, then the difference between these two probabilities is\nvery small, and the system is almost equally likely to be in any state.\nThe Metropolis Algorithm\nMetropolis et al. proposed the following method for performi ng step-by-\nstep simulation of a system at a fixed temperature T. At all times, the\nsimulation main tains a current state of the system and tries to produce a\nnew state by applying a perturbation to this state. We'll assume that we're\nonly interested in states of the system that are “reachable” from some fixed\ninitial state by a sequence of small perturbations, and we'll assume that\nthere is only a finite set \n of such states. In a single step, we first generate a\nsmall random perturbation to the current state S of the system, resulting in a\nnew state S′. Let E(S) and E(S′) denote the ener gies of S and S′, respectively .\nIf E(S′) ≤ E(S), then we updat e the current state to be S′. Otherwise let ΔE =\nE(S′) - E(S) > 0. We update the current state to be S′ with probability e-\nΔE/(kT), and otherwise leave the current state at S.\nMetropolis et al. proved that their simulation algorithm has the\nfollowing property . To prevent too long a digression, we omit the proof; it is\nactually a direct consequence of some basic facts about random walks."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 795})","('type', 'Document')"
"('page_content', '(12.2)  Let\nFor a state S, let fS(t) denote the fraction of the first t steps in which the state of the simulation is in\nS. Then the limit of fS(t) as t approaches  ∞ is, with probability approaching  1, equal to \n.\nThis is exactly the sort of fact one wants, since it says that the\nsimulation spends roughly the correct amount of time in each state,\naccording to the Gibbs-Boltzmann equation.\nIf we want to use this overall scheme to design a local search\nalgorithm for minimization problems, we can use the analogie s of Section\n12.1 in which states of the system are candidate solutions, with energy\ncorresponding to cost. We then see that the operation of the Metropolis\nAlgorithm has a very desirable pair of features in a local search algorithm:\nIt is biased toward “downhill” moves but will also accept “uphill” moves\nwith smaller probability . In this way, it is able to make progress even when\nsituated in a local minimum. Moreover , as expressed in (12.2), it is globally\nbiased toward lower -cost solutions.\nHere is a conc rete formulation  of the Metropolis Algorithm for a\nminimization problem.\nStart with an initial solution S0, and constants k and T\nIn one step:\nLet S be the current solution\nLet S′ be chosen uniformly at random from the neighbors of S\nIf c(S′) ≤ c(S) then\nUpdate S ← S′\nElse\nWith probability e-(c(S′)-c(S))/(kT)\nUpdate S ← S′\nOtherwise\nLeave S unchanged\nEndIf\nThus, on the Vertex Cover instance consisting of the star graph in\nSection 12.1, in which x1 is joined to each of y1, …, yn-1, we see that the')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 796})","('type', 'Document')"
"('page_content', ""Metropolis Algorithm will quickly bounce out of the local minimum that\narises when x1 is deleted: The neighboring solution in which x1 is put back\nin will be genera ted and will be accepted with positive probabili ty. On more\ncomplex graphs  as well, the Metropolis Algorithm is able, to some extent,\nto correct the wrong choices it makes as it proceeds.\nAt the same time, the Metropolis Algorithm does not always behave\nthe way one would want, even in some very simple situations. Let's go back\nto the very first graph we considered, a graph G with no edges. Gradient\ndescent solves this instance with no trouble, deleting nodes in sequence\nuntil none are left. But, while the Metropolis Algorithm will start out this\nway, it begins to go astray as it nears the global optimum. Consider the\nsituation in which the current solution contains only c nodes, where c is\nmuch smaller than the total number of nodes, n. With very high probability ,\nthe neighboring solution generated by the Metropolis Algorithm will have\nsize c + 1, rather than c - 1, and with reasonable probability this uphill move\nwill be accepted. Thus it gets harder and harder to shrink the size of the\nvertex cover as the algorithm proceeds; it is exhibiting a sort of “flinching”\nreaction near the bottom of the funnel.\nThis behavior shows up in more complex examples as well, and in\nmore complex ways; but it is certainly striking for it to show up here so\nsimply . In order to figure out how we might fix this behavior , we return to\nthe physical analogy that motivated the Metropolis Algorithm , and ask:\nWhat's the meaning of the temperature parameter T in the context of\noptimization?\nWe can think of T as a one-dimensional knob that we're able to turn,\nand it controls the extent to which the algorithm is willing to accept uphill\nmoves. As we make T very large, the probability of accepting an uphill\nmove approaches 1, and the Metropolis Algorithm behaves like a random\nwalk that is basically indifferen t to the cost function. As we make T very\nclose to 0, on the other hand, uphill moves are almost never accepted, and\nthe Metropolis Algorithm behaves almost identically to gradient descent.\nSimulated Annealing\nNeither of these temperature extremes—very low or very high—is an\neffective way to solve minimization problems in general, and we can see\nthis in physical settings as well. If we take a solid and heat it to a very high"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 797})","('type', 'Document')"
"('page_content', ""temperature, we do not expect it to maintain a nice crystal structure, even if\nthis is energetica lly favorable; and this can be explained by the large value\nof kT in the expression e-E(S)/(kT), which makes the enormous number of less\nfavorable states  too probable. This is a way in which we can view the\n“flinching” behavior of the Metropolis Algorithm on an easy Vertex Cover\ninstance: It's trying to find the lowest energy state at too high a temperature,\nwhen all the competing states have too high a probability . On the other\nhand, if we take a molten solid and freeze it very abruptly , we do not expect\nto get a perfect crystal either; rather , we get a deformed crystal structure\nwith many impe rfections. This is because, with T very small, we've come\ntoo close to the realm of gradient descent, and the system has become\ntrapped in one of the numerous ridges of its jagged energy landscape. It is\ninteresting to note that when T is very small, then statement (12.2) shows\nthat in the limit , the random walk spends most of its time in the lowest\nenergy state. The problem is that the random walk will take an enormous\namount of time before getting anywhere near this limit.\nIn the early 1980s, as people were considering the connection between\nenergy minimization and comb inatorial optimization, Kirkpatrick, Gelatt,\nand Vecchi (1983) thought about the issues we've been discussin g, and they\nasked the following question: How do we solve this problem for physical\nsystems, and what sort of algori thm does this suggest? In physical systems,\none guides a material to a crystalline state by a process known as annealing :\nThe material is cooled very gradually from a high temperature, allowing it\nenough time to reach equilibrium at a succession of intermediate lower\ntemperatures. In this way, it is able to escape from the energy minima that it\nencounters all the way through the cooling process, eventually arriving at\nthe global optimum.\nWe can thus try to mimic this process computationally , arrivin g at an\nalgorithmic technique known as simulated annealing.  Simulated annealing\nworks by running the Metropolis Algorithm while gradually decreasing the\nvalue of T over the course of the executio n. The exact way in which T is\nupdated is called, for natural reasons, a cooling schedule,  and a number of\nconsiderations go into the design of the cooling schedule. Formally , a\ncooling schedule is a function τ from {1, 2, 3, …} to the positive real\nnumbers; in iteration i of the Metropolis Algorithm, we use the temperature\nT = τ(i) in our definition of the probability ."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 798})","('type', 'Document')"
"('page_content', 'Qualitatively , we can see that simulated annealing allows for large\nchanges in the solution in the early stages of its execution, when the\ntemperature is high. Then, as the search proceeds, the temperature is\nlowered so that we are less likely to undo progress that has already been\nmade. We can also view simulated annealing as trying to optimize a trade-\noff that is implicit in (12.2). According to (12.2), values of T arbitrarily\nclose to 0 put the highest probability on minimum-cost solution s; however ,\n(12.2) by itself says nothing about the rate of conver gence of the functions\nfS(t) that it uses. It turns out that these functions conver ge, in general, much\nmore rapidly for large values of T; and so to find minimum-cost solutions\nquickly , it is useful to speed up conver gence by starting the process with T\nlarge, and then gradually reduc ing it so as to raise the probability on the\noptimal solutions. While we believe that physical systems reach a minimum\nenergy state via annealing, the simulated annealing method has no\nguarantee of finding an optimal solution. To see why, consider the double\nfunnel of Figure 12.2. If the two funnels take equal area, then at high\ntemperatures the system is essentially equally likely to be in either funnel.\nOnce we cool the temperature, it will become harder and harder to switch\nbetween the two funnels. There appears to be no guarantee that at the end of\nannealing, we will be at the bottom of the lower funnel.\nThere are many open problems associated with simulated annealing,\nboth in proving properties of its behavior and in determining the range of\nsettings for which it works well in practice. Some of the general questions\nthat come up here involve probabilistic issues that are beyond the scope of\nthis book.\nHaving spent some time considering local search at a very general\nlevel, we now turn, in the next few sections, to some applications in which\nit is possible to prove fairly strong statements about the behavior of local\nsearch algorithms and about the local optima that they find.\n12.3 An Application of Local Search to Hopfield\nNeural Networks\nThus far we have been discussin g local search as a method for trying to find\nthe global optimum in a comp utational problem. There are some cases,')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 799})","('type', 'Document')"
"('page_content', 'however , in which, by examinin g the specification of the proble m carefully ,\nwe discover that it is really just an arbitrary local  optimum that is required.\nWe now consider a problem that illustrates this phenomenon.\nThe Problem\nThe problem we consider here is that of finding stable configurations  in\nHopfield neural networks.  Hopfield networks have been  proposed as a\nsimple model of an associative memory , in which a large collection of units\nare connected by an underlyin g network, and neighboring units try to\ncorrelate their states. Concretely , a Hopfield network can be viewed as an\nundirected graph G = (V, E), with an intege r-valued weight we on each edge\ne; each weight may be positive or negative. A configuration S of the\nnetwork is an assignment of the value -1 or +1 to each node u; we will refer\nto this value as the state su of the node u. The meaning of a configuration is\nthat each node u, represe nting a unit of the neural network, is trying to\nchoose between one of two possible states (“on” or “off”; “yes” or “no”);\nand its choice is influenced by those of its neighbors as follows. Each edge\nof the network imposes a requir ement  on its endpoints: If u is joined to v by\nan edge of negative weight, then u and v want to have the same state, while\nif u is joined to v by an edge of positive weight, then u and v want to have\nopposite states. The absolute value |we| will indicate the strength  of this\nrequirement, and we will refer to | we| as the absolute weight  of edge e.\nUnfortunately , there may be no configuration that respects the\nrequirements imposed by all the edges. For example, consider three nodes\na, b, c  all mutually connected to one another by edges of weight 1. Then, no\nmatter what configuration we choose, two of these nodes will have the same\nstate and thus will be violating the requirement that they have opposite\nstates.\nIn view of this, we ask for something weaker . With respect to a given\nconfiguration, we say that an edge e = (u, v) is good  if the requirement it\nimposes is satisfied by the states of its two endpoints: either we < 0 and su =\nsv, or we > 0 and su ≠ sv. Otherwise we say e is bad. Note that we can\nexpress the condition that e is good very compactly , as follows: wesusv < 0.\nNext we say that a node u is satisfied  in a given configuration if the total')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 800})","('type', 'Document')"
"('page_content', 'absolute weight of all good edges incident to u is at least as lar ge as the total\nabsolute weight of all bad edges incident to u. We can write this as\nFinally , we call a configuration stable  if all nodes are satisfied.\nWhy do we use the term stable  for such config urations? This is based\non viewing the network from the perspective of an individual node u. On its\nown, the only choice u has is whether to take the state -1 or +1; and like all\nnodes, it wants to respect as many edge requirements as possible (as\nmeasured in absolute weight). Suppose u asks: Should I flip my current\nstate? We see that if u does flip its state (while all other nodes keep their\nstates the same), then all the good edges incident to u become bad, and all\nthe bad edges incident to u become good. So, to maximize the amount of\ngood edge weig ht under its direct control, u should flip its state if and only\nif it is not satisfied. In other words, a stable configuration is one in which no\nindividual node has an incentive to flip its current state.\nA basic question  now arises: Does a Hopfield network always have a\nstable configuration, and if so, how can we find one?\nDesigning the Algorithm\nWe will now design an algorithm that establishes the following result.\n(12.3)  Every Hopfield netwo rk has a stable configuration, and such a configuration can be found in\ntime polynomial in n and W  = Σe |we|.\nWe will see that stable configurations in fact arise very naturally as the\nlocal optima of a certain local search procedure on the Hopfield network.\nTo see that the statement of (12.3) is not entirely trivial, we note that it\nfails to remain true if one chan ges the model in certain natural ways. For\nexample, suppos e we were to define a directed Hopfield network  exactly as\nabove, except that each edge is directed, and each node determi nes whether\nor not it is satisfied by looking only at edges for which it is the tail. Then, in\nfact, such a network need not have a stable configuration. Consider , for')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 801})","('type', 'Document')"
"('page_content', 'example, a directed version of the three-node network we discussed earlier:\nThere are nodes  a, b, c, with directed edges (a, b), (b, c), (c, a), all of\nweight 1. Then, if all nodes have  the same state, they will all be unsatisfied;\nand if one node has a differen t state from the other two, then the node\ndirectly in front of it will be unsatisfied. Thus there is no configuration of\nthis directed network in which all nodes are satisfied.\nIt is clear that a proof of (12.3 ) will need to rely somewhere on the\nundirected nature of the network.\nTo prove (12.3), we will analyze the following simple iterative\nprocedure, which we call the State-Flipping Algorithm, to search for a\nstable configuration.\nWhile the current configuration is not stable\nThere must be an unsatisfied node\nChoose an unsatisfied node u\nFlip the state of u\nEndwhile\nAn exam ple of the execution of this algorithm is depicted in Figure\n12.4, ending in a stable configuration.\nFigur e 12.4 Parts (a)–(f) depict the steps in an execution of the State-\nFlipping Algorithm for a five-node Hopfield network, ending in a stable\nconfiguration. (Nodes are colored black or white to indicate their state.)')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 802})","('type', 'Document')"
"('page_content', ""Analyzing the Algorithm\nClearly , if the State-Flipping Algorithm  we have just defined terminates, we\nwill have a stable configuration . What is not obvious is whether it must in\nfact terminate. Indeed, in the earlier directed example, this process will\nsimply cycle through the three nodes, flipping their states sequentially\nforever .\nWe now prove that the State-Flipping Algorithm always terminates,\nand we give a bound on the number of iterations it takes until termination.\nThis will provide a proof of (12.3). The key to proving that this process\nterminates is an idea we've used in several previous situations: to look for a\nmeasure of progress—namely , a quantity that strictly increases with every\nflip and has an absolute upper bound. This can be used to bound  the number\nof iterations.\nProbably the most natural progress measure would be the number of\nsatisfied nodes: If this increased  every time we flipped an unsatisfied node,\nthe process would run for at most n iterations before terminating with a\nstable configuration. Unfortunately , this does not turn out to work. When"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 803})","('type', 'Document')"
"('page_content', ""we flip an unsat isfied node v, it's true that it has now become satisfied, but\nseveral of its previously satisfied neighbors could now become unsatisfied,\nresulting in a net decrease in the number of satisfied nodes. This actually\nhappens in one of the iterations depicted in Figure 12.4: when the middle\nnode changes state, it render s both of its (formerly satisfied) lower\nneighbors unsatisfied.\nWe also can't try to prove termination by arguing that every  node\nchanges state at most once during the execution of the algorithm: Again,\nlooking at the example in Figure 12.4, we see that the node in the lower\nright changes state twice. (And there are more complex exampl es in which\nwe can get a single node to change state many times.)\nHowever , there is a more subtl e progress measure that does increase\nwith each flip of an unsatisfied node. Specifically , for a given configuration\nS, we define Φ(S) to be the total absolute weight of all good edges in the\nnetwork. That is,\nClearly , for any configuration S, we have Φ(S) ≥ 0 (since Φ(S) is a sum of\npositive integers ), and Φ(S) ≤ W = Σe|we| (since,  at most, every edge is\ngood).\nNow suppose that, in a nonstable configuration S, we choose a node u\nthat is unsatisfie d and flip its state, resulting in a configuration S′. What can\nwe say about the relationship of Φ(S′) to Φ(S)? Recall that when u flips its\nstate, all good edges incident to u become bad, all bad edges incident to u\nbecome good, and all edges that don't have u as an endpoint remain the\nsame. So, if we let gu and bu denote the total absolute weight on good and\nbad edges incident to u, respectively , then we have"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 804})","('type', 'Document')"
"('page_content', ""But, since u was unsatisfied in S, we also know that bu > gu; and since bu\nand gu are both integers, we in fact have bu ≥ gu + 1. Thus\nHence the value of Φ begins at some nonnegative integer , increa ses by\nat least 1 on every flip, and cannot exceed W. Thus our process runs for at\nmost W iterations, and when it terminates, we must have a stable\nconfiguration. Moreover , in each iteration we can identify an unsatisfied\nnode using a number of arithmetic operations that is polynomial  in n; thus a\nrunning-time bound that is polynomial in n and W follows as well.\nSo we see that, in the end, the existence proof for stable configu rations\nwas really about local search. We first set up an objective function Φ that\nwe sought to maximize. Configurations were the possible solutions to this\nmaximization problem, and we defined what it meant for two\nconfigurations S and S′ to be neighbors: S′ should be obtai nable from S by\nflipping a single state. We then studied the behavior of a simple iterative\nimprovement algorithm for local search (the upside-down form of gradient\ndescent, since we have a maxi mization problem); and we discovered the\nfollowing.\n(12.4)  Any local maximum in the State-Flipping Algorithm to maximize  Φ is a stable configuration.\nIt's worth noting that while our algorithm proves the existence of a\nstable configuration, the running time leaves something to be desired when\nthe absolute weights are large. Specifically , and analogously to what we\nsaw in the Subset Sum Problem and in our first algorithm for maximum\nflow, the algorithm we obtain here is polynomial only in the actual\nmagnitude of the weights, not in the size of their binary represe ntation. For\nvery lar ge weights, this can lead to running times that are quite infeasible.\nHowever , no simple way aroun d this situation is currently known. It\nturns out to be an open question to find an algorithm that constructs stable\nstates in time polynomial in n and log W (rather than n and W), or in a\nnumber of primitive arithmetic operations that is polynomial in n alone,\nindependent of the value of W."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 805})","('type', 'Document')"
"('page_content', '12.4 Maximum-Cut Approximation via Local\nSearch\nWe now discuss a case where a local search algorithm can be used to\nprovide a provable approximation guarantee for an optimization problem.\nWe will do this by analyzing the structure of the local optima, and bounding\nthe quality of these locally optimal solutions relative to the global optimum.\nThe problem we consider is the Maximum-Cut Problem, which is closely\nrelated to the problem of finding stable configurations for Hopfield\nnetworks that we saw in the previous section.\nThe Problem\nIn the Maximum-Cut Pr oblem,  we are given an undirected graph G = (V, E),\nwith a positive integer weight we on each edge e. For a partition (A, B) of\nthe verte x set, we use w(A, B) to denote the total weight of edges with one\nend in A and the other in B:\nThe goal is to find a partition (A, B) of the vertex set so that w(A, B) is\nmaximized. Maximum Cut is NP-hard, in the sense that, given a weighted\ngraph G and a bound β, it is NP-complete to decide whether there is a\npartition (A, B) of the vertices of G with w(A,B) ≥ β. At the same time, of\ncourse, Maximum Cut resembles the polynomially solvable Minimum s-t\nCut Problem for flow networks; the crux of its intractability comes from the\nfact that we are seeking to maximize the edge weight across the cut, rather\nthan minimize it.\nAlthough the problem of findin g a stable configuration of a Hopfield\nnetwork was not an optimization  problem per se, we can see that Maximum\nCut is closely related to it. In the language of Hopfield networks, Maximum\nCut is an insta nce in which all edge weights are positive (rather than\nnegative), and configurations of nodes states S correspond naturally to')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 806})","('type', 'Document')"
"('page_content', ""partitions ( A, B): Nodes have state -1 if and only if they are in the set A, and\nstate +1 if and only if they are in the set B. The goal is to assign states so\nthat as much weight as possible is on good edges —those whose endpoints\nhave opposite states. Phrased this way, Maximum Cut seeks to maximize\nprecisely the quantity Φ(S) that we used in the proof of (12.3), in the case\nwhen all edge weights are positive.\nDesigning the Algorithm\nThe State-Flipping Algorithm used for Hopfield networks provides a local\nsearch algorithm to approximate  the Maximum Cut objective function Φ(S)\n= w(A,B). In terms of partitions, it says the following: If there exists a node\nu such that the total weight of edges from u to nodes in its own side of the\npartition exceeds the total weight of edges from u to node s on the other side\nof the partition, then u itself should be moved to the other side of the\npartition.\nWe'll call this the “single-flip” neighborhood on partitions: Partitions\n(A,B) and (A′,B′ ) are neighboring solutions if (A′,B′ ) can be obtained from\n(A, B) by moving a single node from one side of the partition to the other .\nLet's ask two basic questions.\nCan we say anything concrete about the quality of the local optima\nunder the single-flip neighborhood?\nSince the single-flip neighborhood is about as simple as one could\nimagine, what other neighborhoods might yield stronger local search\nalgorithms for Maximum Cut?\nWe address the first of these questions here, and we take up the second one\nin the next section.\nAnalyzing the Algorithm\nThe following result addresses the first question, showing that local optima\nunder the single-flip neighborhood provide solutions achieving a\nguaranteed approximation bound.\n(12.5)  Let (A, B) be a partition that is a local optimum for Maximum Cut under the single-flip\nneighbor hood. Let  (A*,B* ) be a globally optimal partition. Then w (A,B) ≥ ½ w(A*,B* )."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 807})","('type', 'Document')"
"('page_content', 'Proof. Let W = Σe we. We also extend our notation a little: for two nodes u and v, we use wuv to\ndenote we if there is an edge e joining u and v, and 0 otherwise.\nFor any node u ∊ A, we must have\nsince otherwise u should be moved to the other side of the partition, and (A, B) would not be locally\noptimal. Suppose we add up these inequal ities for all u ∊ A; any edge that has both ends in A will\nappear on the left-han d side of exactly two of these inequalities, while any edge that has one end in A\nand one end in B will appear on the right-hand side of exactly one of these inequalities. Thus, we\nhave\nWe can apply the same reasoning to the set B, obtaining\nIf we add together inequalities (12.1)  and (12.2) , and divide by 2, we get\nThe left-ha nd side of inequality (12.3)  accounts for all edge weight that does not cross from A to B;\nso if we add w(A, B) to both sides of (12.3) , the left-hand side becomes equal to W. The right-hand\nside becomes 2 w(A, B), so we have W ≤ 2w(A, B), or w(A, B) ≥ ½ W.\nSince the globally optimal partition (A*,B* ) clearly satisfies w(A*,B* ) ≤ W, we have w(A,B) ≥\n½w(A*,B* ). ▪\nNotice that we never really thought much about the optimal partition\n(A*, B*) in the proof of (12.5); we really showed the stronger statement\nthat, in any locally optimal solution under the single-flip neighborhood, at\nleast half the total edge weight in the graph crosses the partition.\nStatement (12.5) proves that a local optimum is a 2-approximation to\nthe maximum cut. This suggests that the local optimization may be a good\nalgorithm for approximately maximizing the cut value. However , there is')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 808})","('type', 'Document')"
"('page_content', 'one more issue that we need to consider: the running time. As we saw at the\nend of Section 12.3, the Single-Flip Algorithm is only pseudo-polynomial,\nand it is an open problem whether a local optimum can be found in\npolynomial time. However , in this case we can do almost as well, simply by\nstopping the algorithm when there are no “big enough” improvements.\nLet (A, B) be a partition with weight w(A, B). For a fixed ε > 0, let us\nsay that a single node flip is a big-impr ovement-flip  if it improves the cut\nvalue by at least \n  where n = |V|. Now consider a version of the\nSingle-Flip Algorithm when we only accept big-improveme nt-flips and\nterminate once no such flip exists, even if the current partition is not a local\noptimum. We claim that this will lead to almost as good an approximation\nand will run in polynomial time. First we can extend the previo us proof to\nshow that the resulting cut is almost as good. We simply have to add the\nterm \n  to each inequal ity, as all we know is that there are no big-\nimprovement-flips.\n(12.6)  Let (A, B) be a partit ion such that no big-impr ovement-flip is possible. Let (A*, B*) be a\nglobally optimal partition. Then  (2 + ε) w(A, B) ≥ w(A*,B* ).\nNext we consider the running time.\n(12.7)  The versio n of the Single-Flip Algorithm that only accepts big-impr ovement-flips terminates\nafter at most O (ε-1n log W) flips, assuming the weights ar e integral, and W  = Σewe.\nProof. Each  flip improves the objective function by at least a factor of (1 + ε/n). Since (1 + 1/x)x ≥ 2\nfor any x ≥ 1, we see that (1 + ε/n)n/ε ≥ 2, and so the objective function increas es by a factor of at\nleast 2 every n/ε flips. The weight cannot exceed W, and hence it can only be doubled at most log W\ntimes. ▪\n12.5 Choosing a Neighbor Relation\nWe began the chapter by saying that a local search algorithm is really based\non two fundamental ingredients: the choice of the neighbor relation, and the\nrule for choosing a neighboring solution at each step. In Section 12.2 we\nspent time thinking about the second of these: both the Metropolis\nAlgorithm and simulated annealing took the neighbor relation as given and\nmodified the way in which a neighboring solution should be chosen.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 809})","('type', 'Document')"
"('page_content', ""What are some of the issues that should go into our choice of the\nneighbor relatio n? This can turn out to be quite subtle, though at a high\nlevel the trade-of f is a basic one.\n(i) The neighborhood of a solution should be rich enough that we do not\ntend to get stuck in bad local optima; but\n(ii) the neighborhood of a solution should not be too large, since we want to\nbe able to ef ficiently search the set of neighbors for possible local moves.\nIf the first of these points were the only concern, then it would seem that we\nshould simply make all solution s neighbors of one another—after all, then\nthere would be no local optima, and the global optimum would always be\njust one step away! The second point exposes the (obvious) problem with\ndoing this: If the neighborhood of the current solution consists of every\npossible solution, then the local search paradigm gives us no leverage\nwhatsoever; it reduces simply to brute-force search of this neighborhood.\nActually , we've already encountered one case in which choosing the\nright neighbor relation had a profound effect on the tracta bility of a\nproblem, though  we did not explicitly take note of this at the time: This was\nin the Bipartite Matching Proble m. Probably the simplest neighbor relation\non matchings would be the following: M′ is a neighbor of M if M′ can be\nobtained by the insertion or deletion of a single edge in M. Under this\ndefinition, we get “landscapes” that are quite jagged, quite like the Vertex\nCover examples we saw earlier; and we can get locally optimal matchings\nunder this definition that have only half the size of the maximum matching.\nBut suppose we try defining a more complicated (indeed, asymmetric)\nneighbor relation : We say that M′ is a neighbor of M if, when  we set up the\ncorresponding flow network, M′ can be obtained from M by a single\naugmenting path. What can we say about a matching M if it is a local\nmaximum under this neighbor relation? In this case, there is no augmenting\npath, and so M must in fact be a (globally) maximum matching. In other\nwords, with this neighbor relation, the only local maxima are global\nmaxima, and so direct gradient ascent will produce a maximum matching. If\nwe reflect on what the Ford-Fulkerson algorithm is doing in our reduction\nfrom Bipartite Matching to Maximum Flow , this makes sense: the size of\nthe matc hing strictly increases in each step, and we never need to “back\nout” of a local maximum. Thus, by choosing the neighbor relation very\ncarefully , we've turned a jagged optimization landscape into a simple,\ntractable funnel."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 810})","('type', 'Document')"
"('page_content', ""Of course, we do not expect that things will always work out this well.\nFor example, since V ertex Cover is NP-complete, it would be surprising if it\nallowed for a neighbor relation that simultaneously produced “well-\nbehaved” landscapes and neighborhoods that could be searched efficiently .\nWe now look at several possible neighbor relations in the context of the\nMaximum Cut Problem, which we considered in the previous section. The\ncontrasts among these neighbor relations will be characteristic of issues that\narise in the general topic of local search algorithms for computationally\nhard graph-partitioning problems.\nLocal Search Algorithms for Graph Partitioning\nIn Section 12.4 , we considered a state-flipping algorithm for the Maximum-\nCut Problem, and we showed that the locally optimal solutions provide a 2-\napproximation. We now consider neighbor relations that produce larger\nneighborhoods than the single-flip rule, and consequently attempt to reduce\nthe prevalence of local optima.  Perhaps the most natural gene ralization is\nthe k-flip neighbor hood,  for k ≥ 1: we say that partitions (A,B) and (A′,B′ )\nare neighbors under the k-flip rule if (A′, B′ ) can be obtaine d from (A, B) by\nmoving at most k nodes from one side of the partition to the other .\nNow , clearly if (A, B) and (A′, B′) are neighbors under the k-flip rule,\nthen they are also neighbors under the k′-flip rule for every k′ > k. Thus, if\n(A, B) is a local optimum under the k′-flip rule, it is also a local optimum\nunder the k-flip rule for every k < k′. But reducing the set of local optima by\nraising the value of k comes at a steep computational price: to examine the\nset of neighbors of (A, B) under the k-flip rule, we must consider all Θ(nk)\nways of moving up to k nodes to the opposite side of the partition. This\nbecomes prohibitive even for small values of k.\nKernighan and Lin (1970) propo sed an alternate method for generating\nneighboring solutions; it is computationally much more efficient, but still\nallows large-sca le transformati ons of solutions in a single step. Their\nmethod, which we'll call the K-L heuristic, defines the neighbors of a\npartition ( A, B) according the following n-phase procedure.\nIn phase 1, we choose a single node to flip, in such a way that the\nvalue of the resulting solution is as large as possible. We perform this\nflip even  if the value of the solution decreases relative to w(A,B). We"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 811})","('type', 'Document')"
"('page_content', 'mark  the node that has been flipp ed and let (A1, B1) denote the\nresulting solution.\nAt the start of phase k, for k > 1, we have a partition (Ak-1, Bk-1); and k\n- 1 of the nodes are marked. We choose a single unmarked node to flip,\nin such a way that the value of the resulting solution is as large as\npossible. (Again , we do this even if the value of the solution decreases\nas a result.) We mark the node we flip and let (Ak, Bk) denote the\nresulting solution.\nAfter n phases, each node is marked, indicating that it has been flipped\nprecisely once. Consequently , the final partition (An,Bn) is actually the\nmirror image of the original partition (A, B): We have An = B and Bn =\nA.\nFinally , the K-L heuristic defines the n - 1 partitions (A1,B1), …, (An-1,\nBn-1) to be the neighbors of (A, B). Thus (A, B) is a local optimum\nunder the K-L heuristic if and only if w(A, B) ≥ w(Ai, Bj) for 1 ≤ i ≤ n -\n1.\nSo we see that the K-L heuristic tries a very long sequence of flips,\neven while it appears to be making things worse, in the hope that some\npartition ( Ai,Bj) generated along the way will turn out better than (A,B). But\neven though it generates neighbors very different from (A, B), it only\nperforms n flips in total, and each takes only O(n) time to perform . Thus it\nis computationa lly much more reasonable than the k-flip rule for larger\nvalues of k. Moreov er, the K-L heuristic has turned out to be very powerful\nin practice, despite the fact that rigorous analysis of its properties has\nremained lar gely an open problem.\n* 12.6 Classification via Local Search\nWe now consider a more complex application of local search to the design\nof approximation algorithms, related to the Image Segmentation Problem\nthat we consider ed as an applic ation of network flow in Section 7.10. The\nmore complex version of Image Segmentation that we focus on here will\nserve as an example where, in order to obtain good performance from a\nlocal search algorithm, one needs to use a rather complex neighborhood')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 812})","('type', 'Document')"
"('page_content', 'structure on the set of solutions. We will find that the natural “state-\nflipping” neighborhood that we saw in earlier sections can result in very\nbad local optima. To obtain good performance, we will instead use an\nexponentially large neighborhood. One problem with such a large\nneighborhood is that we can no longer afford to search though all neighbors\nof the current solution one by one for an improving solution. Rather , we\nwill need a more sophisticated algorithm to find an improving neighbor\nwhenever one exists.\nThe Problem\nRecall the basic Image Segmentation Problem that we considered as an\napplication of network flow in Section 7.10. There we formulated the\nproblem of segmenting an image as a labeling  problem ; the goal was to\nlabel (i.e., classify) each pixel as belonging to the foreground or the\nbackground of the image. At the time, it was clear that this was a very\nsimple formulation of the problem, and it would be nice to handle more\ncomplex labelin g tasks—for example, to segment the regions of an image\nbased on their distance from the camera. Thus we now consider a labeling\nproblem with more than two labels. In the process, we will end up with a\nframework for classification that applies more broadly than just to the case\nof pixels in an image.\nIn setting up the two-label foreground/background segmentation\nproblem, we ultimately arrived at the following formulation. We were given\na graph G = (V, E) where V corresponded to the pixels of the image, and the\ngoal was to classify each node  in V as belonging to one of two possible\nclasses: foreground or background. Edges represented pairs of nodes likely\nto belon g to the same class (e.g., because they were next to each other), and\nfor each edge (i, j) we were given  a separation penalty pij ≥ 0 for placing  i\nand j in different classes. In addition, we had information about the\nlikelihood of whether a node or pixel was more likely to belong to the\nforeground or the background. These likelihoods translated into penalties\nfor assig ning a node to the class where it was less likely to belon g. Then the\nproblem was to find a labeling of the nodes that minimized the total\nseparation and assignment penalties. We showed that this minimization\nproblem could be solved via a minimum-cut computation. For the rest of')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 813})","('type', 'Document')"
"('page_content', ""this section, we will refer to the problem we defined there as Two-Label\nImage Segmentation .\nHere we will formulate the analogous classification/labeling problem\nwith more than two classes or labels. This problem will turn out to be NP-\nhard, and we will develop a local search algorithm where the local optima\nare 2-approximations for the best labeling. The general labeling problem,\nwhich we will consider in this section, is formulated as follows. We are\ngiven a graph G = (V, E) and a set L of k labels. The goal is to label each\nnode in V with one of the labels in L so as to minim ize a certain penalty .\nThere are two competing forces that will guide the choice of the best\nlabeling. For each edge (i,j) ∊ E, we have a separation penalty pij ≥ 0 for\nlabeling the two nodes i and j with different labels. In addition, nodes are\nmore likely to have certain labels than others. This is expressed through an\nassignment penalty . For each node i ∊ V and each label a ∊ L, we have a\nnonnegative penalty ci(a) ≥ 0 for assig ning label a to node i. (These\npenalties play the role of the likelihoods from the Two-Label Image\nSegmentation Problem, except that here we view them as costs to be\nminimized.) The Labeling Problem  is to find a labeling f: V → L that\nminimizes the total penalty:\nObserve that the Labeling Problem with only two labels is precisely\nthe Image Segmentation Proble m from Section 7.10. For three labels, the\nLabeling Problem is already NP-hard, though we will not prove this here.\nOur goal is to develop a local search algorithm for this problem, in\nwhich local optima are good approximations to the optimal solution. This\nwill also serve as an illustrat ion of the importance of choosing good\nneighborhoods for defining the local search algorithm. Ther e are many\npossible choices for neighbor relations, and we'll see that some work a lot\nbetter than others. In particu lar, a fairly complex definition of the\nneighborhoods will be used to obtain the approximation guarantee.\nDesigning the Algorithm"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 814})","('type', 'Document')"
"('page_content', ""A First Attempt: The Single-F lip Rule  The simplest and perhaps most\nnatural choice for neighbor relation is the single-flip rule from the State-\nFlipping Algorithm for the Maximum-Cut Problem: Two labelings are\nneighbors if we can obtain one from the other by relabeling a single node.\nUnfortunately , this neighborhood can lead to quite poor local optima for our\nproblem even when there are only two labels.\nThis may be initially surprising , since the rule worked quite well for\nthe Maximum-Cut Problem. However , our problem is related to the\nMinimum-Cut Problem. In fact, Minimum s-t Cut corresponds to a special\ncase when there are only two labels, and s and t are the only nodes with\nassignment penalties. It is not hard to see that this State-Flipping  Algorithm\nis not a good approximation algorithm for the Minimum-Cut Problem. See\nFigure 12.5, which indicates how the edges incident to s may form the\nglobal optimum, while the edges incident to t can form a local optimum that\nis much worse.\nA Closer Attempt: Considering Two Labels at a Time Here we will\ndevelop a local search algorith m in which the neighborhoods are much\nmore elaborate. One interesting  feature of our algorithm is that it allows\neach solution to have exponentially many neighbors. This appears to be\ncontrary to the general rule that “the neighborhood of a solution should not\nbe too large,” as stated in Section 12.5. However , we will be working with\nneighborhoods in a more subtle way here. Keeping the size of the\nneighborhood small is good if the plan is to search for an improving local\nstep by brute force; here, however , we will use a polynomial-time\nminimum-cut computation to determine whether any of a solution's\nexponentially many neighbors represent an improvement.\nFigur e 12.5 An instance of the Minimum s-t Cut Problem, where all edges\nhave capacity 1."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 815})","('type', 'Document')"
"('page_content', ""The idea of the local search is to use our polynomial-time algorithm\nfor Two-Label Image Segmenta tion to find improving local steps. First let's\nconsider a basic implementation of this idea that does not always give a\ngood approximation guarantee. For a labeling f, we pick two labels a,b ∊ L\nand restrict atten tion to the nodes that have labels a or b in label ing f. In a\nsingle local step, we will allow any subset of these nodes to flip labels from\na to b, or from  b to a. More formally , two labelings f and f′ are neighbors if\nthere are two labels a,b ∊ L such that for all other labels c ∉ {a, b} and all\nnodes i ∊ V, we have f(i) = c if and only if f′(i) = c. Note that a state f can\nhave exponentially many neigh bors, as an arbitrary subset of the nodes\nlabeled a and b can flip their label. However , we have the following.\n(12.8)  If a labeling f is not locally optimal for the neighbor hood above, then a neighbor with smaller\npenalty can be found via k2 minimum-cut computations.\nProof. Ther e are fewer than k2 pairs of distinct labels, so we can try each pair separately . Given a\npair of labels a,b ∊ L, consider the problem of finding an improved labeling via swapping labels of\nnodes between labels a and b. This is exactly the Segmentation Problem for two labels on the\nsubgraph of nodes that f labels a or b. We use the algorithm developed for Two-Label Image\nSegmentation to find the best such relabeling. ▪\nFigur e 12.6 A bad local optimum for the local search algorithm that\nconsiders only two labels at a time."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 816})","('type', 'Document')"
"('page_content', 'This neighborhood is much better than the single-flip neighborhood we\nconsidered first. For example, it solves the case of two labels optimally .\nHowever , even with this improved neighborhood, local optima can still be\nbad, as shown in Figure 12.6 . In this example, there are three nodes s, t, and\nz that are each required to keep their initial labels. Each other node lies on\none of the sides of the triangle; it has to get one of the two labels associated\nwith the nodes at the ends of this side. These requirements can be expressed\nsimply by givin g each node a very large assignment penalty for the labels\nthat we are not allowing. We define the edge separation penalties as\nfollows: The light edges in the figure have penalty 1, while the heavy edges\nhave a large separation penalty of M. Now observe that the labeling  in the\nfigure has penalty M + 3 but is locally optimal. The (globally) optimal\npenalty is only 3 and is obtained from the labeling in the figure by\nrelabeling both nodes next to s.\nA Local  Search Neighborhood  That Works Next we define a different\nneighborhood that leads to a good approximation algorithm. The local\noptimum in Figure 12.6 may be suggestive of what would be a good\nneighborhood: We need to be able to relabel nodes of different labels in a\nsingle step. The key is to find a neighbor relation rich enough to have this\nproperty , yet one that still allows us to find an improving local step in\npolynomial time.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 817})","('type', 'Document')"
"('page_content', 'Consider a labeling f. As part of a local step in our new algorithm, we\nwill want to do the following. We pick one label a ∊ L and restrict attention\nto the nodes that do not have label a in label ing f. As a single local step, we\nwill allow any subset of these nodes to change their labels to a. More\nformally , for two labelings f and f′, we say that f′ is a neighbor of f if there is\na label a ∊ L such that, for all nodes i ∊ V, either f′(i) = f(i) or f′(i) = a. Note\nthat this neighbor relation is not symmetric; that is, we cannot get f back\nfrom f′ via a single step. We will now show that for any labeling f we can\nfind its best neighbor via k minimum-cut computations, and further , a local\noptimum for this neighborhoo d is a 2-approximation for the minimum\npenalty labeling.\nFinding a Good Neighbor  To find the best neighbor , we will try each label\na separately . Consider a label a. We claim that the best relabeling in which\nnodes may change their labels  to a can be found via a minimum-cut\ncomputation. The construction of the minimum-cut graph G′ = (V′, E′) is\nanalogous to the minimum-cu t computation developed for Two-Label\nImage Segment ation. There we introduced a source s and a sink t to\nrepresent the two labels. Here we will also introduce a source  and a sink,\nwhere the source s will represent label a, while the sink t will effectively\nrepresent the alternate option nodes have— namely , to keep their original\nlabels. The idea will be to find the minimum cut in G′ and relabel all nodes\non the s-side of the cut to label a, while letting all nodes on the t-side keep\ntheir original labels.\nFor each node of G, we will have a corresponding node in the new set\nV′ and will add edges (i, t) and (s, i) to E′, as was done in Figure 7.18 from\nChapter 7  for the case of two labels. The edge (i, t) will have capacity ci(a),\nas cutting the edge (i, t) places node i on the source  side and henc e\ncorresponds to labeling node i with label a. The edge (i, s) will have\ncapacity ci(f(i)), if f(i) ≠ a, and a very large number M (or + ∞) if f(i) = a.\nCutting edge (i, t) places node i on the sink side and hence corresponds to\nnode i retaining its original label f(i) ≠ a. The large capac ity of M prevents\nnodes i with f(i) = a from being placed on the sink side.\nIn the constructi on for the two-la bel problem, we added edges between\nthe nodes of V and used the separation penalties as capacities. This works\nwell for nodes that are separated by the cut, or nodes on the source side that\nare both labeled a. However , if both i and j are on the sink side of the cut,\nthen the edge connecting them is not cut, yet i and j are separated if f(i) ≠')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 818})","('type', 'Document')"
"('page_content', ""f(j). We deal with this difficulty by enhancing the construction  of G′ as\nfollows. For an edge (i,j), if f(i) = f(j) or one of i or j is label ed a, then we\nadd an edge (i,j) to E′ with capacity pij. For the edges e = (i,j) where f(i) ≠\nf(j) and neither has label a, we'll have to do something different to correctly\nencode via the graph G′ that i and j remain separated even if they are both\non the sink side. For each such edge e, we add an extra node e to V′\ncorresponding to edge e, and add the edges (i, e), (e, j), and (e, s) all with\ncapacity Pij. See Figure 12.7  for these edges.\nFigur e 12.7  The construction for edge e = (i, j) with a ≠ f(i) ≠ f(j) ≠ a.\n(12.9)  Given a labeling f and a label a, the minim um cut in the graph G′ = (V′, E′ ) corresponds to the\nminimum-penalty neighbor of labeling f obtained by relabeling a subset of nodes to label a. As a\nresult, the minimum-p enalty neighbor off can be found via k minimum-cut computations, one for each\nlabel in L.\nProof. Let (A,B) be an s-t cut in G′. The large value of M ensures that a minimum-capacity cut will\nnot cut any of these high-capacity edges. Now consider a node e in G′ correspond ing to an edge e =\n(i,j) ∊ E. The node e ∊ V′ has three adjacent edges, each with capacity pij. Give n any partition of the\nother nodes, we can place e so that at most one of these three edges is cut. We'll call a cut good  if no\nedge of capacity M is cut and, for all the nodes corresponding to edges in E, at most one of the\nadjacent edges is cut. So far we have ar gued that all minimum-capacity cuts are good.\nGood s-t cuts in G′ are in one-to-one correspondence with relabelings of f obtained by changing\nthe label of a subset of nodes to a. Cons ider the capacit y of a good cut. The edges (s, i) and (i, t)\ncontribute exactly the assignment penalty to the capacity of the cut. The edges (i,j) directly\nconnecting nodes in V contribute  exactly the separation penalty of the nodes in the corresponding\nlabeling: pij if they are separate d, and 0 otherwise.  Finally , consider an edge e = (i,j) with a\ncorresponding node e ∊ V′. If i and j are both on the sourc e side, none of the three edges adjacent to e\nare cut, and in all other cases exactly one of these edges is cut. So again, the three edges adjacent to e"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 819})","('type', 'Document')"
"('page_content', ""contribute to the cut exactly the separation penalty between i and j in the corresponding labeling. As\na result, the capacity of a good cut is exactly the same as the penalty of the corresponding labeling,\nand so the minimum-capacity cut corresponds to the best relabeling of f. ▪\nAnalyzing the Algorithm\nFinally , we need to consider the quality of the local optima under this\ndefinition of the neighbor relatio n. Recall that in our previous two attempts\nat defini ng neighborhoods, we found that they can both lead to bad local\noptima. Now , by contrast, we'll show that any local optimum under our new\nneighbor relation is a 2-approximation to the minimum possible penalty .\nTo begin the analysis, consider an optimal labeling f*, and for a label a\n∊ L let V*a = {i: f*(i) = a] be the set of nodes labeled by a in f*. Consider a\nlocally optimal labeling f. We obtain a neighbor fa of label ing f by starting\nwith f and relabeling all nodes in V*a to a. The labeling f is locall y optim al,\nand hence this neighbor fa has no smalle r penalty: Φ(fa) ≥ Φ(f). Now\nconsider the difference Φ(fa) - Φ(f), which we know is nonnegative. What\nquantities contri bute to this difference? The only possible change in the\nassignment penalties could come from nodes in Va*: for each i ∊ Va*, the\nchange is ci(f*(i)) - ci(f(i)). The separation penalties differ between the two\nlabelings only in edges (i,j) that have at least one end in Va*. The following\ninequality accounts for these dif ferences.\n(12.10)  For a labeling f and its neighbor f a, we have\nProof. The change in the assignment penalties is exactly Σi ∊Va* ci(f*(i) - ci(f(i)). The separation\npenalty for an edge (i,j) can differ between the two labelings only if edge (i,j) has at least one end in\nVa*. The total separation penalty of labeling f for such edges is exactly"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 820})","('type', 'Document')"
"('page_content', 'while the labeling fa has a separation penalty of at most\nfor these edges. (Note that this latter expression is only an upper bound, since an edge (i,j) leaving\nVa* that has its other end in a does not contribute to the separation penalty of fa.) ▪\nNow we are ready to prove our main claim.\n(12.1 1) For any locally optimal labeling f, and any other labeling f*, we have  Φ(f) ≤ 2Φ( f*).\nProof. Let fa be the neighbor of f defined previously by relabeling nodes to label a. The labeli ng f is\nlocally optimal, so we have Φ(fa) - Φ(f) ≥ 0 for all a ∊ L. We use (12.10) to bound Φ(fa) - Φ(f) and\nthen add the resulting inequalities for all labels to obtain the following:\nWe will rearrange the inequality by grouping the positive terms on the left-hand side and the negative\nterms on the right-ha nd side. On the left-hand side, we get ci(f*(i)) for all nodes i, which is exactly\nthe assignment penalty of f*. In addition, we get the term pij twice for each of the edges separated by\nf* (once for each of the two labels f*(i) and f*(j)).\nOn the right-hand side, we get ci(f(i)) for each node i, which is exactly the assignment penalty of\nf. In addition, we get the terms pij for edges separated by f. We get each such separation penalty at\nleast once, and possibly twice if it is also separated by f*.\nIn summary , we get the following.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 821})","('type', 'Document')"
"('page_content', 'proving the claimed bound. ▪\nWe proved that all local optima are good approximations to the\nlabeling with minimum penalty . There is one more issue to consider: How\nfast does the algorithm find a local optimum? Recall that in the case of the\nMaximum-Cut Problem, we had to resort to a variant of the algorithm that\naccepts only big improvements, as repeated local improvemen ts may not\nrun in polynomial time. The same is also true here. Let ∊  > 0 be a constant.\nFor a given labeling f, we will consider a neighboring labeling f′ a\nsignificant improvement  if Φ(f′) ≤ (1 - ∊ /3k) Φ (f). To make sure the\nalgorithm runs in polynomial time, we should only accept significant\nimprovements, and terminate when no significant improv ements are\npossible. After at most ∊-1k significant improvements, the penalty decreases\nby a constant factor; hence the algorithm will terminate in polyn omial time.\nIt is not hard to adapt the proof of (12.1 1) to establish the following.\n(12.12)  For any fixed ∊ > 0, the version  of the local search algorithm that only accepts significant\nimprovements termina tes in polynomial time and results in a labeling f such that Φ(f) ≤ (2 + ∊)Φ(f*)\nfor any other labeling f *.\n12.7 Best-Response Dynamics and Nash\nEquilibria\nThus far we have been considering local search as a technique for solving\noptimization problems with a single objective—in other words, applying\nlocal operations to a candidate solution so as to minimize its total cost.\nThere are many settings, however , where a potentially large number of\nagents, each with its own goals and objectives, collectively interact so as to\nproduce a solution to some problem. A solution that is produced under these\ncircumstances often reflects the “tug-of-war” that led to it, with each agent\ntrying to pull the solution in a direction that is favorable to it. We will see\nthat these intera ctions can be viewed as a kind of local search procedure;\nanalogues of local minima have a natural meaning as well, but having\nmultiple agents and multiple objectives introduces new challenges.\nThe field of game theory provides a natural framework in which to talk\nabout what happens in such situations, when a collection of agents interacts')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 822})","('type', 'Document')"
"('page_content', 'strategically—in other words, with each trying to optimize an individual\nobjective function. To illustra te these issues, we consider a concrete\napplication, motivated by the problem of routing in networks; along the\nway, we will introduce some notions that occupy central positions in the\narea of game theory more generally .\nThe Problem\nIn a network like the Internet, one frequently encounters situations in which\na number of nodes all want to establish a connection to a single source node\ns. For example, the source s may be generating some kind of data stream\nthat all the given nodes want to receive, as in a style of one-to-many\nnetwork communication known as multicast.  We will model  this situation\nby representing the underlying network as a directed graph G = (V, E), with\na cost ce ≥ 0 on each edge. There is a designated source node s ∊ V and a\ncollection of k agents located at distinct terminal nodes t1, t2, …, tk ∊ V. For\nsimplicity , we will not make a distinction between the agents and the nodes\nat which they reside; in other words, we will think of the agents as being t1,\nt2, …, tk. Each agent tj wants to constru ct a path Pj from s to tj using as little\ntotal cost as possible.\nNow , if there were no interaction among the agents, this would consist\nof k separate shortest-path problems: Each agent tj would find an s-tj path\nfor which the total cost of all edges is minimized, and use this as its path Pj.\nWhat makes this problem interesting is the prospect of agents being able to\nshare the costs of edges. Suppose that after all the agents have chose n their\npaths, agent tj only needs to pay its “fair share” of the cost of each edge e on\nits path; that is, rather than paying ce for each e on Pi, it pays ce divided by\nthe number of agents whose paths contain e. In this way, there is an\nincentive for the agents to choose paths that overlap, since they can then\nbenefit by splitting the costs of edges. (This sharing model is appropriate\nfor settin gs in which the presen ce of multiple agents on an edge does not\nsignificantly degrade the quality of transmission due to congestion or\nincreased latency . If latency effects do come into play, then there is a\ncountervailing penalty for sharing; this too leads to interesting algorithmic\nquestions, but we will stick to our current focus for now, in which sharing\ncomes with benefits only .)')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 823})","('type', 'Document')"
"('page_content', ""Best-Response Dynamics and Nash Equilibria:\nDefinitions and Examples\nTo see how the option of sharing affects the behavior of the agents, let's\nbegin by considering the pair of very simple examples in Figure 12.8. In\nexample (a), each of the two agents has two options for construc ting a path:\nthe middle route through v, and the outer route using a single edge. Suppose\nthat each agent starts out with an initial path but is continually  evaluating\nthe current situation to decide whether it's possible to switch to a better\npath.\nIn example (a), suppose the two agents start out using their outer paths.\nThen t1 sees no advanta ge in switching paths (since 4 < 5 + 1), but t2 does\n(since 8 > 5 + 1), and so t2 updates  its path by moving to the middle. Once\nthis happens, things have chan ged from the perspective of t1: There is\nsuddenly an advantage for t1 in switching as well, since it now gets to share\nthe cost of the middle path, and hence its cost to use the middle path\nbecomes 2.5 + 1 < 4. Thus it will switch to the middle path. Once we are in\na situation where both sides are using the middle path, neither has an\nincentive to switch, and so this is a stable solution.\nFigur e 12.8  (a) It is in the two agents' interest to share the middle path. (b)\nIt would be better for all the agents to share the edge on the left. But if all k\nagents start on the right-hand edge, then no one of them will want to\nunilaterally move from right to left; in other words, the solution in which all\nagents share the edge on the right is a bad Nash equilibrium."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 824})","('type', 'Document')"
"('page_content', ""Let's discuss two definitions from the area of game theory that capture\nwhat's going on in this simple example. While we will continue to focus on\nour particular multicast routing problem, these definitions are relevant to\nany setting in which multiple agents, each with an individual objective,\ninteract to produce a collectiv e solution. As such, we will phrase the\ndefinitions in these general terms.\nFirst of all, in the example, each agent was continually prepared to\nimprove its solution in response to changes made by the other agent(s).\nWe will refer to this process as best-r esponse dynamics . In other\nwords, we are interested in the dynamic behavior of a process in which\neach agent updates based on its best response to the current situation.\nSecond, we are particularly interested in stable solutions, where the\nbest response of each agent is to stay put. We will refer to such a\nsolution, from which no agent has an incentive to deviate, as a Nash\nequilibrium . (This is named after the math ematician John Nash, who\nwon the Nobel Prize in economics for his pioneering work on this\nconcept.) Hence , in example (a), the solution in which both agents use\nthe middle path is a Nash equilibrium. Note that the Nash equilibria\nare precisely the solutions at which best-response dynamics terminate.\nThe example in Figure 12.8(b)  illustrates the possibility of multiple\nNash equilibria. In this example, there are k agents that all reside at a\ncommon node t (that is, t1 = t2 = ··· = tk = t), and there are two parallel\nedges from s to t with different costs. The solution in which all agents use\nthe left-h and edge is a Nash equilibrium in which all agents pay (1 + ∊)/k."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 825})","('type', 'Document')"
"('page_content', ""The solution in which all agents use the right-hand edge is also a Nash\nequilibrium, though here the agents each pay k/k = 1. The fact that this latter\nsolution is a Nash equilibrium exposes an important point about best-\nresponse dynamics. If the agents could somehow synchronous ly agree to\nmove from the right-hand edge to the left-hand one, they'd all be better off.\nBut under best-response dynamics, each agent is only evaluating the\nconsequences of a unilateral move by itself. In effect, an agent isn't able to\nmake any assumptions about future actions of other agents—in an Internet\nsetting, it may not even know anything about these other agents or their\ncurrent solutions—and so it is only willing to perform updates that lead to\nan immediate improvement for itself.\nTo quan tify the sense in which one of the Nash equilibria in Figure\n12.8(b)  is better than the other , it is useful to introduce one further\ndefinition. We say that a solution is a social optimum  if it minimizes the\ntotal cost to all agents. We can think of such a solution as the one that\nwould be imposed by a benevol ent central authority that viewed all agents\nas equally important and hence evaluated the quality of a solution by\nsumming the costs they incurred. Note that in both (a) and (b), there is a\nsocial optimum that is also a Nash equilibrium, although in (b) there is also\na second Nash equilibrium whose cost is much greater .\nThe Relationship to Local Search\nAround here, the connections to local search start to come into focus. A set\nof agent s following best-respon se dynamics are engaged in some kind of\ngradient descent  process, exploring the “landscape” of possible solutions as\nthey try to minimize their individual costs. The Nash equilibria are the\nnatural analogue s of local minima in this process: solutions from which no\nimproving move  is possible. And the “local” nature of the search is clear as\nwell, since agents are only updating their solutions when it leads to an\nimmediate improvement.\nHaving said all this, it's importa nt to think a bit further and notice the\ncrucial ways in which this differs from standard local search. In the\nbeginning of this chapter , it was easy to argue that the gradi ent descent\nalgorithm for a combinatorial problem must terminate at a local minimum:\neach update decreased the cost of the solution, and since there were only\nfinitely many possible solutions, the sequence of updates could not go on"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 826})","('type', 'Document')"
"('page_content', ""forever . In other words, the cost function itself provided the progress\nmeasure we needed to establish termination.\nFigur e 12.9 A network in which the unique Nash equilibrium differs from\nthe social optimum.\nIn best-response  dynamics, on the other hand, each agent has its own\npersonal objective function to minimize, and so it's not clear what overall\n“progress” is being made when, for example, agent ti decides to update its\npath from s. There's progress for ti, of course, since its cost goes down, but\nthis may be of fset by an even lar ger increase in the cost to some other agent.\nConsider , for example, the netw ork in Figure 12.9. If both agents start on\nthe middle path, then t1 will in fact have an incentive to move to the outer\npath; its cost drops from 3.5 to 3, but in the process the cost of t2 increases\nfrom 3.5 to 6. (Once this happens, t2 will also move to its outer path, and\nthis solution—with both nodes  on the outer paths—is the unique Nash\nequilibrium.)\nThere are examples, in fact, where the cost-increasing effects of best-\nresponse dynam ics can be much worse than this. Consider the situation in\nFigure 12.10 , where we have k agents that each have the option to take a\ncommon outer path of cost 1 + Ε (for some small  number Ε > 0), or to take\ntheir own alternate path. The alternate path for tj has cost 1/j. Now suppose\nwe start with a solution in which all agents are sharing the outer path. Each\nagent pays (1+ Ε)/k, and this is the solution that minimizes the total cost to\nall agents. But running best-response dynamics starting from this solution"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 827})","('type', 'Document')"
"('page_content', 'causes things to unwind rapidly . First tk switches to its alternate path, since\n1/k < (1 + Ε)/k.\nFigur e 12.10  A network in which the unique Nash equilibrium costs H(k) =\nΘ(log k) times more than the social optimum.\nAs a result of this, there are now only k - 1 agents sharing the outer path,\nand so tk-1 switches to its alternate path, since 1/(k - 1) < (1 + Ε)/(k - 1).\nAfter this, tk-2 switches, then tk-3, and so forth, until all k agents are using\nthe alternate paths directly from s. Things come to a halt here, due to the\nfollowing fact.\n(12.13)  The solutio n in Figur e 12.10 , in which each agen t uses its direct path from s, is a Nash\nequilibrium, and mor eover it is the unique Nash equilibrium for this instance.\nProof. To verify that the given solution is a Nash equilibrium, we simply need to check that no agent\nhas an incentive to switch from its current path. But this is clear , since all agents are paying at most 1,\nand the only other option—the (currently vacant) outer path—has cost 1 + Ε.\nNow suppo se there were some other Nash equilibrium. In order to be different from the solution\nwe have just been considering, it would have to involve at least one of the agents  using the outer\npath. Let tj1, tj2, …, tje be the agents using the outer path, where j1 < j2 < … jℓ. Then all these agents\nare paying (1 + Ε)/ℓ. But notice that jℓ ≥ ℓ, and so agent tjℓ has the option to pay only 1/jℓ ≤ 1/ℓ by\nusing its alternate path directly from s. Hence tjℓ has an incentive to deviate from the current solution,\nand hence this solution cannot be a Nash equilibrium. ▪\nFigure 12.8(b)  already illustrated that there can exist a Nash\nequilibrium whose total cost is much worse than that of the social optimum,\nbut the examples in Figures 12.9  and 12.10  drive home a further point: The\ntotal cost to all agents under even the most favorable  Nash equilibrium\nsolution can be worse than the total cost under the social optimum. How')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 828})","('type', 'Document')"
"('page_content', ""much worse? The total cost of the social optimum in this example is 1 + Ε,\nwhile the cost of the unique Nash equilibrium is \n .\nWe encountered this expression in Chapter 1 1, where we defin ed it to be the\nharmonic number H(k) and showed that its asymptotic value is H(k) =\nΘ(log k).\nThese examples suggest that one can't really view the social optimum\nas the analogu e of the global minimum in a traditional local search\nprocedure. In standard local search, the global minimum is always a stable\nsolution, since no improvement is possible. Here the social optim um can be\nan unstable solution, since it just requires one agent to have an interest in\ndeviating.\nTwo Basic Questions\nBest-response dynamics can exhibit a variety of different behaviors, and\nwe've just seen a range of examples that illustrate different phenomena. It's\nuseful at this point to step back , assess our current understanding, and ask\nsome basic questions. We group  these questions around the following two\nissues.\nThe existence of a Nash equilib rium.  At this point, we actually don't\nhave a proof that there even exists  a Nash equilibrium solution in every\ninstance of our multicast routing problem. The most natural candidate\nfor a progress measure, the total cost to all agents, does not necessarily\ndecrease when a single agent updates its path.  \nGiven this, it's not immediately clear how to argue that the best-\nresponse dynamics must termin ate. Why couldn't we get into a cycle\nwhere agent t1 improves its solution at the expense of t2, then t2\nimproves its solution at the expense of t1, and we contin ue this way\nforever? Indeed,  it's not hard to define other problems in which exactly\nthis can happen and in which Nash equilibria don't exist. So if we want\nto argue that best-response dynamics leads to a Nash equilibrium in the\npresent case, we need to figure out what's special about our routing\nproblem that causes this to happen.\nThe price of stability . So far we've mainly considered  Nash equilibria\nin the role of “observers”: essen tially , we turn the agents loose  on the\ngraph from an arbitrary starting point and watch what they do. But if"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 829})","('type', 'Document')"
"('page_content', ""we were viewing this as protocol designers, trying to define a\nprocedure by which agents could construct paths from s, we might\nwant to pursue the following approach. Given a set of agents, located\nat nodes t1, t2, …, tk, we could propose a collection of paths, one for\neach agent, with two properties.  \n(i) The set of paths forms a Nash equilibrium solution; and  \n(ii) Subject to (i), the total cost to all agents is as small as possible.  \nOf course, ideally we'd like just to have the smallest total cost, as this\nis the social optimum. But if we propose the social optimum and it's\nnot a Nash equilibrium, then it won't be stable: Agents will begin\ndeviating and constructing new paths. Thus properties (i) and (ii)\ntogether represe nt our protocol's attempt to optimize in the face of\nstability , finding the best solution from which no agent will want to\ndeviate.  \nWe therefore define the price of stability , for a given instance of the\nproblem, to be the ratio of the cost of the best Nash equilibrium\nsolution to the cost of the social optimum. This quantity reflects the\nblow-up in cost that we incur due to the requirement that our solution\nmust be stable in the face of the agents' self-interest.\nNote that this pair of questions can be asked for essentially any\nproblem in which self-interested agents produce a collective solution. For\nour multicast routing problem, we now resolve both these questions.\nEssentially , we will find that the example in Figure 12.10  captures some of\nthe crucial aspects of the probl em in general. We will show that for any\ninstance, best-response dynamics starting from the social optim um leads to\na Nash equilibrium whose cost is greater by at most a factor of H(k) = Θ(log\nk).\nFinding a Good Nash Equilibrium\nWe focus first on showing that best-response dynamics in our problem\nalways termina tes with a Nash equilibrium. It will turn out that our\napproach to this question also provides the necessary technique for\nbounding the price of stability .\nThe key idea is that we don't need to use the total cost to all agents as\nthe progress measure against which to bound the number of steps of best-"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 830})","('type', 'Document')"
"('page_content', ""response dynam ics. Rather , any quantity that strictly decrease s on a path\nupdate by any agent, and which can only decrease a finite numb er of times,\nwill work perfectly well. With this in mind, we try to formulat e a measure\nthat has this property . The measure will not necessarily have as strong an\nintuitive meaning as the total cost, but this is fine as long as it does what we\nneed.\nWe first conside r in more detail why just using the total agent cost\ndoesn't work. Suppose, to take a simple example, that agent tj is currently\nsharing, with x other agents, a path consisting of the single edge e. (In\ngeneral, of course, the agents' paths will be longer than this, but single-edge\npaths are useful to think about for this example.) Now suppose that tj\ndecides it is in fact cheaper to switch to a path consisting of the single edge\nf, which no agent is currently using. In order for this to be the case, it must\nbe that cf < ce/(x + 1). Now , as a result of this switch, the total cost to all\nagents goes up by cf: Previously , x + 1 agents contributed to the cost ce, and\nno one was incurring the cost cf; but, after the switch, x agents still\ncollectively have to pay the full cost ce, and tj is now paying an additional\ncf.\nIn order to view this as progress, we need to redefine what “progress”\nmeans. In particular , it would be useful to have a measure that could offset\nthe added cost cf via some notion  that the overall “potential energy” in the\nsystem has dropped by ce/(x + 1). This would allow us to view the move by\ntj as causing a net decrease, since we have cf < ce/(x + 1). In order to do this,\nwe could maintain a “potential” on each edge e, with the prope rty that this\npotential drops by ce/(x + 1) when the number of agen ts using e decreases\nfrom x + 1 to x. (Corresponding ly, it would need to increase by this much\nwhen the number of agents using e increased from x to x + 1.)\nThus, our intuiti on suggests that we should define the potential so that,\nif there are x agents on an edge e, then the potential should decre ase by ce/x\nwhen the first one stops using e, by ce/(x - 1) when the next one stops using\ne, by ce/(x - 2) for the next one, and so forth. Setting the potential to be\nce(1/x + 1/(x - 1) + ··· + 1/2 + 1) = ce · H(x) is a simple way to accomplish\nthis. More conc retely , we define the potential  of a set of paths P1, P2, …,"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 831})","('type', 'Document')"
"('page_content', ""Pk, denoted Φ(P1,P2, …, Pk), as follows. For each edge e, let xe denote the\nnumber of agents whose paths use the edge e. Then\n(We'll define the harmonic number H(0) to be 0, so that the contribution of\nedges containing no paths is 0.)\nThe following claim establishe s that Φ really works as a progress\nmeasure.\n(12.14)  Suppose that the current set of paths is P1, P2, …, Pk, and agent tj updates its path from Pj\nto P′j. Then the new potential  Φ(P1, …, Pj-1, P′j, Pj+1, …, Pk) is strictly less than the old potential\nΦ(P1, …, Pj-1, Pj, Pj+1, …, Pk).\nProof. Before tj switched its path from  Pj to P′j, it was paying Σe ∊ Pj ce/xe, since it was sharing the\ncost of each edge e with xe - 1 other agents. After the switch, it continues to pay this cost on the\nedges in the intersection Pj ∩ P′j, and it also pays cf/(xf + 1) on each edge f ∊ P′j - Pj. Thus the fact\nthat tj viewed this switch as an improvement means that\nNow let's ask what happens to the potential function Φ. The only edges on which it changes are\nthose in P′j-Pj and those in Pj-P′j On the former set, it increases by\nand on the latter set, it decreases by"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 832})","('type', 'Document')"
"('page_content', ""So the criterion that tj used for switching paths is precisely the statement that the total increase is\nstrictly less than the total decrease, and hence the potential Φ decreases as a result of tj's switch. ▪\nNow there are only finitely many ways to choose a path for each agent\ntj, and (12.14) says that best-response dynamics can never revis it a set of\npaths P1, …, Pk once it leaves it due to an improving move by some agent.\nThus we have shown the following.\n(12.15)  Best-r esponse dynamics always leads to a set of paths that forms a Nash equilibrium\nsolution.\nBounding the Price of Stability  Our potential function Φ also turns out to\nbe very useful in providing a bound on the price of stability . The point is\nthat, although Φ is not equal to the total cost incurred by all agents, it tracks\nit reasonably closely .\nTo see this, let C(P1, …, Pk) denote the total cost to all agents when the\nselected paths are P1, …, Pk. This quantity is simply the sum of ce over all\nedges that appea r in the union of these paths, since the cost of each such\nedge is completely covered by the agents whose paths contain it.\nNow the relationship between the cost function C and the potential\nfunction Φ is as follows.\n(12.16)  For any set of paths P 1, …, Pk, we have\nProof. Recall our notation in which xe denotes the number of paths containing edge e. For the\npurposes of comparing C and Φ, we also define E+ to be the set of all edges that belong to at least\none of the paths P1, …, Pk. Then, by the definition of C, we have C(P1, …, Pk) = Σ e ∊E+ ce.\nA simple fact to notice is that xe ≤ k for all e. Now we simply write\nand"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 833})","('type', 'Document')"
"('page_content', ""Using this, we can give a bound on the price of stability .\n(12.17)  In every instance, there is a Nash equilibrium solution for which the total cost to all agents\nexceeds that of the social optimum by at most a factor of H (k).\nProof. To produce the desired Nash equilibrium,  we start from a social optimum consisting of paths\nP*1, …, P*k and run best-respons e dynamics. By (12.15), this must terminate at a Nash equilibri um\nP1, …, Pk.\nDuring this run of best-response dynamics, the total cost to all agents may have been going up,\nbut by (12.14) the potential function was decreasing. Thus we have Φ( P1, …, Pk) ≤ Φ( P1*, …, P*k.\nThis is basically all we need since, for any set of paths, the quantities C and Φ differ by at most\na factor of H(k). Specifically ,\nThus we have shown that a Nash equilibrium always exists, and there\nis alway s a Nash equilibrium whose total cost is within an H(k) factor of the\nsocial optimum. The example in Figure 12.10  shows that it isn't possible to\nimprove on the bound of H(k) in the worst case.\nAlthough this wraps up certain aspects of the problem very neatly ,\nthere are a numb er of questions here for which the answer isn't known. One\nparticularly intriguing question is whether it's possible to const ruct a Nash\nequilibrium for this problem in polynomial time. Note that our proof of the\nexistence of a Nash equilibrium argued simply that as best-response\ndynamics iterate d through sets of paths, it could never revisit the same set\ntwice, and hence  it could not run forever . But there are exponentially many\npossible sets of paths, and so this does not give a polynomial-time\nalgorithm. Beyond the question of finding any Nash equilibrium efficiently ,\nthere is also the open question of efficiently finding a Nash equilibrium that\nachieves a bound of H(k) relative to the social optimum, as guaranteed by\n(12.17).\nIt's also important to reiterate something that we mentioned earlier: It's\nnot hard to find problems for which best-response dynamics  may cycle\nforever and for which Nash equilibria do not necessarily exist. We were\nfortunate here that best-response dynamics could be viewed as iteratively"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 834})","('type', 'Document')"
"('page_content', ""improving a potential function  that guaranteed our progress toward a Nash\nequilibrium, but the point is that potential functions like this do not exist for\nall problems in which agents interact.\nFinally , it's interesting to compare what we've been doing here to a\nproblem that we considered earlier in this chapter: finding a stable\nconfiguration in a Hopfield network. If you recall the discus sion of that\nearlier problem,  we analyzed a process in which each node “flips” between\ntwo possible states, seeking to increase the total weight of “good” edges\nincident to it. This can in fact be viewed as an instance of best-response\ndynamics for a problem in which each node has an objective function that\nseeks to maximize this measure of good edge weight. However , showing\nthe conver gence of best-response dynamics for the Hopfield network\nproblem was much easier than the challenge we faced here: There it turned\nout that the state-flipping process was in fact a “disguised” form of local\nsearch with an objective function obtained simply by adding together the\nobjective functions of all nodes—in effect, the analogue of the total cost to\nall agents served as a progress measure. In the present case, it was precisely\nbecause this total cost function did not work as a progress measure that we\nwere forced to embark on the more complex analysis described here.\nSolved Exercises\nSolved Exercise 1\nThe Center Selection Problem from Chapter 1 1 is anoth er case in which one\ncan study the performance of local search algorithms.\nHere is a simple local search approach to Center Selection (indeed, it's\na common strategy for a variety of problems that involve locating\nfacilities). In this problem, we are given a set of sites S = {s1, s2, …, sn} in\nthe plane, and we want to choose a set of k centers C = {c1, c2, …, ck}\nwhose covering radius —the farthest that people in any one site must travel\nto their nearest center—is as small as possible.\nWe start by arbitrarily choosing k points in the plane to be the centers\nc1, c2, …, ck. We now alternate the following two steps."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 835})","('type', 'Document')"
"('page_content', ""(i) Given the set of k centers c1, c2, …, ck, we divide S into k sets: For i =\n1,2,…, k, we define Si to be the set of all the sites for which ci is the\nclosest center .\n(ii) Given this division of S into k sets, construct new centers that will be as\n“central” as possible relative to them. For each set Si, we find the\nsmallest circle in the plane that contains all points in Si, and define center\nci to be the center of this circle.\nIf steps (i) and (ii) cause the covering radius to strictly decrease, then we\nperform another iteration; otherwise the algorithm stops.\nThe alternation of steps (i) and (ii) is based on the following natural\ninterplay between sites and centers. In step (i) we partition the sites as well\nas possible given the centers; and then in step (ii) we place the centers as\nwell as possible  given the partition of the sites. In addition to its role as a\nheuristic for placing facilities, this type of two-step interplay is also the\nbasis for local search algorithms in statistics, where (for reason s we won't\ngo into here) it is called the Expectation Maximization  approach.\n(a) Prove that this local search algorithm eventually terminates.\n(b) Consider the following statement.\nThere is an absolute constant b > 1 (independent of the particular input instance), so\nwhen the local search algorithm terminates, the covering radius of its solution is at\nmost b times the optimal covering radius.\nDecide whether you think this statement is true or false, and give a proof of either the\nstatement or its negation.\nSolution  To prove part (a), one's first thought is the following: The set of\ncovering radii decreases in each iteration; it can't drop below the optimal\ncovering radius;  and so the iterations must terminate. But we have to be a\nbit careful, since we're dealing with real numbers. What if the covering radii\ndecreased in every iteration, but by less and less, so that the algorithm was\nable to run arbitrarily long as its covering radii conver ged to some value\nfrom above?\nIt's not hard to take care of this concern, however . Note that the\ncovering radius at the end of step (ii) in each iteration is completely\ndetermined by the current partit ion of the sites into S1, S2, …, Sk. There are\na finite number of ways to partition the sites into k sets, and if the local"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 836})","('type', 'Document')"
"('page_content', 'search algorithm ran for more than this number of iterations, it would have\nto produ ce the same partition in two of these iterations. But then it would\nhave the same covering radius at the end of each of these iteratio ns, and this\ncontradicts the assumption that the covering radius strictly decreases from\neach iteration to the next.\nThis proves that the algorithm always terminates. (Note that it only\ngives an exponential bound on the number of iterations, however , since\nthere are exponentially many ways to partition the sites into k sets.)\nTo disprove part (b), it would be enough to find a run of the algorithm\nin which  the iterations gets “stuck” in a configuration with a very large\ncovering radius . This is not very hard to do. For any constant b > 1,\nconsider a set S of four points in the plane that form the corners of a tall,\nnarrow rectangle of width w and height h = 2bw. For example, we could\nhave the four points be (0, 0), (0, h), (w, h), (w, 0).\nNow suppose k = 2, and we start the two centers anywhere to the left\nand right of the rectangle, respectively (say, at (-1, h/2) and (w + 1, h/2)).\nThe first iteration proceeds as follows.\nStep (i) will divide S into the two points S1 on the left side of the\nrectangle (with x-coordinate 0) and the two points S2 on the right side\nof the rectangle (with x-coordinate w).\nStep (ii) will place centers at the midpoints of S1 and S2 (i.e., at (0, h/2)\nand ( w, h/2)).\nWe can check that in the next iteration, the partition of S will not change ,\nand so the locations of the cente rs will not change; the algorithm  terminates\nhere at a local minimum.\nThe covering radius of this solution is h/2. But the optimal solution\nwould place centers at the midpoints of the top and bottom sides of the\nrectangle, for a covering radiu s of w/2. Thus  the covering radius of our\nsolution is h/w = 2b > b times that of the optimum.\nExercises')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 837})","('type', 'Document')"
"('page_content', ""1. Consider the problem of finding a stable state in a Hopfield neural\nnetwork, in the special case when all edge weights are positive. This\ncorresponds to the Maximum-C ut Problem that we discussed earlier in\nthe chap ter: For every edge e in the graph G, the endpoints of G would\nprefer to have opposite states.  \nNow suppose the underlying graph G is conn ected and bipartite; the\nnodes can be partitioned into sets X and Y so that each edge has one\nend in X and the other in Y. Then there is a natural “best” configuration\nfor the Hopfield net, in which all nodes in X have the state +1 and all\nnodes in Y have the state -1. This way, all edges are good , in that their\nends have opposite states.  \nThe question is: In this special case, when the best configuratio n is so\nclear , will the State-Flipping Algorithm described in the text (as long\nas there  is an unsatisfied node,  choose one and flip its state) always\nfind this configuration? Give a proof that it will, or an example of an\ninput instance, a starting config uration, and an execution of the State-\nFlipping Algorithm that terminates at a configuration in which not all\nedges are good.\n2. Recall that for a problem in which the goal is to maximize some\nunderlying quantity , gradient descent has a natural “upside-down”\nanalogue, in which one repeatedly moves from the current solution to a\nsolution of strictly greater value. Naturally , we could call this a\ngradient ascent algorithm.  (Often in the literature you'll also see such\nmethods referred to as hill-climbing  algorithms.)  \nBy straight symmetry , the observations we've made in this chapter\nabout gradient descent carry over to gradient ascent: For many\nproblems you can easily end up with a local optimum that is not very\ngood. But sometimes one encounters problems—as we saw, for\nexample, with the Maximum-Cut and Labeling Problems—for which a\nlocal search algorithm comes with a very strong guarantee: Every local\noptimum is close in value to the global optimum. We now consi der the\nBipartite Matching Problem and find that the same phenomenon\nhappens here as well.  \nThus, consider the following Gradient Ascent Algorithm for finding a\nmatching in a bipartite graph.  \nAs long as there is an edge whose endpoints are unmatched, add it to the current\nmatching. When there is no longer such an edge, terminate with a locally optimal"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 838})","('type', 'Document')"
"('page_content', ""matching.\n(a) Give an example of a bipartite graph G for which this gradient\nascent algorithm does not return the maximum matching.  \n(b) Let M and M′ be matchings in a bipartite graph G. Suppose that | M′|\n> 2|M|. Show that there is an edge e′ ∊ M′ such that M ∪ {e′} is a\nmatching in G. \n(c) Use (b) to concl ude that any locally optimal matching returned by\nthe gradient ascent algorithm in a bipartite graph G is at least half as\nlarge as a maximum matching in G.\n3. Suppose you're consulting for a biotech company that runs\nexperiments on two expensive high-throughput assay machines, each\nidentical, which we'll label M1 and M2. Each day they have a number\nof jobs that they need to do, and each job has to be assigned to one of\nthe two machines. The problem they need help on is how to assign the\njobs to machine s to keep the loads balanced each day. The problem is\nstated as follows. There are n jobs, and each job j has a required\nprocessing time tj. They need to partition the jobs into two groups A\nand B, where set A is assigned to M1 and set B to M2. The time needed\nto process all of the jobs on the two machines is T1 = Σj ∊A tj and T2 =\nΣj ∊B tj. The problem is to have the two machines work roughly for the\nsame amounts of time—that is, to minimize | T1 - T2]. \nA previous consultant showed  that the problem is NP-hard  (by a\nreduction from Subset Sum). Now they are looking for a good local\nsearch algorithm. They propose  the following. Start by assigning jobs\nto the two machines arbitrarily (say jobs 1,…, n/2 to M1, the rest to\nM2). The local moves are to move a single job from one machine to the\nother , and we only move jobs if the move decreases the absolute\ndifference in the processing times. You are hired to answer some basic\nquestions about the performance of this algorithm.  \n(a) The first question is: How good  is the solution obtained? Assu me\nthat there is no single job that dominates all the processing time—that\nis, that tj ≤ ½ Σi=1n ti for all jobs j. Prove that for every locally optimal\nsolution, the times the two machines operate are roughly balanced:\n½T1≤T2≤2T1. \n(b) Next you worry about the running time of the algorithm: How"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 839})","('type', 'Document')"
"('page_content', ""often will jobs be moved back and forth between the two machines?\nYou propose the following small modification in the algorithm. If, in a\nlocal move, many different jobs can move from one machine to the\nother , then the algorithm should  always move the job j with maximum\ntj. Prove that, under this variant, each job will move at most once.\n(Hence the local search terminates in at most n moves.)  \n(c) Finally , they wonder if they shou ld work on better algorithms. Give\nan example in which the local search algorithm above will not lead to\nan optimal solution.\n4. Consider the Load Balancing Problem from Section 11.1. Some\nfriends of yours are running a collection of Web servers, and they've\ndesigned a local search heuristi c for this problem, different from the\nalgorithms described in Chapter 1 1. \nRecall that we have m machines M1, …, Mm, and we must assign each\njob to a machine. The load of the ith job is denoted ti. The makespan of\nan assignment is the maximum load  on any machine:  \n \nYour friends' local search heuristic works as follows. They start with\nan arbitrary assignment of jobs to machines, and they then repeatedly\ntry to apply the following type of “swap move.”  \nLet A(i) and A(j) be the jobs assigned to machines Mi and Mj, respectively . To\nperform a swap move  on Mi and Mj, choose subsets of jobs B(i) ⊆ A(j) and B(j)\n⊆ A(j), and “swa p” these jobs between the two machines. That is, update A(i) to\nbe A(i) ∪B(j) - B(i), and upda te A(j) to be A(j) ∪ B(i) - B(j). (One is allowed to\nhave B(i) = A(i), or to have B(i) be the empty set; and analogously for B(j).)\n \nConsider a swap move applied  to machines Mi and Mj. Suppose the\nloads on Mi and Mj before the swap  are Ti and Tj, respectively , and the\nloads after the swap are Ti′ and Tj′. We say that the swap move is"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 840})","('type', 'Document')"
"('page_content', 'improving  if max( Ti′, Tj′) < max( Ti, Tj)—in other words, the larger of\nthe two loads involved has strictly decreased. We say that an\nassignment of jobs to machine s is stable  if there does not exist an\nimproving swap move, beginning with the current assignment.  \nThus the local search heuristic simply keeps executing improving swap\nmoves until a stable assignment is reached; at this point, the resulting\nstable assignment is returned as the solution.  \nExample.  Suppose there are two machines: In the current assignment,\nthe machine M1 has jobs of sizes 1, 3, 5, 8, and machine M2 has jobs of\nsizes 2,4. Then one possible improving swap move would be to define\nB(1) to consist of the job of size 8, and define B(2) to consist of the job\nof size 2. After these two sets are swapped, the resulting assig nment\nhas jobs of size 1, 2, 3, 5 on M1, and jobs of size 4, 8 on M2. This\nassignment is stable. (It also has an optimal makespan of 12.)  \n(a) As specified, there is no explic it guarantee that this local search\nheuristic will always terminate. What if it keeps cycling forever\nthrough assignments that are not stable?  \nProve that, in fact, the local search heuristic terminates in a finite\nnumber of steps, with a stable assignment, on any instance.  \n(b) Show that any stable assignmen t has a makespan that is within a\nfactor of 2 of the minimum possible makespan.\nNotes and Further Reading\nKirkpatrick, Gelatt, and Vecchi (1983) introduced simulated annealing,\nbuilding on an algorithm of Metropolis et al. (1953) for simulat ing physical\nsystems. In the process, they highlighted the analogy between energy\nlandscapes and the solution spaces of computational problems.\nThe book of surveys edited by Aarts and Lenstra (1997) covers a wide\nrange of applications of local search techniques for algorithmic problems.\nHopfield neural networks were  introduced by Hopfield (1982) and are\ndiscussed in more detail in the book by Haykin (1999). The heuristic for\ngraph partitioning discussed in Section 12.5 is due to Kern ighan and Lin\n(1970).')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 841})","('type', 'Document')"
"('page_content', 'The local search algorithm for classification based on the Labeling\nProblem is due to Boykov , Veksler , and Zabih (1999). Further  results and\ncomputational experiments are discussed in the thesis by V eksler (1999).\nThe multi-agent routing problem considered in Section 12.7 raises\nissues at the intersection of algorithms and game theory , an area concerned\nwith the general issue of strategic interaction among agents. The book by\nOsborne (2003) provides an introduction to game theory; the algorithmic\naspects of the subject are discus sed in surveys by Papadimitriou (2001) and\nTardos (2004) and the thesis and subsequent book by Roughgarden (2002,\n2004). The use of potential functions to prove the existen ce of Nash\nequilibria has a long history in game theory (Beckmann, McGuire, and\nWinsten, 1956; Rosenthal 1973), and potential functions were used to\nanalyze best-response dynamics by Monderer and Shapley (1996). The\nbound on the price of stability for the routing problem in Section 12.7  is due\nto Anshelevich et al. (2004).')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 842})","('type', 'Document')"
"('page_content', 'Chapter 13')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 843})","('type', 'Document')"
"('page_content', 'Randomized Algorithms\n13.1 A First Application: Contention Resolution  \n13.2 Finding the Global Minimum Cut  \n13.3 Random V ariables and Their Expectations  \n13.4 A Randomized Appr oximation Algorithm for MAX 3-SA T \n13.5 Randomized Divide and Conquer: Median-Finding and Quicksort  \n13.6 Hashing: A Randomized Implementation of Dictionaries  \n13.7 Finding the Closest Pair of Points: A Randomized Appr oach  \n13.8 Randomized Caching  \n13.9 Chernoff Bounds  \n13.10 Load Balancing  \n13.11 Packet Routing  \n13.12 Backgr ound: Some Basic Pr obability Definitions  \nSolved Exer cises  \nExer cises  \nNotes and Further Reading\nThe idea that a process can be “random” is not a modern one; we can trace\nthe notio n far back into the history of human thought and certainly see its\nreflections in gambling and the insurance business, each of which reach into\nancient times. Yet, while similar ly intuitive subjects like geometry and logic\nhave been treated mathematically for several thousand years, the\nmathematical study of probability is surprisingly young; the first known\nattempts to seriously formalize it came about in the 1600s. Of course, the\nhistory of computer science plays out on a much shorter time scale, and the\nidea of randomization has been with it since its early days.\nRandomization and probabilistic analysis are themes that cut across\nmany areas of computer science, including algorithm design, and when one\nthinks about random processes in the context of computation, it is usually in\none of two distinct ways. One view is to consider the world as behaving\nrandomly: One can consider traditional algorithms that confront randomly\ngenerated input. This approach is often termed average-case analysis , since')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 844})","('type', 'Document')"
"('page_content', ""we are studying the behavior of an algorithm on an “average” input (subject\nto some underlying random process), rather than a worst-case input.\nA second view is to consider algorithms that behave randoml y: The\nworld provides the same worst-case input as always, but we allow our\nalgorithm to make random decis ions as it processes the input. Thus the role\nof randomization in this approach is purely internal to the algorithm and\ndoes not require new assumptions about the nature of the input. It is this\nnotion of a randomized algorithm  that we will be considering in this\nchapter .\nWhy might it be useful to design an algorithm that is allowed to make\nrandom decision s? A first answ er would be to observe that by allowing\nrandomization, we've made our underlying model more powerful. Efficient\ndeterministic algorithms that always yield the correct answer are a special\ncase of efficient randomized algorithms that only need to yield  the correct\nanswer with high probability; they are also a special case of randomized\nalgorithms that are always correct, and run efficiently in expectation . Even\nin a worst-cas e world, an algorithm that does its own “internal”\nrandomization may be able to offset certain worst-case phenomena. So\nproblems that may not have been solvable by efficient deterministic\nalgorithms may still be amenable to randomized algorithms.\nBut this is not the whole story, and in fact we'll be looking at\nrandomized algorithms for a number of problems where there exist\ncomparably efficient deterministic algorithms. Even in such situations, a\nrandomized approach often exhibits considerable power for further reasons:\nIt may be conceptually much simpler; or it may allow the algorithm to\nfunction while maintaining very little internal state or memory  of the past.\nThe advantages of randomization seem to increase further as one considers\nlarger computer systems and networks, with many loosely interacting\nprocesses—in other words, a distributed system . Here random behavior on\nthe part of individual processes can reduce the amount of explicit\ncommunication or synchronization that is required; it is often valuable as a\ntool for symmetry-br eaking  among processes, reducing the danger of\ncontention and “hot spots.” A number of our examples will come from\nsettings like this: regulating access to a shared resource, balanc ing load on\nmultiple processors, or routing packets through a network. Even a small\nlevel of comfort with random ized heuristics can give one considerable\nleverage in thinking about lar ge systems."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 845})","('type', 'Document')"
"('page_content', ""A natural worry in approaching  the topic of randomized algorit hms is\nthat it requires an extensive knowledge of probability . Of course , it's always\nbetter to know more rather than less, and some algorithms are indeed based\non comp lex probabilistic ideas.  But one further goal of this chapter is to\nillustrate how little underlying probability is really needed in order to\nunderstand many of the well-known algorithms in this area. W e will see that\nthere is a small set of useful probabilistic tools that recur frequently , and\nthis chapter will try to develop the tools alongside the algorithms.\nUltimately , facility with these tools is as valuable as an understanding of the\nspecific algorithms themselves.\n13.1 A First Application: Contention Resolution\nWe begin with a first application of randomized algorithms—contention\nresolution in a distributed system—that illustrates the general style of\nanalysis we will be using for many of the algorithms that follow . In\nparticular , it is a chance to work through some basic manipulations\ninvolving events  and their proba bilities, analyzi ng intersections of events\nusing independence  as well as unions of events using a simple Union\nBound.  For the sake of completeness, we give a brief summary of these\nconcepts in the final section of this chapter (Section 13.15).\nThe Problem\nSuppose we have n processes P1,P2, …,Pn, each competing for access to a\nsingle shared database. We imagine time as being divided into discrete\nrounds.  The database has the property that it can be accessed by at most  one\nprocess in a single round; if two or more processes attempt to access it\nsimultaneously , then all process es are “locked out” for the duration of that\nround. So, while each process wants to access the database as often as\npossible, it's pointless for all of them to try accessing it in every round; then\neveryone will be perpetually locked out. What's needed is a way to divide\nup the rounds among the processes in an equitable fashion,  so that all\nprocesses get through to the database on a regular basis.\nIf it is easy for the processes to communicate with one another , then\none can imagine all sorts of direct means for resolving the contention. But"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 846})","('type', 'Document')"
"('page_content', ""suppose that the processes can't communicate with one another at all; how\nthen can they work out a protocol under which they manage to “take turns”\nin accessing the database?\nDesigning a Randomized Algorithm\nRandomization provides a natural protocol for this problem, which we can\nspecify simply as follows. For some number p > 0 that we'll determine\nshortly , each process will attempt to access the database in each round with\nprobability p, independently of the decisions of the other processes. So, if\nexactly one process decides to make the attempt in a given round, it will\nsucceed; if two or more try, then they will all be locked out; and if none try,\nthen the round is in a sense “wasted.” This type of strategy , in which each\nof a set of identical processes randomizes its behavior , is the core of the\nsymmetry-br eaking  paradigm that we mentioned initially: If all the\nprocesses operated in lockstep, repeatedly trying to access the database at\nthe same time, there'd be no progress; but by randomizing, they “smooth\nout” the contention.\nAnalyzing the Algorithm\nAs with many applications of randomization, the algorithm in this case is\nextremely simple to state; the interesting issue is to analyze its performance.\nDefining Some Basic Events  When confronte d with a probabilistic system\nlike this, a good first step is to write down some basic events and think\nabout their proba bilities. Here's a first event to consider . For a given process\nPi and a given round t, let A[i, t] denote  the event that Pi attempts to access\nthe database in round t. We know that each process attempts an access in\neach round with probability p, so the probabil ity of this event , for any i and\nt, is Pr[A[i, t]] = p. For every event, there is also a complementary event,\nindicating that the event did not occur; here we have the complementary\nevent \n  that Pi does not attemp t to access the database in round t, with\nprobability"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 847})","('type', 'Document')"
"('page_content', 'Our real concern is whether a process succeeds  in accessing the\ndatabase in a given round. Let \n [i, t] denote this event. Clearly , the process\nPi must attempt an access in round  t in order  to succeed. Indeed, succeeding\nis equivalent to the following: Process Pi attempts to access the database in\nround t, and each other  process does not attempt to access the database in\nround t. Thus \n [i, t] is equa l to the intersection of the event A[i, t] with all\nthe complementary events \n , for j ≠ i:\nAll the events in this intersection are independent, by the definition of the\ncontention-resolution protocol. Thus, to get the probability of \n[i, t], we can\nmultiply the probabilities of all the events in the intersection:\nWe now have a nice, closed-form  expression for the probability that Pi\nsucceeds in accessing the database in round t; we can now ask how to set p\nso that this success probability is maximized. Observe first that the success\nprobability is 0 for the extreme cases p = 0 and p = 1 (these corre spond to\nthe extreme case in which processes never bother attempting, and the\nopposite extreme case in which every process tries accessing the database in\nevery round, so that everyone is locked out). The function f(p) = p(1 - p)n-1\nis positive for values of p strictly between 0 and 1, and its derivative f′(p) =\n(1 - p)n-1 - (n - 1)p(1 - p)n-2 has a single zero at the value p = 1/n, where the\nmaximum is achieved. Thus we can maximize the success probability by\nsetting p = 1/n. (Notice that p = 1/n is a natural intuitive choice as well, if\none wants exactly one process to attempt an access in any round.)')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 848})","('type', 'Document')"
"('page_content', ""When we set p = 1/n, we get \n . It's worth gettin g\na sense for the asymptotic value of this expression, with the help of the\nfollowing extremely useful fact from basic calculus.\n(13.1)\n(a) The function  \n  conver ges monotonically fr om ¼ up to  \n as n incr eases fr om 2.\n(b) The function  \n  conver ges monotonically fr om ½ down to  \n as n incr eases fr om 2.\nUsing (13.1), we see that \n , and hence  \n is asymptotically equal to Θ(1/ n).\nWaiting for a Particular Proce ss to Succeed  Let's consider this protocol\nwith the optimal value p = 1/n for the access probability . Suppose we are\ninterested in how long it will take process Pi to succeed in accessing the\ndatabase at least once. We see from the earlier calculation that the\nprobability of its succeeding in any one round is not very good, if n is\nreasonably lar ge. How about if we consider multiple rounds?\nLet \n [i, t] denote the “failure event” that process Pi does not succee d\nin any of the rounds 1 through t. This is clearly just the intersection of the\ncomplementary events \n  for r = 1, 2, …, t. Moreover , since each of\nthese events is independent, we can compute the probability of \n[i, t] by\nmultiplication:\nThis calculation does give us the value of the probability; but at this point,\nwe're in danger of ending up with some extremely complica ted-looking\nexpressions, and so it's important to start thinking asymptotically . Recall\nthat the probability of success was Θ(1/n) after one round; specifically , it\nwas bounded between 1/(en) and 1/(2n). Using the expression above, we\nhave"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 849})","('type', 'Document')"
"('page_content', ""Now we notice that if we set t = en, then we have an expression that can be\nplugged directly into (13.1). Of course en will not be an integer; so we can\ntake t = [en] and write\nThis is a very compact and useful asymptotic statement: The\nprobability that process Pi does not succeed in any of rounds 1 through [en]\nis upper-bounde d by the constant e-1, independent of n. Now , if we increase\nt by some fairly small factors, the probability that Pi does not succeed in\nany of rounds 1 through t drops precipitously: If we set t = [en] · (c ln n),\nthen we have\nSo, asymptotica lly, we can view things as follows. After Θ(n) rounds,\nthe probability that Pi has not yet succeeded is bounded by a constant; and\nbetween then and Θ(n ln n), this probability drops to a quantity that is quite\nsmall, bounded by an inverse polynomial in n.\nWaiting for All Processes to Get Through  Finally , we're in a position to ask\nthe question that was implicit in the overall setup: How many rounds must\nelapse before there's a high probability that all processes will have\nsucceeded in accessing the database at least once?\nTo address this, we say that the protocol fails after t rounds if some\nprocess has not yet succeeded in accessing the database. Let \nt denote the"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 850})","('type', 'Document')"
"('page_content', ""event that the protocol fails after t rounds; the goal is to find a reasonably\nsmall value of t for which Pr[\nt] is small.\nThe event \nt occurs if and only if one of the events \n [i, t] occurs; so\nwe can write\nPreviously , we considered intersections of independent events, which were\nvery simple to work with; here, by contrast, we have a union of events that\nare not indepen dent. Probabiliti es of unions like this can be very hard to\ncompute exactly , and in many settings it is enough to analyze them using a\nsimple Union Bound,  which says that the probability of a union of events is\nupper -bounded by the sum of their individual probabilities:\n(13.2)  (The Union Bound) Given events Ε 1, Ε2, …, Εn, we have\nNote that this is not an equality; but the upper bound is good enough\nwhen, as here, the union on the left-hand side represents a “bad event” that\nwe're trying to avoid, and we want a bound on its probability in terms of\nconstituent “bad events” on the right-hand side.\nFor the case at hand, recall that \n , and so\nThe expression on the right-hand side is a sum of n terms, each with the\nsame value; so to make the probability of \nt small, we need to make each of"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 851})","('type', 'Document')"
"('page_content', ""the terms on the right significantly smaller than 1/n. From our earlier\ndiscussion, we see that choosin g t = Θ(n) will not be good enough, since\nthen each term on the right is only bounded by a constant. If we choose t =\n[en] · (c ln n), then we have Pr[\n[i, t]] ≤ n-c for each i, which is what we\nwant. Thus, in particular , taking t = 2[ en] ln n gives us\nand so we have shown the following.\n(13.3)  With probability at least 1 - n-1, all processes succeed in accessing the database at least once\nwithin t  = 2[ en] ln n rounds.\nAn interesting observation here is that if we had chosen a value of t\nequal to qn ln n for a very smal l value of q (rather than the coefficient 2e\nthat we actually used), then we would have gotten an upper bound for Pr[\n[i, t]] that was larger than n-1, and hence a corresponding upper bound for\nthe overall failure probability Pr[\nt] that was larger than 1—in other words,\na completely worthless bound. Yet, as we saw, by choosing larger and larger\nvalues for the coef ficient q, we can drive the upper bound on Pr[\nt] down to\nn-c for any constant c we want; and this is really a very tiny upper bound.\nSo, in a sense, all the “action” in the Union Bound takes place rapidly in the\nperiod when t = Θ(n ln n); as we vary the hidden constant inside the Θ(·),\nthe Union Bound goes from providing no information to giving an\nextremely strong upper bound on the probability .\nWe can ask whether this is simply an artifact of using the Union Bound\nfor our upper bound, or whether it's intrinsic to the process we're  observing.\nAlthough we won't do the (som ewhat messy) calculations here, one can\nshow that when  t is a small constant times n ln n, there really is a sizable\nprobability that some process has not yet succeeded in accessing the\ndatabase. So a rapid falling-of f in the value of Pr[\nt] genuinely does happen\nover the range t = Θ(n ln n). For this problem, as in many problems of this\nflavor , we're really identifying the asymptotically “correct” value of t\ndespite our use of the seemingly weak Union Bound."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 852})","('type', 'Document')"
"('page_content', '13.2 Finding the Global Minimum Cut\nRandomization naturally suggested itself in the previous example, since we\nwere assuming a model with many processes that could not directly\ncommunicate. We now look at a problem on graphs for which a randomized\napproach comes  as somewhat more of a surprise, since it is a problem for\nwhich perfectly reasonable deterministic algorithms exist as well.\nThe Problem\nGiven an undirected graph G = (V, E), we define a cut of G to be a partition\nof V into two non-empty sets A and B. Earlier, when we looked at network\nflows, we worked with the closely related definition of an s-t cut: there,\ngiven a directed graph G = (V, E) with distinguished source and sink nodes s\nand t, an s-t cut  was defined to be a partition of V into sets A and B such that\ns ∊ A and t ∊ B. Our definition now is slightly different, since the\nunderlying graph is now undirected and there is no source or sink.\nFor a cut (A, B) in an undirect ed graph G, the size of (A, B) is the\nnumber of edges with one end in A and the other in B. A global minimum\ncut (or “global min-cut” for short) is a cut of minimum size. The term\nglobal  here is meant to connote that any cut of the graph is allowed; there is\nno source or sink. Thus the global min-cut is a natural “robustness”\nparameter; it is the smallest number of edges whose deletion disconnects\nthe graph. We first check that network flow techniques are indee d sufficient\nto find a global min-cut.\n(13.4)  There is a polynomial-time algorithm to find a global min-cut in an undir ected graph G.\nProof. We start from the similarity between cuts in undirected graphs and s-t cuts in directed graphs,\nand with the fact that we know how to find the latter optimally .\nSo given an undirecte d graph G = (V, E), we need to transform it so that there are directed edges\nand there is a source and sink. We first replace every undirected edge e = (u, v) ∊ E with two\noppositely oriented directed edges, e′ = (u,v) and e′ = (v,u), each of capacity 1. Let G′ denote the\nresulting directed graph.\nNow suppo se we pick two arbitrary nodes s,t ∊ V, and find the minimum  s-t cut in G′. It is easy\nto check that if (A, B) is this minimum cut in G′, then (A, B) is also a cut of minimum size in G\namong all those that separate s from t. But we know that the global min-cut in G must  separate s\nfrom something,  since both sides A and B are nonempty , and s belongs to only one of them. So we fix\nany s ∊ V and comp ute the minimum s-t cut in G′ for every other node  t ∊ V - {s}. This is n - 1\ndirected minimum-cut computations, and the best among these will be a global min-cut of G. ▪')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 853})","('type', 'Document')"
"('page_content', ""The algorithm in (13.4) gives the strong impression that finding a\nglobal min-cut in an undirected graph is in some sense a harder problem\nthan finding a minimum s-t cut in a flow network, as we had to invoke a\nsubroutine for the latter problem  n - 1 times in our method for solving the\nformer . But it turns out that this is just an illusion. A sequence of\nincreasingly simple algorithms in the late 1980s and early 1990s showed\nthat global min-cuts in undirected graphs could actually be comp uted just as\nefficiently as s-t cuts or even more so, and by techniques that didn't require\naugmenting paths or even a notion of flow. The high point of this line of\nwork came with David Karger's discovery in 1992 of the Contraction\nAlgorithm, a randomized meth od that is qualitatively simpler than all\nprevious algorithms for global min-cuts. Indeed, it is sufficiently simple\nthat, on a first impression, it is very hard to believe that it actually works.\nDesigning the Algorithm\nHere we describe the Contrac tion Algorithm in its simplest form. This\nversion, while it runs in polynomial time, is not among the most efficient\nalgorithms for global min-cuts. However , subsequent optimizations to the\nalgorithm have given it a much better running time.\nThe Contraction Algorithm works with a connected multigraph G  = (V,\nE); this is an undirected graph that is allowed to have multiple “parallel”\nedges between the same pair of nodes. It begins by choosing an edge e = (u,\nv) of G uniform ly at random and contracting  it, as shown in Figure 13.1.\nThis means we produce a new graph G′ in which u and v have been\nidentified into a single new node w; all other nodes keep their identity .\nEdges that had one end equal to u and the other equal to v are deleted from\nG′. Each other edge e is preserved in G′, but if one of its ends was equa l to\nu or v, then this end is updated to be equal to the new node w. Note that,\neven if G had at most one edge between any two nodes, G′ may end up with\nparallel edges.\nThe Contraction  Algorithm then continues recursively on G′, choosing\nan edge uniformly at random and contracting it. As these recursive calls\nproceed, the constituent vertice s of G′ should be view ed as supernodes:\nEach supernode w corresponds to the subset S(w) ⊆ V that has been\n“swallowed up” in the contr actions that produced w. The algorithm\nterminates when  it reaches a graph G′ that has only two supernodes v1 and"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 854})","('type', 'Document')"
"('page_content', ""v2 (presumably with a number of parallel edges between them) . Each of\nthese super -nodes vi has a corresponding subset S(vi) ⊆ V consisting of the\nnodes that have been contracted  into it, and these two sets S(v1) and S(v2)\nform a partition of V. We output (S(v1), S(v2)) as the cut found by the\nalgorithm.\nFigur e 13.1  The Contraction Algorithm applied to a four -node input graph.\nThe Contraction Algorithm applied to a multigraph G = (V,E):\nFor each node v, we will record the set S(v) of nodes that have been contracted into v\nInitially S(v) = { v} for each v\nIf G has two nodes v1 and v2, then return the cut ( S(v1), S(v2))\nElse choose an edge e = (u, v) of G uniformly at random\nLet G′ be the graph resulting from the contraction of e, with a new node zuv replacing u and v\nDefine S(zuv) = S(u) ∪ S(v)\nApply the Contraction Algorithm recursively to G′\nEndif\nAnalyzing the Algorithm\nThe algorithm is making random choices, so there is some probability that it\nwill succeed in finding a global min-cut and some probability that it won't.\nOne might imagine at first that the probability of success is exponentially\nsmall. After all, there are expo nentially many possible cuts of G; what's\nfavoring the minimum cut in the process? But we'll show first that, in fact,\nthe success probability is only polynomially small. It will then follow that\nby runni ng the algorithm a polynomial number of times and returning the\nbest cut found in any run, we can actually produce a global min-cut with\nhigh probability ."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 855})","('type', 'Document')"
"('page_content', '(13.5)  The Contraction Algorithm r eturns a global min-cut of G with pr obability at least  \n .\nProof. We focus on a globa l min-cut (A, B) of G and suppose it has size k; in other words, there  is a\nset F of k edges with one end in A and the other in B. We want to give a lower bound on the\nprobability that the Contraction Algorithm returns the cut ( A, B).\nConsider what could go wrong in the first step of the Contraction Algorithm: The problem\nwould be if an edge in F were contracted. For then, a node of A and a node of B woul d get thrown\ntogether in the same supernode, and (A, B) could not be returned as the output of the algorithm.\nConversely , if an edge not in F is contracted, then there is still a chance that ( A, B) could be returned.\nSo what we want is an upper bound on the probability that an edge in F is contracted, and for\nthis we need a lower bound on the size of E. Notice that if any node v had degree less than k, then the\ncut ({v}, V - {v}) would have size less than k, contradicting our assumption that (A, B) is a global\nmin-cut. Thus every node in G has degree at least k, and so |E| ≥ ½kn. Hence the probability that an\nedge in F is contracted is at most\nNow consi der the situation after j iterations, when there are n - j super -nodes in the current\ngraph G′, and suppose that no edge in F has been contracted yet. Every cut of G′ is a cut of G, and so\nthere are at least k edges incident to every supernode of G′. Thus G′ has at least ½k{n - j) edges, and\nso the probability that an edge of F is contracted in the next iteration j + 1 is at most\nThe cut (A, B) will actua lly be returned by the algorithm  if no edge of F is contracted in any of\niterations 1, 2, …, n - 2. If we write Εj for the event that an edge of F is not contracted in iteration j,\nthen we have shown Pr[Ε1] ≥ 1 - 2/n and Pr[ Εj+1| Ε1 ∩ Ε2 ··· ∩ Εj] ≥ 1 - 2/(n - j). We are interested\nin lower -bounding the quantity Pr[Ε1 ∩ Ε2 ··· ∩ Εn - 2], and we can check  by unwinding the\nformula for conditional probability that this is equal to')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 856})","('type', 'Document')"
"('page_content', ""So we now know that a single run of the Contraction Algorithm fails to\nfind a global min-cut with probability at most \n . This number is\nvery close to 1, of course, but we can amplify our probability  of success\nsimply by repeatedly running the algorithm, with independent random\nchoices, and taking the best cut we find. By fact (13.1), if we run the\nalgorithm \n  times, then the probability that we fail to find a global min-cut\nin any run is at most\nAnd it's easy to drive the failure probability below 1/e with further\nrepetitions: If we run the algorithm \n  ln n times, then the probability we\nfail to find a global min-cut is at most e-ln n = 1/n.\nThe overall running time required to get a high probability of success\nis polynomial in n, since each run of the Contraction Algorithm takes\npolynomial time, and we run it a polynomial number of times. Its running\ntime will be fairly large compared with the best network flow techniques,\nsince we perform Θ( n2) independent runs and each takes at least Ω(m) time.\nWe have chosen to describe this version of the Contraction Algo rithm since\nit is the simple st and most elegant; it has been shown that some clever\noptimizations to the way in whic h multiple runs are performed can improve\nthe running time considerably .\nFurther Analysis: The Number of Global\nMinimum Cuts\nThe analysis of the Contraction  Algorithm provides a surprisingly simple\nanswer to the following question : Given an undirected graph G = (V,E) on n\nnodes, what is the maximum number of global min-cuts it can have (as a\nfunction of n)?\nFor a directed flow network, it's easy to see that the number of\nminimum s-t cuts can be exponential in n. For example, consider a directed\ngraph with nodes s, t, v1, v2, –, vn, and unit-capacity edges (s, vi) and (vi, t)"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 857})","('type', 'Document')"
"('page_content', ""for each i. Then s together with any subset of {v1, v2, …, vn} will constitute\nthe source side of a minimum cut, and so there are 2n minimum s-t cuts.\nBut for global min-cuts in an undirected graph, the situation looks\nquite different. If one spends some time trying out examples, one finds that\nthe n-node cycle has \n  global min-cuts (obtained by cutting any two\nedges), and it is not clear how to construct an undirected graph with more.\nWe now show how the analysis of the Contraction Algorithm settles\nthis question immediately , estab lishing that the n-node cycle is indeed an\nextreme case.\n(13.6)  An undir ected graph G  = (V, E) on n nodes has at most  \n global min-cuts.\nProof. The key is that the proof of (13.5) actually established more than was claimed. Let G be a\ngraph, and let C1, …, Cr denote all its global min-cuts. Let Εi denote the event that Ci is returned  by\nthe Contraction Algorithm, and let Ε = ∪ri=1Εi denote the event that the algorithm returns any\nglobal min-cut.\nThen, altho ugh (13.5)  simply asserts that Pr[Ε] ≥ 1/\n , its proof actually shows that for each i,\nwe have Pr[ Εi] ≥ 1/\n . Now each pair of events Εi and Εj are disjoint—since only one cut is returned\nby any given run of the algorithm—so by the Union Bound for disjoint events (13.49), we have\nBut clearly Pr[ Ε] ≤ 1, and so we must have r ≤ \n . ▪\n13.3 Random Variables and Their Expectations\nThus far our analysis of randomized algorithms and processes has been\nbased on identifying certain “bad events” and bounding their probabilities.\nThis is a qualita tive type of analysis, in the sense that the algorithm either\nsucceeds or it doesn't. A more quantitative style of analysis would consider\ncertain parameters associated with the behavior of the algorithm—for\nexample, its running time, or the quality of the solution it produces—and\nseek to determine the expected  size of these parameters over the random"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 858})","('type', 'Document')"
"('page_content', ""choices made by the algorithm. In order to make such analysis possible, we\nneed the fundamental notion of a random variable.\nGiven a probability space, a random variable X is a function from the\nunderlying sample space to the natural numbers, such that for each natural\nnumber j, the set X-1(j) of all sample points taking the value j is an event.\nThus we can write Pr[X = j] as loose shorth and for Pr[X-1(j)]; it is because\nwe can ask about X's probab ility of taking a given value that we think of it\nas a “random variable.”\nGiven a random variable X, we are often interested in determining its\nexpectation —the “average value” assumed by X. We define this as\ndeclaring this to have the value ∞ if the sum diver ges. Thus, for example, if\nX takes each of the values in {1, 2, …, n} with probability 1/n, then \n."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 859})","('type', 'Document')"
"('page_content', ""Example: Waiting for a First Success\nHere's a more useful example, in which we see how an appropr iate random\nvariable lets us talk about something like the “running time” of a simple\nrandom process . Suppose we have a coin that comes up heads with\nprobability p > 0, and tails with probability 1 - p. Differen t flips of the coin\nhave independent outcomes. If we flip the coin until we first get a heads,\nwhat's the expected number of flips we will perform? To answer this, we let\nX denote the random variable equal to the number of flips perfor med. For j\n> 0, we have Pr[X = j] = (1 - p)j-1p: in order for the process to take exactly j\nsteps, the first j - 1 flips must come up tails, and the jth must come up heads.\nNow , applying the definition, we have\nThus we get the following intuitively sensible result.\n(13.7)  If we repeatedly perform independent trials of an experiment, each of which succeeds with\nprobability p  > 0, then the expected number of trials we need to perform until the first success is  1/p.\nLinearity of Expectation\nIn Sections 13.1 and 13.2, we broke events down into unions of much\nsimpler events, and worked with the probabilities of these simpler events.\nThis is a powerf ul technique when working with random variab les as well,\nand it is based on the principle of linearity of expectation.\n(13.8)  Linearity of Expectation. Given two random variables X and Y defined over the same\nprobability space, we can define X + Y to be the random variable equal to X(ω) + Y(ω) on a sample\npoint ω. For any X and Y , we have"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 860})","('type', 'Document')"
"('page_content', ""We omit the proof, which is not difficult. Much of the power of (13.8)\ncomes from the fact that it applies to the sum of any random variables; no\nrestrictive assum ptions are needed. As a result, if we need to compute the\nexpectation of a complicated random variable X, we can first write it as a\nsum of simpler random variables X = X1 + X2 + ··· + Xn, compute each\nE[Xi], and then determine E[X] = Σ E[Xi]. We now look at some examples of\nthis principle in action.\nExample: Guessing Cards\nMemoryless Guessing  To amaz e your friends, you have them shuffle a deck\nof 52 cards and then turn over one card at a time. Before each card is turned\nover, you predict its identity . Unfortunately , you don't have any particular\npsychic abilities—and you're not so good at remembering what's been\nturned over alrea dy—so your strategy is simply to guess a card uniformly at\nrandom from the full deck each time. On how many predictions do you\nexpect to be correct?\nLet's work this out for the more general setting in which the deck has n\ndistinct cards, using X to deno te the random variable equal to the number of\ncorrect predictions. A surprisingly effortless way to compute X is to define\nthe random variable Xi, for i = 1, 2, …, n, to be equal to 1 if the ith\nprediction is correct, and 0 otherwise. Notice that X = X1 + X2 + ··· + Xn,\nand\nIt's worth pausing to note a usefu l fact that is implicitly demonst rated by the\nabove calculation: If Z is any random variable that only takes the values 0\nor 1, then E[Z] = Pr [ Z = 1].\nSince \n  for each i, we have"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 861})","('type', 'Document')"
"('page_content', ""Thus we have shown the following.\n(13.9)  The expect ed number of correct predictions under the memoryless guessing strategy is 1,\nindependent of n.\nTrying to compu te E[X] directly from the definition Σj=0∞j · Pr[X = j]\nwould be much more painful, since it would involve working out a much\nmore elaborate summation. A significant amount of complexit y is hidden\naway in the seemingly innocuous statement of (13.8).\nGuessing with Memory  Now let's consider a second scenario. Your psychic\nabilities have not developed any further since last time, but you have\nbecome very good at remembering which cards have already been turned\nover. Thus, when you predict the next card now, you only guess uniformly\nfrom among the cards not yet seen. How many correct predictions do you\nexpect to make with this strategy?\nAgain, let the random variable Xi take the value 1 if the ith prediction is\ncorrect, and 0 otherwise. In order for the ith prediction to be correct, you\nneed only guess the correct one out of n - i + 1 remaining cards; hence\nand so we have\nThis last expression \n  is the harmonic number\nH(n), and it is something that has come up in each of the previous two\nchapters. In particular , we show ed in Chapter 11 that H(n), as a function of"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 862})","('type', 'Document')"
"('page_content', ""n, closely shadow s the value \n . For our purpos es here, we\nrestate the basic bound on H(n) as follows.\n(13.10)  ln(n + 1) < H(n) < 1 + ln n, and mor e loosely , H(n) = Θ(log n).\nThus, once you are able to remember the cards you've already seen, the\nexpected number of correct predictions increases significantly above 1.\n(13.1 1) The expected number of correct predictions under the guessing strategy with memory is H(n)\n= Θ(log n).\nExample: Collecting Coupons\nBefore moving on to more sophisticated applications, let's consider one\nmore basic example in which linearity of expectation provides significant\nleverage.\nSuppose that a certain brand of cereal includes a free coupon in each\nbox. There are n different types of coupons. As a regular consumer of this\nbrand, how many boxes do you expect to buy before finally getting a\ncoupon of each type?\nClearly , at least n boxes are neede d; but it would  be sort of surprising\nif you actually had all n types of coupon s by the time you'd bought n boxes.\nAs you collect more and more different types, it will get less and less likely\nthat a new box has a type of coupon you haven't seen before. Once you\nhave n - 1 of the n different types, there's only a probability of 1/n that a\nnew box has the missing type you need.\nHere's a way to work out the expected time exactly . Let X be the\nrandom variable equal to the number of boxes you buy until you first have a\ncoupon of each type. As in our previous examples, this is a reasonably\ncomplicated random variable to think about, and we'd like to write it as a\nsum of simpler random variab les. To think about this, let's consider the\nfollowing natural idea: The coupon-collecting process makes progress\nwhenever you buy a box of cereal containing a type of coupon you haven't\nseen before. Thus the goal of the process is really to make progr ess n times.\nNow , at a given point in time, what is the probability that you make\nprogress in the next step? This depends on how many different types of\ncoupons you already have. If you have j types, then the probability of\nmaking progress in the next step is (n - j)/n: Of the n types of coupons, n - j"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 863})","('type', 'Document')"
"('page_content', ""allow you to make progress. Since the probability varies depending on the\nnumber of different types of coupons we have, this suggests a natural way\nto break down X into simpler random variables, as follows.\nLet's say that the coupon-collecting process is in phase j when you've\nalready collected j different types of coupons and are waiting to get a new\ntype. When you see a new type of coupon, phase j ends and phase j + 1\nbegins. Thus we start in phase 0, and the whole process is done at the end of\nphase n - 1. Let Xj be the random variable equal to the number of steps you\nspend in phase j. Then X = X0 + X1 + ··· + Xn-1, and so it is enough to work\nout E[Xj] for each j.\n(13.12)  E[Xj] = n/(n - j).\nProof. In each step of phase j, the phase ends immediately if and only if the coupon you get next is\none of the n - j types you haven't seen before. Thus, in phase j, you are really just waiting for an event\nof probability ( n - j)/n to occur , and so, by (13.7), the expected length of phase j is E[Xj] = n/(n - j).\n▪\nUsing this, linearity of expectation gives us the overall expected time.\n(13.13)  The expected time befor e all n types of coupons ar e collected is E [X] = nH(n) = Θ( n log n).\nProof. By linearity of expectation, we have\nBy (13.10), we know this is asymptotically equal to Θ( n log n). ▪\nIt is interesting to compare the dynamics of this process to one's\nintuitive view of it. Once n - 1 of the n types of coupons are collected, you\nexpect to buy n more boxes of cereal before you see the final type. In the\nmeantime, you keep getting coupons you've already seen before, and you\nmight conclude that this final type is “the rare one.” But in fact it's just as\nlikely as all the others; it's simply that the final one, whichever it turns out\nto be, is likely to take a long time to get.\nA Final Definition: Conditional Expectation"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 864})","('type', 'Document')"
"('page_content', 'We now discuss one final, very useful notion concerning random variables\nthat will come up in some of the subsequent analyses. Just as one can define\nthe cond itional probability of one event given another , one can analogously\ndefine the expectation of a random variable conditioned on a certain event.\nSuppose we have a random variable X and an event Ε of positive\nprobability . Then we define the conditional expectation  of X, given Ε, to be\nthe expected value of X comput ed only over the part of the sample space\ncorresponding to Ε. We denote this quantity by E[X | Ε]. This simply\ninvolves replacing the probabilities Pr[X = j] in the defini tion of the\nexpectation with conditional probabilities:\n13.4 A Randomized Approximation Algorithm for\nMAX 3-SAT\nIn the previous section, we saw a number of ways in which linearity of\nexpectation can be used to analyze a randomized process. We now describe\nan application of this idea to the design of an approximation algorithm. The\nproblem we consider is a variation of the 3-SA T Problem, and we will see\nthat one consequence of our randomized approximation algorithm is a\nsurprisingly strong general statement about 3-SA T that on its surface seems\nto have nothing to do with either algorithms or randomization.\nThe Problem\nWhen we studie d NP-completen ess, a core problem was 3-SA T: Given a set\nof clauses C1, …, Ck, each of length 3, over a set of variables X = {x1, …,\nxn], does there exist a satisfying truth assignment?\nIntuitively , we can imagine such a problem arising in a system that\ntries to decide the truth or falsehood of statements about the world (the')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 865})","('type', 'Document')"
"('page_content', ""variables {xi}), given pieces of information that relate them to one another\n(the clauses {Cj}). Now  the world is a fairly contradictory place, and if our\nsystem gathers enough information, it could well end up with a set of\nclauses that has no satisfying truth assignment. What then?\nA natural approach, if we can't find a truth assignment that satisfies all\nclauses, is to turn the 3-SA T instance into an optimization problem: Given\nthe set of input clauses C1, …, Ck, find a truth assignment that satisfies as\nmany as possible.  We'll call this the Maximum 3-Satisfiability Problem  (or\nMAX 3-SA T for short). Of course, this is an NP-hard optimization problem,\nsince it's NP-complete to decide whether the maximum number of\nsimultaneously satisfiable claus es is equal to k. Let's see what can be said\nabout polynomial-time approximation algorithms.\nDesigning and Analyzing the Algorithm\nA remarkably simple randomized algorithm turns out to give a strong\nperformance guarantee for this problem. Suppose we set each variable x1,\n…, xn indepen dently to 0 or 1 with probability ½ each. What is the expected\nnumber of clauses satisfied by such a random assignment?\nLet Z denote the random variable equal to the number of satisfie d\nclauses. As in Section 13.3, let's decompose Z into a sum of random\nvariables that each take the value 0 or 1; specifically , let Zi = 1 if the clause\nCi is satisf ied, and 0 otherwise. Thus Z = Z1 + Z2 + ··· + Zk. Now E[Zi] is\nequal to the probability that Ci is satisfied, and this can be computed easily\nas follows. In order for Ci not to be satisfied, each of its three variables\nmust be assigne d the value that fails to make it true; since the variables are\nset independently , the probabil ity of this is (½)3 = ⅛. Thus clause Ci is\nsatisfied with probability 1 - ⅛ = ⅞, and so E[Zi] = ⅞.\nUsing linearity of expectation, we see that the expected number of\nsatisfied clauses  is E[Z] = E[Z1 + E[Z2] + ··· + E[Zk] = ⅞k. Since no\nassignment can satisfy more than k clauses, we have the following\nguarantee.\n(13.14)  Consider a 3-SA T formula, wher e each clause has three differ ent variables. The expected\nnumber of clauses satisfied by a random assignment is within an appr oximation factor  ⅞ of optimal."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 866})","('type', 'Document')"
"('page_content', ""But, if we look at what really happened in the (admittedly simple)\nanalysis of the random assignment, it's clear that something stronger is\ngoing on. For any random variable, there must be some point at which it\nassumes some value at least as large as its expectation. We've shown that\nfor every instance of 3-SA T, a random truth assignment satisfies a ⅞\nfraction of all clauses in expectation; so, in particular , there must exist a\ntruth assignment that satisfies a number of clauses that is at least as large as\nthis expectation.\n(13.15)  For every instance of 3-SA T, there is a truth assignment that satisfies at least a ⅞ fraction of\nall clauses.\nThere is something genuinely surprising about the statement of\n(13.15). We have arrived at a nonobvious fact about 3-SA T—th e existence\nof an assignment satisfying many clauses—whose statement has nothing to\ndo with randomization; but we have done so by a randomized construction.\nAnd, in fact, the randomized construction provides what is quite possibly\nthe simplest proof of (13.15). This is a fairly widespread principle in the\narea of combina torics—namely , that one can show the existen ce of some\nstructure by showing that a random construction produces it with positive\nprobability . Constructions of this sort are said to be applications of the\nprobabilistic method.\nHere's a cute but minor application of (13.15): Every instance of 3-\nSAT with at most seven clauses is satisfiable. Why? If the instance has k ≤ 7\nclauses, then (13.15) implies that there is an assignment satisfying at least\n⅞k of them. But when k ≤ 7, it follows that ⅞ k > k - 1; and since the number\nof clauses satisfied by this assig nment must be an integer , it must be equal\nto k. In other words, all clauses are satisfied.\nFurther Analysis: Waiting to Find a Good\nAssignment\nSuppose we aren't satisfied with a “one-shot” algorithm that produces a\nsingle assignme nt with a large number of satisfied clauses in expectation.\nRather , we'd like a randomized  algorithm whose expected running time is\npolynomial and that is guarantee d to output a truth assignment satisfying at\nleast a ⅞ fraction of all clauses."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 867})","('type', 'Document')"
"('page_content', ""A simple way to do this is to generate random truth assignments until\none of them satisfies at least ⅞k clauses.  We know that such an assignment\nexists, by (13.15); but how long will it take until we find one by random\ntrials?\nThis is a natural place to apply the waiting-time bound we derived in\n(13.7). If we can show that the probability a random assignment satisfies at\nleast ⅞k clauses is at least p, then the expected number of trials performed\nby the algorithm is 1/ p. So, in particular , we'd like to show that this quantity\np is at least as lar ge as an inverse polynomial in n and k.\nFor j = 0, 1, 2, …, k, let pj denote the probability that a random\nassignment satisfies exactly j clauses . So the expected numb er of clauses\nsatisfied, by the definition of expectation, is equal to Σkj=0jpj; and by the\nprevious analysi s, this is equal to ⅞k. We are interest ed in the quanti ty p =\nΣj≥7k/8pj. How can we use the lower bound on the expected value to give a\nlower bound on this quantity?\nWe start by writing\nNow let k′ denote the largest natural numb er that is strictly smaller than ⅞k.\nThe right-hand side of the abov e equation only increases if we replace the\nterms in the first sum by k′pj and the terms in the second sum by kpj. We\nalso observe that \n , and so\nand hence kp ≥ ⅞k - k′. But ⅞k - k′ ≥ ⅛, since k′ is a natural number strictly\nsmaller than ⅞ times another natural number , and so"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 868})","('type', 'Document')"
"('page_content', ""This was our goal—to get a lower bound on p—and so by the waiting-time\nbound (13.7), we see that the expected number of trials needed to find the\nsatisfying assignment we want is at most 8 k.\n(13.16)  There is a randomized algorithm with polynomial expected running time that is guaranteed to\nproduce a truth assignment satisfying at least a  ⅞ fraction of all clauses.\n13.5 Randomized Divide and Conquer: Median-\nFinding and Quicksort\nWe've seen the divide-and-conquer paradigm for designing algorithms at\nvarious earlier points in the book. Divide and conquer often works well in\nconjunction with randomization, and we illustrate this by giving divide-and-\nconquer algorithms for two fundamental problems: computing the median\nof n numbers, and sorting. In each case, the “divide” step is performed\nusing randomization; consequently , we will use expectations of random\nvariables to analyze the time spent on recursive calls.\nThe Problem: Finding the Median\nSuppose we are given a set of n numbers S = {a1, a2, ………, an). Their\nmedian  is the number that would be in the middle position if we were to\nsort them. There's an annoying technical difficulty if n is even, since then\nthere is no “middle position”; thus we define things precisely as follows:\nThe median of S = {a1, a2, …, an} is equal to the kth largest element in S,\nwhere k = (n + 1)/2 if n is odd, and k = n/2 if n is even. In what follows,\nwe'll assume for the sake of simplicity that all the numbers are distinct.\nWithout this assumption, the problem becomes notation ally more\ncomplicated, but no new ideas are brought into play .\nIt is clearly easy to compute the median in time O(n log n) if we\nsimply sort the numbers first. But if one begins thinking about the problem,"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 869})","('type', 'Document')"
"('page_content', ""it's far from clear why sorting is necessary  for computing the median, or\neven why Ω(n log n) time is necessary . In fact, we'll show how a simple\nrandomized approach, based on divide-and-conquer , yields an expected\nrunning time of O(n).\nDesigning the Algorithm\nA Generic Algorithm Based on Splitters  The first key step toward getting\nan expected linear running time is to move from median-finding to the more\ngeneral problem of selection.  Given a set of n numbers S and a number k\nbetween 1 and n, consider the function Select( S, k) that returns the kth\nlargest element in S. As special cases, Select includes the problem of\nfinding the median of S via Select( S, n/2) or Select( S, (n + 1)/2); it also\nincludes the easier problems of finding the minimum (Select( S, 1)) and the\nmaximum (Select( S, n)). Our goal is to design an algorithm that implements\nSelect so that it runs in expected time O(n).\nThe basic structure of the algori thm implementing Select is as follows.\nWe choose an element ai ∊ S, the “splitter ,” and form the sets S- = {aj: aj <\nai} and S+ = {aj: aj > ai}. We can then determine which  of S- or S+ contains\nthe kth largest element, and iterate only on this one. Without specifying yet\nhow we plan to choose the splitter, here's a more concrete description of\nhow we form the two sets and iterate.\nSelect( S,k):\nChoose a splitter ai ∊ S\nFor each element aj of S\nPut aj in S- if aj < ai\nPut aj in S+ if aj > ai\nEndfor\nIf |S-| = k - 1 then\nThe splitter ai was in fact the desired answer\nElse if | S-|≥k then\nThe kth largest element lies in S-\nRecursively call Select (S-, k)\nElse suppose | S-| = ℓ < k - 1\nThe kth largest element lies in S+\nRecursively call Select (S+, k - 1 - ℓ"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 870})","('type', 'Document')"
"('page_content', ""Endif\nObserve that the algorithm is always called recursively on a strictly smaller\nset, so it must terminate. Also, observe that if |S| = 1, then we must have k =\n1, and indeed the single element in S will be returned by the algori thm.\nFinally , from the choice of which recursive call to make, it's clear by\ninduction that the right answer will be returned when |S| > 1 as well. Thus\nwe have the following\n(13.17)  Regar dless of how the splitter is chosen, the algorithm above returns the kth largest element\nof S.\nChoosing a Good Splitter  Now let's consider how the running time of\nSelect depends on the way we choose the splitter . Assuming we can select a\nsplitter in linear  time, the rest of the algorithm takes linear time plus the\ntime for the recursive call. But how is the running time of the recursive call\naffected by the choice of the splitter? Essentially , it's import ant that the\nsplitter significantly reduce the size of the set being considered, so that we\ndon't keep maki ng passes through large sets of numbers many times. So a\ngood choice of splitter should produce sets S- and S+ that are approxi mately\nequal in size.\nFor example, if we could always choose the median as the splitter , then\nwe could show a linear bound on the running time as follows. Let cn be the\nrunning time for Select, not counting the time for the recursive call. Then,\nwith medians as splitters, the running time T(n) would be bounded by the\nrecurrence T(n) < T(n/2) + cn. This is a recurrence that we encountered at\nthe beginning of Chapter 5 , where we showed that it has the solution T(n) =\nO(n).\nOf cours e, hopin g to be able to use the median as the splitter is rather\ncircular , since the median is what we want to compute in the first place!\nBut, in fact, one can show that any “well-centered” element can serve as a\ngood splitter: If we had a way to choose splitters ai such that there were at\nleast Εn elements both larger and smaller than ai, for any fixed constant Ε >\n0, then the size of the sets in the recursive call would shrink by a factor of at\nleast (1 - Ε) each time. Thus the running time T(n) would be bounded by the\nrecurrence T(n) ≤ T((1 - Ε)n) + cn. The same argument that showed the"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 871})","('type', 'Document')"
"('page_content', ""previous recurre nce had the solution T(n) = O(n) can be used here: If we\nunroll this recurrence for any Ε > 0, we get\nsince we have a conver gent geometric series.\nIndeed, the only thing to really beware of is a very “off-center” splitter .\nFor example, if we always chose the minimum element as the splitter , then\nwe may end up with a set in the recursive call that's only one element\nsmaller than we had before. In this case, the running time T(n) would be\nbounded by the recurrence T(n) ≤ T(n - 1) + cn. Unrolling this recurrence,\nwe see that there's a problem:\nRandom Splitters  Choosing a “well-centered” splitter , in the sense we have\njust defined, is certainly similar in flavor to our original problem of\nchoosing the median; but the situation is really not so bad, since any well-\ncentered splitter will do.\nThus we will implement the as-yet-unspecified step of selecting a\nsplitter using the following simple rule:\nChoose a splitter ai ∊ S uniformly at random\nThe intuition here is very natural: since a fairly large fraction of the\nelements are reasonably well-centered, we will be likely to end up with a\ngood splitter simply by choosing an element at random.\nThe analysis of the running time with a random splitter is based on this\nidea; we expect the size of the set under consideration to go down by a\nfixed constant fraction every iteration, so we should get a conver gent series"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 872})","('type', 'Document')"
"('page_content', ""and hence a linear bound as previously . We now show how to make this\nprecise.\nAnalyzing the Algorithm\nWe'll say that the algorithm is in phase j when the size of the set unde r\nconsideration is at most n(¾)j but greater than n(¾)y+1. Let's try to bound\nthe expected time spent by the algorithm in phase j. In a given iteration of\nthe algorithm, we say that an element of the set under consideration is\ncentral  if at least a quarter of the elements are smaller than it and at least a\nquarter of the elements are lar ger than it.\nNow observe that if a central element is chosen as a splitter , then at\nleast a quarter of the set will be thrown away , the set will shrink by a factor\nof ¾ or better , and the current phase will come to an end. Moreover , half of\nall the elements in the set are central, and so the probability that our random\nchoice of splitte r produces a central element is ½. Hence, by our simple\nwaiting-time bound (13.7), the expected number of iterations before a\ncentral element is found is 2; and so the expected number of iterations spent\nin phase j, for any j, is at most 2.\nThis is pretty much all we need for the analysis. Let X be a random\nvariable equal to the number of steps taken by the algorithm. We can write\nit as the sum X = X0 + X1 + X2 + ···, where Xj is the expected number of\nsteps spent by the algorithm in phase j. When the algorithm is in phase j, the\nset has size at most n(¾)j, and so the number of steps required for one\niteration in phase j is at most cn(¾)j for some constant c. We have just\nargued that the expected numb er of iterations spent in phase j is at most\ntwo, and hence we have E[Xj] ≤ 2cn(¾)j. Thus we can bound the total\nexpected running time using linearity of expectation,\nsince the sum Σj(¾)j is a geometric series that conve rges. Thus we have the\nfollowing desired result."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 873})","('type', 'Document')"
"('page_content', '(13.18)  The expected running time of  Select( n, k) is O(n).\nA Second Application: Quicksort\nThe randomized divide-and-conquer technique we used to find the median\nis also the basis of the sorting algorithm Quicksort. As before, we choose a\nsplitter for the input set S, and separate S into the eleme nts below the\nsplitter value and those above it. The difference is that, rather than looking\nfor the median on just one side of the splitter , we sort both sides recursively\nand glue the two sorted pieces together (with the splitter in between) to\nproduce the overall output. Also , we need to explicitly include  a base case\nfor the recursive  code: we only use recursion on sets of size at least 4. A\ncomplete description of Quicksort is as follows.\nQuicksort( S):\nIf |S| ≤ 3 then\nSort S\nOutput the sorted list\nElse\nChoose a splitter ai ∊ S uniformly at random\nFor each element aj of S\nPut aj in S- if aj < ai\nPut aj in S+ if aj > ai\nEndfor\nRecursively call Quicksort( S-) and Quicksort( S+)\nOutput the sorted set S-, then ai, then the sorted set S+\nEndif\nAs with median -finding, the worst-case running time of this method is\nnot so good. If we always select the smallest element as a splitter , then the\nrunning time T(n) on n-element sets satisfies the same recurrence as before:\nT(n) ≤ T(n - 1) + cn, and so we end up with a time bound of T(n) = Θ( n2). In\nfact, this is the worst-case running time for Quicksort.\nOn the positive side, if the splitters selected happened to be the\nmedians of the sets at each iteration, then we get the recurrence T(n) ≤\n2T(n/2) + cn, which arose frequently in the divide-and-conquer analyses of\nChapter 5 ; the running time in this lucky case is O(n log n).')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 874})","('type', 'Document')"
"('page_content', 'Here we are concerned with the expected running time;  we will show\nthat this can be bounded by O(n log n), almost as good as in the best case\nwhen the splitters are perfectly  centered. Our analysis of Quicksort will\nclosely follow the analysis of median-finding. Just as in the Select\nprocedure that we used for median-finding, the crucial definition is that of a\ncentral splitter —one that divid es the set so that each side contains at least a\nquarter of the elements. (As we discussed earlier , it is enough for the\nanalysis that each side contains at least some fixed constant fraction of the\nelements; the use of a quarter here is chosen for convenience.) The idea is\nthat a random choice is likely to lead to a central splitter , and central\nsplitters work well. In the case of sorting, a central splitter divides the\nproblem into two considerably smaller subproblems.\nTo simp lify the presentation, we will slightly modify the algorithm so\nthat it only issues its recursive calls when it finds a central splitter .\nEssentially , this modified algori thm differs from Quicksort in that it prefers\nto throw away an “off-center” splitter and try again; Quicksort, by contrast,\nlaunches the recursive calls even with an off-center splitter , and at least\nbenefits from the work already done in splitting S. The point is that the\nexpected running time of this modified algorithm can be analyzed very\nsimply , by direct analogy with our analysis for median-finding. With a bit\nmore work, a very similar but somewhat more involved analysis  can also be\ndone for the original Quicksort algorithm as well; however , we will not\ndescribe this analysis here.\nModified Quicksort( S):\nIf |S| ≤ 3 then\nSort S\nOutput the sorted list\nEndif\nElse\nWhile no central splitter has been found\nChoose a splitter ai ∊ S uniformly at random\nFor each element aj of S\nPut aj in S- if aj < ai\nPut aj in S+ if aj > ai\nEndfor\nIf |S-| ≥ |S|/4 and | S+| ≥ |S|/4 then\nai is a central splitter\nEndif')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 875})","('type', 'Document')"
"('page_content', ""Endwhile\nRecursively call Quicksort( S-) and Quicksort ( S+)\nOutput the sorted set S-, then ai, then the sorted set S+\nEndif\nConsider a subproblem for some set S. Each iteration of the While loop\nselects a possible splitter ai and spends O(|S|) time splitting the set and\ndeciding if ai is central. Earlier we argued that the number of iterations\nneeded until we find a centra l splitter is at most 2. This gives us the\nfollowing statement.\n(13.19)  The expected running time for the algorithm on a set S, excluding the time spent on recursive\ncalls, is O (|S|).\nThe algorithm is called recursive ly on multiple subproblems. We will group\nthese subproblems by size. We'll say that the subproblem is of type j if the\nsize of the set under considerati on is at most n(¾)j but greater than n(¾)j+1.\nBy (13.19), the expected time spent on a subproblem of type j, excluding\nrecursive calls, is O(n(¾)j). To bound the overall running  time, we need to\nbound the number of subproblems for each type j. Splitting a type j\nsubproblem via a central splitter creates two subproblems of higher type. So\nthe subproblems  of a given type j are disjoint. This gives us a bound on the\nnumber of subproblems.\n(13.20)  The number of type j subpr oblems cr eated by the algorithm is at most  \n .\nThere are at most \n  subproblems of type j, and the expected time\nspent on each is O(n(¾)j) by (13.19). Thus, by linearity of expectation, the\nexpected time spent on subpro blems of type j is O(n). The number of\ndifferent types is bounded by \n , which gives the desired\nbound.\n(13.21)  The expected running time of  Modified Quicksort is O(n log n).\nWe considered this modified version of Quicksort to simplify the\nanalysis. Coming back to the original Quicksort, our intuition suggests that\nthe expected running time is no worse than in the modified algorithm, as"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 876})","('type', 'Document')"
"('page_content', 'accepting the noncentral splitters helps a bit with sorting, even if it does not\nhelp as much as when a central splitter is chosen. As mentioned  earlier , one\ncan in fact make this intuition precise, leading to an O(n log n) expected\ntime bound for the original Quicksort algorithm; we will not go into the\ndetails of this here.\n13.6 Hashing: A Randomized Implementation of\nDictionaries\nRandomization has also proved to be a powerful technique in the\ndesign of data structures. Here we discuss perhaps the most fundamental\nuse of randomization in this setting, a technique called hashing  that can be\nused to maintain a dynamically changing set of elements. In the next\nsection, we will show how an application of this technique yields a very\nsimple algorithm for a problem that we saw in Chapter 5—the problem of\nfinding the closest pair of points in the plane.\nThe Problem\nOne of the most basic applicatio ns of data structures is to simply maintain a\nset of elements that changes over time. For example, such applications\ncould include a large company maintaining the set of its current employees\nand contractors, a news indexing service recording the first paragraphs of\nnews articles it has seen coming across the newswire, or a searc h algorithm\nkeeping track of the small part of an exponentially large search space that it\nhas already explored.\nIn all these examples, there is a universe U  of possi ble elem ents that is\nextremely large: the set of all possible people, all possible paragraphs (say,\nup to some character length  limit), or all possible solutions to a\ncomputationally hard problem. The data structure is trying to keep track of\na set S ⊆ U whose size is generally a negligible fraction of U, and the goal\nis to be able to insert and delete elements from S and quickly determine\nwhether a given element belongs to S.\nWe will call a data structure that accomplishes this a dictionary . More\nprecisely , a dictionary is a data structure that supports the following\noperations.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 877})","('type', 'Document')"
"('page_content', ""MakeDictionary . This operation initializes a fresh dictionary that can\nmaintain a subset S of U; the dictionary starts out empty .\nInsert( u) adds element u ∊ U to the set S. In many applications, there\nmay be some additional information that we want to associate with u\n(for example, u may be the name or ID number of an employee, and\nwe want to also store some personal information about this employee),\nand we will simply imagine this being stored in the dictionary as part\nof a record together with u. (So, in general, when we talk about the\nelement u, we really mean u and any additional information stored\nwith u.)\nDelete( u) removes element u from the set S, if it is currently present.\nLookup( u) determ ines whether u currently belongs to S; if it does, it\nalso retrieves any additional information stored with u.\nMany of the implementations we've discussed earlier in the book\ninvolve (most of) these operatio ns: For example, in the implem entation of\nthe BFS and DFS graph traversal algorithms, we needed to maintain the set\nS of nodes already visited. But there is a fundamental difference between\nthose problems and the presen t setting, and that is the size of U. The\nuniverse U in BFS or DFS is the set of nodes V, which is already given\nexplicitly as part of the input. Thus it is completely feasible in those cases\nto maintain a set S ⊆ U as we did there: defining an array with |U|\npositions, one for each possible element, and setting the array position for u\nequal to 1 if u ∊ S, and equal to 0 if u ∉ S. This allows for insertion,\ndeletion, and lookup of element s in constant time per operation, by simply\naccessing the desired array entry .\nHere, by contrast, we are considering the setting in which the universe\nU is enormous. So we are not going to be able to use an array whose size is\nanywhere near that of U. The fundamental question is whether , in this case,\nwe can still implement a dictionary to support the basic operations almost\nas quickly as when U was relatively small.\nWe now descr ibe a randomized technique called hashing  that\naddresses this question. While we will not be able to do quite as well as the\ncase in which it is feasible to define an array over all of U, hashing will\nallow us to come quite close.\nDesigning the Data Structure"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 878})","('type', 'Document')"
"('page_content', ""As a motivating  example, let's think a bit more about the problem faced by\nan automated service that processes breaking news. Suppose you're\nreceiving a steady stream of short articles from various wire services,\nweblog postings , and so forth, and you're storing the lead paragraph of each\narticle (truncated  to at most 1,000 characters). Because you're using many\nsources for the sake of full coverage, there's a lot of redundanc y: the same\narticle can show up many times.\nWhen a new article shows up, you'd like to quickly check whether\nyou've seen the lead paragraph before. So a dictionary is exactly what you\nwant for this problem: The universe U is the set of all strings of length at\nmost 1,000 (or of length exactly 1,000, if we pad them out with blanks), and\nwe're maintaining a set S ⊆ U consisti ng of strings (i.e., lead paragraphs)\nthat we've seen before.\nOne solution would be to keep a linked list of all paragraphs, and scan\nthis list each time a new one arrives. But a Lookup operation in this case\ntakes time proportional to |S|. How can we get back to some thing that looks\nlike an array-based solution?\nHash Functions  The basic idea of hashing is to work with an array of size\n|S|, rather than one comparable to the (astronomical) size of U.\nSuppose we want to be able to store a set S of size up to n. We will set\nup an array H of size n to store  the information, and use a function h : U →\n{0,1, …, n - 1} that maps elements of U to array  positions. We call such a\nfunction h a hash function,  and the array H a hash table.  Now , if we want to\nadd an element u to the set S, we simply place u in posit ion h(u) of the array\nH. In the case of storing paragraphs of text, we can think of h(·) as\ncomputing some kind of numerical signature or “check-sum” of the\nparagraph u, and this tells us the array position at which to store u.\nThis would work extremely well if, for all distinct u and v in our set S,\nit happened to be the case that h(u) ≠ h(v). In such a case, we could look up\nu in constant time: when we check array position H[h(u)], it would either be\nempty or would contain just u.\nIn gener al, though, we cannot expect to be this lucky: there can be\ndistinct elements u, v ∊ S for which h(u) = h(v). We will say that these two\nelements collide,  since they are mapped to the same place in H. There are a\nnumber of ways to deal with collisions. Here we will assume that each\nposition H[i] of the hash table stores a linked list of all elements u ∊ S with\nh(u) = i. The operation Lookup( u) would now work as follows."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 879})","('type', 'Document')"
"('page_content', ""Compute the hash function h(u).\nScan the linked list at position H[h(u)] to see if u is present in this list.\nHence the time required for Lookup( u) is proportional to the time to\ncompute h(u), plus the length of the linked list at H[h(u)]. And this latter\nquantity , in turn, is just the number of elements in S that collide with u. The\nInsert and Delete operations work similarly: Insert adds u to the linked list\nat position H[h(u)], and Delete scans this list and removes u if it is present.\nSo now the goal is clear: We'd like to find a hash function that\n“spreads out” the elements being added, so that no one entry of the hash\ntable H contains too many elements. This is not a problem for which worst-\ncase analysis is very informative. Indeed, suppose that |U| ≥ n2 (we're\nimagining applications where it's much larger than this). Then, for any hash\nfunction h that we choose , there will be some set S of n elemen ts that all\nmap to the same position. In the worst case, we will insert all the elements\nof this set, and then our Lookup operations will consist of scann ing a linked\nlist of length n.\nOur main goal here is to show that randomization can help\nsignificantly for this problem. As usual, we won't make any assumptions\nabout the set of elements S being random ; we will simply exploit\nrandomization in the design of the hash function. In doing this, we won't be\nable to comple tely avoid collisions, but can make them relatively rare\nenough, and so the lists will be quite short.\nChoosing a Good Hash Function  We've seen that the efficiency of the\ndictionary is based on the choic e of the hash function h. Typically , we will\nthink of U as a large set of numbers, and then use an easily computable\nfunction h that maps each number u ∊ U to some  value in the smaller range\nof integers {0,1,…, n - 1}. There are many simple ways to do this: we could\nuse the first or last few digits of u, or simply take u modulo n. While these\nsimple choices may work well in many situations, it is also possible to get\nlarge numbers of collisions. Indeed, a fixed choice of hash function may run\ninto problems because of the types of elements u encountered in the\napplication: Maybe the particula r digits we use to define the hash function\nencode some property of u, and hence maybe only a few options are\npossible. T aking u modulo n can have the same problem, especially if n is a\npower of 2. To take a concrete example, suppose we used a hash function\nthat took an English paragraph, used a standard character encoding scheme"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 880})","('type', 'Document')"
"('page_content', ""like ASCII to map it to a sequence of bits, and then kept only the first few\nbits in this sequence. We'd expect a huge number of collisions at the array\nentries correspon ding to the bit strings that encoded common English words\nlike The, while vast portions of the array can be occupied only by\nparagraphs that begin with strings like qxf, and hence will be empty .\nA slightly better choice in practice is to take (u mod p) for a prime\nnumber p that is approximately equal to n. While in some applications this\nmay yield a good hashing functi on, it may not work well in all applications,\nand some primes may work much better than others (for example, primes\nvery close to powers of 2 may not work so well).\nSince hashing has been widely used in practice for a long time, there is\na lot of experie nce with what makes for a good hash function, and many\nhash functions have been proposed that tend to work well empirically . Here\nwe would like to develop a hashing scheme where we can prove that it\nresults in ef ficient dictionary operations with high probability .\nThe basic idea, as suggested earlier , is to use randomization  in the\nconstruction of h. First let's consider an extreme version of this: for every\nelement u ∊ U, when we go to insert u into S, we select a value h(u)\nuniformly at random in the set {0,1,…, n - 1}, independently of all previo us\nchoices. In this case, the probability that two randomly selected  values h(u)\nand h(v) are equal (and hence cause a collision) is quite small.\n(13.22)  With this uniform random hashing scheme, the probability that two randomly selecte d values\nh(u) and h (v) collide—that is, that h (u) = h(v)—is exactly  1/n.\nProof. Of the n2 possible choices for the pair of values (h(u), h(v)), all are equally likely, and exactly\nn of these choices results in a collision. ▪\nHowever , it will not work to use a hash function with indepen dently\nrandom chosen values. To see why, suppose we inserted u into S, and then\nlater want to perform either Delete( u) or Lookup( u). We immediat ely run\ninto the “Where  did I put it?” problem: We will need to know the random\nvalue h(u) that we used, so we will need  to have stored the value h(u) in\nsome form where we can quickly look it up. But this is exactly the same\nproblem we were trying to solve in the first place.\nThere are two things that we can learn from (13.22). First, it provides a\nconcrete basis for the intuition from practice that hash functions that spread\nthings around in a “random” way can be effective at reducing collisions.\nSecond, and more crucial for our goals here, we will be able to show how a"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 881})","('type', 'Document')"
"('page_content', ""more controlled use of randomization achieves performance as good as\nsuggested in (13.22), but in a way that leads to an efficien t dictionary\nimplementation.\nUniversal Classes of Hash Functions  The key idea is to choose a hash\nfunction at random not from the collection of all possible functions into [0,\nn - 1], but from a carefully selected class of functions. Each function h in\nour class of functions \n  will map the universe U into the set {0,1,…, n - 1},\nand we will design it so that it has two properties. First, we'd like it to come\nwith the guarantee from (13.22):\nFor any pair of elements u,v ∊ U, the probability  that a random ly\nchosen h ∊ \n satisfies h(u) = h(v) is at most 1/ n.\nWe say that a class \n  of functions is universal  if it satisfies this first\nproperty . Thus (13.22) can be viewed as saying that the class of all possible\nfunctions from U into {0,1, …, n - 1} is universal.\nHowever , we also need \n  to satisfy a second property . We will state\nthis slightly informally for now and make it more precise later .\nEach h ∊ \n can be compactly represented and, for a given h ∊ \n and u\n∊ U, we can compute the value h(u) efficiently .\nThe class of all possible functio ns failed to have this property:  Essentially ,\nthe only way to represent an arbitrary function from U into {0,1, …, n - 1}\nis to write down the value it takes on every single element of U.\nIn the remainder of this section, we will show the surprising fact that\nthere exist classe s \n that satisfy both of these properties. Before we do this,\nwe first make precise the basic property we need from a universal class of\nhash functions. We argue that if a function h is selec ted at random from a\nuniversal class of hash function s, then in any set S ⊆ U of size at most  n,\nand any u ∊ U, the expected number of items in S that collide with u is a\nconstant.\n(13.23)  Let \n be a univer sal class of hash functions mapping a universe U to the set {0,1,…, n - 1},\nlet S be an arbitrary subset of U of size at most n, and let u be any element in U. We define X to be a\nrandom variable equa l to the number of elements s ∊  S for which h(s) = h(u), for a random choice of\nhash function h ∊ \n. (Here S and u are fixed, and the randomne ss is in the choice of h ∊ \n.) Then\nE[X] ≤ 1."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 882})","('type', 'Document')"
"('page_content', 'Proof. For an element s ∊ S, we define  a random variable Xs that is equal to 1 if h(s) = h{u), and\nequal to 0 otherwise. W e have E [Xs] = Pr [ Xs = 1] ≤ 1/ n, since the class of functions is universal.\nNow X = Σs ∊S Xs, and so, by linearity of expectation, we have\nDesigning a Universal Class of Hash Functions  Next we will design a\nuniversal class of hash function s. We will use a prime number p ≈ n as the\nsize of the hash table H. To be able to use integer arithmetic in designing\nour hash functions, we will identify the universe with vectors of the form x\n= (x1, x2, … xr) for some integer r, where 0 ≤ xi < p for each i. For example,\nwe can first identify U with integers in the range [0, N - 1] for some N, and\nthen use consecu tive blocks of [log p] bits of u to define the corresponding\ncoordinates xi. If U ⊆ [0, N - 1], then we will need a number of coordinates\nr ≈ log N/ log n.\nLet A be the set of all vectors of the form a = (a1, …, ar), where ai is\nan integer in the range [0, p - 1] for each i = 1, …, r. For each a ∊ A, we\ndefine the linear function\nThis now completes our random implementation of dictionaries. We\ndefine the family of hash functions to be \n  = {ha :a ∊ A}. To execute\nMakeDictionary , we choose a random hash function from \n ; in other\nwords, we choo se a random vector from A (by choosing each coordinate\nuniformly at random), and form  the function ha. Note that in order to define\nA, we need to find a prime number p ≥ n. There are meth ods for generating\nprime numbers quickly , which we will not go into here. (In practice, this\ncan also be accomplished using a table of known prime numbers, even for\nrelatively lar ge n.)')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 883})","('type', 'Document')"
"('page_content', ""We then use this as the hash function with which to implement Insert,\nDelete, and Lookup. The family  \n = {ha : a ∊ A} satisfies a formal version\nof the second property we were  seeking: It has a compact representation,\nsince by simply choosing and remembering a random a ∊ A, we can\ncompute ha(u) for all elements u ∊ U. Thus, to show that \n  leads to an\nefficient, hashing-based implementation of dictionaries, we just need to\nestablish that \n  is a universal family of hash functions.\nAnalyzing the Data Structure\nIf we are using a hash function ha from the class \n  that we've defined, then\na collision ha(x) = ha(y) defines a linear equation modulo the prime number\np. In order to analyze such equations, it's useful to have the following\n“cancellation law .”\n(13.24)  For any prime p and any integer z ≠ 0 mod p, and any two integers α, β, if αz = βz mod p,\nthen α = β  mod p.\nProof. Suppose αz = βz mod p. Then , by rearranging  terms, we get z(α - β) = 0 mod p, and hence  z(α\n- β) is divisible by p. But z ≠ 0 mod p, so z is not divisible by p. Since p is prime, it follows that α - β\nmust be divisible by p; that is, α = β mod p as claimed. ▪\nWe now use this to prove the main result in our analysis.\n(13.25)  The class of linear functions  \n defined above is universal.\nProof. Let x = (x1, x2, … xr) and y = (y1, y2, … yr) be two distinct elements of U. We need to show\nthat the probability of ha(x) = ha(y), for a randomly chosen a ∊ A, is at most 1/ p.\nSince x ≠ y, then there  must be an index j such that xj = yj. We now consider the following way\nof choosing the random vector a ∊ A. We first choose all the coordinates ai where i ≠ j. Then, finally ,\nwe choose  coordinate  aj. We will show that regardless of how all the other coordinates ai were\nchosen, the probability of ha(x) = ha(y), taken over the final choice of aj, is exactly 1/ p. It will follow\nthat the probability of ha(x) = ha(y) over the random choice of the full vector a must be 1/ p as well.\nThis conclusion is intuitively clear: If the probability is 1/p regardless  of how we choose all\nother ai, then it is 1/p overall. There is also a direct proof of this using conditional probabilities. Let\nΕ be the event that ha(x) = ha(y), and let \n b be the event that all coordinates ai (for i ≠ j) receive a\nsequence of values b. We will show, below , that Pr [Ε | \nb] = 1/p for all b. It then follows that \n.\nSo, to conclude the proof, we assume that values have been chosen arbitrarily for all other\ncoordinates ai, and we consider the probability of selecting aj so that ha(x) = ha(y). By rearranging\nterms, we see that ha(x) = ha(y) if and only if"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 884})","('type', 'Document')"
"('page_content', 'Since the choices for all ai (i ≠ j) have been fixed, we can view the right-hand side as some fixed\nquantity m. Also, let us define z = yj - xj.\nNow it is enough to show that there is exactly one value 0 ≤ aj < p that satisfi es ajz = m mod p;\nindeed, if this is the case, then there is a probability of exactly 1/p of choosing this value for aj. So\nsuppose there were two such values, aj and a′j. Then we would have ajz = a′jz mod p, and so by\n(13.24) we would have aj = a′j mod p. But we assumed that aj, a′j < p, and so in fact aj and a′j would\nbe the same. It follows that there is only one aj in this range that satisfies ajz = m mod p.\nTracing back through  the implications, this means that the probability of choosing aj so that\nha(x) = ha(y) is 1/p, however we set the other coordinates ai in a; thus the probability  that x and y\ncollide is 1/ p. Thus we have shown that \n  is a universal class of hash functions. ▪\n13.7 Finding the Closest Pair of Points: A\nRandomized Approach\nIn Chapter 5, we used the divide-and-conquer technique to develop an O(n\nlog n) time algorithm for the problem of finding the closest pair of points in\nthe plane. Here we will show how to use randomization to develop a\ndifferent algorithm for this problem, using an underlying dictionary data\nstructure. We will show that this algorithm runs in O(n) expected time, plus\nO(n) expected dictionary operations.\nThere are several related reasons why it is useful to express the\nrunning time of our algorithm in this way, accounting for the dictionary\noperations separ ately . We have seen in Section 13.6  that dictionaries have a\nvery efficient implementation using hashing, so abstracting out the\ndictionary operations allows us to treat the hashing as a “black box” and\nhave the algorithm inherit an overall running time from whatever\nperformance guarantee is satisfied by this hashing procedure. A concrete\npayof f of this is the following. It has been shown that with the right choice\nof hashi ng procedure (more powerful, and more complicated, than what we\ndescribed in Section 13.6), one can make the underlying dictionary\noperations run in linear expected time as well, yielding an overall expected\nrunning time of O(n). Thus the randomized approach we describe here leads\nto an improvement over the running time of the divide-a nd-conquer')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 885})","('type', 'Document')"
"('page_content', ""algorithm that we saw earlier . We will talk about the ideas that lead to this\nO(n) bound at the end of the section.\nIt is worth remarking at the outset that randomization shows up for two\nindependent reasons in this algorithm: the way in which the algorithm\nprocesses the input points will have a random component, regardless of\nhow the dictionary data structur e is implemented; and when the dictionary\nis implemented  using hashing, this introduces an additional source of\nrandomness as part of the hash-table operations. Expressing the running\ntime via the number of dictionary operations allows us to cleanly separate\nthe two uses of randomness.\nThe Problem\nLet us start by recalling the problem's (very simple) statement. W e are given\nn points in the plane, and we wish to find the pair that is closest together . As\ndiscussed in Chapter 5, this is one of the most basic geometric proximity\nproblems, a topic with a wide range of applications.\nWe will use the same notation as in our earlier discussion of the\nclosest-pair problem. We will denote the set of points by P = {p1, …, pn},\nwhere pi has coordinates ( xi, yj); and for two points pi,pj ∊ P, we use d(pi,pj)\nto denote the standard Euclidean  distance between them. Our goal is to find\nthe pair of points pi,pj that minimizes d(pi,pj).\nTo simplify the discussion, we will assume that the points are all in the\nunit square: 0 ≤ xi, yi < 1 for all i = 1, …, n. This is no loss of generality: in\nlinear time, we can rescale all the x- and y-coordinates of the points so that\nthey lie in a unit square, and then we can translate them so that this unit\nsquare has its lower left corner at the origin.\nDesigning the Algorithm\nThe basic idea of the algorithm is very simple. We'll consider the points in\nrandom order , and maintain a current value δ for the closest pair as we\nprocess the points in this order . When we get to a new point p, we look “in\nthe vicinity” of p to see if any of the previously considered points are at a\ndistance less than δ from p. If not, then the closest pair hasn't changed, and\nwe move on to the next point in the random order . If there is a point within"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 886})","('type', 'Document')"
"('page_content', ""a distance less than δ from p, then the closest pair has changed, and we will\nneed to update it.\nThe challenge in turning this into an efficient algorithm is to figure out\nhow to implement the task of looking for points in the vicinit y of p. It is\nhere that the dictionary data structure will come into play .\nWe now begin making this more concrete. Let us assume for simplicity\nthat the points in our random order are labeled p1, …, pn. The algorithm\nproceeds in stages; during each stage, the closest pair remains constant. The\nfirst stage starts by setting δ = d(p1,p2), the distance of the first two points.\nThe goal of a stage is to either  verify that δ is indeed the distance of the\nclosest pair of points, or to find a pair of points pi, pj with d(pi,pj) < δ.\nDuring a stage, we'll gradually add points in the order p1,p2,…,pn. The\nstage terminates when we reach a point pi so that for some j < i, we have\nd(pi, pj) < δ.  We then let δ for the next stage be the closest distance found so\nfar: δ = minj:j < i d(pi,pj).\nThe number of stages used will depend on the random order . If we get\nlucky , and p1,p2 are the closest pair of points, then a single stage will do. It\nis also possible to have as many as n - 2 stages, if adding a new point\nalways decrease s the minimum distance. We'll show that the expected\nrunning time of the algorithm is within a constant factor of the time needed\nin the first, lucky case, when the original value of δ is the smallest distance.\nTesting a Proposed Distance  The main subroutine of the algorithm is a\nmethod to test whether the current pair of points with distance δ remains the\nclosest pair when a new point is added and, if not, to find the new closest\npair.\nThe idea of the verification is to subdivide the unit square (the area\nwhere the points lie) into subsqu ares whose sides have length δ/2, as shown\nin Figure 13.2. Forma lly, there will be N2 subsquares, where N = [1/(2 δ)]:\nfor 0 ≤ s ≤ N - 1 and 1 ≤ t ≤ N - 1, we define the subsquare Sst as\nWe claim that this collection of subsquares has two nice proper ties for\nour purposes. First, any two points that lie in the same subsquare have"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 887})","('type', 'Document')"
"('page_content', 'distance less than δ. Second, and a partial converse to this, any two points\nthat are less than δ away from each other must fall in either the same\nsubsquare or in very close subsquares.\n(13.26)  If two points p and q belong to the same subsquar e Sst, then d (p,q) < δ.\nProof. If points p and q are in the same subsquare, then both coordinates of the two points differ by\nat most δ/2, and hence \n , as required. ▪\nFigur e 13.2  Dividing the square into size δ/2 subsquares. The point p lies in\nthe subsquare Sst.\nNext we say that subsquares Sst and Ss′t′ are close  if |s - s′| ≤ 2 and | t - t′|\n≤ 2. (Note that a subsquare is close to itself.)\n(13.27)  If for two points p,q  ∊ P we have d (p, q) < δ, then the subsquar es containing them ar e close.\nProof. Consider two points p, q ∊ P belonging to subsqua res that are not close; assume p ∊ Sst and q\n∊ Ss′t′, where one of s, s′ or t, t′ differs by more than 2. It follows that in one of their respective x- or\ny-coordinates, p and q differ by at least δ, and so we cannot have d(p,q) < δ. ▪\nNote that for any subsquare Sst, the set of subsq uares close to it form a\n5 × 5 grid aroun d it. Thus we conclude that there are at most 25 subsquares\nclose to Sst, counting Sst itself. (There will be fewer than 25 if Sst is at the\nedge of the unit square containing the input points.)\nStatements (13.26) and (13.27 ) suggest the basic outline of our\nalgorithm. Suppose that, at some point in the algorithm, we have proceeded\npartway through  the random order of the points and seen P′ ⊆ P, and')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 888})","('type', 'Document')"
"('page_content', ""suppose that we know the minimum distance among points in P′ to be δ.\nFor each of the points in P′, we keep track of the subsquare containing it.\nNow , when the next point p is consi dered, we determine which of the\nsubsquares Sst it belongs to. If p is going to cause the minimum distance to\nchange, there must be some earlier point p′ ∊ P′ at distan ce less than δ from\nit; and hence, by (13.27), the point p′ must be in one of the 25 squares\naround the square Sst containing p. So we will simply check each of these\n25 squares one by one to see if it contains a point in P′; for each point in P′\nthat we find this way, we compute its distance to p. By (13.26), each of\nthese subsquares contains at most one point of P′, so this is at most a\nconstant number of distance computations. (Note that we used a similar\nidea, via (5.10), at a crucial point in the divide-and-conquer algorithm for\nthis problem in Chapter 5 .)\nA Data  Struct ure for Maintaining the Subsquares  The high-level\ndescription of the algorithm relies on being able to name a subsquare Sst and\nquickly determine which points of P, if any, are contained in it. A\ndictionary is a natural data struc ture for implementing such operations. The\nuniverse U of possible elem ents is the set of all subsquares, and the set S\nmaintained by the data structure  will be the subsquares that contain points\nfrom among the set P′ that we've seen so far. Specifically , for each point p′\n∊ P′ that we have seen so far, we keep the subsquare containing it in the\ndictionary , tagge d with the index of p′. We note that N2 = [1/(2 δ)]2 will, in\ngeneral, be much larger than n, the number of points. Thus we are in the\ntype of situation  considered in Section 13.6 on hashing, where the universe\nof possible elements (the set of all subsquares) is much larger than the\nnumber of elements being indexed (the subsquares containing an input\npoint seen thus far).\nNow , when we consider the next point p in the random order , we\ndetermine the subsquare Sst containing it and perform a Lookup operation\nfor each of the 25 subsquares close to Sst. For any points  discovered by\nthese Lookup operations, we compute the distance to p. If none of these\ndistances are less than δ, then the closest distance hasn't changed; we insert\nSst (tagged with p) into the dictionary and proceed to the next point.\nHowever , if we find a point p′ such that δ′ = d(p,p′) < δ, then we need\nto update our closest pair. This updating is a rather dramatic activity: Since\nthe value of the closest pair has dropped from δ to δ′, our entire colle ction"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 889})","('type', 'Document')"
"('page_content', ""of subsq uares, and the dictionary supporting it, has become useless—it was,\nafter all, designed only to be useful if the minimum distance was δ. We\ntherefore invoke  MakeDictionary to create a new, empty dictionary that will\nhold subsquares whose side lengths are δ′/2. For each point seen thus far,\nwe determine the subsquare containing it (in this new collection of\nsubsquares), and we insert this subsquare into the dictionary . Having done\nall this, we are again ready to handle the next point in the random order .\nSummary of the Algorithm  We have  now actually described  the algorithm\nin full. T o recap:\nOrder the points in a random sequence p1,p2,…,pn\nLet δ denote the minimum distance found so far\nInitialize δ = d(p1,p2)\nInvoke MakeDictionary for storing subsquares of side length δ/2\nFor i = 1, 2, …, n:\nDetermine the subsquare Sst containing pi\nLook up the 25 subsquares close to pi\nCompute the distance from pi to any points found in these subsquares\nIf there is a point pj (j<i) such that δ′ = d(pj,pi) < δ then\nDelete the current dictionary\nInvoke MakeDictionary for storing subsquares of side length δ′/2\nFor each of the points p1,p2, …,pi:\nDetermine the subsquare of side length δ′/2 that contains it\nInsert this subsquare into the new dictionary\nEndfor\nElse\nInsert pi into the current dictionary\nEndif\nEndfor\nAnalyzing the Algorithm\nThere are already some things we can say about the overall running time of\nthe algorithm. To consider a new point pi, we need to perform only a\nconstant number of Lookup operations and a constant number of distance\ncomputations. Moreover , even if we had to update the closest pair in every\niteration, we'd only do n MakeDictionary operations.\nThe missing ingredient is the total expected cost, over the course  of the\nalgorithm's execution, due to reinsertions into new dictionarie s when the"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 890})","('type', 'Document')"
"('page_content', 'closest pair is updated. We will consider this next. For now, we can at least\nsummarize the current state of our knowledge as follows.\n(13.28)  The algorit hm correctly maintains the closest pair at all times, and it performs at most O(n)\ndistance computations, O (n) Lookup operations, and O (n) MakeDictionary operations.\nWe now conclude the analysis by bounding the expected number of\nInsert operations. Trying to find a good bound on the total expec ted number\nof Insert  operations seems a bit problematic at first: An update to the closest\npair in iteration i will result in i insertions, and so each update comes at a\nhigh cost once i gets large. Despite this, we will show the surprising fact\nthat the expected number of insertions is only O(n). The intuition here is\nthat, even as the cost of updates  becomes steeper as the iteratio ns proceed,\nthese updates become correspondingly less likely .\nLet X be a random variable specifying the number of Insert operation s\nperformed; the value of this random variable is determined by the random\norder chosen at the outset. We are interested in bounding E [X], and as usual\nin this type of situation, it is helpful to break X down into a sum of simpler\nrandom variables. Thus let Xi be a random variable equal to 1 if the ith point\nin the random order causes the minimum distance to change, and equal to 0\notherwise.\nUsing these random variables Xi, we can write a simple formula for the\ntotal number of Insert operations . Each point is inserted once when it is first\nencountered; and i points need to be reinserted if the minimum distance\nchanges in iteration i. Thus we have the following claim.\n(13.29)  The total number of  Insert operations performed by the algorithm is n  + Σi iXi.\nNow we bound the probability Pr [Xi = 1] that considering the ith point\ncauses the minimum distance to change.\n(13.30)  Pr [Xi = 1 < 2/ i.\nProof. Consider the first i points p1,p2,…,pi in the random order . Assume that the minimum distance\namong these points is achieved by p and q. Now the point pi can only cause the minimum distance to\ndecrease if pi = p or pi = q. Since the first i points are in a random order , any of them is equally likely\nto be last, so the probability that p or q is last is 2/ i. ▪')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 891})","('type', 'Document')"
"('page_content', ""Note that 2/i is only an uppe r bound in (13.30) because there could be\nmultiple pairs among the first i points that define the same smallest\ndistance.\nBy (13.29) and (13.30), we can bound the total number of Insert\noperations as\nCombining this with (13.28), we obtain the following bound on the running\ntime of the algorithm.\n(13.31)  In expecta tion, the randomized closest-pair algorithm requir es O(n) time plus O(n)\ndictionary operations.\nAchieving Linear Expected Running Time\nUp to this point , we have treated the dictionary data structure  as a black\nbox, and in (13.31) we bounded  the running time of the algorithm in terms\nof computational time plus dictionary operations. We now want to give a\nbound on the actual expected running time, and so we need to analyze the\nwork involved in performing these dictionary operations.\nTo implement the dictionary , we'll use a universal hashing schem e, like\nthe one discussed in Section 13.6. Once the algorithm employs a hashing\nscheme, it is making use of randomness in two distinct ways: First, we\nrandomly order the points to be added; and second, for each new minimum\ndistance δ, we apply randomization to set up a new hash table using a\nuniversal hashing scheme.\nWhen inserting  a new point pi, the algorithm uses the hash-table\nLookup operati on to find all nodes in the 25 subsquares close to pi.\nHowever , if the hash table has collisions, then these 25 Lookup  operations\ncan involve inspecting many more than 25 nodes. Statement (13.23) from\nSection 13.6 shows that each such Lookup operation involves considering\nO(1) previously inserted points, in expectation. It seems intuitively clear\nthat performing O(n) hash-table operations in expectation, each of which\ninvolves considering O(1) elem ents in expectation, will result in an"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 892})","('type', 'Document')"
"('page_content', 'expected running time of O(n) overall. To make this intuition  precise, we\nneed to be careful with how these two sources of randomness interact.\n(13.32)  Assume we implement the randomized closest-pair algorithm using a universal hashing\nscheme. In expectation, the total number  of points consider ed during the Lookup operations is\nbounded by O (n).\nProof. From (13.31) we know that the expected number of Lookup operations is O(n), and from\n(13.23) we know that each of these Lookup operations involves considering only O(1) points in\nexpectation. In order to conclude that this implies the expected number of points considered is O(n),\nwe now consider the relationship between these two sources of randomness.\nLet X be a random variab le denoting the number of Lookup operations performed by the\nalgorithm. Now the random order σ that the algorithm chooses for the points completely determines\nthe sequence of minim um-distance values the algorithm will consider and the sequence of dictionary\noperations it will perform. As a result, the choice of σ determines the value  of X; we let X(σ) denote\nthis value, and we let Εσ denote the event the algorithm chooses the random order σ. Note  that the\nconditional expectation E[X| Εσ] is equal to X(σ). Also, by (13.31), we know that E[X] ≤ c0n, for\nsome constant c0.\nNow consi der this sequence of Lookup operations for a fixed order σ. For i = 1, …, X(σ), let Yi\nbe the number of points that need to be inspected during the ith Lookup operations— namely , the\nnumber of previously  inserted points that collide with the dictionary entry involved  in this Lookup\noperation. We would like to bound the expected value of \n , where expectation is over both\nthe random choice of σ and the random choice of hash function.\nBy (13.23) , we know that E [Yi | Εσ] = O(1) for all σ and all values of i. It is useful to be able to\nrefer to the constant in the expression O(1) here, so we will say that E [Yi | Εσ] ≤ c1 for all σ and all\nvalues of i. Summing over all i, and using linearity of expectation, we get E [ΣiYi | Εσ] ≤ c1X(σ).\nNow we have\nSince we know that E[X] is at most c0n, the total expected number of points considered is at most\nc0c1n = O(n), which proves the claim. ▪\nArmed with this claim, we can use the universal hash function s from\nSection 13.6  in our closest-pair algorithm. In expectation, the algorithm will\nconsider O(n) points  during the Lookup operations. We have to set up')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 893})","('type', 'Document')"
"('page_content', ""multiple hash tables—a new one each time the minimum distance changes\n—and we have to compute O(n) hash-fu nction values. All hash tables are\nset up for the same size, a prime p ≥ n. We can select one prime and use the\nsame table throughout the algorithm. Using this, we get the following\nbound on the running time.\n(13.33)  In expectat ion, the algorithm uses O(n) hash-function comput ations and O(n) additional time\nfor finding the closest pair of points.\nNote the distinction between this statement and (13.31). There we\ncounted each dictionary operation as a single, atomic step; here, on the\nother hand, we've conceptually opened up the dictionary operations so as to\naccount for the time incurred due to hash-table collisions and hash-function\ncomputations.\nFinally , consid er the time needed for the O(n) hash-function\ncomputations. How fast is it to compute the value of a universal hash\nfunction h? The class of universal hash functions developed in Section 13.6\nbreaks numbers in our universe U into r ≈ log N/ log n smaller numbers of\nsize O(log n) each, and then uses O(r) arithmetic operations on these\nsmaller number s to compute the hash-function value. So computing the\nhash value of a single point involves O(log N/ log n) multiplications, on\nnumbers of size log n. This is a total of O(n log N/ log n) arithmetic\noperations over the course of the algorithm, more than the O(n) we were\nhoping for .\nIn fact, it is possible to decrease the number of arithmetic operat ions to\nO(n) by using a more sophisticated class of hash functions. There are other\nclasses of universal hash functions where computing the hash-function\nvalue can be done by only O(1) arithmetic operations (though these\noperations will have to be done on larger numbers, integers of size roughly\nlog N). This class of improved hash functions also comes with one extra\ndifficulty for this application: the hashing scheme needs a prime that is\nbigger than the size of the universe (rather than just the size of the set of\npoints). Now the universe in this application grows inversely with the\nminimum distance δ, and so, in particular , it increases every time we\ndiscover a new, smaller minimu m distance. At such points, we will have to\nfind a new prime and set up a new hash table. Although we will not go into\nthe detai ls of this here, it is possible to deal with these difficultie s and make\nthe algorithm achieve an expected running time of O(n)."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 894})","('type', 'Document')"
"('page_content', '13.8 Randomized Caching\nWe now discuss the use of randomization for the caching problem, which\nwe first encountered in Chapter 4. We begin by developing a class of\nalgorithms, the marking algorithms , that include both deterministic and\nrandomized approaches. After deriving a general performanc e guarantee\nthat applies to all marking algorithms, we show how a stronge r guarantee\ncan be obtained for a particular marking algorithm that exploits\nrandomization.\nThe Problem\nWe begin by recalling the Cache Maintenance Problem  from Chapter 4. In\nthe most basic setup, we consider a processor whose full memory has n\naddresses; it is also equipped with a cache  containing k slots of memory\nthat can be accessed very quickly . We can keep copies of k items from the\nfull mem ory in the cache slots, and when a memory location is accessed,\nthe processor will first check the cache to see if it can be quick ly retrieved.\nWe say the request is a cache hit  if the cache contains the requested item; in\nthis case, the access is very quick. We say the request is a cache miss  if the\nrequested item is not in the cache; in this case, the access takes much\nlonger , and moreover , one of the items currently in the cache must be\nevicted  to make room for the new item. (We will assume that the cache is\nkept full at all times.)\nThe goal of a Cache Maintenance Algorithm is to minimize the\nnumber of cache misses, which are the truly expensive part of the process.\nThe sequence of memory references is not under the control of the\nalgorithm—this is simply dictated by the application that is running—and\nso the job of the algorithms we consider is simply to decide on an eviction\npolicy : Which item currently in the cache should be evicted on each cache\nmiss?\nIn Chapter 4, we saw a greedy algorithm that is optimal for the\nproblem: Alway s evict the item that will be needed the farthest in the\nfutur e. While this algorithm is useful to have as an absolute benchma rk on\ncaching performance, it clearly cannot be implemented under real operating')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 895})","('type', 'Document')"
"('page_content', ""conditions, since we don't know ahead of time when each item will be\nneeded next. Rather , we need to think about eviction policies that operate\nonline , using only information about past requests without knowledge of the\nfuture.\nThe eviction policy that is typically used in practice is to evict the item\nthat was used the least recently (i.e., whose most recent access was the\nlongest ago in the past); this is referred to as the Least-Recen tly-Used, or\nLRU, policy. The empirical justification for LRU is that algorit hms tend to\nhave a certain locality in accessing data, generally using the same set of\ndata frequently for a while. If a data item has not been accessed for a long\ntime, this is a sign that it may not be accessed again for a long time.\nHere we will evaluate the performance of different eviction policies\nwithout making any assumptions (such as locality) on the sequence of\nrequests. To do this, we will compare the number of misses made by an\neviction policy on a sequence σ with the minimum number of misses it is\npossible to make on σ. We will use f(σ) to denote this latter quantity; it is\nthe number of misses achieved  by the optimal Farthest-in-Future policy .\nComparing eviction policies to the optimum is very much in the spirit of\nproviding performance guarantees for approximation algorithms, as we did\nin Chapter 11. Note, however , the following interesting difference: the\nreason the optimum was not attainable in our approximation analyses from\nthat chapter (assuming P = NP) is that the algorithms were constrained to\nrun in polynom ial time; here, on the other hand, the eviction policies are\nconstrained in their pursuit of the optimum by the fact that they do not\nknow the requests that are coming in the future.\nFor eviction policies operating under this online constraint, it initially\nseems hopeless to say somethin g interesting about their performance: Why\ncouldn't we just design a reque st sequence that completely confounds any\nonline eviction policy? The surprising point here is that it is in fact possible\nto give absolute guarantees on the performance of various online policies\nrelative to the optimum.\nWe first show that the number of misses incurred by LRU, on any\nrequest sequence, can be bounded by roughly k times the optim um. We then\nuse randomization to develop a variation on LRU that has an exponentially\nstronger bound on its performan ce: Its number of misses is never more than\nO(log k) times the optimum."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 896})","('type', 'Document')"
"('page_content', ""Designing the Class of Marking Algorithms\nThe bounds for both LRU and its randomized variant will follow from a\ngeneral template for designing online eviction policies—a class of policies\ncalled marking algorithms.  They are motivated by the following intuition.\nTo do well against the benchmar k of f(σ), we need an eviction policy that is\nsensitive to the difference between the following two possibilitie s: (a) in the\nrecent past, the request sequence has contained more than k distinct items;\nor (b) in the recent past, the request sequence has come exclusively from a\nset of at most k items. In the first case, we know that f(σ) must be\nincreasing, since no algorithm can handle more than k distinct items without\nincurring a cache miss. But, in the second case, it's possible that σ is passing\nthrough a long stretch in which an optimal algorithm need not incur any\nmisses at all. It is here that our policy must make sure that it incurs very few\nmisses.\nGuided by these considerations, we now describe the basic outline of a\nmarking algorithm, which prefers evicting items that don't seem to have\nbeen used in a long time. Such an algorithm operates in phases;  the\ndescription of one phase is as follows.\nEach memory item can be either marked  or unmarked\nAt the beginning of the phase, all items are unmarked\nOn a request to item s:\nMark s\nIf s is in the cache, then evict nothing\nElse s is not in the cache:\nIf all items currently in the cache are marked then\nDeclare the phase over\nProcessing of s is deferred to start of next phase\nElse evict an unmarked item from the cache\nEndif\nEndif\nNote that this describes a class of algorithms, rather than a single\nspecific algorithm, because the key step—evict an unmarked item from the\ncache—does not specify which unmarked item should be selected. We will\nsee that eviction policies with different properties and performance\nguarantees arise depending on how we resolve this ambiguity ."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 897})","('type', 'Document')"
"('page_content', 'We first observe that, since a phase starts with all items unmarke d, and\nitems become marked only when accessed, the unmarked items have all\nbeen accessed less recently than the marked items. This is the sense in\nwhich a marking algorithm is trying to evict items that have not been\nrequested recently . Also, at any point in a phase, if there are any unmarked\nitems in the cache, then the least recently used item must be unmarked. It\nfollows that the LRU policy evicts an unmarked item whenever one is\navailable, and so we have the following fact.\n(13.34)  The LRU policy is a marking algorithm.\nAnalyzing Marking Algorithms\nWe now describe a method for analyzing marking algorithms, ending with a\nbound on performance that applies to all marking algorithms. After this,\nwhen we add randomization, we will need to strengthen this analysis.\nConsider an arbitrary marking algorithm operating on a request\nsequence σ. For the analy sis, we picture an optimal caching algorithm\noperating on σ alongside this marking algorithm, incurring an overall cost\nof f(σ). Suppose that there are r phases in this sequence σ, as defined by the\nmarking algorithm.\nTo make the analysis easier to discuss, we are going to “pad” the\nsequence σ both at the beginning and the end with some extra requests ;\nthese will not add any extra misses to the optimal algorithm—that is, they\nwill not cause f(σ) to increase—and so any bound we show on the\nperformance of the marking algorithm relative to the optimum for this\npadded sequence will also apply to σ. Specifically , we imagine a “phase 0”\nthat takes place before the first phase, in which all the items initially in the\ncache are reques ted once. This does not affect the cost of either the marking\nalgorithm or the optimal algorit hm. We also imagine that the final phase r\nends with an epilogue in which  every item currently in the cache of the\noptimal algorithm is requested twice in round-robin fashion. This does not\nincrease f(σ); and by the end of the second  pass through these items, the\nmarking algorithm will contain each of them in its cache, and each will be\nmarked.\nFor the performance bound, we need two things: an upper bound on\nthe number of misses incurred by the marking algorithm, and a lower bound')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 898})","('type', 'Document')"
"('page_content', ""saying that the optimum must incur at least a certain number of misses.\nThe division of the request sequence σ into phases turns out to be the\nkey to doing this. First of all, here is how we can picture the history of a\nphase, from the marking algorithm's point of view . At the beginning of the\nphase, all items are unmarked. Any item that is accessed during the phase is\nmarked, and it then remains in the cache for the remainder of the phase.\nOver the course of the phase, the number of marked items grows from 0 to\nk, and the next phase begins with a request to a (k + 1)st item, different from\nall of these marked items. We summarize some conclusion s from this\npicture in the following claim.\n(13.35)  In each phase, σ contains accesses to exactly k distinct items. The subsequent phase begins\nwith an access to a differ ent (k + 1)st item.\nSince an item, once marked, remains in the cache until the end of the\nphase, the mark ing algorithm cannot incur a miss for an item more than\nonce in a phase. Combined with (13.35), this gives us an uppe r bound on\nthe number of misses incurred by the marking algorithm.\n(13.36)  The marking algorithm incurs at most k misses per phase, for a total of at most kr misses\nover all r phases .\nAs a lower bound on the optimum, we have the following fact.\n(13.37)  The optimum incurs at least r  - 1 misses. In other wor ds, f(σ) > r - 1.\nProof. Consider any phase but the last one, and look at the situation just after the first access (to an\nitem s) in this phase. Curre ntly s is in the cache main tained by the optima l algorithm, and (13.35)\ntells us that the remainder of the phase will involve accesses to k - 1 other distinct items, and the first\naccess of the next phase will involve a kth other item as well. Let S be this set of k items other than s.\nWe note that at least one of the members of S is not currently in the cache maintained by the optimal\nalgorithm (since, with s there, it only has room for k - 1 other items), and the optimal algorithm  will\nincur a miss the first time this item is accessed.\nWhat we've shown, therefore, is that for every phase j < r, the sequence from the second access\nin phase j through the first access in phase j + 1 involves at least one miss by the optimum. This\nmakes for a total of at least r - 1 misses.\n▪\nCombining (13.36) and (13.37), we have the following performance\nguarantee.\n(13.38)  For any marking algorithm, the number of misses it incurs on any sequence  σ is at most  k ·\nf(σ) + k."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 899})","('type', 'Document')"
"('page_content', ""Proof. The number of misses incurred by the marking algorithm is at most\nwhere the final inequality is just (13.37). ▪\nNote that the “+k” in the bound of (13.38) is just an additive constant,\nindependent of the length of the request sequence σ, and so the key aspect\nof the bound is the factor of k relative to the optimum. T o see that this factor\nof k is the best bound possible for some marking algorithms, and for LRU\nin particular , consider the behav ior of LRU on a request sequence in which\nk + 1 items are repeatedly requested in a round-robin fashion. LRU will\neach time evict the item that will be needed just in the next step, and hence\nit will incur a cache miss on each access. (It's possible to get this kind of\nterrible caching performance in practice for precisely such a reason: the\nprogram is executing a loop that is just slightly too big for the cache.) On\nthe other hand, the optimal policy , evicting the page that will be requested\nfarthest in the future, incurs a miss only every k steps, so LRU incurs a\nfactor of k more misses than the optimal policy .\nDesigning a Randomized Marking Algorithm\nThe bad example for LRU that we just saw implies that, if we want to\nobtain a better bound for an online caching algorithm, we will not be able to\nreason about fully general marking algorithms. Rather , we will define a\nsimple Randomized Marking Algorithm  and show that it never incurs more\nthan O(log k) times the number of misses of the optimal algorithm—an\nexponentially better bound.\nRandomization is a natural choice in trying to avoid the unfortunate\nsequence of “wrong” choices in the bad example for LRU. To get this bad\nsequence, we needed to define a sequence that always evicted precisely the\nwrong item. By randomizing, a policy can make sure that, “on average,” it\nis throw ing out an unmarked item that will at least not be needed right\naway .\nSpecifically , where the general description of a marking contained the\nline"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 900})","('type', 'Document')"
"('page_content', ""Else evict an unmarked item from the cache\nwithout specifying how this unmarked item is to be chosen, our\nRandomized Marking Algorithm uses the following rule:\nElse evict an unmarked item chosen uniformly at random from the cache\nThis is arguably the simplest way to incorporate randomization into the\nmarking framework.1\nAnalyzing the Randomized Marking\nAlgorithm\nNow we'd like to get a bound for the Randomized Marking Algorithm that\nis stronger than (13.38); but in order to do this, we need to extend the\nanalysis in (13.36) and (13.37) to something more subtle. This is because\nthere are sequences σ, with r phases, where the Randomiz ed Marking\nAlgorithm can really be made to incur kr misses—just consider a sequence\nthat never repeats an item. But the point is that, on such sequences, the\noptimum will incur many more than r - 1 misses. We need a way to bring\nthe upper and lower bounds closer together , based on the structure of the\nsequence.\nThis picture of a “runaway sequence” that never repeats an item is an\nextreme instance  of the distinction we'd like to draw: It is usefu l to classify\nthe unmarked items in the middle of a phase into two further categories. We\ncall an unmarked item fresh if it was not marked in the previous phase\neither , and we call it stale  if it was marked in the previous phase.\nRecall the picture of a single phase that led to (13.35): The phase\nbegins with all items unmarked, and it contains accesses to k distinct items,\neach of which goes from unmarked to marked the first time it is accessed.\nAmong these k accesses to unmarked items in phase j, let cj denote the\nnumber of these that are to fresh items.\nTo strengthen the result from (13.37), which essentially said that the\noptimum incurs at least one miss per phase, we provide a bound in terms of\nthe number of fresh items in a phase."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 901})","('type', 'Document')"
"('page_content', ""(13.39)  \nProof. Let fj(σ) denote the number of misses incurred by the optimal algorithm in phase j, so that f(σ)\n= Σrj=1fj(σ). From (13.35), we know that in any phase j, there are requests to k distinct items.\nMoreover , by our definition of fresh, there are requests to Cj+1 further items in phase j + 1; so\nbetween phases; and i + 1, there are at least k + cj+1 distinct items requested. It follows that the\noptimal algorithm must incur at least Cj+1 misse s over the course of phases j and j + 1, so fj(σ) + fj+\n1(σ) > cj+1. This holds even for j = 0, since the optimal algorithm incurs c1 misses in phase 1. Thus\nwe have\nBut the left-hand side is at most \n , and the right-hand side is \n . ▪\nWe now give an upper bound  on the expected number of misses\nincurred by the Randomized Marking Algorithm, also quantified in terms of\nthe number of fresh items in each phase. Combining these upper and lower\nbounds will yield the performan ce guarantee we're seeking. In the following\nstatement, let Mσ denote the random variable equal to the number of cache\nmisses incurred by the Randomized Marking Algorithm on the request\nsequence σ.\n(13.40)  For every r equest sequence σ, we have  \n .\nProof. Reca ll that we used cj to denote the numbe r of requests in phase j to fresh items. There  are k\nrequests to unmarked items in a phase, and each unmarked item is either fresh or stale, so there must\nbe k - Cj requests in phase j to unmarked stale items.\nLet Xj denote the number of misses incurred by the Randomized Marking Algorithm in phase j.\nEach reque st to a fresh item results in a guaranteed miss for the Randomized Mark ing Algorithm;\nsince the fresh item was not marked in the previous phase, it cannot possibly be in the cache when it\nis requested in phase j. Thus the Randomized Marking Algorithm  incurs at least Cj misses in phase j\nbecause of requests to fresh items.\nStale items , by contrast, are a more subtl e matter . The phase starts with k stale items in the\ncache; these are the items that were unmarked en masse  at the beginning of the phase. On a request to\na stale item s, the concern is whether the Randomized Marking Algorithm evicted it earlier in the\nphase and now incurs  a miss as it has to bring it back in. What is the probability that the ith request to\na stale item, say s, results in a miss? Suppose that there have been c ≤ cj reque sts to fresh items thus\nfar in the phase. Then the cache contain s the c formerly fresh items that are now marked, i - 1\nformerly stale items that are now marked, and k - c - i + 1 items that are stale and not yet marked in\nthis phase. But there are k - i + 1 items overall that are still stale; and since exactly k - c - i + 1 of\nthem are in the cache, the remaining c of them are not. Each of the k - i + 1 stale items is equally"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 902})","('type', 'Document')"
"('page_content', 'likely to be no longe r in the cache, and so s is not in the cache at this moment with probability  \n.\nThis is the probability  of a miss on the request to s. Summing over all requests to unmarked items,\nwe have\nThus the total expected number of misses incurred by the Randomized Marking Algorithm is\nCombining (13.39) and (13.40), we immediately get the following\nperformance guarantee.\n(13.41)  The expected number of misses incurr ed by the Randomized Marking Algorithm is at most\n2H(k) · f (σ) = O(log k) · f(σ).\n13.9 Chernoff Bounds\nIn Section 13.3, we defined the expectation of a random variable formally\nand have worked with this definition and its consequences ever since.\nIntuitively , we have a sense that the value of a random variable ought to be\n“near” its expectation with reasonably high probability , but we have not yet\nexplored the extent to which this is true. We now turn to some results that\nallow us to reach conclusions like this, and see a sampling of the\napplications that follow .\nWe say that two random variables X and Y are independent  if, for any\nvalues i and j, the events Pr[X = i] and Pr[Y = j] are independent. This\ndefinition exten ds naturally to larger sets of random variables. Now\nconsider a random variable X that is a sum of several independent 0-1-\nvalued random variables: X = X1 + X2 + … + Xn, where Xi takes the value 1\nwith probability pi, and the value 0 otherwise. By linearity of expectation,')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 903})","('type', 'Document')"
"('page_content', ""we have \n . Intuiti vely, the independenc e of the random\nvariables X1, X2,…, Xn suggests that their fluctuations are likely to “cancel\nout,” and so their sum X will have a value close to its expectation with high\nprobability . This is in fact true, and we state two concrete versions of this\nresult: one boun ding the probability that X deviate s above E[X], the other\nbounding the probability that X deviates below E[X]. We call these results\nChernoff bounds,  after one of the probabilists who first established bounds\nof this form.\n(13.42)  Let X,X1,X2,…, Xn be defined as above, and assume that μ ≥ E[X]. Then, for any δ > 0, we\nhave\nProof. To bound the probability that X exceeds (1 + δ)μ, we go through a sequence of simple\ntransformations. First note that, for any t > 0, we have \n ,\nas the function f(x) = etx is monotone in x. We will use this observation with a t that we'll select later .\nNext we use some simple properties of the expectation. For a random variable Y, we have  \n, by the definition of the expectation. This allows us to bound the probability\nthat Y exceeds γ in terms of E[Y]. Combining these two ideas, we get the following inequalities.\nNext we need to bound the expectatio n E[etX]. Writing X as X = ΣiXi, the expe ctation is \n. For independent variables Y and Z, the expectation of the\nproduct YZ is E[YZ] = E[Y]E[Z]. The variables Xi are independent, so we get \nNow , etXt is et with probability pi and e0 = 1 otherwise, so its expectation can be bounded as\nwhere the last inequ ality follows from the fact that 1 + α ≤ ea for any α ≥ 0. Combining the\ninequalities, we get the following bound."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 904})","('type', 'Document')"
"('page_content', 'To obtained the bound claimed by the statement, we substitute t = ln (1 + δ).\nWhere (13.42) provided an upper bound, showing that X is not likely\nto deviate far above its expectation, the next statement, (13.43) , provides a\nlower bound, showing that X is not likely to deviate far below its\nexpectation. Note that the statem ents of the results are not symmetric, and\nthis makes sense: For the upper bound, it is interesting to consid er values of\nδ much lar ger than 1, while this would not make sense for the lower bound.\n(13.43)  Let X, X 1, X2,…, Xn and μ be as defined above, and assume that μ  < E[X]. Then for any 1 > δ\n> 0, we have\nThe proof of (13.43) is similar to the proof of (13.42), and we do not\ngive it here. For the applications that follow , the statements of (13.42) and\n(13.43), rather than the internals of their proofs, are the key things to keep\nin mind.\n13.10 Load Balancing\nIn Section 13.1, we considered a distributed system in which\ncommunication among processes was difficult, and randomization to some\nextent replaced explicit coordination and synchronization. We now revisit\nthis theme through another stylized example of randomization in a\ndistributed setting.\nThe Problem')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 905})","('type', 'Document')"
"('page_content', ""Suppose we have a system in which m jobs arrive in a stream and need to\nbe processed immediately . We have a collection of n identical processors\nthat are capable of performing the jobs; so the goal is to assign each job to a\nprocessor in a way that balances  the workload evenly across the processors.\nIf we had a central controller for the system that could receive each job and\nhand it off to the processors in round-robin fashion, it would be trivial to\nmake sure that each processor received at most ⌈ m/n ⌉  jobs—th e most even\nbalancing possible.\nBut suppose the system lacks the coordination or centralization to\nimplement this. A much more lightweight approach would be to simply\nassign each job to one of the processors uniformly at random. Intuitively ,\nthis should also balance the jobs evenly , since each processor is equally\nlikely to get each job. At the same time, since the assignment is completely\nrandom, one doesn't expect everything to end up perfectly balanced. So we\nask: How well does this simple randomized approach work?\nAlthough we will stick to the motivation in terms of jobs and\nprocessors here, it is worth noting that comparable issues come up in the\nanalysis of hash functions, as we saw in Section 13.6. There,  instead  of\nassigning jobs to processors, we're assigning elements to entries in a hash\ntable. The concern about producing an even balancing in the case of hash\ntables is based on wanting to keep the number of collisions at any particular\nentry relatively small. As a result, the analysis in this section is also relevant\nto the study of hashing schemes.\nAnalyzing a Random Allocation\nWe will see that the analysis of our random load balancing process depends\non the relative sizes of m, the number of jobs, and n, the number of\nprocessors. We start with a particularly clean case: when m = n. Here it is\npossible for each processor to end up with exactly one job, though this is\nnot very likely . Rather , we expect that some processors will receive no jobs\nand others will receive more than one. As a way of assessing the quality of\nthis randomized load balancing heuristic, we study how heavily loaded with\njobs a processor can become.\nLet Xi be the random variable equal to the number of jobs assigned to\nprocessor i, for i = 1, 2,…, n. It is easy to determine the expected value of\nX: We let Yiy be the random variable equal  to 1 if job j is assig ned to"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 906})","('type', 'Document')"
"('page_content', 'processor i, and 0 otherw ise; then \n  and E[Yij] = 1/n, so \n. But our concern is with how far Xi can deviate\nabove its expectation: What is the probability that Xi > c? To give an upper\nbound on this, we can directly apply (13.42): Xi is a sum of independent 0-\n1-valued random  variables {Yij}; we have μ = 1 and 1 + δ = c. Thus the\nfollowing statement holds.\n(13.44)\nIn order  for there to be a small  probability of any Xi exceeding c, we will\ntake the Union Bound over i = 1, 2,…, n; and so we need to choose c large\nenough to drive Pr [Xi > c] down well below 1/n for each i. This requires\nlooking at the denominator cc in (13.4 4). To make this denominator large\nenough, we need to understand how this quantity grows with c, and we\nexplore this by first asking the question: What is the x such that xx = n?\nSuppose we write γ(n) to denote this number x. There is no closed-\nform expression  for γ(n) but we can determine its asymptotic value as\nfollows. If xx = n, then taking logarithms gives x log x = log n; and taking\nlogarithms again gives log x + log log x = log log n. Thus we have\nand, using this to divide through the equation xlogx = log n, we get')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 907})","('type', 'Document')"
"('page_content', ""Thus \nNow , if we set c = eγ(n), then by (13.44) we have\nThus, applying the Union Bound  over this upper bound for X1, X2,…,Xn, we\nhave the following.\n(13.45)  With probability at least  1 - n-1, no processor receives more than \njobs.\nWith a more involved analysis,  one can also show that this bound is\nasymptotically tight: with high probability , some processor actually receives\n jobs.\nSo, although the load on some processors will likely exceed the\nexpectation, this deviation is only logarithmic in the number of processors.\nIncreasing the Number of Jobs  We now use Chernof f bounds to argue that,\nas more jobs are introduced into the system, the loads “smooth out” rapidly ,\nso that the number of jobs on each processor quickly become the same to\nwithin constant factors.\nSpecifically , if we have m = 16n ln n jobs, then the expected load per\nprocessor is μ = 16lnn. Using (13.42),  we see that the probability of any\nprocessor's load exceeding 32 ln n is at most\nAlso, the probability that any processor's load is below 8 ln n is at most"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 908})","('type', 'Document')"
"('page_content', 'Thus, applying the Union Bound, we have the following.\n(13.46)  When there are n processors and Σ(nlogn) jobs, then with high probability , every processor\nwill have a load between half and twice the average.\n13.11 Packet Routing\nWe now consider a more complex example of how randomization can\nalleviate contention in a distributed system—namely , in the context of\npacket r outing .\nFigur e 13.3  Three packets whose paths involve a shared edge e.\nThe Problem\nPacket r outing  is a mechanism to support comm unication among nodes of a\nlarge network, which we can model as a directed graph G = (V, E). If a node\ns wants to send data to a node t, this data is discretized into one or more\npackets,  each of which is then sent over an s-t path P in the network. At any\npoint in time, there may be many packets in the network, associated with\ndifferent sources and destinations and following different paths. However ,\nthe key constraint is that a single edge e can only transm it a single pack et')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 909})","('type', 'Document')"
"('page_content', ""per time step. Thus, when a packet p arrives at an edge e on its path, it may\nfind there are several other packets already waiting to traverse e; in this\ncase, p joins a queue  associated with e to wait until e is ready to trans mit it.\nIn Figure 13.3, for example, three packets with different sources and\ndestinations all want to traverse edge e; so, if they all arrive at e at the same\ntime, some of them will be forced to wait in a queue for this edge.\nSuppose we are given a network G with a set of packets that need to be\nsent across specified paths. We'd like to understand how many steps are\nnecessary in order for all packe ts to reach their destinations. Although the\npaths for the packets are all specified, we face the algorithmic question of\ntiming the movements of the packets across the edges. In particular , we\nmust decide when to release each packet from its source, as well as a queue\nmanagement policy  for each edge e—that is, how to select the next packet\nfor transmission from e's queue in each time step.\nIt's important to realize that these packet scheduling  decisions can have\na significant effect on the amoun t of time it takes for all the packets to reach\ntheir destination s. For example, let's consider the tree network in Figure\n13.4, where there are nine packets that want to traverse the respective\ndotted paths up the tree. Suppose all packets are released from their sources\nimmediately , and each edge e manages its queue by always transmitting the\npacket that is closest to its destination. In this case, packet 1 will have to\nwait for packets 2 and 3 at the second level of the tree; and then later it will\nhave to wait for packets 6 and 9 at the fourth level of the tree. Thus it will\ntake nine steps for this packet to reach its destination. On the other hand,\nsuppose that each edge e manages its queue by always transmitting the\npacket that is farthest from its destination. Then packet 1 will never have to\nwait, and it will reach its destination in five steps; moreover , one can check\nthat every packet will reach its destination within six steps.\nFigur e 13.4  A case in which the scheduling of packets matters."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 910})","('type', 'Document')"
"('page_content', ""There is a natural generalization of the tree network in Figure 13.4, in\nwhich the tree has height h and the nodes  at every other  level have k\nchildren. In this case, the queue  management policy that always transmits\nthe pack et nearest its destination results in some packet requiring Ω(hk)\nsteps to reach its destination (since the packet traveling farthes t is delayed\nby Ω( k) steps at each of Ω(h) levels), while the policy that always transmits\nthe packet farthest from its destination results in all packets reaching their\ndestinations within O(h + k ) steps. This can become quite a large difference\nas h and k grow lar ge.\nSchedules and Their Durations  Let's now move from these examples to\nthe question of scheduling packets and managing queues in an arbitrary\nnetwork G. Given  packets labeled 1,2,…, N and associate d paths\nP1,P2,…,PN, a packet schedule  specifie s, for each edge e and each time step\nt, which packet will cross edge e in step t. Of course, the schedule must\nsatisfy some basic consistency properties: at most one packet can cross any\nedge e in any one step; and if packet i is scheduled to cross e at step t, then\ne should be on the path Pi, and the earlier portions of the schedule should\ncause i to have alread y reached e. We will say that the duration  of the"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 911})","('type', 'Document')"
"('page_content', ""schedule is the number of steps that elapse until every packet reaches its\ndestination; the goal is to find a schedule of minimum duration.\nWhat are the obstacles to having a schedule of low duration? One\nobstacle would be a very long path that some packet must trave rse; clearly ,\nthe duration will be at least the length of this path. Another obstacle would\nbe a single edge e that many pack ets must cross; since each of these packets\nmust cross e in a distinct step, this also gives a lower bound on the duration.\nSo, if we define  the dilation d of the set of paths {P1, P2,…, PN} to be the\nmaximum length of any Pi, and the congestion c  of the set of paths to be the\nmaximum numb er that have any single edge in common, then the duration\nis at least max( c, d) = Ω( c + d ).\nIn 1988, Leighton, Maggs, and Rao proved the following striking\nresult: Congesti on and dilation are the only obstacles to finding fast\nschedules, in the sense that there is always a schedule of duratio n O(c + d).\nWhile the statem ent of this result is very simple, it turns out to be extremely\ndifficult to prove; and it yields only a very complicated method to actually\nconstruct  such a schedule. So, instead of trying to prove this result, we'll\nanalyze a simple algorithm (also proposed by Leighton, Maggs, and Rao)\nthat can be easily implemented in a distributed setting and yields a duration\nthat is only worse by a logarithmic factor: O(c + d  log(mN)), where m is the\nnumber of edges and N is the number of packets.\nDesigning the Algorithm\nA Simple Randomized Schedule  If each edge simply transmits an arbitrary\nwaiting packet in each step, it is easy to see that the resulting schedule has\nduration O(cd): at worst, a packet can be blocked by c - 1 other packets on\neach of the d edges in its path. To reduce this bound, we need to set things\nup so that each packet only waits for a much smaller number of steps over\nthe whole trip to its destination.\nThe reason a bound as large as O(cd) can arise is that the packets are\nvery badly timed with respect to one another: Blocks of c of them all meet\nat an edge at the same time, and once this congestion has cleare d, the same\nthing happens at the next edge. This sounds pathological, but one should\nremember that a very natural queue management policy caused it to happen\nin Figure 13.4 . However , it is the case that such bad behavior relies on very\nunfortunate synchronization in the motion of the packets; so it is believable"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 912})","('type', 'Document')"
"('page_content', 'that, if we introduce some randomization in the timing of the packets, then\nthis kind of behavior is unlikely to happen. The simplest idea would be just\nto randomly shift the times at which the packets are released from their\nsources. Then if there are many packets all aimed at the same edge, they are\nunlikely to hit it all at the same time, as the contention for edges has been\n“smoothed out.” We now show that this kind of randomization, properly\nimplemented, in fact works quite well.\nConsider first the following algorithm, which will not quite work. It\ninvolves a parameter r whose value will be determined later .\nEach packet i behaves as follows:\ni chooses a random delay s between 1 and r\ni waits at its source for s time steps\ni then moves full speed ahead, one edge per time step until it reaches its destination\nIf the set of random delays were really chosen so that no two packets\never “collided”—reaching the same edge at the same time—then this\nschedule would work just as advertised; its duration would be at most r (the\nmaximum initial delay) plus d (the maximum number of edges on any\npath). However , unless r is chosen to be very large, it is likely that a\ncollision will occur somewhere inthe network, and sothe algorithm will\nprobably fail: T wo packets will show up at the same edge e in the same time\nstep t, and both will be required to cross e in the next step.\nGrouping Time into Blocks  To get around this problem, we consider the\nfollowing genera lization of this strategy: rather than implementing the “full\nspeed ahead” plan at the level of individual time steps, we implement it at\nthe level of contiguous blocks  of time steps.\nFor a parameter b, group intervals of b consecutive time steps into single blocks  of time\nEach packet i behaves as follows:\ni chooses a random delay s between 1 and r\ni waits at its source for s blocks\ni then moves forward one edge per block, until it reaches its destination\nThis schedule will work provid ed that we avoid a more extreme type\nof collision: It should not be the case that more than b packets are supposed\nto show up at the same edge e at the start of the same block. If this happens,')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 913})","('type', 'Document')"
"('page_content', ""then at least one of them will not be able to cross e in the next block.\nHowever , if the initial delays smooth things out enough so that no more\nthan b packets arrive at any edge in the same block, then the schedule will\nwork just as intended. In this case, the duration will be at most b(r + d)—\nthe maximum number of blocks, r + d, times the length of each block, b.\n(13.47)  Let ∊ denote the event that more than b packets are requir ed to be at the same edge e at the\nstart of the same block. If  ∊ does not occur , then the duration of the schedule is at most b (r + d ).\nOur goal is now to choose values of r and b so that both the probability Pr\n[ ∊] and the duration b(r + d) are small quantities. This is the crux of the\nanalysis since, if we can show this, then (13.47) gives a bound on the\nduration.\nAnalyzing the Algorithm\nTo give a bound on Pr [ ∊], it's useful to decompose it into a union of\nsimpler bad events, so that we can apply the Union Bound. A natural set of\nbad events arises from considering each edge and each time block\nseparately; if e is an edge, and t is a block betw een 1 and r + d, we let \net\ndenote the event  that more than b packets are required to be at e at the start\nof block t. Clearly , ∊ = ∪e, t\n et. Moreover , if Net is a random variable equal\nto the number of packets schedu led to be at e at the start of block t, then \net\nis equivalent to the event [ Net > b].\nThe next step in the analysis is to decompose the random variable Net\ninto a sum of independent 0-1-valued random variables so that we can\napply a Chernof f bound. This is naturally done by defining Xeti to be equal\nto 1 if packet i is required to be at edge e at the start of block t, and equal to\n0 otherw ise. Then \n ; and for different values of i, the random\nvariables Xeti are independent, since the packets are choosing independent\ndelays. (Note that Xeti and Xe′t′i, where the value of i is the same, would\ncertainly not be independent; but our analysis does not requir e us to add\nrandom variables of this form together .) Notice that, of the r possible delays\nthat packet i can choose, at most one will require it to be at e at block  t; thus\nE[Xeti] ≤ 1/r. Moreover , at most c packets have paths that include e; and if i\nis not one of these packets, then clearly E[Xeti] = 0. Thus we have"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 914})","('type', 'Document')"
"('page_content', ""We now have the setup for applying the Chernof f bound (13.42) , since\nNet is a sum of the independent 0-1-valued random variables Xeti. Indeed,\nthe quan tities are sort of like what they were when we analyzed the problem\nof throwing m jobs at rando m onto n process ors: in that case, each\nconstituent random variable had expectation 1/n, the total expectation was\nm/n, and we needed m to be Ω(n log n) in order for each processor load to\nbe close to its expectation with high probability . The appropriate analogy in\nthe case at hand  is for r to play the role of n, and c to play the role of m:\nThis makes sense symbolically , in terms of the parameters; it also accords\nwith the picture that the packets are like the jobs, and the different time\nblocks of a single edge are like the different processors that can receive the\njobs. This suggests that if we want the number of packets destined for a\nparticular edge in a particular block to be close to its expectation, we should\nhave c = Ω( r log r).\nThis will work, except that we have to increase the logarithmic term a\nlittle to make sure that the Union  Bound over all e and all t works out in the\nend. So let's set\nwhere q is a constant that will be determined later .\nLet's fix a choice of e and t and try to bound the probability that Net\nexceeds a constant times \n . We define μ = \n, and observe that E[Net] ≤ μ, so\nwe are in a position to apply the Chernof f bound (13.42). We choose  \n, and we use this as the upper bound\nin the expression \n . Now , applying (13.42), we\nhave"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 915})","('type', 'Document')"
"('page_content', ""where z is a constant that can be made as large as we want by choosing the\nconstant q appropriately .\nWe can see from  this calculation that it's safe to set b = 3c/r; for, in this\ncase, the event \net that Net > b will have very small probability for each\nchoice of e and t. There are m different choices for e, and d + r different\nchoice for t, where we observe that d + r  ≤ d + c  - 1 ≤ N. Thus we have\nwhich can be made as small as we want by choosing z large enough.\nOur choice of the parameters b and r, combined with (13.44), now\nimplies the following.\n(13.48)  With high pr obability , the duration of the schedule for the packets is  O(c + d log (mN)).\nProof. We have just argued that the probability of the bad event ∊ is very small, at most (mN)-(z-1)\nfor an arbitrarily large constant z. And provided that ∊ does not happen, (13.47) tells us that the\nduration of the schedule is bounded by\n▪\n13.12 Background: Some Basic Probability\nDefinitions"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 916})","('type', 'Document')"
"('page_content', ""For many, thoug h certainly not all, applications of randomized algorithms,\nit is enough to work with probabilities defined over finite sets only; and this\nturns out to be much easier to think about than probabilities over arbitrary\nsets. So we begin by considering just this special case. We'll then end the\nsection by revisiting all these notions in greater generality .\nFinite Probability Spaces\nWe have an intuitive understan ding of sentences like, “If a fair coin is\nflipped, the probability of 'heads' is ½.” Or, “If a fair die is rolled, the\nprobability of a '6' is ⅙ .” What we want to do first is to describe a\nmathematical framework in which we can discuss such statements\nprecisely . The framework will work well for carefully circumscribed\nsystems such as coin flips and rolls of dice; at the same time, we will avoid\nthe lengthy and substantial philosophical issues raised in trying to model\nstatements like, “The probab ility of rain tomorrow is 20 percent.”\nFortunately , most algorithmic settings are as carefully circumscribed as\nthose of coins and dice, if perhaps somewhat lar ger and more complex.\nTo be able to compute probabili ties, we introduce the notion of a finite\nprobability space.  (Recall that we're dealing with just the case of finite sets\nfor now.) A finite probability space is defined by an underlying sample\nspace  Ω, which consists of the possible outcomes  of the process under\nconsideration. Each point i in the sample space also has a nonnegative\nprobability mass  p(i) ≥ 0; these probability masses  need only satisfy the\nconstraint that their total sum is 1; that is, \n . We define an event\n∊ to be any subse t of Ω—an event is defined simply by the set of outcomes\nthat constitute it—and we define the probability  of the event to be the sum\nof the probability masses of all the points in ∊. That is,\nIn many  situatio ns that we'll consider , all points in the sample  space have\nthe same probability mass, and then the probability of an event ∊ is simply\nits size relative to the size of Ω; that is, in this special case, Pr[ ∊] = | ∊|/|Ω|."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 917})","('type', 'Document')"
"('page_content', ""We use \n  to denote the complementary event Ω- ∊; note that \n.\nThus the points in the sample space and their respective probability\nmasses form a complete description of the system under consid eration; it is\nthe even ts—the subsets of the sample space—whose probabil ities we are\ninterested in computing. So to represent a single flip of a “fair” coin, we can\ndefine the samp le space to be Ω = {heads, tails} and set p(heads) = p(tails)\n= ½. If we want to consider a biased coin in which “heads”  is twice as\nlikely as “tails,” we can define the probability masses to be p(heads) = 2/3\nand p(tails) = 1/3. A key thing to notice even in this simple example is that\ndefining the probability masses is a part of defining the underlying problem;\nin setting up the problem, we are specifying whether the coin is fair or\nbiased, not deriving this from some more basic data.\nHere's a slightly more complex example, which we could call the\nProcess Naming , or Identifier Selection Problem.  Suppose we have n\nprocesses in a distributed system, denoted p1,p2,…,pn, and each of them\nchooses an identifier for itself uniformly at random from the space of all k-\nbit strings. Moreover , each process's choice happens concurrently with\nthose of all the other processes , and so the outcomes of these choices are\nunaffected by one another . If we view each identifier as being chosen from\nthe set {0,1, 2,…, 2k - 1} (by considering the numerical value of the\nidentifier as a number in binary notation), then the sample space  Ω could be\nrepresented by the set of all n-tuples of integers, with each integer between\n0 and 2k - 1. The sample space would thus have (2k)n = 2kn points, each with\nprobability mass 2-kn.\nNow suppose we are interested in the probability that processes p1 and\np2 each choose the same name. This is an event ∊, represented by the subset\nconsisting of all n-tuples from Ω whose first two coordinates are the same.\nThere are 2k(n-1) such n-tuples: we can choose any value for coordinates 3\nthrough n, then any value  for coordinate 2, and then we have no freedom of\nchoice in coordinate 1. Thus we have"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 918})","('type', 'Document')"
"('page_content', 'This, of course, corresponds to the intuitive way one might work out the\nprobability , which is to say that we can choose any identifier we want for\nprocess p2, after which there is only 1 choice out of 2k for process p1 that\nwill cause the names to agree. It\'s worth checking that this intuition is really\njust a compact description of the calculation above.\nConditional Probability and Independence\nIf we view the probability of an event ∊, roughly, as the likelihood that ∊ is\ngoing to occur , then we may also want to ask about its probability given\nadditional information. Thus, given another event \n  of posit ive probability ,\nwe define the conditional pr obability of  ∊ given  \n as\nThis is the “righ t” definition intuitively , since it\'s performing the following\ncalculation: Of the portion of the sample space that consists of 3"" (the event\nwe “know” to have occurred), what fraction is occupied by ∊?\nOne often uses conditional probabilities to analyze Pr [ ∊] for some\ncomplicated event ∊, as follo ws. Suppose that the events \n1, \n2,…, \nk each\nhave positive probability , and they partition the sample space; in other\nwords, each outcome in the sample space belongs to exactly one of them, so\n. Now suppose we know these values Pr[\nj], and we are also\nable to determine Pr [ ∊ | \nj] for each j = 1,2,… , k. That is, we know what\nthe probability of ∊ is if we assume that any one of the events \nj has\noccurred. Then we can compute Pr [ ∊] by the following simple formula:\nTo justify this formula, we can unwind the right-hand side as follows:')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 919})","('type', 'Document')"
"('page_content', ""Independent Events  Intuitively , we say that two events are independent  if\ninformation about the outcome of one does not affect our estimate of the\nlikelihood of the other . One way to make this concrete would be to declare\nevents ∊ and \n  independent if Pr [ ∊ | \n] = Pr [ ∊], and Pr [\n | ∊] = Pr [\n].\n(We'll assume here that both have positive probability; otherwis e the notion\nof indep endence is not very interesting in any case.) Actually , if one of\nthese two equalities holds, then the other must hold, for the following\nreason: If Pr [ ∊ | \n] = Pr [ ∊], then\nand hence \n , from which the other equality holds as\nwell.\nIt turns out to be a little cleaner to adopt this equivalent formula tion as\nour working definition of independence. Formally , we'll say that events ∊\nand \n  are independent  if \n .\nThis product formulation leads to the following natural generalization.\nWe say that a collection of events ∊1, ∊2, …, ∊n is independent  if, for every\nset of indices I ⊆ {1, 2,…, n], we have\nIt's impo rtant to notice the follo wing: To check if a large set of events\nis independent, it's not enough  to check whether every pair of them is\nindependent. For example, suppose we flip three independent fair coins: If\n∊i denotes the event that the ith coin comes up heads, then the events ∊1,\n∊2, ∊3 are independent and each has probability ½. Now let A denote the"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 920})","('type', 'Document')"
"('page_content', ""event that coins 1 and 2 have the same value; let B denote the event that\ncoins 2 and 3 have the same value; and let C denote the event that coins 1\nand 3 have different values. It's easy to check that each of these  events has\nprobability ½, and the intersectio n of any two has probability ¼. Thus every\npair draw n from  A, B, C is independent. But the set of all three events A, B,\nC is not independent, since Pr [ A ∩ B ∩ C] = 0.\nThe Union Bound\nSuppose we are given a set of events ∊1, ∊2,…, ∊n, and we are interested in\nthe probability that any of them  happen s; that is, we are interested in the\nprobability \n . If the events are all pairwise disjoint from one\nanother , then the probability mass of their union is comprised simply of the\nseparate contributions from each event. In other words, we have the\nfollowing fact.\n(13.49)  Suppose we have events  ∊1, ∊2,…, ∊n such that  \n  for each pair . Then\nIn general, a set of events ∊1, ∊2,…, ∊n may overlap in complex ways. In\nthis case, the equality in (13.49)  no longer holds; due to the overlaps among\nevents, the probability mass of a point that is counted once on the left-hand\nside will be counted one or more times on the right-hand side. (See Figure\n13.5.) This means that for a general set of events, the equality in (13.49) is\nrelaxed to an inequality; and this is the content of the Union Bound. We\nhave stated the Union Bound as (13.2), but we state it here again for\ncomparison with (13.49).\nFigur e 13.5 The Union Bound: The probability of a union is maximized\nwhen the events have no overlap."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 921})","('type', 'Document')"
"('page_content', ""(13.50)  (The Union Bound) Given events  ∊1, ∊2,…, ∊n, we have\nGiven its innocuous appearance, the Union Bound is a surpr isingly\npowerful tool in the analysis of randomized algorithms. It draws its power\nmainly from the following ubiquitous style of analyzing randomized\nalgorithms. Given a randomized algorithm designed to produce a correct\nresult with high probability , we first tabulate a set of “bad events” ∊1,\n∊2,…, ∊n with the following property: if none of these bad events occurs,\nthen the algorithm will indeed produce the correct answer . In other words, if\nF denotes the event that the algorithm fails, then we have\nBut it's hard to compute the probability of this union, so we apply the Union\nBound to conclude that"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 922})","('type', 'Document')"
"('page_content', ""Now , if in fact we have an algorithm that succeeds with very high\nprobability , and if we've chosen  our bad events carefully , then each of the\nprobabilities Pr [ ∊i] will be so small that even their sum—and hence our\noverestimate of the failure probability—will be small. This is the key:\ndecomposing a highly complicat ed event, the failure of the algorithm, into a\nhorde of simple events whose probabilities can be easily computed.\nHere is a simple  example to make the strategy discussed above more\nconcrete. Recall the Process Naming Problem we discussed earlier in this\nsection, in which each of a set of processes chooses a random identifier .\nSuppose that we have 1,000 processes, each choosing a 32-bit identifier ,\nand we are concerned that two of them will end up choosing the same\nidentifier . Can we argue that it is unlikely this will happen? To begin with,\nlet's denote this event by \n . While it would not be overwhelmingly difficult\nto comp ute Pr [\n] exactly , it is much simpler to bound it as follows. The\nevent \n  is really a union of \n  “atomic” events; these are the events ∊ij\nthat processes pi and Pj choose the same identifier . It is easy to verify that\nindeed, \n . Now , for any i ≠ j, we have Pr [ ∊ij] = 2-32, by the\nargument in one of our earlier examples. Applying the Union  Bound, we\nhave\nNow , \n  is at most half a million, and 232 is (a little bit) more than 4\nbillion, so this probability is at most \n .\nInfinite Sample Spaces\nSo far we've gotten by with finite probability spaces only. Several of the\nsections in this chapter , howev er, consider situations in which a random\nprocess can run for arbitrarily long, and so cannot be well described by a\nsample space of finite size. As a result, we pause here to develo p the notion\nof a probability space more gene rally. This will be somewhat technical, and"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 923})","('type', 'Document')"
"('page_content', ""in part we are providing it simply for the sake of completeness: Although\nsome of our applications require  infinite sample spaces, none of them really\nexercises the full power of the formalism we describe here.\nOnce we move to infinite sample spaces, more care is needed in\ndefining a probability function. We cannot simply give each point in the\nsample space Ω a probability mass and then compute the probability of\nevery set by summing. Indeed, for reasons that we will not go into here, it is\neasy to get into trouble if one even allows every subset of Ω to be an event\nwhose probabili ty can be computed. Thus a general probability space has\nthree components:\n(i) The sample space Ω.\n(ii) A collec tion § of subsets of Ω; these are the only events on which we\nare allowed to compute probabilities.\n(iii) A proba bility function Pr, which maps events in § to real numbers in\n[0,1].\nThe collection δ of allowable events can be any family of sets that satisfies\nthe follo wing basic closure properties: the empty set and the full sample\nspace Ω both belong to δ; if ∊ ∊ δ, then \n  ∊ δ (closure under complement);\nand if ∊1, ∊2,…, ∊  δ, then \n  (closure  under countable union). The\nprobability function Pr can be any function from δ to [0,1] that satisfies the\nfollowing basic consistency properties:  \n and the Union  Bound for disjoint\nevents (13.49) should hold even for countable unions—if S1 ∊1, ∊2,…, ∊  δ\nare all pairwise disjoint, then\nNotice how, since we are not building up Pr from the more basic  notion of a\nprobability mass anymore, (13.4 9) moves from being a theorem  to simply a\nrequired property of Pr .\nWhen an infinite sample space arises in our context, it's typically for\nthe following reason: we have an algorithm that makes a sequence of\nrandom decisions, each one from a fixed finite set of possibilities; and since"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 924})","('type', 'Document')"
"('page_content', 'it may run for arbitrarily long, it may make an arbitrarily large number of\ndecisions. Thus we consider sample spaces Ω constructed as follows. We\nstart with a finite set of symbols X = {1, 2,…, n], and assign a weight  w(i) to\neach symbol i ∊ X. We then define Ω to be the set of all infinite sequences\nof symb ols from  X (with repetitions allowed). So a typical element of Ω\nwill look like \x00 x1,x2,x3,…\x00 with each entry xi ∊X.\nThe simplest type of event we will be concerned with is as follows: it\nis the event that a point ω ∊ Ω begins with a particular finite sequence of\nsymbols. Thus, for a finite sequence σ = x1x2 …xs of lengt h s, we define the\nprefix event associated with σ to be the set of all sample points of Ω whose\nfirst s entries form the sequence σ. We denote this event by ∊σ, and we\ndefine its probability to be Pr [ ∊σ] = w(x1)w(x2) … w(xs).\nThe following fact is in no sense easy to prove.\n(13.51)  There is a probability space (Ω, δ, Pr), satisfying the requir ed closur e and consistency\nproperties, such that  Ω is the sample space defined above , ∊σ ∊ δ for each finite sequen ce σ, and Pr\n[ ∊σ] = w(x1)w(x2) … w(xs).\nOnce we have this fact, the closure of δ under complement and\ncountable union , and the consistency of Pr with respect to these operations,\nallow us to compute probabilities of essentially any “reasonabl e” subset of\nΩ.\nIn our infinite sample space Ω, with events and probabilities defined as\nabove, we encounter a phenome non that does not naturally arise with finite\nsample spaces. Suppose the set X used to generat e Ω is equal to {0,1}, and\nw(0) = w(1) = ½. Let ∊ denote the set consisting of all sequences that\ncontain at least one entry equal to 1. (Note that ∊ omits the “all-0”\nsequence.) We observe that ∊ is an event in δ, since we can define σi to be\nthe sequence of i - 1 0s followed by a 1, and observe that \n .\nMoreover , all the events ∊σi are pairwise disjoint, and so')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 925})","('type', 'Document')"
"('page_content', ""Here, then, is the phenomenon: It's possible for an event to have  probability\n1 even when it's not equal to the whole sample space Ω. Simila rly, Pr [\n] =\n1 - Pr [ ∊ ] = 0, and so we see that it's possible for an event to have\nprobability 0 even when it's not the empty set. There is nothing  wrong with\nany of these results; in a sense, it's a necessary step if we want probabilities\ndefined over infinite sets to make sense. It's simply that in such cases, we\nshould be careful to distinguish between the notion that an event has\nprobability 0 and the intuitive idea that the event “can't happen.”\nSolved Exercises\nSolved Exercise 1\nSuppose we have a collection  of small, low-powered devices scattered\naround a building. The devices can exchange data over short distances by\nwireless communication, and we suppose for simplicity that each device has\nenough range to communicate with d other devices. Thus we can model the\nwireless connect ions among these devices as an undirected graph G = (V, E)\nin which each node is incident to exactly d edges.\nNow we'd like to give some of the nodes a stronger uplink transmitter\nthat they can use to send data back to a base station. Giving such a\ntransmitter to every node would  ensure that they can all send data like this,\nbut we can achieve this while handing out fewer transmitters. Suppose that\nwe find a subset S of the nodes with the property that every node in V - S is\nadjacent to a node in S. We call such a set S a dominating set, since it\n“dominates” all other nodes in the graph. If we give uplink transmitters only\nto the nodes in a dominating set S, we can still extract data from all nodes:\nAny node u ∉S can choose a neighbor v ∊ S, send its data to v, and have v\nrelay the data back to the base station.\nThe issue is now to find a dominating set S of minimum possible size,\nsince this will minimize the number of uplink transmitters we need. This is\nan NP-hard problem; in fact, proving this is the crux of Exercise 29 in\nChapter 8. (It's also worth noting here the difference between dominating\nsets and vertex covers: in a dominating set, it is fine to have an edge (u, v)\nwith neither u nor v in the set S as long as both u and v have neighbors in S."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 926})","('type', 'Document')"
"('page_content', ""So, for example , a graph consis ting of three nodes all connect ed by edges\nhas a dominating set of size 1, but no vertex cover of size 1.)\nDespite the NP-hardness, it's important in applications like this to find\nas small a dominating set as one can, even if it is not optimal. We will see\nhere that a simple randomized strategy can be quite effective. Recall that in\nour graph G, each node is incident to exactly d edges. So clearly any\ndominating set will need to have  size at least \n , since each node we place\nin a dominating set can take care only of itself and its d neighbors. We want\nto show that a random selection  of nodes will, in fact, get us quite close to\nthis simple lower bound.\nSpecifically , show that or some constant c, a set of \n  nodes chosen\nuniformly at random from G will be a dominating set with high probability .\n(In other words, this completely random set is likely to form a dominating\nset that is only O(log n) times lar ger than our simple lower bound of \n .)\nSolution  Let \n , where we will choose the constant c later, once we\nhave a better idea of what's going on. Let ∊ be the event that a random\nchoice of k nodes is a dominating set for G. To make the analysis simpler ,\nwe will consider a model in which the nodes are selected one at a time, and\nthe same node may be selected twice (if it happens to be picked twice by\nour sequence of random choices).\nNow we want to show that if c (and hence k) is large enough , then Pr\n[E] is close to 1. But ∊  is a very complicated-looking event, so we begin by\nbreaking it down into much simpler events whose probabili ties we can\nanalyze more easily .\nTo start with, we say that a node w dominates  a node v if w is a\nneighbor of v, or w = v. We say that a set S dominates a node v if some\nelement of S dominates v. (These definitions let us say that a dominating set\nis simply a set of nodes that dominates every node in the graph.) Let \n [v, t]\ndenote the event that the tth random node we choose domin ates node v. The\nprobability of this event can be determined quite easily: of the n nodes in\nthe graph, we must choose v or one of its d neighbors, and so"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 927})","('type', 'Document')"
"('page_content', ""Let \nv denote the even t that the random set consisting of all k selected\nnodes dominates v. Thus\nFor independent events, we've seen in the text that it's easier to work\nwith intersections—where we can simply multiply out the probabilities—\nthan with unions. So rather than thinking about \nv, we'll consider the\ncomplementary “failure event” \nv, that no node  in the random  set\ndominates v. In order for no node to dominate v, each of our choices has to\nfail to do so, and hence we have\nSince the events  \n  are independent, we can compute the probability on\nthe right-hand side by multiplying all the individual probabilities; thus\nNow , \n , so we can write this last expression as"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 928})","('type', 'Document')"
"('page_content', ""where the inequality follows from (13.1) that we stated earlier in the\nchapter .\nWe have not yet specified the base of the logarithm we use to define k,\nbut it's starting to look like base e is a good choice. Using this, we can\nfurther simplify the last expression to\nWe are now very close to done. We have shown that for each node v,\nthe probability that our random set fails to dominate it is at most n-c, which\nwe can drive down to a very small quantity by making c moderately large.\nNow recall the original event ∊, that our random set is a dominating set.\nThis fails to occur if and only if one of the events \nv fails to occur , so \n. Thus, by the Union Bound (13.2), we have\nSimply choosing c = 2 makes this probability \n , which is much less than 1.\nThus, with high probability , the event E holds and our random choice of\nnodes is indeed a dominating set.\nIt's interesting to note that the probability of success, as a function of k,\nexhibits behavio r very similar to what we saw in the contention-resolution\nexample in Section 13.1 . Setting \n  is enoug h to guarantee that each\nindividual node is dominated with constant probability . This, however , is\nnot enough to get anything useful out of the Union Bound. Then, raising k\nby another logarithmic factor is enough to drive up the probability of\ndominating each node to some thing very close to 1, at which point the\nUnion Bound can come into play .\nSolved Exercise 2"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 929})","('type', 'Document')"
"('page_content', ""Suppose we are given a set of n variables x1, x2,…, xn, each of which can\ntake one of the values in the set {0,1}. We are also given a set of k\nequations; the rth equation has the form\nfor some choice of two distinct variables xi, xj, and for some value br that is\neither 0 or 1. Thus each equation specifies whether the sum of two variables\nis even or odd.\nConsider the problem of finding an assignment of values to variables\nthat maximizes the number of equations that are satisfied (i.e., in which\nequality actually holds). This problem is NP-hard, though you don't have to\nprove this.\nFor example, suppose we are given the equations\nover the four variables x1,…, x4. Then it's possible to show that no\nassignment of values to variable s will satisfy all equations simultaneously ,\nbut setting all variables equal to 0 satisfies three of the four equations.\n(a) Let c* denote the maximum possible number of equations that can be\nsatisfied by an assignment of values to variables. Give a polynomial-time\nalgorithm that produces an assignment satisfying at least ½c* equations.\nIf you want, your algorithm can be randomized; in this case, the expected\nnumber of equations it satisfies should be at least ½c*. In either case, you\nshould prove that your algorithm has the desired performance guarantee.\n(b) Suppose we drop the condition  that each equation must have  exactly\ntwo variables; in other words, now each equation simply specifies that"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 930})","('type', 'Document')"
"('page_content', ""the sum of an arbitrary subset of the variables, mod 2, is equal to a\nparticular value br.\nAgain let c* denote the maximum possible number of equations that\ncan be satisfied by an assignment of values to variables, and give a\npolynomial-time algorithm that produces an assignment satisfying at least\n½c* equatio ns. (As before, your algorithm can be randomized.) If you\nbelieve that your algorithm from part (a) achieves this guaran tee here as\nwell, you can state this and justify it with a proof of the performance\nguarantee for this more general case.\nSolution  Let's recall the punch line of the simple randomized algorithm for\nMAX 3-SAT that we saw earlie r in the chapter: If you're given a constraint\nsatisfaction problem, assigning variables at random can be a surprisingly\neffective way to satisfy a constant fraction of all constraints.\nWe now try applying this principle to the problem here, beginning with\npart (a). Consider the algorithm  that sets each variable indepe ndently and\nuniformly at random. How well does this random assignment do, in\nexpectation? As usual, we will approach this question using linearity of\nexpectation: If X is a random variable denoting  the number of satisfied\nequations, we'll break X up into a sum of simpler random variables.\nFor some r between 1 and k, let the rth equation be\nLet Xr be a random variable equal to 1 if this equation is satisfied, and\n0 otherwise. E [Xr] is the probability that equation r is satisf ied. Of the four\npossible assignments to equation i, there are two that cause it to evaluate to\n0 mod 2 (xi = xj = 0 and xi = xj = 1) and two that cause it to evaluate to 1\nmod 2 ( xi = 0; xj = 1 and xi = i; xj = 0). Thus E [Xr] = 2/4 = ½.\nNow , by linearit y of expectation, we have E[X] = Σr E[Xr] = k/2. Since\nthe maximum number of satisfiable equations c* must be at most k, we\nsatisfy at least c*/2 in expectation. Thus, as in the case of MAX 3-SA T, a\nsimple random assignment to the variables satisfies a constant fraction of all\nconstraints."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 931})","('type', 'Document')"
"('page_content', ""For part (b), let's press our luck by trying the same algorithm. Again let\nXr be a random variable equal to 1 if the rth equation is satisfied, and 0\notherwise; let X be the total number of satisfied  equations; and let c* be the\noptimum.\nWe want to claim  that E [Xr] = ½ as before, even when there can be an\narbitrary numbe r of variables in the rth equatio n; in other words, the\nprobability that the equation takes the correct value mod 2 is exactly ½. We\ncan't just write down all the cases the way we did for two variables per\nequation, so we will use an alternate ar gument.\nIn fact, there are two natural ways to prove that E [Xr] = ½. The first\nuses a trick that appeared in the proof of (13.25) in Section 13.6  on hashing:\nWe consider assigning values arbitrarily to all variables but the last one in\nthe equation, and then we randomly assign a value to the last variable x.\nNow , regardless of how we assign values to all other variables, there are\ntwo ways to assign a value to x, and it is easy to check that one of these\nways will satisfy the equation and the other will not. Thus, regardless of the\nassignments to all variables other than x, the probability of setting x so as to\nsatisfy the equation is exactly ½. Thus the probability the equation is\nsatisfied by a random assignment is ½.\n(As in the proof of (13.25), we can write this argument in terms of\nconditional probabilities. If ∊ is the event that the equation is satisfied, and \nb, is the event that the variables other than x receive a seque nce of values\nb, then we have argued that Pr [ ∊ | \nb] = ½ for all b, and so \n.)\nAn alternate proof simply counts the number of ways for the rth\nequation to have an even sum, and the number of ways for it to have an odd\nsum. If we can show that these two numbers are equal, then the probability\nthat a random assignment satisfi es the rth equation is the probability it gives\nit a sum with the right even/odd parity , which is ½.\nIn fact, at a high level, this proof is essentially the same as the previous\none, with the difference that we make the underlying counting problem\nexplicit. Suppose that the rth equation has t terms; then there are 2t possible\nassignments to the variables in this equation. We want to claim that 2t-1\nassignments produce an even sum, and 2t-1 produce an odd sum, which will\nshow that E[Xr] = ½. We prove  this by inducti on on t. For t = 1, there are"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 932})","('type', 'Document')"
"('page_content', ""just two assignments, one of each parity; and for t = 2, we already  proved\nthis earlier by considering all 22 = 4 possible assignments. Now suppose the\nclaim holds for an arbitrary value of t - 1. Then there are exactly 2t-1 ways\nto get an even sum with t variables, as follows:\n2t-2 ways to get an even sum on the first t - 1 variables (by induction),\nfollowed by an assignment of 0 to the tth, plus\n2t-2 ways to get an odd sum on the first t - 1 variables (by induction),\nfollowed by an assignment of 1 to the tth.\nThe remaining 2t-1 assignments give an odd sum, and this completes the\ninduction step.\nOnce we have E[Xr] = ½, we conclude as in part (a): Linearity of\nexpectation gives us E [X] = Σr E [Xr] = k/2 > c*/2.\nExercises\n1. 3-Coloring  is a yes/no question, but we can phrase it as an\noptimization problem as follows.  \nSuppose we are given a graph G = (V, E), and we want to color each\nnode with one of three colors, even if we aren't necessarily able to give\ndifferent colors to every pair of adjacent nodes. Rather , we say that an\nedge ( u, v) is satisfied  if the colors assigned to u and v are dif ferent.  \nConsider a 3-coloring that maximizes the number of satisfied edges,\nand let c* denote this number . Give a polynomial-time algorithm that\nproduces a 3-coloring that satisfies at least ⅔c* edges. If you want,\nyour algorithm can be randomized; in this case, the expected  number\nof edges it satisfies should be at least ⅔ c*.\n2. Consider a county in which 100,000 people vote in an election. There\nare only two candidates on the ballot: a Democratic candidate (denoted\nD) and a Republican candidate (denoted R). As it happens, this county\nis heavily Democratic, so 80,000 people go to the polls with the\nintention of voting for D, and 20,000 go to the polls with the intention\nof voting for R."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 933})","('type', 'Document')"
"('page_content', ""However , the layout of the ballot is a little confusing, so each voter ,\nindependently and with probability 1/100, votes for the wrong\ncandidate— that is, the one that he or she didn't  intend to vote for.\n(Remember that in this election , there are only two candidates  on the\nballot.)  \nLet X denote the random variable equal to the number of votes\nreceived by the Democratic cand idate D, when the votin g is conducted\nwith this process of error . Determine the expected value of X, and give\nan explanation of your derivation of this value.\n3. In Section 13.1, we saw a simple distributed  protocol to solve a\nparticular contention-resolution problem. Here is another setting in\nwhich randomization can help with contention resolution, through the\ndistributed construction of an independent set.  \nSuppose we have a system with n processes. Certain pairs of processes\nare in conflict , meaning that they both require access to a shared\nresource. In a given time interval, the goal is to schedule a large subset\nS of the processes to run—the rest will remain idle—so that no two\nconflicting processes are both in the scheduled set S. We'll call such a\nset S conflict-fr ee. \nOne can picture this process in terms of a graph G = (V, E) with a node\nrepresenting each process and an edge joining pairs of processes that\nare in conflict. It is easy to check that a set of processes S is conflict-\nfree if and only if it forms an independent set in G. This suggests that\nfinding a maximum-size conflic t-free set S, for an arbitrary  conflict G,\nwill be difficult (since the general Independent Set Prob lem is\nreducible to this problem). Nevertheless, we can still look for\nheuristics that find a reasonably large conflict-free set. Moreover , we'd\nlike a simple method for achie ving this without centralized control:\nEach process should communic ate with only a small number of other\nprocesses and then decide whether or not it should belong to the set S. \nWe will suppose for purposes of this question that each node has\nexactly d neighbors in the graph G. (That is, each process is in conflict\nwith exactly d other processes.)  \n(a) Consider the following simple protocol.  \nEach process Pi independe ntly picks  a random value xi; it sets xi to 1 with\nprobability  ½ and sets x i to 0 with pr obability  ½. It then decides to enter the set S"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 934})","('type', 'Document')"
"('page_content', ""if and only if it chooses the value  1, and each of the processes with which it is in\nconflict chooses the value  0.\nProve that the set S resulting from the execution of this protocol is\nconflict-free. Also, give a formula for the expected size of S in terms\nof n (the number of processes) and d (the number of conflicts per\nprocess).  \n(b) The choice of the probability ½ in the protocol above was fairly\narbitrary , and it's not clear that it should give the best system\nperformance. A more general specification of the protocol would\nreplace the probability ½ by a parameter p betwee n 0 and 1, as\nfollows.  \nEach process Pi independe ntly picks  a random value xi; it sets xi to 1 with\nprobability p and sets xi to 0 with pr obability  1-p. It then decides to enter the set\nS if and only if it chooses the value  1, and each of the processes with which it is\nin conflict chooses the value  0.\nIn terms of the parameters of the graph G, give a value of p so that the\nexpected size of the resulting set S is as large as possible. Give a\nformula for the expected size of S when p is set to this optimal value.\n4. A number of peer-to-peer systems  on the Internet are based on overlay\nnetworks . Rather than using the physical Internet topology as the\nnetwork on which to perform computation, these systems run protocols\nby whic h nodes choose collections of virtual “neighbors” so as to\ndefine a higher -level graph whose structure may bear little or no\nrelation to the underlying physical network. Such an overlay network\nis then used for sharing data and services, and it can be extremely\nflexible compare d with a physic al network, which is hard to modify in\nreal time to adapt to changing conditions.  \nPeer-to-peer networks tend to grow through the arrival of new\nparticipants, who join by linking into the existing structure. This\ngrowth process has an intrinsic effect on the characteristics of the\noverall network. Recently , people have investigated simple abstract\nmodels for network growth that might provide insight into the way\nsuch processes behave, at a qualitative level, in real networks.  \nHere's a simple example of such a model. The system begins with a\nsingle node v1. Nodes then join one at a time; as each node joins, it\nexecutes a protocol whereby it forms a directed link to a singl e other"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 935})","('type', 'Document')"
"('page_content', ""node chosen uniformly at random from those already in the system.\nMore concretely , if the system already contains nodes v1, v2, …, vk-1\nand node vk wishes to join, it randomly selects one of v1, v2, …, vk-1\nand links to this node.  \nSuppose we run this process until we have a system consis ting of\nnodes v1, v2, …, vn; the random process described above will produce a\ndirected network in which each node other than v1 has exactly one\noutgoing edge. On the other hand, a node may have multiple incoming\nlinks, or none at all. The incoming links to a node vj reflect all the\nother nodes whose access into the system is via vj; so if vj has many\nincoming links, this can place a large load on it. To keep the system\nload-balanced, then, we'd like all nodes to have a roughly comparable\nnumber of incoming links. That's unlikely to happen here, however ,\nsince nodes that join earlier in the process are likely to have more\nincoming links than nodes that join later. Let's try to quantify this\nimbalance as follows.  \n(a) Given the random process described above, what is the expected\nnumber of incoming links to node vj in the resulting network? Give an\nexact formula in terms of n and j, and also try to express this quantity\nasymptotically (via an expression without large summations) using\nΘ(·) notation.  \nFigur e 13.6 Towns T1, T2 …, Tn need to decide how to share the cost\nof the cable.\n \n(b) Part (a) makes precise a sense in which the nodes that arrive early\ncarry an “unfair” share of the connections in the network. Another way\nto quantify the imbalance is to observe that, in a run of this random\nprocess, we expect many nodes to end up with no incoming links.  \nGive a formula for the expected number of nodes with no incoming\nlinks in a network grown randomly according to this model."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 936})","('type', 'Document')"
"('page_content', ""5. Out in a rural part of the county somewhere, n small towns have\ndecided to get connected to a large Internet switching hub via a high-\nvolume fiberopt ic cable. The towns are labeled T1, T2,…, Tn, and they\nare all arranged on a single long highway , so that town Ti is i miles\nfrom the switching hub (See Figure 13.6 ). \nNow this cable is quite expensive; it costs k dollars per mile, resulting\nin an overall cost of kn dollars for the whole cable. The towns get\ntogether and discuss how to divide up the cost of the cable.  \nFirst, one of the towns way out at the far end of the highway makes the\nfollowing proposal.  \nProposal A.  Divide the cost evenly among all towns, so each pays k dollars.\nThere's some sense in which Proposal A is fair, since it's as if each\ntown is paying for the mile of cable directly leading up to it.  \nBut one of the towns very close to the switching hub objects, pointing\nout that the faraway towns are actually benefiting from a large section\nof the cable, whereas the close-in towns only benefit from a short\nsection of it. So they make the following counterproposal.\nProposal B. Divide the cost so that the contribution of town Ti is proport ional to i, its\ndistance fr om the switching hub.\nOne of the other towns very close to the switching hub points out that\nthere's another way to do a nonproportional division that is also\nnatural. This is based on concep tually dividing the cable into n equal-\nlength “edges” e1, …, en, where the first edge e1 runs from the\nswitching hub to T1, and the ith edge ei (i > 1) runs from Ti-1 to Ti. Now\nwe observe that, while all the towns benefit from e1, only the last town\nbenefits from en. So they suggest  \nProposal C. Divide the cost separately for each edge  ei. The cost of ei should be shared\nequally by the towns T i, Ti+1,…,Tn, since these ar e the towns “downstr eam” of e i.\nSo now the town s have many different options; which is the fairest? To\nresolve this, they turn to the work of Lloyd Shapley , one of the most\nfamous mathematical economists of the 20th century . He proposed\nwhat is now called the Shapley value  as a general mechanism for"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 937})","('type', 'Document')"
"('page_content', ""sharing costs or benefits among several parties. It can be viewed as\ndetermining the “mar ginal contribution” of each party , assuming the\nparties arrive in a random or der. \nHere's how it would work concretely in our setting. Consider an\nordering \n  of the towns, and suppose that the towns “arrive”in this\norder . The marginal cost of town Ti in order \n is determined as\nfollows. If Ti is first in the order \n , then Ti pays ki, the cost of running\nthe cable all the way from the switching hub to Ti. Otherwise, look at\nthe set of towns that come before Ti in the order \n , and let Tj be the\nfarthest among these towns from the switching hub. When Ti arrives,\nwe assume the cable already reaches out to Tj but no farther . So if j > i\n(Tj is farther out than Ti), then the marginal cost of Ti is 0, since the\ncable already runs past Ti on its way out to Tj. On the other hand, if j <\ni, then the marginal cost of Ti is k(i - j): the cost of extending the cable\nfrom Tj out to Ti. \n(For example, suppose n = 3 and the towns arrive in the order T1, T3,\nT2. First T1 pays k when it arrives. Then, when T3 arrives,  it only has to\npay 2 k to exten d the cable from T1. Finally , when T2 arrives, it doesn't\nhave to pay anything since the cable already runs past it out to T3.) \nNow , let Xi be the random variable equal to the marginal cost of town\nTi when the order \n  is selected uniformly at random from all\npermutations of the towns. Under the rules of the Shapley value, the\namount that Ti should contribu te to the overal l cost of the cable is the\nexpected value of Xi. \nThe question is: Which of the three proposals above, if any, gives the\nsame division of costs as the Shapley value cost-sharing mechanism?\nGive a proof for your answer .\n6. One of the (man y) hard problems that arises in genome mapping can\nbe form ulated in the following abstract way. We are given a set of n\nmarkers  {μ1,…, μn}—these are positions on a chromosome that we are\ntrying to map-and our goal is to output a linear ordering of these\nmarkers. The output should be consistent with a set of k constraints ,\neach specified by a triple ( μi, μj, μk), requiring that μj lie between μi and"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 938})","('type', 'Document')"
"('page_content', ""μk in the total ordering that we produce. (Note that this constraint does\nnot specify which of μi; or μk should come first in the ordering, only\nthat μj should come between them.)  \nNow it is not always possible to satisfy all constraints simultan eously ,\nso we wish to produce an ordering that satisfies as many as possible.\nUnfortunately , deciding whether there is an ordering that satisfies at\nleast k′ of the k constraints is an NP-complete problem (you don't have\nto prove this.)  \nGive a constant  α > 0 (independent of n) and an algorit hm with the\nfollowing property . If it is possible to satisfy k* of the constraints, then\nthe algorithm produces an ordering of markers satisfying at least αk*\nof the constraints. Your algorithm may be randomized; in this case it\nshould produce an ordering for which the expected  number of satisfied\nconstraints is at least αk*\n7. In Section 13.4, we designed an approximation algorithm to within a\nfactor of 7/8 for the MAX 3-SAT Problem, where we assumed that\neach clause has terms associated  with three different variables. In this\nproblem, we will consider the analogous MAX SAT Problem: Given a\nset of clauses C1,…,Ck over a set of variables X = {x1,…, xn}, find a\ntruth assignment satisfying as many of the clauses as possible. Each\nclause has at least one term in it, and all the variables in a single clause\nare distinct, but otherwise we do not make any assumptions on the\nlength of the clauses: There may be clauses that have a lot of variables,\nand others may have just a single variable.  \n(a) First consider the randomized approximation algorithm we used for\nMAX 3-SA T, setting each varia ble independently to true or false  with\nprobability ½ each. Show that the expected number of clauses satisfied\nby this random assignment is at least k/2, that is, at least half of the\nclauses are satisfied in expectation. Give an example to show that there\nare MAX SAT instances such that no assignment satisfies more than\nhalf of the clauses.  \n(b) If we have a clause that consists only of a single term (e.g., a clause\nconsisting just of x1, or just of \n ), then there is only a single way to\nsatisfy it: We need to set the corresponding variable in the appropriate\nway. If we have  two clauses such that one consists of just the term xi,\nand the other consists of just the negated term \n , then this is a pretty"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 939})","('type', 'Document')"
"('page_content', ""direct contradiction.  \nAssume that our instance has no such pair of “conflicting clauses”; that\nis, for no variable xi do we have both a clause C = {xi} and a clause  \n Modify the randomized procedure above to improve the\napproximation factor from ½ to at least .6. That is, change the\nalgorithm so that the expected number of clauses satisfied by the\nprocess is at least .6 k. \n(c) Give a randomized polynomial-time algorithm for the general\nMAX SAT Problem, so that the expected number of clauses satisfied\nby the algorithm is at least a .6 fraction of the maximum possible.  \n(Note that, by the example in part (a), there are instances where one\ncannot satisfy more than k/2 clauses; the point here is that we'd still\nlike an efficient algorithm that, in expectation, can satisfy a .6 fraction\nof the maximum that can be satisfied by an optimal assignment .)\n8. Let G = (V,E) be an undirected graph with n nodes and m edges. For a\nsubset X ⊆ V, we use G[X] to denote the subgraph induced  on X-that\nis, the graph whose node set is X and whose edge set consists of all\nedges of G for which both ends lie in X. \nWe are given a natural number k ≤ n and are interest ed in finding a set\nof k nodes that induces a “dense” subgraph of G; we'll phrase this\nconcretely as follows. Give a polynomial-time algorithm that\nproduces, for a given natural number k ≤ n, a set X ⊆ V of k nodes with\nthe property that the induced subgraph G[X] has at least \n  edges.  \nYou may give either (a) a determ inistic algorithm, or (b) a randomized\nalgorithm that has an expected running time that is polynomial, and\nthat only outputs correct answers.\n9. Suppose you're designing strategies for selling items on a popular\nauction Web site. Unlike other auction sites, this one uses a one-pass\nauction , in which each bid must be immediately (and irrevocably)\naccepted or refused. Specifically , the site works as follows.  \nFirst a seller puts up an item for sale.\nThen buyers appear in sequence.\nWhen buyer i appears, he or she makes a bid bi > 0.\nThe seller must decide immediately whether to accept the bid or\nnot. \nIf the seller accepts the bid, the item is sold and all future buyers"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 940})","('type', 'Document')"
"('page_content', ""are turned away . If the seller rejects the bid, buyer i departs and\nthe bid is withdr awn; and only then does the seller see any future\nbuyers.\n \nSuppose an item is offered for sale, and there are n buyers, each with a\ndistinct bid. Suppose further that the buyers appear in a random order ,\nand that the seller knows the number n of buyers. We'd like to design a\nstrategy whereb y the seller has a reasonable chance of accept ing the\nhighest of the n bids. By a strategy , we mean a rule by which the seller\ndecides whether to accept each presented bid, based only on the value\nof n and the sequence of bids seen so far . \nFor example, the seller could always accept the first bid presented.\nThis results in the seller accepting the highest of the n bids with\nprobability only 1/n, since it requires the highest bid to be the first one\npresented.  \nGive a strategy under which the seller accepts the highest of the n bids\nwith probability at least ¼, regardless of the value of n. (For simplicity ,\nyou may assume that n is an even number .) Prove that your strategy\nachieves this probabilistic guarantee.\n10. Consider a very simple online auction system that works as follows.\nThere are n bidding agents ; agent i has a bid bi, which is a positive\nnatural number . We will assume that all bids bi are distinct from one\nanother . The bidding agents appear in an order chosen uniformly at\nrandom, each proposes its bid bi in turn, and at all times the system\nmaintains a variable b* equal to the highest bid seen so far. (Initially b*\nis set to 0.)  \nWhat is the expected number of times that b* is updated when this\nprocess is executed, as a function of the parameters in the problem?  \nExample . Suppose b1 = 20, b2 = 25, and b3 = 10, and the bidders\narrive in the order 1, 3, 2. Then b* is updated for 1 and 2, but not for 3.\n11. Load balancing algorithms  for parallel or distributed systems seek to\nspread out collections of computing jobs over multiple machines. In\nthis way , no one machine becomes a “hot spot.” If some kind of central\ncoordination is possible, then the load can potentially be spread out\nalmost perfectly . But what if the jobs are coming from diverse sources\nthat can't coordinate? As we saw in Section 13.10 , one option is to"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 941})","('type', 'Document')"
"('page_content', ""assign them to machines at random and hope that this random ization\nwill work to prevent imbalances. Clearly , this won't generally work as\nwell as a perfectly centralized solution, but it can be quite effective.\nHere we try analyzing some variations and extensions on the simple\nload balancing heuristic we considered in Section 13.10 . \nSuppose you have k machines, and k jobs show up for processing.\nEach job is assigned to one of the k machines independently at random\n(with each machine equally likely).  \n(a) Let N(k) be the expecte d number of machines that do not receive\nany jobs, so that N(k)/k is the expected fraction of machines with\nnothing to do. What is the value of the limit \n  Give a proof\nof your answer . \n(b) Suppose that machines are not able to queue up excess jobs, so if\nthe random assignment of jobs to machines sends more than one job to\na machine M, then M will do the first of the jobs it receives and reject\nthe rest. Let R(k) be the expected number of rejected jobs; so R(k)/k is\nthe expected fraction of rejected jobs. What is \n  Give a\nproof of your answer . \n(c) Now assume that machines have slightly larger buffers; each\nmachine M will do the first two jobs it receives, and reject any\nadditional jobs. Let R2(k) denote the expected number of rejected jobs\nunder this rule. What is \n  Give a proof of your answer . \n12. Consider the following analogue of Karger's algorithm for finding\nminimum s-t cuts. We will contract edges iteratively using the\nfollowing randomized procedure. In a given iteration, let s and t denote\nthe possibly contracted nodes that contain the original nodes s and t,\nrespectively . To make sure that s and t do not get contracted, at each\niteration we delete any edges connecting s and t and select a random\nedge to contract  among the rema ining edges. Give an example to show\nthat the probability that this method finds a minimum s-t cut can be\nexponentially small.\n13. Consider a balls-and-bins exper iment with 2n balls but only two bins.\nAs usual, each ball independently selects one of the two bins, both bins\nequally likely . The expected number of balls in each bin is n. In this\nproblem, we explore the questio n of how big their difference is likely\nto be. Let X1 and X2 denote the number of balls in the two bins,"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 942})","('type', 'Document')"
"('page_content', ""respectively . (X1 and X2 are random variables.) Prove that for any ∊ >\n0 there is a constant c > 0 such that the probability \n .\n14. Some people designing parallel physical simulations come to you with\nthe following problem. They have a set P of k basic processes  and\nwant to assign each process to run on one of two machines, M1 and\nM2. They are then going to run a sequence of n jobs , J1,…,Jn. Each job\nJi is repre sented by a set Pi ⊆ P of exactly 2n basic processes which\nmust be running (each on its assigned machine) while the job is\nprocessed. An assignment of basic processes to machines will be\ncalled perfectly balanced  if, for each job Ji, exactly n of the basic\nprocesses assoc iated with Ji have been assigned to each of the two\nmachines. An assignment of basic processes to machines will be called\nnearly balanced  if, for each job Ji, no more than \n  of the basic\nprocesses associated with Ji have been assigned to the same machine.  \n(a) Show that for arbitrarily large values of n, there exist sequences of\njobs J1,…,Jn for which no perfectly balanced assignment exists.  \n(b) Suppose that n ≥ 200. Give an algorithm that takes an arbitrary\nsequence of jobs J1,…,Jn and produces a nearly balanced assignment\nof basic processes to machines. Your algorithm may be randomized, in\nwhich case its expected runnin g time should be polynomial, and it\nshould always produce the correct answer .\n15. Suppose you are presented with a very large set S of real numbers, and\nyou'd like to approximate the median of these numbers by sampling.\nYou may assume all the numbe rs in S are distinct. Let n = |S| we will\nsay that a number x is an ∊-appr oximate median  of S if at least (½ -\n∊)n numbers in S are less than x, and at least (½ - ∊)n numbers in S\nare greater than x. \nConsider an algorithm that work s as follows. You select a subset S′ ⊆S\nuniformly at random, compute the median of S′, and return this as an\napproximate median of S. Show that there is an absolute constant c,\nindependent of n, so that if you apply this algori thm with a sample S′\nof size c, then with proba bility at least .99, the number returned will be\na (.05)-approximate median of S. (You may consider either the version\nof the algorithm that constructs  S′ by sampling with replacement , so"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 943})","('type', 'Document')"
"('page_content', 'that an element of S can be selected multiple times, or one without\nreplacement.)\n16. Consider the following (partially specified) method for transmitting a\nmessage securely between a sender and a receiver . The message will\nbe repre sented as a string of bits. Let Σ = {0,1}, and let Σ* denote the\nset of all string s of 0 or more bits (e.g., 0,00,1 110001 ∊  Σ*). The\n“empty string,” with no bits, will be denoted λ ∊  Σ*. \nThe sender and receiver share a secret function f : Σ* × Σ →Σ. That is,\nf takes a word and a bit, and returns a bit. When the receiver gets a\nsequence of bits α ∊  Σ*, he or she runs the following method to\ndecipher it.  \nLet α = α1α2…αn, where n is the number of bits in α\nThe goal is to produce an n-bit deciphered message,\nβ = β1β2…βn\nSet β1 = f(λ, α)\nFor i = 2,3,4,…, n\nSet βi = f(β1 β2…βi-1, αi)\nEndfor\nOutput β\n \nOne could view this is as a type of “stream cipher with feedback .” One\nproblem with this approach is that, if any bit αi gets corrupted in\ntransmission, it will corrupt the computed value of βj for all j ≥ i. \nWe consider the following problem. A sender S wants to transmit the\nsame (plain-text) message β to each of k receivers Rl,…,Rk. With each\none, he shares a different secret  function f(i). Thus he sends a different\nencrypted message α(i) to each receiver , so that α(i) decrypts to β when\nthe above algorithm is run with the function f(i). \nUnfortunately , the communicati on channels are very noisy , so each of\nthe n bits in each of the k transmi ssions is independently  corrupted\n(i.e., flipped to its complement ) with probability ¼. Thus no single\nreceiver on his or her own is likely to be able to decrypt the message\ncorrectly . Show , however , that if k is large enough as a function of n,\nthen the k receivers can jointly reconstruct the plain-text message in')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 944})","('type', 'Document')"
"('page_content', 'the following way. They get together , and without revealing any of the\nα(i) or the f(i), they interactively run an algorithm that will produce the\ncorrect β with probability at least 9/10. (How large do you need k to be\nin your algorithm?)\n17. Consider the following simple model of gambling in the presence of\nbad odds. At the beginning, your net profit is 0. You play for a\nsequence of n rounds;  and in each round, your net profit increases by 1\nwith probability 1/3, and decreases by 1 with probability 2/3.  \nShow that the expected numbe r of steps in which your net profit is\npositive can be upper-bounded by an absolute constant, independent of\nthe value of n.\n18. In this problem, we will consider the following simple randomized\nalgorithm for the V ertex Cover Algorithm.  \nStart with S= \x00\nWhile S is not a vertex cover ,\nSelect an edge e not covered by S\nSelect one end of e at random (each end equally likely)\nAdd the selected node to S\nEndwhile\n \nWe will be interested in the expected cost of a vertex cover selec ted by\nthis algorithm.  \n(a) Is this algorithm a c-approximation algorithm for the Minimum\nWeight V ertex Cover Problem for some constant c? Prove your answer . \n(b) Is this algorithm a c-approximation algorithm for the Minimum\nCardinality Vertex Cover Problem for some constant c? Prove your\nanswer . \n(Hint:  For an edge, let pe denote the probability that edge e is selected\nas an uncovered edge in this algorithm. Can you express the expected\nvalue of the solution in terms of these probabilities? To bound the\nvalue of an optimal solution in terms of the pe probab ilities, try to\nbound the sum of the probabilities for the edges incident to a given\nvertex v, namely , \n .)')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 945})","('type', 'Document')"
"('page_content', ""Notes and Further Reading\nThe use of randomization in algorithms is an active research area; the books\nby Motwani and Raghavan (1995) and Mitzenmacher and Upfal (2005) are\ndevoted to this topic. As the contents of this chapter make clear , the types of\nprobabilistic arguments used in the study of basic randomized algorithms\noften have a discrete, combinatorial flavor; one can get backgr ound in this\nstyle of probabilistic analysis from the book by Feller (1957).\nThe use of randomization for contention resolution is common in\nmany systems and network ing applications. Ethernet-style shared\ncommunication media, for exam ple, use randomized backoff  protocols to\nreduce the number of collisions  among different senders; see the book by\nBertsekas and Gallager (1992) for a discussion of this topic.\nThe randomized algorithm for the Minimum-Cut Problem described in\nthe text is due to Karger, and after further optimizations due to Karger and\nStein (1996), it has become one of the most efficient approa ches to the\nminimum cut problem. A number of further extensions and applications of\nthe algorithm appear in Kar ger's (1995) Ph.D. thesis.\nThe approximation algorithm for MAX 3-SA T is due to Johnson\n(1974), in a pape r that contains a number of early approximation algorithms\nfor NP-h ard problems. The surprising punch line to that section—that every\ninstance of 3-SA T has an assignment satisfying at least 7/8 of the clauses—\nis an example of the probabilistic method , whereby a combinatorial\nstructure with a desired property is shown to exist simply by arguing that a\nrandom structure has the property with positive probability . This has grown\ninto a highly refined technique in the area of combinatorics; the book by\nAlon and Spencer (2000) covers a wide range of its applications.\nHashing is a topic that remains the subject of extensive study , in both\ntheoretical and applied settings, and there are many variants of the basic\nmethod. The approach we focus on in Section 13.6 is due to Carte r and\nWegman (1979). The use of randomization for finding the closest pair of\npoints in the plane was originally proposed by Rabin (1976), in an\ninfluential early paper that exposed the power of randomization in many\nalgorithmic settings. The algorithm we describe in this chapter was\ndeveloped by Golin et al. (1995). The technique used there to bound the\nnumber of dictionary operations, in which one sums the expecte d work over"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 946})","('type', 'Document')"
"('page_content', ""all stages of the random order , is sometimes referred to as backwar ds\nanalysis ; this was originally proposed by Chew (1985) for a related\ngeometric problem, and a number of further applications of backwards\nanalysis are described in the survey by Seidel (1993).\nThe performance guarantee for the LRU caching algorithm is due to\nSleator and Tarjan (1985), and the bound for the Randomized Marking\nalgorithm is due to Fiat, Karp, Luby, McGeoch, Sleator , and Young (1991).\nMore generally , the paper by Sleator and Tarjan highlighted the notion of\nonline algorithms , which must process input without knowledge of the\nfuture; caching is one of the fundamental applications that call for such\nalgorithms. The book by Borodin and El-Yaniv (1998) is devoted to the\ntopic of online algorithms and includes many further results on caching in\nparticular .\nThere are many ways to formulate bounds of the type in Section 13.9,\nshowing that a sum of 0-1-value d independent random variables is unlikely\nto deviate far from its mean. Results of this flavor are gene rally called\nChernoff bounds , or Chernoff-Hoeffding  bounds, after the work of Chernof f\n(1952) and Hoef fding (1963). The books by Alon and Spencer (1992),\nMotwani and Raghavan (1995), and Mitzenmacher and Upfal (2005)\ndiscuss these kinds of bounds in more detail and provide further\napplications.\nThe results for packet routing in terms of congestion and dilation are\ndue to Leighton , Maggs, and Rao (1994). Routing is another area in which\nrandomization can be effective at reducing contention and hot spots; the\nbook by Leighton (1992) covers many further applications of this principle.\nNotes on the Exercises  Exercis e 6 is based on a result of Benny Chor and\nMadhu Sudan; Exercise 9 is a version of the Secretary Problem , whose\npopularization is often credited to Martin Gardner .\n1 It is not, however , the simplest way to incorporate randomization into a\ncaching algorithm. W e could have considered the Purely Random Algorithm\nthat dispenses with the whole notion of marking, and on each cache miss\nselects one of its k current items for eviction uniformly at random. (Note the\ndifference: The Randomized Marking Algorithm randomizes only over the\nunmarked items .) Although we won't prove this here, the Purely Random\nAlgorithm can incur at least c times more misses than the optimum, for any\nconstant c < k, and so it does not lead to an improvement over LRU."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 947})","('type', 'Document')"
"('page_content', ""Epilogue: Algorithms That Run Forever\n\xa0\n\xa0\nEvery decade has its addictive puzzles; and if Rubik's Cube stands out as\nthe preeminent solitaire recreati on of the early 1980s, then Tetris evokes a\nsimilar nostalgia for the late eighties and early nineties. Rubik 's Cube and\nTetris have a number of things in common—they share  a highly\nmathematical flavor , based on stylized geometric forms—but the\ndifferences between them are perhaps more interesting.\nRubik's Cube is a game whose  complexity is based on an enormous\nsearch space; given a scrambled configuration of the Cube, you have to\napply an intricate sequence of operations to reach the ultima te goal. By\ncontrast, Tetris—in its pure form—has a much fuzzier definition of success;\nrather than aiming for a particu lar endpoint, you're faced with a basically\ninfinite stream of events to be dealt with, and you have to react\ncontinuously so as to keep your head above water .\nThese novel features of Tetris parallel an analogous set of themes that\nhas emer ged in recent thinking about algorithms. Increasingly , we face\nsettings in which the standard view of algorithms—in which  one begins\nwith an input, runs for a finite number of steps, and produces an output—\ndoes not really apply . Rather , if we think about Internet routers that move\npackets while avoiding congestion, or decentralized file-sharing\nmechanisms that replicate and distribute content to meet user demand, or\nmachine learning routines that form predictive models of concepts that\nchange over time, then we are dealing with algorithms that effectively are\ndesigned to run forever. Instead  of producing an eventual output, they\nsucceed if they can keep up with an environment that is in constant flux and\ncontinuously throws new tasks  at them. For such applications, we have\nshifted from the world of Rubik's Cube to the world of T etris.\nThere are many settings in which we could explore this theme, and as\nour final topic for the book we consider one of the most compelling: the\ndesign of algorithms for high-speed packet switching on the Internet.\nThe Problem"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 949})","('type', 'Document')"
"('page_content', ""A packe t travel ing from a source to a destination on the Internet can be\nthought of as traversing a path in a large graph whose nodes are switches\nand whose edges are the cables that link switches together . Each packet p\nhas a header from  which a switch can determine, when p arrives on an input\nlink, the output link on which p needs to depart.  The goal of a switch is thus\nto take streams of packets arrivi ng on its input links and move each packet,\nas quickly as possible, to the particular output link on which  it needs to\ndepart. How quickly? In high-volume settings, it is possible for a packet to\narrive on each input link once every few tens of nanoseconds; if they aren't\noff loaded to their respective output links at a comparable rate, then traffic\nwill back up and packets will be dropped.\nIn order to think about the algorithms operating inside a switch, we\nmodel the switch itself as follows. It has n input links I1, …, In and n output\nlinks O1, …,On. Packets arrive on the input links; a given packet p has an\nassociated input/output type (I[p], O[p]) indicating that it has arrived at\ninput link I[p] and needs to depart on output link O[p]. Time moves in\ndiscrete steps;  in each step, at most one new packet arrives on each input\nlink, and at most one packet can depart on each output link.\nConsider the example in Figure E.1. In a single time step, the three\npackets p, q, and r have arrived at an empty switch on input links I1, I3, and\nI4, respectively . Packet p is destined for O1, packet q is destined for O3, and\npacket r is also destined for O3. Now there's no problem sending packet p\nout on link O1; but only one packet can depart on link O3, and so the switch\nhas to resolve the contention between q and r. How can it do this?\nThe simplest model of switch  behavior is known as pure output\nqueueing,  and it's essentially an idealized picture of how we wished a\nswitch behaved.  In this model, all nodes that arrive in a given time step are\nplaced in an output buffer  associated with their output link, and one of the\npackets in each output buffer actually gets to depart. More concretely , here's\nthe model of a single time step.\nOne step under pure output queueing:\nPackets arrive on input links\nEach packet p of type ( I[p], O[p]) is moved to output buf fer O[p]\nAt most one packet departs from each output buf fer"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 950})","('type', 'Document')"
"('page_content', ""Figur e E.1 A switch with n = 4 inputs and outputs. In one time step,\npackets p, q, and r have arrived.\nSo, in Figure E.1 , the given time step could end with packets p and q having\ndeparted on their output links, and with packet r sitting in the output buffer\nO3. (In discussing this example here and below , we'll assume that q is\nfavored over r when decisions are made.) Under this model, the switch is\nbasically a “frictionless” object  through which packets pass unimpeded to\ntheir output buf fer.\nIn reality , however , a packet that arrives on an input link must be\ncopied over to its appropriate output link, and this operation requires some\nprocessing that ties up both the input and output links for a few\nnanoseconds. So, really , constraints within the switch do pose some\nobstacles to the movement of packets from inputs to outputs.\nThe most restrictive model of these constraints, input/output queueing,\nworks as follow s. We now have an input buffer  for each input link I, as well\nas an output buffer for each output link O. When each packet arrives, it\nimmediately lands in its associ ated input buffer. In a single time step, a\nswitch can read at most one pack et from each input buffer and write at most\none packet to each output buffer. So under input/output queueing, the\nexample of Figure E.1 would work as follows. Each of p, q, and r would\narrive in different input buffers; the switch could then move p and q to their\noutput buffers, but it could not move all three, since moving all three would\ninvolve writing two packets into the output buffer O3. Thus the first step\nwould end with p and q having departed on their output links, and r sitting\nin the input buf fer I4 (rather than in the output buf fer O3)."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 951})","('type', 'Document')"
"('page_content', ""More generally , the restriction of limited reading and writing amounts\nto the following: If packets p1, …, pℓ are moved in a single time step from\ninput buffers to output buffers, then all their input buffers and all their\noutput buffers must be distinct. In other words, their types {(I[pi], O[pi]): i\n= 1, 2, …, ℓ} must form a bipartite matchin g. Thus we can model a single\ntime step as follows.\nOne step under input/output queueing:\nPackets arrive on input links and are placed in input buf fers\nA set of packets whose types form a matching are moved to their associated output buf fers\nAt most one packet departs from each output buf fer\nThe choice of which matching to move is left unspecified for now; this is a\npoint that will become crucial later .\nSo under input/output queueing, the switch introduces some “friction”\non the movement of packets, and this is an observable phenomenon: if we\nview the switch as a black box, and simply watch the sequence of\ndepartures on the output links, then we can see the difference between pure\noutput queueing and input/output queueing. Consider an example whose\nfirst step is just like Figure E.1, and in whose second step a single packet s\nof type (I4, O4) arrives. Under pure output queueing, p and q would depart\nin the first step, and r and s would depart in the second step. Under\ninput/output queueing, however , the sequence of events depicte d in Figure\nE.2 occurs: At the end of the first step, r is still sitting in the input buffer I4,\nand so, at the end of the second step, one of r or s is still in the input buffer\nI4 and has not yet departed. This conflict between r and s is called head-of-\nline blocking , and it causes a switch with input/output queueing to exhibit\ninferior delay characteristics compared with pure output queueing.\nSimulating a Switch with Pure Output Queueing  While pure output\nqueueing would be nice to have, the arguments above indicate why it's not\nfeasible to design a switch with this behavior: In a single time step (lasting\nonly tens of nanoseconds), it would not generally be possible to move\npackets from each of n input links to a common output buf fer.\nBut what if we were to take a switch that used input/output queueing\nand ran it somewhat faster , moving several matchings in a single time step\ninstead of just one? Would it be possible to simulate a switch that used pure"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 952})","('type', 'Document')"
"('page_content', ""output queueing? By this we mean that the sequence of depar tures on the\noutput links (viewing the switch  as a black box) should be the same under\nthe beha vior of pure output queueing and the behavior of our sped-up\ninput/output queueing algorithm.\nIt is not hard to see that a speed-up of n would suffice: If we could\nmove n matchings in each time step, then even if every arriving packet\nneeded to reach the same output buffer, we could move them all in the\ncourse of one step. But a speed-up of n is completely infeasible; and if we\nthink about this worst-case example, we begin to worry that we might need\na speed-up of n to make this work—after all, what if all the arriving packets\nreally did need to go to the same output buf fer?\nFigur e E.2 Parts (a) and (b) depict a two-step example in which head-of -\nline blocking occurs.\nThe crux of this section is to show that a much more modest speed-up\nis sufficient. We'll describe a striking result of Chuang, Goel, McKeown,"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 953})","('type', 'Document')"
"('page_content', ""and Prabhakar (1999), showing  that a switch using input/outp ut queueing\nwith a speed-up of 2can simulate a switch that uses pure output queueing.\nIntuitively , the result exploits the fact that the behavior of the switch at an\ninternal level need not resemble the behavior under pure output queueing,\nprovided that the sequence of output link departures is the same. (Hence, to\ncontinue the example in the previous paragraph, it's okay that we don't\nmove all n arriving packets to a common output buffer in one time step; we\ncan afford more time for this, since their departures on this common output\nlink will be spread out over a long period of time anyway .)\nDesigning the Algorithm\nJust to be precise, here's our model for a speed-up of 2.\nOne step under sped-up input/output queueing:\nPackets arrive on input links and are placed in input buf fers\nA set of packets whose types form a matching are moved to their associated output buf fers\nAt most one packet departs from each output buf fer\nA set of packets whose types form a matching are moved to their associated output buf fers\nIn order  to prove that this model can simulate pure output queueing,\nwe need  to resolve the crucial  underspecified point in the model above:\nWhich matchings should be moved in each step? The answer to this\nquestion will form the core of the result, and we build up to it through a\nsequence of intermediate steps. To begin with, we make one simple\nobservation right away: If a packet of type (I, O) is part of a matching\nselected by the switch, then the switch will move the packet of this type that\nhas the earliest  time to leave.\nMaintaining Input and Output Buf fers To decide which two matchings the\nswitch should move in a given  time step, we define some quantities that\ntrack the curren t state of the switch relative to pure output queueing. To\nbegin with, for a packet p, we define its time to leave , TL(p), to be the time\nstep in which it would depart on its output link from a switch that was\nrunning pure output queueing. The goal is to make sure that each packet p\ndeparts from our switch (running sped-up input/output queueing) in\nprecisely the time step TL(p)."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 954})","('type', 'Document')"
"('page_content', ""Conceptually , each input buffer is maintained as an ordere d list;\nhowever , we retain the freedom to insert an arriving packet into the middle\nof this order , and to move a packet to its output buffer even when it is not\nyet at the front of the line. Despite this, the linear ordering of the buffer will\nform a useful progress measure . Each output buffer, by contra st, does not\nneed to be ordered; when a packet's time to leave comes up, we simply let it\ndepart. We can think of the whole setup as resembling a busy airport\nterminal, with the input buffers corresponding to check-in counters, the\noutput buffers to the departure lounge, and the internals of the switch to a\ncongested securi ty checkpoint. The input buffers are stressful places: If you\ndon't make it to the head of the line by the time your departure is\nannounced, you could miss your time to leave; to mitigate this, there are\nairport personnel who are allowed to helpfully extract you from the middle\nof the line and hustle you throu gh security . The output buffers, by way of\ncontrast, are relaxing places: You sit around until your time to leave is\nannounced, and then you just go. The goal is to get everyone through the\ncongestion in the middle so that they depart on time.\nOne consequenc e of these obser vations is that we don't need to worry\nabout packets that are already in output buffers; they'll just depart at the\nright time. Hence we refer to a packet p as unprocessed  if it is still in its\ninput buffer, and we define some further useful quantities for such packets.\nThe input cushion IC (p) is the number of packets ordered in front of p in its\ninput buffer. The output cushion OC(p) is the number of packets already in\np's output buf fer that have an earlier time to leave. Things are going well for\nan unprocessed packet p if OC(p) is significantly greater than IC(p); in this\ncase, p is near the front  of the line in its input buffer, and there are still a lot\nof packe ts before it in the output buffer. To capture this relationship, we\ndefine Slack (p) = OC(p) - IC(p), observing that large values of Slack (p) are\ngood.\nHere is our plan: We will move  matchings through the switch so as to\nmaintain the following two properties at all times.\n(i) Slack (p) ≥ 0 for all unprocessed packets p.\n(ii) In any step that begins with IC(p) = OC(p) = 0, packet p will be moved\nto its output buf fer in the first matching.\nWe first claim that it is suf ficient to maintain these two properties.\n(E.1)  If properties (i) and (ii) are maintained for all unprocessed packets at all times, then every\npacket p will depart at its time to leave TL (p)."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 955})","('type', 'Document')"
"('page_content', ""Proof. If p is in its output buffer at the start of step TL(p), then it can clearly depart. Otherwise it\nmust be in its input buffer. In this case, we have OC(p) = 0 at the start of the step. By property (i), we\nhave Slack (p) = OC(p) - IC(p) ≥ 0, and hence IC(p) = 0. It then follows from property (ii) that p will\nbe moved to the output buffer in the first matching of this step, and hence will depart in this step as\nwell. ▪\nIt turns out that property (ii) is easy to guarantee (and it will arise\nnaturally from the solution below), so we focus on the tricky task of\nchoosing matchings so as to maintain property (i).\nMoving a Matching through a Switch  When a packet p first arrives on an\ninput link, we insert it as far back in the input buffer as possible  (potentially\nsomewhere in the middle) consistent with the requirement Slack (p) ≥ 0.\nThis makes sure property (i) is satisfied initially for p.\nNow , if we want to maintain nonnegative slacks over time, then we\nneed to worry about counterbalancing events that cause Slack (p) to\ndecrease. Let's return to the description of a single time step and think about\nhow such decreases can occur .\nOne step under sped-up input/output queueing:\nPackets arrive on input links and are placed in input buf fers\nThe switch moves a matching\nAt most one packet departs from each output buf fer\nThe switch moves a matching\nConsider a given packet p that is unprocessed at the beginning of a\ntime step. In the arrival phase of the step, IC(p) could increase by 1 if the\narriving packet is placed in the input buffer ahead of p. This would cause\nSlack (p) to decrease by 1. In the departure phase of the step, OC(p) could\ndecrease by 1, since a packet with an earlier time to leave will no longer be\nin the output buffer. This too would cause Slack (p) to decrease by 1. So, in\nsummary , Slack (p) can potentially  decrease by 1 in each of the arrival and\ndeparture phases. Consequently , we will be able to maintain property (i) if\nwe can guarantee that Slack (p) increases by at least 1 each time the switch\nmoves a matching. How can we do this?\nIf the matching to be moved includes a packet in I[p] that is ahead  of\np, then IC(p) will decrease and hence Slack (p) will increase. If the matching\nincludes a packet destined for O[p] with an earlier time to leave than p, then\nOC(p) and Slack (p) will increase. So the only problem is if neither of these\nthings happens. Figure E.3 gives a schematic picture of such a situation."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 956})","('type', 'Document')"
"('page_content', ""Suppose that packet x is moved out of I[p] even though it is farther back in\norder , and pack et y is moved to O[p] even though it has a later time to\nleave. In this situation, it seems that buffers I[p] and O[p] have both been\ntreated “unfairly”: It would have been better for I[p] to send a packet like p\nthat was farther forward, and it would have been better for O[p] to receive a\npacket like p that had an earlier time to leave. Taken together , the two\nbuffers form something reminiscent of an instability  from the Stable\nMatching Problem.\nIn fact, we can make this precise, and it provides the key to finishing\nthe algorithm. Suppose we say that output buffer O prefers  input buffer I to\nI′ if the earliest time to leave among packets of type (I, O) is smaller than\nthe earliest time to leave among packets of type (I′, O). (In other words,\nbuffer I is more  in need of sending something to buffer O.) Further , we say\nthat input buffer I prefers  output buffer O to output buffer O′ if the\nforwardmost packet of type (I, O) comes ahead of the forwardmost packet\nof type (I, O′) in the ordering  of I. We construct a preference list for each\nbuffer from these rules; and if there are no packets at all of type (I,O), then I\nand O are placed at the end of each other's preference lists, with ties broken\narbitrarily . Final ly, we determine a stable matching M with respect to these\npreference lists, and the switch moves this matching M.\nFigur e E.3  Choosing a matching to move.\nAnalyzing the Algorithm\nThe following fact establishes that choosing a stable matching will indeed\nyield an algorithm with the performance guarantee that we want."")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 957})","('type', 'Document')"
"('page_content', '(E.2)  Suppose the switch always moves a stable matching M with respect to the preference lists\ndefined above. (And for each type (I, O) contained in M, we select the packet of this type with the\nearliest time to leave). Then, for all unprocessed packets p, the value Slack (p) increases by at least  1\nwhen the matching M is moved.\nProof. Consider any unprocessed packet p. Following the discussion above, suppose that no packet\nahead of p in I[p] is moved as part of the matching M, and no packet destin ed for O[p] with an earlier\ntime to leave is moved as part of M. So, in particular , the pair (I[p], O[p]) is not in M; suppose that\npairs ( I′, O[p]) and ( I[p], O′) belong to M.\nNow p has an earlier time to leave than any packet of type (I′, O[p]), and it comes ahead of\nevery packet of type (I[p], O′) in the ordering of I[p]. It follows that I[p] prefers O[p] to O′, and O[p]\nprefers I[p] to I′. Hence the pair (I[p], O[p]) forms an instability , which contradicts our assumption\nthat M is stable. ▪\nThus, by moving a stable matching in every step, the switch maintains\nthe property Slack (p) ≥ 0 for all packets p; hence, by (E.1) , we have shown\nthe following.\n(E.3)  By moving two stable matchings in each time step, accor ding to the preferences just defined,\nthe switch is able to simulate the behavior of pur e output queueing.\nOverall, the algorithm makes for a surprising last-minute appearance\nby the topic with which we bega n the book—and rather than matching men\nwith women or applicants with employers, we find ourselves matching\ninput links to output links in a high-speed Internet router .\nThis has been one glimpse into the issue of algorithms that run forever ,\nkeeping up with an infinite stream of new events. It is an intriguing topic,\nfull of open directions and unresolved issues. But that is for another time,\nand another book; and, as for us, we are done.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 958})","('type', 'Document')"
"('page_content', 'R e f e r e n c e s\n\xa0\n\xa0\nE. Aarts and J. K. Lenstra (eds.). Local Search in Combinator ial\nOptimization . Wiley, 1997.\nR. K. Ahuja, T. L. Magnanti, and J. B. Orlin. Network Flows: Theory ,\nAlgorithms, and Applications . Prentice Hall, 1993.\nN. Alon and J. Spencer . The Probabilistic Method  (2nd edition). Wiley,\n2000.\nM. Anderber g. Cluster Analysis for Applications . Academic Press, 1973.\nE. Ansh elevich, A. Dasgupta, J. Kleinber g, É. Tardos, T. Wexler , and T.\nRoughgar -den. The price of stability for network design with fair cost\nallocation. Proc. 45th IEEE Symposium on Foundations of Computer\nScience , pp. 295–304, 2004.\nK. Appel and W. Haken. The solution of the four-color -map problem.\nScientific American , 237:4(1977), 108–121.\nS. Arora and C. Lund. Hardness of approximations. In Appr oximation\nAlgorithms for NP-Har d Problems , edited by D. S. Hochbaum. PWS\nPublishing, 1996.\nB. Awerbuch, Y. Azar , and S. Plotkin. Throughput-competitive online\nrouting, Proc. 34th IEEE Symposium on Foundations of Computer Science ,\npp. 32–40, 1993.\nR. Bar-Yehuda and S. Even. A linear -time approximation algor ithm for the\nweighted vertex cover problem. J. Algorithms  2 (1981), 198–203.\nA.-L. Barabasi. Linked: The New Science of Networks . Perseus, 2002.\nM. Beck mann, C. B. McGuire, and C. B. Winsten. Studies in the Economics\nof Transportation . Yale University Press, 1956.\nL. Belad y. A study of replaceme nt algorithms for virtual storage computers.\nIBM Systems Journal  5 (1966), 78–101.\nT. C. Bell, J. G. Cleary , and I. H. Witten. Text Compr ession . Prentice Hall,\n1990.\nR. E. Bellman. Dynamic Pr ogramming . Princeton University Press, 1957.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 959})","('type', 'Document')"
"('page_content', 'R. Bellm an. On a routing problem. Quarterly of Applied Mathematics  16\n(1958), 87–90.\nR. Bellm an. On the approximation of curves by line segments using\ndynamic programming. Communications of the ACM , 4:6 (June 1961), 284.\nM. de Berg, M. van Kreveld, M. Overmars, and O. Schwarzkopf.\nComputational Geometry: Algorithms and Applications . Springer -Verlag,\n1997.\nC. Berge. Graphs and Hyper graphs . North-Holland Mathematical Library ,\n1976.\nE. R. Berlekamp, J. H. Conwa y, and R. K. Guy. Winning Ways for Your\nMathematical Plays . Academic Press, 1982.\nM. Bern and D. Eppstein. Approximation algorithms for geometric\nproblems. In Appr oximation Algorithms for NP-Har d Problems , edited by\nD. S. Hochbaum. PWS Publishing, 1996.\nD. Bertsekas and R. Gallager . Data Networks . Prentice Hall, 1992.\nB. Bollobas. Modern Graph Theory . Springer -Verlag, 1998.\nA. Borodin and R. El-Y aniv. Online Computation and Competitive Analysis .\nCambridge University Press, 1998.\nA. Boro din, M. N. Nielsen, and C. Rackof f. (Incremental) priority\nalgorithms. Proc. 13th Annual ACM-SIAM Symposium on Discr ete\nAlgorithms , pp. 752–761, 2002.\nY. Boykov , O. V eksler , and R. Zabih. Fast approximate ener gy minimization\nvia graph cuts. International Confer ence on Computer Vision , pp. 377–384,\n1999.\nL. J. Carter and M. L. Wegma n. Universal classes of hash functions. J.\nComputer and System Sciences  18:2 (1979), 143–154.\nB. V. Cherkassk y, A. V. Goldber g, and T. Radzik. Shortest paths algorithms:\nTheory and experimental evaluation. Proc. 5th ACM-SIAM Symposium on\nDiscr ete Algorithms , pp. 516–525, 1994.\nH. Chernof f. A measure of asymptotic efficiency for tests of a hypothesis\nbased on the sum of observations. Annals of Math ematical Statist ics, 23\n(1952), 493–509.\nL. P. Chew . Building Voronoi diagrams for convex polygon s in linear\nexpected time. Technical Repo rt, Dept. of Math and Computer Science,\nDartmouth College, Hanover , NH, 1985.\nY. J. Chu and T. H. Liu. On the shortest arborescence of a directed graph.\nSci. Sinica 14  (1965), 1396–1400.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 960})","('type', 'Document')"
"('page_content', 'S.-T. Chuang, A. Goel, N. McK eown, and B. Prabhakar . Matching output\nqueueing with a combined input output queued switch. IEEE J. on Selected\nAreas in Communications , 17:6 (1999), 1030–1039.\nV. Chva tal. A greedy heuristic for the set covering problem. Mathematics of\nOperations Resear ch, 4 (1979), 233–235.\nS. A. Cook. The complexity of theorem proving procedures. Proc. 3rd ACM\nSymp. on Theory of Computing , pp. 151–158. 1971.\nW. J. Cook, W. H. Cunningham, W. R. Pulleyblank, and A. Schrijver .\nCombinatorial Optimization . Wiley, 1998.\nT. Cover and J. Thomas. Elements of Information Theory . Wiley, 1991.\nR. Diestel, K. Yu. Gorbunov , T.R. Jensen, and C. Thomassen. Highly\nconnected sets and the exclude d grid theorem. J. Combinatorial Theory ,\nSeries B  75(1999), 61–73.\nR. Diestel. Graph Theory  (2nd edition). Springer -Verlag, 2000.\nE. W. Dijkstra. A note on two problems in connexion with graphs.\nNumerische Matematik , 1 (1959), 269–271.\nE. A. Dinitz. Algorithm for solution of a problem of maximum flow in\nnetworks with power estimation. Soviet Mathematics Doklady , 11(1970),\n1277–1280.\nR. Downey and M. Fellows. Parametrized Complexity . Springer -Verlag,\n1999.\nZ. Drezner (ed.). Facility location. Springer -Verlag, 1995.\nR. Duda, P. Hart, and D. Stork. Pattern Classification  (2nd edition). Wiley,\n2001.\nM. E. Dyer and A. M. Frieze. A simple heuristic for the p-centre problem.\nOperations Resear ch Letters , 3 (1985), 285–288.\nJ. Edmonds. Minimum partition  of a matroid into independen t subsets. J.\nResear ch of the National Bur eau of Standar ds B, 69 (1965), 67–72.\nJ. Edmonds. Optimum branchings. J. Resea rch of the National Bureau of\nStandar ds, 71B (1967), 233–240.\nJ. Edmonds. Matroids and the Greedy Algorithm. Math. Programming  1\n(1971), 127–136.\nJ. Edmonds and R. M. Karp. Theoretical improvements in algorithmic\nefficiency for network flow problems. Journal of the ACM  19:2(1972),\n248–264.\nL. Euler . Solutio problematis ad geometriam situs pertinentis. Commetarii\nAcademiae Scientiarum Imperialis Petr opolitanae  8 (1736), 128–140.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 961})","('type', 'Document')"
"('page_content', 'R. M. Fano. Transmission of Information . M.I.T . Press, 1949.\nW. Feller . An Introduction to Probability Theory and Its Applications , Vol.\n1. W iley, 1957.\nA. Fiat, R. M. Karp, M. Luby , L. A. McGeoch, D. D. Sleator , and N. E.\nYoung. Competitive paging algorithms. J. Algorithms  12 (1991), 685–699.\nR. W. Floyd. Algorithm 245 (TreeSort). Communications of the ACM , 7\n(1964), 701.\nL. R. Ford. Netw ork Flow Theory . RAND Corporation Technic al Report P-\n923, 1956.\nL. R. Ford and D. R. Fulkerson . Flows in Networks . Princeton University\nPress, 1962.\nD. Gale. The two-sided matching problem: Origin, development and current\nissues. International Game Theory Review , 3:2/3 (2001), 237–252.\nD. Gale and L. Shapley . College admissions and the stability of marriage.\nAmerican Mathematical Monthly  69 (1962), 9–15.\nM. R. Garey and D. S. Johnson . Computers and Intractability . A Guide to\nthe Theory of NP-Completeness . Freeman, 1979.\nM. Garey, D. Johnson, G. Miller , and C. Papadimitriou. The complexity of\ncoloring circular  arcs and chords. SIAM J. Algebraic and Discr ete Methods ,\n1:2 (June 1980), 216–227.\nM. Ghallab, D. Nau, and P. Traverso. Automated Planning: Theory and\nPractice . Mor gan Kaufmann, 2004.\nM. X. Goemans and D. P. Williamson. The primal-dual method for\napproximation algorithms and its application to network design problems.\nIn Appr oximation Algorithms for NP-Har d Problems , edited by D. S.\nHochbaum. PWS Publishing, 1996.\nA. Goldber g. Efficient Graph Algorithms for Sequential and Parallel\nComputers. Ph.D. thesis, MIT , 1986.\nA. Goldber g. Network Optimization Library .\nhttp://www .avglab.com/andr ew/soft.html .\nA. Gold berg, É. Tardos, and R. E. Tarjan. Network flow algorithms. In\nPaths, Flows, and VLSI-Layout , edited by B. Korte et al. Springer -Verlag,\n1990.\nA. Goldber g and R. Tarjan. A new approach to the maximum flow problem.\nProc. 18th ACM Symposium on Theory of Computing , pp. 136–146, 1986.\nM. Golin, R. Raman, C. Schwarz, and M. Smid. Simple randomized\nalgorithms for closest pair problems. Nordic J. Comput. , 2 (1995), 3–27.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 962})","('type', 'Document')"
"('page_content', 'M. C. Golumbic. Algorithmic Graph Theory and Perfect Graphs . Academic\nPress, 1980.\nR. L. Graham. Bounds for certain multiprocessing anomalies. Bell System\nTechnical Journal  45 (1966), 1563–1581.\nR. L. Graham. Bounds for multiprocessing timing anomalies. SIAM J.\nApplied Mathematics  17 (1969), 263–269.\nR. L. Graham and P. Hell. On the history of the minimum spanning tree\nproblem. Annals of the History of Computing , 7 (1985), 43–57.\nM. Gran ovetter . Threshold models of collective behavior . American Journal\nof Sociology  83:6(1978), 1420–1443.\nD. Greig, B. Porteous, and A. Seheult. Exact maximum a posteriori\nestimation for binary images. J. Royal Statistical Society B, 51:2(1989), pp.\n271–278.\nD. Gusfield. Algorithms on Strings, Trees, and Sequences: Computer\nScience and Computational Biology . Cambridge University Press, 1997.\nD. R. Gusfield and R. W. Irving . The Stable Marriage Problem: Structur e\nand Algorithms . MIT Press, 1989.\nL. A. Hall. Approximation algorithms for scheduling. In Appr oximation\nAlgorithms for NP-Har d Problems , edited by D. S. Hochbaum. PWS\nPublishing, 1996.\nP. Hall. On representation of subsets. J. Londo n Math ematical Societ y 10\n(1935), 26–30.\nS. Haykin. Neural Networks: A Compr ehensive Foundation  (2nd ed.).\nMacmillan, 1999.\nD. S. Hirschber g. A linear space algorithm for computing maximal common\nsubsequences. Communications of the ACM  18 (1975) 341–343.\nD. S. Hochbaum. Approximation algorithms for the set covering and vertex\ncover problems. SIAM J. on Computing , 11:3 (1982), 555–556.\nD. S. Hochbaum (ed.). Appr oximation Algorithms for NP-Har d Problems.\nPWS Publishing, 1996.\nD. S. Hochbaum. Approximatin g covering and packing problems: set cover ,\nvertex cover , independent set and related problems. In Appr oximation\nAlgorithms for NP-Har d Problems , edited by D. S. Hochbaum. PWS\nPublishing, 1996.\nD. S. Hochbaum and D. B. Shmoys. A best possible heuristi c for the k-\ncenter problem. Mathematics of Operations Resear ch 10:2 (1985), 180–\n184.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 963})","('type', 'Document')"
"('page_content', 'D. S. Hochbaum and D. B. Shmoys. Using dual approximation  algorithms\nfor scheduling problems: Theoretical and practical results. Journal of the\nACM  34 (1987), 144–162.\nW. Hoef fding. Probability inequalities for sums of bounded random\nvariables. J. American Statistical Association , 58 (1963), 13–30.\nJ. Hopfield. Neural networks and physical systems with emer gent collective\ncomputational properties. Proc. National Academy of Sciences of the USA,\n79 (1982), 2554–2588.\nD. A. Huffman. A method for the construction of minimum-redundancy\ncodes. Proc. IRE  40: 9 (Sept. 1952), 1098–1 101.\nA. Jain and R. Dubes. Algorithms for Clustering Data . Prentice Hall, 1981.\nT. R. Jensen and B. Toft. Graph Coloring Problems . Wiley Interscience,\n1995.\nD. S. Johnson. Approximation algorithms for combinatorial problems. J. of\nComputer and System Sciences , 9 (1974), 256–278.\nM. Jordan (ed.). Learning in Graphical Models . MIT Press, 1998.\nA. Karatsuba and Y. Ofman. Multiplication of multidigit numbers on\nautomata. Soviet Physics Doklady , 7 (1962), 595–596.\nD. Karger. Random Sampling in Graph Optimization Problems. Ph.D.\nThesis, Stanford University , 1995.\nD. R. Karger, C. Stein. A new approach to the minimum cut problem.\nJournal of the ACM  43:4(1996), 601–640.\nN. Karmarkar . A new polynomial-time algorithm for linear programming.\nCombi-natorica , 4:4(1984), 373–396.\nR. M. Karp. Reducibility among combinatorial problems. In Complexity of\nComputer Computations , edited by R. Miller and J. Thatcher , pp. 85–103.\nPlenum Press, 1972.\nB. Kernighan and S. Lin. An efficient heuristic procedure for partitioning\ngraphs. The Bell System T echnical Journal , 49:2 (1970), 291–307.\nS. Keshav . An Engineering Appr oach to Computer Networking . Addison-\nWesley , 1997.\nL. Khachiyan. A polynomial algorithm in linear programming. Soviet\nMathematics Doklady , 20:1(1979), 191–194.\nS. Kirkpatrick, C. D. Gelatt, Jr., and M. P. Vecchi. Optimization by\nsimulated annealing. Science , 220:4598 (1983), 671–680.\nJ. Kleinber g. Approximation Algorithms for Disjoint Paths Problems. Ph.D\nThesis, MIT , 1996.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 964})","('type', 'Document')"
"('page_content', 'J. Kleinber g and É. Tardos. Disjoint paths in densely embedded graphs.\nProc. 36th IEEE Symposium on Foundations of Computer Science , pp. 52–\n61, 1995.\nD. E. Knuth, The Art of Computer Programming , Vol. 1: Fundamental\nAlgorithms  (3rd edition). Addison-W esley , 1997a.\nD. E. Knuth. The Art of Computer Programming , Vol. 2: Seminumerical\nAlgorithms  (3rd edition). Addison-W esley , 1997b.\nD. E. Knuth. Stable marriage and its relation to other combinatorial\nproblems. CRM Proceedings and Lectur e Notes , vol. 10. American\nMathematical Society , 1997c.\nD. E. Knuth. The Art of Computer Programming , Vol. 3: Sorting and\nSearching  (3rd edition). Addison-W esley , 1998.\nV. Kolmogorov and R. Zabih. What energy functions can be minimized via\ngraph cuts? IEEE Transactions on Patte rn Analysis and Machine\nIntelligence (P AMI), 26:2 (2004), 147–159.\nD. Konig. Uber Graphen und ihre Anwendung auf Determinantentheorie\nund Mengenlehre. Mathematische Annalen , 77 (1916), 453–465.\nB. Korte, L. Lovász, H. J. Prömel, A. Schrijver (eds.). Paths, Flows, and\nVLSI-Layout  Springer -Verlag, 1990.\nE. Lawler . Combinatorial Optimization: Networks and Matr oids. Dover ,\n2001.\nE. L. Lawler , J. K. Lenstra, A. H. G. Rinnooy Kan, and D. B. Shmoys. The\nTraveling Salesman Problem: A Guided Tour of Combinatorial\nOptimization.  Wiley, 1985.\nE. L. Lawler , J. K. Lenstra, A. H. G. Rinnooy Kan, and D. B. Shmoys.\nSequencing and scheduling: Algorithms and complexity . In Handbooks in\nOperations Resear ch and Management Science  4, edited by S. C. Graves,\nA. H. G. Rinnooy Kan, and P . H. Zipkin. Elsevier , 1993.\nF. T. Leighton, Introduction to Parallel Algor ithms and Architectur es.\nMorgan Kaufmann, 1992.\nF. T. Leighton, B. M. Maggs, and S. Rao. Packet routing and job-shop\nscheduling in O(congestion + dilation) steps. Combinatorica , 14:2 (1994),\n167–186.\nD. Lelewer and D. S. Hirshber g. Data Compression. Computing Surveys\n19:3 (1987), 261–297.\nJ. K. Lenstra, D. Shmoys, and É. Tardos. Approximation algorithms for\nscheduling unrelated parallel machines. Mathematical Programming , 46')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 965})","('type', 'Document')"
"('page_content', '(1990), 259–271.\nL. Levin. Universal Search Problems (in Russian). Problemy Peredachi\nInformatsii , 9:3 (1973), pp. 265–266. For a partial English translation, see\nB. A. Trakhtenb rot, A survey of Russian approaches to Perebor (brute-force\nsearch) algorithms. Annals of the History of Comp uting  6:4 (1984), 384–\n400.\nL. Lovász. On the ratio of the optimal integral and fractional covers.\nDiscr ete Mathematics  13 (1975), 383–390.\nS. Martello and P. Toth. Knapsack Problems: Algorithms and Computer\nImplementations . Wiley, 1990.\nD. H. Mathews and M. Zuker . RNA secondary structure prediction. In\nEncyclopedia of Genetics, Genomics, Proteomics and Bioinformatics ,\nedited by P . Clote. W iley, 2004.\nK. Mehlhorn and St. Näher . The LEDA Platform of Combi natorial and\nGeometric Computing . Cambridge University Press, 1999.\nK. Menger . Zur allgemeinen Kurventheorie. Fundam. Math.  19 (1927), 96–\n115.\nK. Menger . On the origin of the n-Arc Theorem. J. Graph Theory  5 (1981),\n341–350.\nN. Metropolis, A. W. Rosenbluth, M. N. Rosenbluth. A. H. Teller, and E.\nTeller. Equation  of state calculations by fast computing machines. J.\nChemical Physics  21 (1953), 1087–1092.\nM. Mitzenmach er and E. Upfal. Probability and Computing: Randomized\nAlgorithms and Pr obabilistic Analysis . Cambridge University Press, 2005.\nD. Mon derer and L. Shapley . Potential Games. Games and Economic\nBehavior  14 (1996), 124–143.\nR. Motwani and P. Raghavan. Randomized Algorithms . Cambridge\nUniversity Press, 1995.\nJohn F. Nash, Jr. Equilibrium points in n-person games. Proc. National\nAcademy of Sciences of the USA , 36 (1950), 48–49.\nS. B. Needleman and C. D. Wunsch. J. Molecular Biology . 48 (1970), 443–\n453.\nG. L. Nemhauser and L. A. Wolsey . Integer and Combinatorial\nOptimization . Wiley, 1988.\nJ. Nesetril. A few remarks on the history of MST -problem. Archivum\nMathematicum Brno , 33 (1997), 15–22.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 966})","('type', 'Document')"
"('page_content', 'M. Newborn. Kaspar ov versus Deep Blue: Computer Chess Comes of Age.\nSpringer -Verlag, 1996.\nR. Nowakowski (ed.). Games of No Chance . Cambridge University Press,\n1998.\nM. Osborne. An Introduction to Game Theory . Oxford University Press,\n2003.\nC. H. Papadimitriou. Computational Complexity . Addison-W esley , 1995.\nC. H. Papadimitriou. Algorithms, games, and the Internet. Proc. 33rd ACM\nSymposium on Theory of Computing , pp. 749–753, 2001.\nS. Plotk in. Com petitive routing in ATM networks. IEEE J. Selected Areas\nin Communications , 1995, pp. 1 128–1 136.\nF. P. Preparata and M. I. Shamos. Computational Geometry: An\nIntroduction . Springer -Verlag, 1985.\nW. H. Press, B. P. Flannery , S. A. Teukolsky , and W. T. Vetterling.\nNumerical Recipes in C . Cambridge University Press, 1988.\nM. O. Rabin. Probabilistic algorithms. In Algorithms and Complexity: New\nDirections and Recent Results , edited by J. Traub, 21–39. Academic Press,\n1976.\nB. Reed. Tree width and tangles, a new measure of connectivity and some\napplications. Surveys in Combinatorics , edited by R. Bailey . Cambridge\nUniversity Press, 1997.\nN. Robertson and P. D. Seymour . An outline of a disjoint paths algorithm.\nIn Paths, Flows, and VLSI-Layout , edited by B. Korte et al. Springer -\nVerlag, 1990.\nR. W. Rosenthal . The network equilibrium problem in integers. Networks  3\n(1973), 53–59.\nS. Ross. Introduction to Stochastic Dynamic Programming , Academic\nPress, 1983.\nT. Roughgarden. Selfish Routing. Ph.D. thesis, Cornell University , 2002.\nT. Roughgarden. Selfish Routing and the Price of Anar chy. MIT Press,\n2004.\nS. Russell and P. Norvig. Artificial Intelligence: A Modern Appr oach  (2nd\nedition). Prentice Hall, 2002.\nD. Sankof f. The early introduction of dynamic programming into\ncomputational biology . Bioinformatics  16:1 (2000), 41–47.\nJ. E. Savage. Models of Computation . Addison-W esley , 1998.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 967})","('type', 'Document')"
"('page_content', 'W. Savitch. Relationships between nondeterministic and determ inistic tape\ncomplexities. J. Computer and System Sciences  4 (1970), 177–192.\nT. Schaefer . On the complexity of some two-person perfect-information\ngames. J. Computer and System Sciences  16:2 (April 1978), 185–225.\nT. Schelling. Micr omotives and Macr obehavior . Norton, 1978.\nA. Schrijver . On the history of the transportation and maximum flow\nproblems. Math. Pr ogramming  91 (2002), 437–445.\nR. Seidel. Backwards analysis of randomized geometric algorithms. In New\nTrends in Discr ete and Computa tional Geometry , edited by J. Pach, pp. 37–\n68. Springer -Verlag, 1993.\nM. I. Shamos and D. Hoey . Closest-point problems. Proc. 16th IEEE\nSymposium on Foundations of Computer Science , pp. 151–162, 1975.\nC. E. Shannon and W. Weaver . The Mathematical Theory of\nCommunication . University of Illinois Press, 1949.\nM. Sipser . The history and status of the P versus NP question. Proc. 24th\nACM Symposium on the Theory of Computing , pp. 603–618, 1992.\nD. D. Sleator and R. E. Tarjan . Amortized efficiency of list update and\npaging rules. Communications of the ACM , 28:2 (1985), 202–208.\nM. Smid. Closest-point problems in computational geometry . In Handbook\nof Computational Geometry , edited by J. Rudiger Sack and J. Urrutia, pp.\n877–935. Elsevier Science Publishers, B.V . North-Holland, 1999.\nJ. W. Stewart. BGP4: Inter -Domain Routing in the Internet . Addison-\nWesley , 1998.\nL. Stock meyer and A. K. Chandra. Provably difficult combinatorial games.\nSIAM J. on Computing  8 (1979), 151–174.\nL. Stockmeyer and A. Meyer . Word problems requiring exponential time.\nProc. 5th Annual ACM Symposium on Theory of Computing , pp. 1–9, 1973.\nÉ. Tardos. Network Games. Proc. 36th ACM Symposium on Theory of\nComputing , pp. 341–342, 2004.\nR. E. Tarjan. Data structures and network algorithms. CBMS-NS F Regional\nConfer ence Series in Applied Mathematics  44. Society for Industrial and\nApplied Mathematics, 1983.\nR. E. Tarjan. Algorithmic design. Communications of the ACM , 30:3\n(1987), 204– 212.\nA. Tucker . Coloring a family of circular arcs. SIAM J. Applied\nMathematics , 29:3 (November 1975), 493–502.\nV. Vazirani. Appr oximation Algorithms . Springer -Verlag, 2001.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 968})","('type', 'Document')"
"('page_content', 'O. Veksler . Efficient Graph-Based Energy Minimization Methods in\nComputer V ision. Ph.D. thesis, Cornell University , 1999.\nM. Waterman. Introduction to Computational Biology: Sequences, Maps\nand Genomes . Chapman Hall, 1995.\nD. J. W atts. Six Degr ees: The Science of a Connected Age . Norton, 2002.\nK. Wayne. A new property and faster algorithm for baseball elimination.\nSIAM J. Discr ete Mathematics , 14:2 (2001), 223–229.\nJ. W. J. Williams. Algorithm 232 (Heapsort). Communications of the ACM ,\n7 (1964), 347–348.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 969})","('type', 'Document')"
"('page_content', 'I n d e x\n\xa0\nA page number  ending in ex refers to a topic that is discussed in an\nexercise.\n\xa0\nNumbers  \n3-Coloring Problem  \nNP-completeness, 487–490  \nas optimization problem, 782 ex \n3-Dimensional Matching Problem  \nNP-completeness, 481–485  \npolynomial time approximation algorithm for , 656 ex \nproblem, 481  \n3-SA T Problem, 459–460  \nassignments in, 459, 594–596 ex \nas Constraint Satisfaction Problem, 500  \nin Lecture Planning exercise, 503–504 ex \nMAX-3-SA T \nalgorithm design and analysis for , 725–726  \ngood assignments in, 726–727  \nnotes, 793  \nproblem, 724–725  \nrandom assignment for , 725–726, 787 ex\nNP completeness, 471  \npolynomial space algorithm for , 532  \nQuantified. See QSA T (Quantified 3-SA T)\nreductions in, 459–463  \n4-Dimensional Matching Problem, 507 ex\nA \nAarts, E., 705  \n(a,b)-skeletons, 517–518 ex \nABL (average bits per letter) in encoding, 165  \nAbsolute weight of edges, 671')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 970})","('type', 'Document')"
"('page_content', 'Ad hoc networks, 435–436 ex \nAdaptive compression schemes, 177  \nAdd lists in planning problems, 534, 538  \nAdenine, 273  \nAdjacency lists, 87–89, 93  \nAdjacency matrices, 87–89  \nAdopters in human behaviors, 523 ex \nAds \nadvertising policies, 422–423 ex \nStrategic Advertising Problem, 508–509 ex \nAffiliation network graphs, 76  \nAgglomerative clustering, 159  \nAhuja, Ravindra K., 449–450  \nAirline route maps, 74  \nAirline Scheduling Problem, 387  \nalgorithm for  \nanalyzing, 390–391  \ndesigning, 389–390  \nproblem, 387–389  \nAlignment, sequence. See Sequence alignment  \nAllocation  \nrandom, in load balancing, 761–762  \nregister , 486  \nresource. See Resource allocation  \nAlon, N., 793–794  \nAlternating paths in Bipartite Matching Problem, 370  \nAlthofer , Ingo, 207  \nAmbiguity in Morse code, 163  \nAncestors  \nlowest common, 96  \nin trees, 77  \nAnderber g, M., 206  \nAnnealing, 669–670  \nAnshelevich, E., 706  \nAntigens, blood, 418–419 ex \nApartments, expense sharing in, 429–430 ex \nAppalachian T rail exercise, 183–185 ex')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 971})","('type', 'Document')"
"('page_content', 'Appel, K., 490  \nApproximate medians, 791 ex \nApproximate time-stamps, 196–197 ex \nApproximation algorithms, 599–600  \nin caching, 751  \ngreedy algorithms for  \nCenter Selection Problem, 606–612  \nInterval Scheduling Problem, 649–651 ex \nload balancing, 600–606  \nSet Cover Problem, 612–617  \nKnapsack Problem, 644  \nalgorithm analysis for , 646–647  \nalgorithm design for , 645–646  \nproblem, 644–645  \nlinear programming and rounding. See Linear programming and rounding  \nload balancing, 637  \nalgorithm design and analysis for , 638–643  \nproblem, 637–638  \nMaximum-Cut Problem, 676, 683–684  \nalgorithm analysis for , 677–679  \nalgorithm design for , 676–677  \nfor graph partitioning, 680–681  \nnotes, 659  \npricing methods  \nDisjoint Paths Problem, 624–630  \nVertex Cover Problem, 618–623  \nApproximation thresholds, 660  \nArbitrage opportunities for shortest paths, 291  \nArbitrarily good approximations for Knapsack Problem, 644  \nalgorithms for  \nanalyzing, 646–647  \ndesigning, 645–646  \nproblem, 644–645  \nArborescences, minimum-cost, 1 16, 177  \ngreedy algorithms for  \nanalyzing, 181–183  \ndesigning, 179–181')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 972})","('type', 'Document')"
"('page_content', 'problem, 177–179  \nArc coloring. See Circular -Arc Coloring Problem  \nArithmetic coding, 176  \nArora, S., 660  \nArrays  \nin dynamic programming, 258–259  \nfor heaps, 60–61  \nin Knapsack Problem, 270–271  \nin Stable Matching Algorithm, 42–45  \nfor Union-Find structure, 152–153  \nASCII code, 162  \nAssignment penalty in Image Segmentation Problem, 683  \nAssignments  \n3-SA T, 459, 594–596 ex \nin bipartite matching, 15  \nfor linear equations mod 2, 780–781 ex \nin load balancing, 637  \nfor MAX-3-SA T problem, 725–726, 787 ex \npartial, 591–594 ex \nwavelength, 486  \nAstronomical events, 325–326 ex \nAsymmetric distances in T raveling Salesman Problem, 479  \nAsymmetry of NP , 495–497  \nAsymptotic order of growth, 35–36  \nin common functions, 40–42  \nlower bounds, 37  \nnotes, 70  \nproperties of, 38–40  \ntight bounds, 37–38  \nupper bounds, 36–37  \nAsynchronous algorithms  \nBellman-Ford, 299  \nGale-Shapley , 10 \nAtmospheric science experiment, 426–427 ex \nAttachment costs, 143  \nAuctions  \ncombinatorial, 51 1 ex')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 973})","('type', 'Document')"
"('page_content', 'one-pass, 788–789 ex \nAugment algorithm, 342–343, 346  \nAugmentation along cycles, 643  \nAugmenting paths, 342–343  \nchoosing, 352  \nalgorithm analysis in, 354–356  \nalgorithm design in, 352–354  \nalgorithm extensions in, 356–357  \nfinding, 412 ex \nin Minimum-Cost Perfect Matching Problem, 405  \nin neighbor relations, 680  \nAverage bits per letter (ABL) in encoding, 165  \nAverage-case analysis, 31, 707  \nAverage distances in networks, 109–1 10 ex \nAwerbuch, B., 659  \nAzar , Y., 659\nB \nBack-up sets for networks, 435–436 ex \nBackof f protocols, 793  \nBackward edges in residual graphs, 341–342  \nBackward-Space-Ef ficient-Alignment, 286–287  \nBackwards analysis, 794  \nBacon, Kevin, 448 ex \nBank cards, fraud detection, 246–247 ex \nBar-Yehuda, R., 659  \nBarabasi, A. L., 1 13 \nBarter economies, 521–522 ex \nBase of logarithms, 41  \nBase-pairing in DNA, 273–275  \nBase stations  \nfor cellular phones, 190 ex, 430–431 ex \nfor mobile computing, 417–418 ex \nBaseball Elimination Problem, 400  \nalgorithm design and analysis for , 402–403  \ncharacterization in, 403–404  \nnotes, 449  \nproblem, 400–401')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 974})","('type', 'Document')"
"('page_content', 'Bases, DNA, 273–275  \nBeckmann, M., 706  \nBelady , Les, 133, 206  \nBell, T . C., 206  \nBellman, Richard, 140, 292, 335  \nBellman-Ford algorithm  \nin Minimum-Cost Perfect Matching Problem, 408  \nfor negative cycles in graphs, 301–303  \nfor router paths, 298–299  \nfor shortest paths, 292–295  \nBerge, C., 1 13 \nBerlekamp, E. R., 551  \nBern, M., 659  \nBertsekas, D.  \nbackof f protocols, 793  \nshortest-path algorithm, 336  \nBertsimas, Dimitris, 336  \nBest achievable bottleneck rate, 198–199 ex \nBest-response dynamics, 690, 693–695  \ndefinitions and examples, 691–693  \nNash equilibria and, 696–700  \nnotes, 706  \nproblem, 690–691  \nquestions, 695–696  \nBest valid partners in Gale-Shapley algorithm, 10–1 1 \nBFS (breadth-first search), 79–82  \nfor bipartiteness, 94–96  \nfor directed graphs, 97–98  \nimplementing, 90–92  \nin planning problems, 541  \nfor shortest paths, 140  \nBGP (Border Gateway Protocol), 301  \nBicriteria shortest path problems, 530  \nBidding agents, 789 ex \nBids \nin combinatorial auctions, 51 1 ex \nin one-pass auctions, 788–789 ex')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 975})","('type', 'Document')"
"('page_content', 'Big-improvement-flips, 678  \nBillboard placement, 307–309 ex \nBin-packing, 651 ex \nBinary search  \nin arrays, 44  \nin Center Selection Problem, 610  \nsublinear time in, 56  \nBinary trees  \nnodes in, 108 ex \nfor prefix codes, 166–169  \nBiology  \ngenome mapping, 279, 521 ex, 787 ex \nRNA Secondary Structure Prediction Problem, 272–273  \nalgorithm for , 275–278  \nnotes, 335  \nproblem, 273–275  \nsequences in, 279  \nBipartite graphs, 14–16, 337, 368–370  \n2-colorability of, 487  \nnotes, 449  \ntesting for , 94–96  \nBipartite Matching Problem, 337, 367  \nalgorithm for  \nanalyzing, 369–371  \ndesigning, 368  \nextensions, 371–373  \ncosts in, 404–405  \nalgorithm design and analysis for , 405–410  \nalgorithm extensions for , 410–41 1 \nproblem, 405  \ndescription, 14–16  \nin Hopfield neural networks, 703 ex \nneighbor relations in, 679–680  \nin packet switching, 798  \nproblem, 368  \nBipartiteness testing, breadth-first search for , 94–96  \nBits in encoding, 162–163')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 976})","('type', 'Document')"
"('page_content', 'Blair W itch Pr oject , 183–185 ex \nBlocking  \nin Disjoint Paths Problem, 627  \nin Interval Scheduling Problem, 650 ex \nin packet switching, 798–799  \nBlood types, 418–419 ex \nBoese, K., 207  \nBoies, David, 503 ex \nBollobas, B., 1 13 \nBoolean formulas  \nwith quantification, 534  \nin Satisfiability Problem, 459–460  \nBorder Gateway Protocol (BGP), 301  \nBorodin, Allan  \ncaching, 794  \ngreedy algorithms, 207  \nBottleneck edges, 192 ex \nBottlenecks  \nin augmenting paths, 342–345, 352  \nin communications, 198–199 ex \nBounds  \nin asymptotic order of growth  \nlower , 37 \ntight, 37–38  \nupper , 36–37  \nChernof f, 758–760  \nfor load balancing, 762  \nfor packet routing, 767–769  \nin circulations, 382–384, 414 ex \nin Load Balancing Problem  \nalgorithm analysis for , 601–604  \nalgorithm design for , 601  \nalgorithm extensions for , 604–606  \nproblem, 600  \nBoxes, nesting arrangement for , 434–435 ex \nBoykov , Yuri, 450, 706  \nBreadth-first search (BFS), 79–82')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 977})","('type', 'Document')"
"('page_content', 'for bipartiteness, 94–96  \nfor directed graphs, 97–98  \nimplementing, 90–92  \nin planning problems, 541  \nfor shortest paths, 140  \nBroadcast T ime Problem, 527–528 ex \nBrute-force search  \nand dynamic programming, 252  \nin worst-case running times, 31–32  \nBuffers in packet switching, 796–801  \nButterfly specimens, 107–108 ex\nC \nCache hits and misses, 132–133, 750  \nCache Maintenance Problem  \ngreedy algorithms for  \ndesigning and analyzing, 133–136  \nextensions, 136–137  \nnotes, 206  \nproblem, 131–133  \nCaching  \noptimal  \ngreedy algorithm design and analysis for , 133–136  \ngreedy algorithm extensions for , 136–137  \nproblem, 131–133  \nrandomized, 750–751  \nmarking algorithm for , 753–755  \nnotes, 794  \nproblem, 750–752  \nrandomized algorithm for , 755–758  \nCapacity and capacity conditions  \nin circulation, 380, 383  \nof cuts, 346, 348  \nof edges, 338  \nin integer -valued flows, 351  \nin network models, 338–339  \nof nodes, 420–421 ex \nfor preflows, 357')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 978})","('type', 'Document')"
"('page_content', ""in residual graphs, 342  \nCard guessing  \nwith memory , 721–722  \nwithout memory , 721  \nCarpool scheduling, 431 ex \nCarter , L. J., 794  \nCascade processes, 523 ex \nCellular phone base stations, 190 ex, 430–431 ex \nCenter Selection Problem, 606  \nalgorithms for , 607–612  \nlimits on approximability , 644  \nlocal search for , 700–702 ex \nnotes, 659  \nproblem, 606–607  \nand representative sets, 652 ex \nCentral nodes in flow networks, 429 ex \nCentral splitters  \nin median-finding, 729–730  \nin Quicksort, 732  \nCertifiers, in ef ficient certification, 464  \nChain molecules, entropy of, 547–550 ex \nChandra, A. K., 551  \nChange detection in Segmented Least Squares Problem, 263  \nChangeKey operation  \nfor heaps, 65  \nfor Prim's Algorithm, 150  \nfor shortest paths, 141–142  \nChao, T ., 207  \nCharacter encoding. See Huffman codes  \nCharacter sets, 162  \nCharacterizations  \nnotes, 529  \nin NP and co-NP , 496–497  \nChar ged particles, 247–248 ex \nCheck reconciliation, 430 ex \nCherkassky , Boris V ., 336  \nChernof f, H., 794"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 979})","('type', 'Document')"
"('page_content', 'Chernof f bounds, 758–760  \nfor load balancing, 762  \nfor packet routing, 767–769  \nChernof f-Hoef fding bounds, 794  \nChess, 535  \nChew , L. P ., 794  \nChildren  \nin heaps, 59–61  \nin trees, 77  \nChor , Benny , 794  \nChromatic number . See Coloring Problems  \nChromosomes  \nDNA, 279  \nin genome mapping, 521 ex, 787 ex\nChu, Y . J., 206  \nChuang, S.-T ., 799  \nChvatal, V ., 659  \nCircuit Satisfiability Problem  \nin NP completeness, 466–470  \nrelation to PSP ACE-completeness, 543  \nCircular -Arc Coloring Problem, 563  \nalgorithms for  \nanalyzing, 572  \ndesigning, 566–571  \nnotes, 598  \nproblem, 563–566  \nCirculations  \nin Airline Scheduling Problem, 390  \nwith demands, 379–384, 414 ex \nwith lower bounds, 382–384, 387, 414 ex \nin survey design, 387  \nCitation networks, 75  \nClassification via local search, 681–682\nalgorithm analysis for , 687–689  \nalgorithm design for , 683–687  \nnotes, 706  \nproblem, 682–683')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 980})","('type', 'Document')"
"('page_content', 'Clause gadgets, 483–484  \nClauses with Boolean variables, 459–460  \nCleary , J. G., 206  \nClock signals, 199 ex \nClones ‘R’ Us exercise, 309–31 1 ex \nClose to optimal solutions, 599  \nClosest-Pair algorithm, 230  \nClosest pair of points, 209, 225  \nalgorithm for  \nanalyzing, 231  \ndesigning, 226–230  \nnotes, 249  \nproblem, 226  \nrandomized approach, 741–742  \nalgorithm analysis for , 746–747  \nalgorithm design for , 742–746  \nlinear expected running time for , 748–750  \nnotes, 794  \nproblem, 742  \nrunning time of, 51–52  \nClustering, 157–158  \nformalizing, 158, 515–516 ex \ngreedy algorithms for  \nanalyzing, 159–161  \ndesigning, 157–158  \nnotes, 206  \nproblem, 158  \nCMS (Course Management System), 431–433 ex \nCo-NP , 495–496\nfor good characterization, 496–497  \nin PSP ACE, 532–533  \nCoalition, 500–502 ex \nCobham, A., 70  \nCoherence property , 575  \nCohesiveness of node sets, 444 ex \nCollaborative filtering, 221–222  \nCollecting coupons example, 722–724')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 981})","('type', 'Document')"
"('page_content', 'Collective human behaviors, 522–524 ex \nCollisions in hashing, 736–737  \nColoring problems  \n3-Coloring Problem  \nNP-completeness, 487–490  \nas optimization problem, 782 ex \nCircular -Arc Coloring Problem, 563  \nalgorithm analysis for , 572  \nalgorithm design for , 566–571  \nnotes, 598  \nproblem, 563–566  \nGraph Coloring Problem, 485–486, 499  \nchromatic number in, 597 ex \ncomputational complexity of, 486–487  \nnotes, 529  \nNP-completeness, 487–490  \nfor partitioning, 499  \nCombinatorial auctions, 51 1 ex \nCombinatorial structure of spanning trees, 202–203 ex \nCommon running times, 47–48  \ncubic, 52–53  \nlinear , 48–50  \nO(n log n), 50–51  \nO(nk), 53–54  \nquadratic, 51–52  \nsublinear , 56 \nCommunication networks  \ngraphs as models of, 74–75  \nswitching in, 26–27 ex, 796–804  \nCompatibility  \nof configurations, 516–517 ex \nof labelings and preflows, 358  \nof prices and matchings, 408  \nCompatible intervals, 1 16, 253  \nCompatible requests, 13, 1 16, 1 18–1 19 \nCompetitive 3-SA T game, 544–547  \nCompetitive Facility Location Problem, 17')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 982})","('type', 'Document')"
"('page_content', 'games in, 536–537  \nin PSP ACE completeness, 544–547  \nCompiler design, 486  \nComplementary base-pairing in DNA, 273–275  \nComplementary events, 710  \nComplex plane, 239  \nComplex roots of unity , 239  \nComponent array , 152–153  \nComponent Grouping Problem, 494–495  \nCompression. See Data compression  \nComputational steps in algorithms, 35–36  \nComputational biology  \nRNA Secondary Structure Prediction Problem, 272–273  \nalgorithm for , 275–278  \nnotes, 335  \nproblem, 273–275  \nsequence alignment. See Sequence alignment  \nComputational complexity . See Computational intractability;\nComputational tractability  \nComputational geometry  \nclosest pair of points, 226, 741  \nnotes, 249  \nComputational intractability , 451–452  \nCircuit Satisfiability Problem, 466–470  \nefficient certification in, 463–466  \nGraph Coloring Problem, 485–486  \ncomputational complexity of, 486–487  \nnotes, 529  \nNP-completeness, 487–490  \nnumerical problems, 490  \nin scheduling, 493–494  \nSubset Sum Problem, 491–495  \npartitioning problems, 481–485  \npolynomial-time reductions, 452–454  \nIndependent Set in, 454–456  \nTuring, 473  \nVertex Cover in, 456–459')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 983})","('type', 'Document')"
"('page_content', 'Satisfiability Problem, 459–463  \nsequencing problems, 473–474  \nHamiltonian Cycle Problem, 474–479  \nHamiltonian Path Problem, 480–481  \nTraveling Salesman Problem, 474, 479  \nComputational tractability , 29–30  \nefficiency in, 30–31  \npolynomial time, 32–35  \nworst-case running times, 31–32  \nCompute-Opt algorithm, 255–256  \nComputer game-playing  \nchess, 551  \nPSPACE for , 535–536  \nComputer vision, 226, 391, 681  \nConcatenating sequences, 308–309 ex,517 ex \nConditional expectation, 724  \nConditional probability , 771–772  \nConditions, in planning problems, 534, 538  \nConfigurations  \nin Hopfield neural networks, 671, 676, 700, 702–703 ex \nin planning problems, 538–539  \nConflict graphs, 16  \nConflicts  \nin 3-SA T Problem, 461  \ncontention resolution for , 782–784 ex \nin Interval Scheduling Problem, 1 18 \nCongestion  \nin Minimum Spanning T ree Problem, 150  \nof packet schedule paths, 765  \nConjunction with Boolean variables, 459  \nConnected components, 82–83  \nConnected undirected graphs, 76–77  \nConnectivity in graphs, 76–79  \nbreadth-first search for , 79–82  \nconnected components in, 82–83, 86–87, 94  \ndepth-first search for , 83–86  \ndirected graphs, 97–99')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 984})","('type', 'Document')"
"('page_content', 'Conservation conditions  \nfor flows, 339  \nfor preflows, 357  \nConsistent check reconciliation, 430 ex \nConsistent k-coloring, 569  \nConsistent metrics, 202 ex \nConsistent truth assignment, 592 ex \nConstraint Satisfaction Problems  \nin 3-SA T, 500  \nin Lecture Planning Problem, 503 ex \nConstraints in Linear Programming Problem, 632–634  \nConsumer preference patterns, 385  \nContainer packing, 651 ex \nContention resolution, 708–709  \nalgorithm for  \nanalyzing, 709–714  \ndesigning, 709  \nnotes, 793  \nproblem, 709  \nrandomization in, 782–784 ex \nContext-free grammars, 272  \nContingency planning, 535  \nContraction Algorithm  \nanalyzing, 716–718  \ndesigning, 715–716  \nfor number of global minimum cuts, 718–719  \nControl theory , 335  \nConver gence of probability functions, 71 1 \nConvolutions, 234  \nalgorithms for , 238–242  \ncomputing, 237–238  \nproblem, 234–237  \nConway , J. H., 551  \nCook, S. A., NP-completeness, 467, 529, 543  \nCook reduction, 473  \nCooling schedule in simulated annealing, 669–670  \nCorner -to-corner paths for sequence alignment, 284–285, 287–288')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 985})","('type', 'Document')"
"('page_content', ""Cost function in local search, 663  \nCost-sharing  \nfor apartment expenses, 429–430 ex \nfor edges, 690  \nfor Internet services, 690–700, 785–786 ex \nCoulomb's Law , 247–248 ex \nCounting inversions, 222–223, 246 ex \nCounting to infinity , 300–301  \nCoupon collecting example, 722–724  \nCourse Management System (CMS), 431–433 ex \nCover , T., 206  \nCoverage Expansion Problem, 424–425 ex \nCovering problems, 455–456, 498  \nCovering radius in Center Selection Problem, 607–608, 700–702 ex \nCrew scheduling, 387  \nalgorithm for  \nanalyzing, 390–391  \ndesigning, 389–390  \nproblem, 387–389  \nCrick, F ., 273  \nCross-examination in Lecture Planning Problem, 503 ex \nCryptosystem, 491  \nCubic time, 52–53  \nCushions in packet switching, 801  \nCut Property  \ncharacteristics of, 187–188 ex \nin Minimum Spanning T ree Problem, 146–149  \nCuts. See Minimum cuts  \nCycle Cover Problem, 528 ex \nCycle Property  \ncharacteristics of, 187–188 ex \nin Minimum Spanning T ree Problem, 147–149  \nCytosine, 273\nD \nDAGs (directed acyclic graphs), 99–104  \nalgorithm for , 101–104  \nproblem, 100–101"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 986})","('type', 'Document')"
"('page_content', 'topological ordering in, 104 ex, 107 ex \nDaily Special Scheduling Problem, 526 ex \nDas, Gautam, 207  \nDashes in Morse code, 163  \nData compression, 162  \ngreedy algorithms for  \nanalyzing, 173–175  \ndesigning, 166–173  \nextensions, 175–177  \nnotes, 206  \nproblem, 162–166  \nData mining  \nfor event sequences, 190 ex \nin Segmented Least Squares Problem, 263  \nfor survey design, 385  \nData stream algorithms, 48  \nData structures  \narrays, 43–44  \ndictionaries, 734–735  \nin graph traversal, 90–94  \nfor representing graphs, 87–89  \nhashing, 736–741  \nlists, 44–45  \nnotes, 70  \npriority queues. See Priority queues  \nqueues, 90  \nin Stable Matching Problem, 42–47  \nstacks, 90  \nUnion-Find, 151–157  \nDe Ber g, M., 250  \nDeadlines  \nminimizing lateness, 125–126  \nalgorithm analysis for , 128–131  \nalgorithm design for , 126–128  \nalgorithm extensions for , 131  \nnotes, 206  \nin schedulable jobs, 334 ex')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 987})","('type', 'Document')"
"('page_content', 'in NP-complete scheduling problems, 493, 500  \nDecentralized algorithm for shortest paths, 290–291  \nDecision-making data, 513–514 ex \nDecision problem  \nfor ef ficient certification, 463  \nvs. optimization version, 454  \nDecision variables in W eighted V ertex Cover problem, 634  \nDecisive Subset Problem, 513–514 ex \nDecomposition  \npath, 376  \ntree. See Tree decompositions  \nDeep Blue program  \nin chess matches, 535  \nnotes, 552  \nDegrees  \nof nodes, 88  \nof polynomials, 40  \nDelete lists in planning problems, 534, 538  \nDelete operation  \nfor dictionaries, 735–736, 738  \nfor heaps, 62, 64–65  \nfor linked lists, 44–45  \nDeLillo, Don, 400  \nDemands  \nin circulation, 379–384, 414 ex \nin survey design, 386  \nDemers, Al, 450  \nDemographic groups, advertising policies for , 422–423 ex \nDense subgraphs, 788 ex \nDependencies in directed acyclic graphs, 100  \nDependency networks, graphs for , 76 \nDepth  \nof nodes, 167  \nof sets of intervals, 123–125, 566–567  \nDepth-first search (DFS), 83–86  \nfor directed graphs, 97–98  \nimplementing, 92–94')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 988})","('type', 'Document')"
"('page_content', ""in planning problems, 541  \nDescendants in trees, 77  \nDetermined variables, 591 ex \nDFS. See Depth-first search (DFS)  \nDiagonal entries in matrices, 428 ex \nDiameter of networks, 109–1 10 ex \nDictionaries  \nhashing for , 734  \ndata structure analysis for , 740–741  \ndata structure design for , 735–740  \nproblem, 734–735  \nsequence alignment in, 278–279  \nDiestel, R.  \ngraph theory , 113 \ntree decomposition, 598  \nDifferentiable functions, minimizing, 202 ex, 519–520 ex \nDijkstra, Edsger W ., 137, 206  \nDijkstra's Algorithm  \nin Minimum-Cost Perfect Matching Problem, 408  \nfor paths, 137–141, 143, 290, 298  \nDilation of paths in packet schedules, 765  \nDinitz, A., 357  \nDirected acyclic graphs (DAGs), 99–104  \nalgorithm for , 101–104  \nproblem, 100–101  \ntopological ordering in, 101, 104 ex, 107 ex \nDirected Disjoint Paths Problem. See Disjoint Paths Problem  \nDirected Edge-Disjoint Paths Problem, 374, 624–625  \nDirected edges for graphs, 73  \nDirected graphs, 73  \nconnectivity in, 97–99  \ndisjoint paths in, 373–377  \nrepresenting, 97  \nsearch algorithms for , 97 \nstrongly connected, 77, 98–99  \nWorld W ide W eb as, 75  \nDirected Hopfield networks, 672"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 989})","('type', 'Document')"
"('page_content', 'Discovering nodes, 92  \nDiscrete Fourier transforms, 240  \nDisjoint Paths Problem, 373–374, 624  \nalgorithms for  \nanalyzing, 375–377  \ndesigning, 374–375  \nextensions, 377–378  \ngreedy approximation, 625–627  \ngreedy pricing, 628–630  \nnotes, 449, 659  \nNP-complete version of, 527 ex \nproblem, 374, 624–625  \nfor undirected graphs, 377–378, 597 ex \nDisjunction with Boolean variables, 459  \nDisks in memory hierarchies, 132  \nDistance function  \nin clustering, 158  \nfor biological sequences, 279–280, 652 ex \nDistance vector protocols  \ndescription, 297–300  \nproblems with, 300–301  \nDistances  \nin breadth-first search, 80  \nin Center Selection Problem, 606–607  \nfor closest pair of points, 226, 743–745  \nbetween graph nodes, 77  \nin Minimum Spanning T ree Problem, 150  \nin networks, 109–1 10 ex \nin Traveling Salesman Problem, 479  \nDistinct edge costs, 149  \nDistributed systems, 708  \nDiverse Subset Problem, 505 ex \nDivide-and-Conquer -Alignment algorithm, 288–289  \nDivide-and-conquer approach, 209, 727  \nclosest pair of points, 225  \nalgorithm analysis for , 231  \nalgorithm design for , 226–230')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 990})","('type', 'Document')"
"('page_content', 'convolutions, 234  \nalgorithms for , 238–242  \ncomputing, 237–238  \nproblem, 234–237  \ninteger multiplication, 231  \nalgorithm analysis for , 233–234  \nalgorithm design for , 232–233  \nproblem, 231–232  \ninversions in, 221  \nalgorithms for , 223–225  \nproblem, 221–223  \nlimitations of, 251  \nmedian-finding, 727  \nalgorithm analysis for , 730–731  \nalgorithm design for , 728–730  \nproblem, 727–728  \nMergesort Algorithm, 210–21 1 \napproaches to, 21 1–212  \nsubstitutions in, 213–214  \nunrolling recurrences in, 212–213  \nQuicksort, 731–734  \nrelated recurrences in, 220–221  \nsequence alignment  \nalgorithm analysis for , 282–284  \nalgorithm design for , 281–282  \nproblem, 278–281  \nsubproblems in, 215–220  \nDNA, 273–275  \ngenome mapping, 521 ex \nRNA. See RNA Secondary Structure Prediction Problem  \nsequence alignment for , 279  \nDobkin, David, 207  \nDoctors W ithout W eekends, 412–414 ex, 425–426 ex \nDomain Decomposition Problem, 529 ex \nDominating Set Problem  \nMinimum-Cost, 597 ex \nin wireless networks, 776–779 ex')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 991})","('type', 'Document')"
"('page_content', 'definition, 519 ex \nDormant nodes in negative cycle detection, 306  \nDots in Morse code, 163  \nDoubly linked lists, 44–45  \nDouglas, Michael, 1 15 \nDowney , R., 598  \nDownstream nodes in flow networks, 429 ex \nDownstream points in communications networks, 26–27 ex \nDreyfus, S., 336  \nDrezner , Z., 551, 659  \nDroid T rader! game, 524 ex \nDubes, R., 206  \nDuda, R., 206  \nDuration of packet schedules, 765  \nDyer , M. E., 659  \nDynamic programming, 251–252  \nfor approximation, 600  \nfor Circular -Arc Coloring, 569–571  \nin interval scheduling, 14  \nover intervals, 272–273  \nalgorithm for , 275–278  \nproblem, 273–275  \nfor Knapsack Problem, 266–267, 645, 648  \nalgorithm analysis for , 270–271  \nalgorithm design for , 268–270  \nalgorithm extension for , 271–272  \nfor Maximum-W eight Independent Set Problem, 561–562  \nnotes, 335  \nin planning problems, 543  \nprinciples of, 258–260  \nSegmented Least Squares Problem, 261  \nalgorithm analysis for , 266  \nalgorithm design for , 264–266  \nproblem, 261–264  \nfor sequence alignment. See Sequence alignment  \nfor shortest paths in graphs. See Shortest Path Problem  \nusing tree decompositions, 580–584')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 992})","('type', 'Document')"
"('page_content', 'Weighted Interval Scheduling Problem, 252  \nalgorithm design, 252–256  \nmemoized recursion, 256–257\nE \nEarliest Deadline First algorithm, 127–128  \nEdahiro, M., 207  \nEdge congestion, 150  \nEdge costs  \ndistinct, 149  \nin Minimum Spanning T ree Problem, 143  \nsharing, 690  \nEdge-disjoint paths, 374–376, 624–625  \nEdge lengths in shortest paths, 137, 290  \nEdge-separation property , 575–577  \nEdges  \nbottleneck, 192 ex \ncapacity of, 338  \nin graphs, 13, 73–74  \nin Minimum Spanning T ree Problem, 142–150  \nin n-node trees, 78  \nreduced costs of, 409  \nEdmonds, Jack  \ngreedy algorithms, 207  \nminimum-cost arborescences, 126  \nNP-completeness, 529  \npolynomial-time solvability , 70 \nstrongly polynomial algorithms, 357  \nEfficiency  \ndefining, 30–31  \nof polynomial time, 32–35  \nof pseudo-polynomial time, 271  \nEfficient certification in NP- completeness, 463–466  \nEfficient Recruiting Problem, 506 ex \nEl Goog, 191–192 ex \nEl-Yaniv, R., 794\nElectoral districts, gerrymandering in, 331–332 ex \nElectromagnetic observation, 512–513 ex')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 993})","('type', 'Document')"
"('page_content', 'Electromagnetic pulse (EMP), 319–320 ex \nEncoding. See Huffman codes  \nEnds of edges, 13, 73  \nEntropy of chain molecules, 547–550 ex \nEnvironment statistics, 440–441 ex \nEppstein, D., 659  \nEquilibrium  \nNash. See Nash equilibria  \nof prices and matchings, 41 1 \nErenrich, Jordan, 450  \nErgonomics of floor plans, 416–417 ex \nError of lines, 261–262  \nEscape Problem, 421 ex \nEuclidean distances  \nin Center Selection Problem, 606–607  \nin closest pair of points, 226, 743–745  \nEuler , Leonhard, 1 13 \nEvasive Path Problem, 510–51 1 ex \nEven, S., 659  \nEvents  \nin contention resolution, 709–712  \nindependent, 771–772  \nin infinite sample spaces, 775  \nin probability , 769–770  \nEviction policies and schedules  \nin optimal caching, 132–133  \nin randomized caching, 750–751  \nExcess of preflows, 358  \nExchange ar guments  \nin greedy algorithms, 1 16, 128–131  \nin Minimum Spanning T ree Problem, 143  \nin optimal caching, 131–137  \nfor prefix codes, 168–169  \nproving, 186 ex \nExpectation Maximization approach, 701 ex \nExpectation, 708  \nconditional, 724')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 994})","('type', 'Document')"
"('page_content', ""linearity of, 720–724  \nof random variables, 719–720, 758–762  \nExpected running time  \nfor closest pair of points, 748–750  \nfor median-finding, 729–731  \nfor Quicksort, 732–733  \nExpected value in voting, 782 ex \nExpenses, sharing  \napartment, 429–430 ex \nInternet services, 690–700, 785–786 ex\nExploring nodes, 92  \nExponential functions in asymptotic bounds, 42  \nExponential time, 54–56, 209, 491  \nExtractMin operation  \nfor heaps, 62, 64  \nfor Prim's Algorithm, 150  \nfor shortest paths, 141–142\nF \nFacility Location Problem  \ngames in, 536–537  \nin PSP ACE completeness, 544–547  \nfor W eb servers, 658–659 ex \nFactorial growth of search space, 55  \nFactoring, 491  \nFailure events, 71 1–712  \nFair driving schedules, 431 ex \nFair prices, 620–621  \nFano, Robert M., 169–170, 206  \nFarthest-in-Future algorithm, 133–136, 751  \nFast Fourier T ransform (FFT), 234  \nfor convolutions, 238–242  \nnotes, 250  \nFCC (Fully Compatible Configuration) Problem, 516–517 ex \nFeasible assignments in load balancing, 637  \nFeasible circulation, 380–384  \nFeasible sets of projects, 397  \nFeedback, stream ciphers with, 792 ex"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 995})","('type', 'Document')"
"('page_content', 'Feedback sets, 520 ex \nFeller , W., 793  \nFellows, M., 598  \nFFT (Fast Fourier T ransform), 234  \nfor convolutions, 238–242  \nnotes, 250  \nFiat, A., 794  \nFiction, hypertext, 509–510 ex \nFIFO (first-in, first-out) order , 90 \nFifteen-puzzle, 534  \nFiltering, collaborative, 221–222  \nFinancial trading cycles, 324 ex \nFind operation in Union-Find structure, 151–156  \nFind-Solution algorithm, 258–259  \nFindMin operation, 64  \nFinite probability spaces, 769–771  \nFirst-in, first-out (FIFO) order , 90 \nFixed-length encoding, 165–166  \nFlooding, 79, 140–141  \nFloor plans, er gonomics of, 416–417 ex \nFlows. See Network flows  \nFloyd, Robert W ., 70 \nFood webs, 76  \nForbidden pairs in Stable Matching Problem, 19–20 ex \nForcing partial assignment, 592–593 ex \nFord,L.R.  \ndynamic programming, 292  \nflow, 344, 448  \nshortest paths, 140, 335  \nFord-Fulkerson Algorithm, 344–346  \naugmenting paths in, 352, 356  \nfor disjoint paths, 376  \nflow and cuts in, 346–352  \nfor maximum matching, 370  \nneighbor relations in, 680  \nvs. Preflow-Push algorithm, 359  \nForeground/background segmentation, 391–392')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 996})","('type', 'Document')"
"('page_content', 'algorithm for , 393–395  \nlocal search, 681–682  \nproblem, 392–393  \ntool design for , 436–438 ex \nForests, 559  \nFormatting in pretty-printing, 317–319 ex \nForward edges in residual graphs, 341–342  \nFour-Color Conjecture, 485, 490\nFraud detection, 246–247 ex \nFree ener gy of RNA molecules, 274  \nFree-standing subsets, 444 ex \nFrequencies of letters in encoding, 163, 165–166  \nFresh items in randomized marking algorithm, 756–757  \nFrieze, A. M., 659  \nFulkerson, D. R., 344, 448  \nFull binary trees, 168  \nFully Compatible Configuration (FCC) Problem, 516–517 ex \nFunnel-shaped potential ener gy landscape, 662–663\nG \nG-S (Gale-Shapley) algorithm, 6  \nanalyzing, 7–9  \ndata structures in, 43  \nextensions to, 9–12  \nin Stable Matching Problem, 20–22 ex \nGadgets  \nin 3-Dimensional Matching Problem, 482–484  \nin Graph Coloring Problem, 487–490  \nin Hamiltonian Cycle Problem, 475–479  \nin PSP ACE-completeness reductions, 546  \nin SA T problems, 459–463  \nGalactic Shortest Path Problem, 527 ex \nGale, David, 1–3, 28  \nGale-Shapley (G-S) algorithm, 6  \nanalyzing, 7–9  \ndata structures in, 43  \nextensions to, 9–12  \nin Stable Matching Problem, 20–22 ex')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 997})","('type', 'Document')"
"('page_content', 'Gallager , R. \nbackof f protocols, 793  \nshortest-path algorithm, 336  \nGambling model, 792 ex \nGame theory , 690  \ndefinitions and examples, 691–693  \nand local search, 693–695  \nNash equilibria in, 696–700  \nquestions, 695–696  \nnotes, 706  \nGames  \nDroid T rader!, 524 ex \nGeography , 550–551 ex \nnotes, 551  \nPSPACE, 535–538, 544–547  \nGaps  \nin Preflow-Push Algorithm, 445 ex \nin sequences, 278–280  \nGardner , Martin, 794  \nGarey , M., 529  \nGaussian elimination, 631  \nGaussian smoothing, 236  \nGeiger , Davi, 450  \nGelatt, C. D., Jr ., 669, 705  \nGeneralized Load Balancing Problem  \nalgorithm design and analysis for , 638–643  \nnotes, 660  \nGenomes  \nmapping, 521 ex, 787 ex \nsequences in, 279  \nGeographic information systems, closest pair of points in, 226  \nGeography game, 550–551 ex \nGeometric series in unrolling recurrences, 219  \nGerrymandering, 331–332 ex \nGhallab, Malik, 552  \nGibbs-Boltzmann function, 666–667  \nGlobal minimum cuts, 714')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 998})","('type', 'Document')"
"('page_content', 'algorithm for  \nanalyzing, 716–718  \ndesigning, 715–716  \nnumber of, 718–719  \nproblem, 714–715  \nGlobal minima in local search, 662  \nGoal conditions in planning problems, 534  \nGoel, A., 799  \nGoemans, M. X., 659  \nGoldber g, Andrew V . \nPreflow-Push Algorithm, 449  \nshortest-path algorithm, 336  \nGolin, M., 794  \nGolovin, Daniel, 530  \nGolumbic, Martin C., 1 13, 205  \nGood characterizations  \nnotes, 529  \nin NP and co-NP , 496–497  \nGorbunov , K. Y u., 598  \nGradient descents in local search, 665–666, 668  \nGraham, R. L.  \ngreedy algorithms, 659  \nminimum spanning tree, 206  \nGranovetter , Mark, 522 ex \nGraph Coloring Problem, 485–486, 499  \nchromatic number in, 597 ex \ncomputational complexity of, 486–487  \nnotes, 529  \nNP-completeness, 487–490  \nfor partitioning, 499  \nGraph partitioning  \nlocal search for , 680–681  \nnotes, 705  \nGraphics  \nclosest pair of points in, 226  \nhidden surface removal in, 248 ex \nGraphs, 12–13, 73–74')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 999})","('type', 'Document')"
"('page_content', 'bipartite, 14–16, 337, 368–370  \n2-colorable, 487  \nbipartiteness of, 94–96  \nnotes, 449  \nbreadth-first search in, 90–92  \nconnectivity in, 76–79  \nbreadth-first search in, 79–82  \nconnected components in, 82–83, 86–87, 94  \ndepth-first search in, 83–86  \ndepth-first search in, 92–94  \ndirected. See Directed graphs  \ndirected acyclic (DAGs), 99–104  \nalgorithm for , 101–104  \nproblem, 100–101  \ntopological ordering in, 101, 104 ex,107 ex \nexamples of, 74–76  \ngrid \ngreedy algorithms for , 656–657 ex \nlocal minima in, 248–249 ex \nfor sequence alignment, 283–284  \npaths in, 76–77  \nqueues and stacks for traversing, 89–90  \nrepresenting, 87–89  \nshortest paths in. See Shortest Path Problem  \ntopological ordering in, 101–104  \nalgorithm design and analysis for , 101–104  \nin DAGs, 104 ex,107 ex \nproblem, 100–101  \ntrees. See Trees \nGreedy algorithms, 1 15–1 16 \nfor Appalachian T rail exercise, 183–185 ex \nfor approximation, 599  \nCenter Selection Problem, 606–612  \nload balancing, 600–606  \nSet Cover Problem, 612–617  \nShortest-First, 649–651 ex \nfor clustering')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1000})","('type', 'Document')"
"('page_content', 'analyzing, 159–161  \ndesigning, 157–158  \nfor data compression, 161–166  \nanalyzing, 173–175  \ndesigning, 166–173  \nextensions, 175–177  \nfor Interval Scheduling Problem, 14, 1 16 \nanalyzing, 1 18–121  \ndesigning, 1 16–1 18 \nextensions, 121–122  \nfor Interval Coloring, 121–125  \nlimitations of, 251  \nfor minimizing lateness, 125–126  \nanalyzing, 128–131  \ndesigning, 126–128  \nextensions, 131  \nfor minimum-cost arborescences, 177–179  \nanalyzing, 181–183  \ndesigning, 179–181  \nfor Minimum Spanning T ree Problem, 142–143  \nanalyzing, 144–149  \ndesigning, 143–144  \nextensions, 150–151  \nfor NP-hard problems on trees, 558–560  \nfor optimal caching, 131–133  \ndesigning and analyzing, 133–136  \nextensions, 136–137  \npricing methods in Disjoint Paths Problem, 624  \nanalyzing, 626, 628–630  \ndesigning, 625–626, 628  \nproblem, 624–625  \nShortest-First, 649–651 ex \nfor shortest paths, 137  \nanalyzing, 138–142  \ndesigning, 137–138  \nGreedy-Balance algorithm, 601–602  \nGreedy-Disjoint-Paths algorithm, 626')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1001})","('type', 'Document')"
"('page_content', ""Greedy-Paths-with-Capacity algorithm, 628–630  \nGreedy-Set-Cover algorithm, 613–616  \nGreig, D., 449  \nGrid graphs  \ngreedy algorithms for , 656–657 ex \nlocal minima in, 248–249 ex \nfor sequence alignment, 283–284  \nGroup decision-making data, 513–514 ex \nGrowth order , asymptotic, 35–36  \nin common functions, 40–42  \nlower bounds, 37  \nnotes, 70  \nproperties of, 38–40  \ntight bounds, 37–38  \nupper bounds, 36–37  \nGuanine, 273  \nGuaranteed close to optimal solutions, 599  \nGuessing cards  \nwith memory , 721–722  \nwithout memory , 721  \nGusfield, D. R.  \nsequence analysis, 335  \nstable matching, 28  \nGuthrie, Francis, 485  \nGuy, R. K., 551\nH \nHaken, W ., 490  \nHall, L., 659–660  \nHall, P ., 449  \nHall's Theorem, 372  \nand Menger's Theorem, 377  \nnotes, 449  \nfor NP and co-NP , 497  \nHamiltonian Cycle Problem, 474  \ndescription, 474–475  \nNP-completeness of, 475–479  \nHamiltonian Path Problem, 480"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1002})","('type', 'Document')"
"('page_content', ""NP-completeness of, 480–481  \nrunning time of, 596 ex \nHard problems. See Computational intractability; NP-hard problems  \nHarmonic numbers  \nin card guessing, 722  \nin Nash equilibrium, 695  \nHart, P ., 206  \nHartmanis, J., 70  \nHash functions, 736–737  \ndesigning, 737–738  \nuniversal classes of, 738–740, 749–750  \nHash tables, 736–738, 760  \nHashing, 734  \nfor closest pair of points, 742, 749–750  \ndata structures for analyzing, 740–741  \ndesigning, 735–740  \nfor load balancing, 760–761  \nnotes, 794  \nproblem, 734–735  \nHaykin, S., 705  \nHead-of-line blocking in packet switching, 798–799  \nHeads of edges, 73  \nHeap order , 59–61  \nHeapify-down operation, 62–64  \nHeapify-up operation, 60–62, 64  \nHeaps, 58–60  \noperations for , 60–64  \nfor priority queues, 64–65  \nfor Dijkstra's Algorithm, 142  \nfor Prim's Algorithm, 150  \nHeights of nodes, 358–359  \nHell, P ., 206  \nHidden surface removal, 248 ex \nHierarchical agglomerative clustering, 159  \nHierarchical metrics, 201 ex \nHierarchies  \nmemory , 131–132"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1003})","('type', 'Document')"
"('page_content', 'in trees, 78  \nHigh-Score-on-Droid-T rader! Problem (HSoDT!), 525 ex \nHighway billboard placement, 307–309 ex \nHill-climbing algorithms, 703 ex \nHirschber g, Daniel S., 206  \nHistograms with convolution, 237  \nHitting Set Problem  \ndefined, 506–507 ex \noptimization version, 653 ex \nset size in, 594 ex \nHo, J., 207  \nHochbaum, Dorit, 659–660  \nHoef fding, H., 794  \nHoey , D., 226  \nHoffman, Alan, 449  \nHopcroft, J., 70  \nHopfield neural networks, 671  \nalgorithms for  \nanalyzing, 674–675  \ndesigning, 672–673  \nnotes, 705  \nproblem, 671–672  \nstable configurations in, 676, 700, 702–703 ex \nHospital resident assignments, 23–24 ex \nHouses, floor plan er gonomics for , 416–417 ex \nHSoDT! (High-Score-on-Droid- T rader! Problem), 525 ex \nHsu, Y ., 207  \nHuffman, David A., 170, 206  \nHuffman codes, 1 16, 161  \ngreedy algorithms for  \nanalyzing, 173–175  \ndesigning, 166–173  \nextensions, 175–177  \nnotes, 206  \nproblem, 162–166  \nHuman behaviors, 522–524 ex')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1004})","('type', 'Document')"
"('page_content', 'Hyperlinks in W orld W ide W eb, 75  \nHypertext fiction, 509–510 ex\nI \nIbarra, Oscar H., 660  \nIdentifier Selection Problem, 770  \nIdle time in minimizing lateness, 128–129  \nImage Segmentation Problem, 391–392  \nalgorithm for , 393–395  \nwith depth, 437–438 ex \nlocal search, 681–682  \nproblem, 392–393  \ntool design for , 436–438 ex \nImplicit labels, 248 ex \nInapproximability , 660  \nIndependent events, 709–710, 771–772  \nIndependent random variables, 758  \nIndependent Set Problem, 16–17, 454  \n3-SA T reduction to, 460–462  \ncontention resolution with, 782–784 ex \nwith Interval Scheduling Problem, 16, 505 ex \nnotes, 205  \nin O(nk) time, 53–54  \nin a path, 312–313 ex \nin polynomial-time reductions, 454–456  \nrunning times of, 54–55  \nusing tree decompositions, 580–584  \nrelation to V ertex Cover , 455–456, 619  \nIndependent sets  \nfor grid graphs, 657 ex \nin packing problems, 498  \nstrongly , 519 ex \nin trees, 558–560  \nIndif ferences in Stable Matching Problem, 24–25 ex \nInequalities  \nlinear  \nin Linear Programming Problem, 631  \nfor load balancing, 638')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1005})","('type', 'Document')"
"('page_content', 'for V ertex Cover Problem, 634  \ntriangle, 203 ex, 334–335 ex \nInfinite capacities in Project Selection Problem, 397  \nInfinite sample spaces, 774–776  \nInfluence Maximization Problem, 524 ex \nInformation networks, graphs for , 75 \nInformation theory  \nfor compression, 169  \nnotes, 206  \nInitial conditions in planning problems, 534, 538  \nInput buf fers in packet switching, 797–801  \nInput cushions in packet switching, 801  \nInput/output queueing in packet switching, 797  \nInsert operation  \nfor closest pair of points, 746–747  \nfor dictionaries, 734–736  \nfor heaps, 64  \nfor linked lists, 44–45  \nInstability in Stable Matching Problem, 4, 20–25 ex \nInteger multiplication, 209, 231  \nalgorithm for  \nanalyzing, 233–234  \ndesigning, 232–233  \nnotes, 250  \nproblem, 231–232  \nInteger programming  \nfor approximation, 600, 634–636  \nfor load balancing, 638–639  \nfor V ertex Cover Problem, 634  \nInteger Programming Problem, 633–635  \nInteger -valued circulations, 382  \nInteger -valued flows, 351  \nInterference-free schedules, 105 ex \nInterference in Nearby Electromagnetic Observation Problem, 512–513 ex \nInterior point methods in linear programming, 633  \nInterleaving signals, 329 ex \nInternal nodes in network models, 339')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1006})","('type', 'Document')"
"('page_content', 'Internet routers, 795  \nInternet routing  \nnotes, 336  \nshortest paths in, 297–301  \nInternet services, cost-sharing for , 690–700, 785–786 ex \nInterpolation of polynomials, in Fast Fourier T ransform, 238, 241–242  \nIntersection Interface Problem, 513 ex \nInterval Coloring Problem, 122–125, 566  \nfrom Circular -Arc Coloring Problem, 566–569  \nnotes, 598  \nInterval graphs, 205  \nInterval Partitioning Problem, 122–125, 566  \nInterval Scheduling Problem, 13–14, 1 16 \ndecision version of, 505 ex \ngreedy algorithms for , 116 \nfor Interval Coloring, 121–125  \nanalyzing, 1 18–121  \ndesigning, 1 16–1 18 \nextensions, 121–122  \nMultiple Interval Scheduling, 512 ex \nnotes, 206  \nfor processors, 197 ex \nShortest-First greedy algorithm for , 649–651 ex\nIntervals, dynamic programming over  \nalgorithm for , 275–278  \nproblem, 273–275  \nInventory problem, 333 ex \nInverse Ackermann function, 157  \nInversions  \nalgorithms for counting, 223–225  \nin minimizing lateness, 128–129  \nproblem, 221–223  \nsignificant, 246 ex \nInvestment simulation, 244–246 ex \nIrving, R. W ., 28 \nIshikawa, Hiroshi, 450  \nIterative-Compute-Opt algorithm, 259')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1007})","('type', 'Document')"
"('page_content', 'Iterative procedure  \nfor dynamic programming, 258–260  \nfor W eighted Interval Scheduling Problem, 252\nJ \nJagged funnels in local search, 663  \nJain, A., 206  \nJars, stress-testing, 69–70 ex \nJensen, T . R., 529, 598  \nJobs \nin Interval Scheduling, 1 16 \nin load balancing, 600, 637–638, 789–790 ex \nin Scheduling to Minimize Lateness, 125-126  \nin Scheduling with Release T imes and Deadlines, 493  \nJohnson, D. S.  \ncircular arc coloring, 529  \nMAX-SA T algorithm, 793  \nNP-completeness, 529  \nSet Cover algorithm, 659  \nJordan, M., 598  \nJoseph, Deborah, 207  \nJunction boxes in communications networks, 26–27 ex\nK \nK-clustering, 158  \nK-coloring, 563, 569–570  \nK-flip neighborhoods, 680  \nK-L (Kernighan-Lin) heuristic, 681\nKahng, A., 207  \nKaratsuba, A., 250  \nKarger, David, 715, 790 ex, 793  \nKarmarkar , Narendra, 633  \nKarp, R. M.  \naugmenting paths, 357  \nNP-completeness, 529  \nRandomized Marking algorithm, 794  \nKarp reduction, 473  \nKasparov , Garry , 535  \nKempe, D., 530')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1008})","('type', 'Document')"
"('page_content', ""Kernighan, B., 681, 705  \nKernighan-Lin (K-L) heuristic, 681\nKeshav , S., 336  \nKeys  \nin heaps, 59–61  \nin priority queues, 57–58  \nKhachiyan, Leonid, 632  \nKim, Chul E., 660  \nKirkpatrick, S., 669, 705  \nKleinber g, J., 659  \nKnapsack algorithm, 266–267, 648–649  \nKnapsack-Approx algorithm, 646–647  \nKnapsack Problem, 266–267, 499  \nalgorithms for  \nanalyzing, 270–271  \ndesigning, 268–270  \nextensions, 271–272  \napproximations, 644  \nalgorithm analysis in, 646–647  \nalgorithm design in, 645–646  \nproblem, 644–645  \ntotal weights in, 657–658 ex \nnotes, 335, 529  \nKnuth, Donald E., 70, 336  \nrecurrences, 249–250  \nstable matching, 28  \nKolmogorov , Vladimir , 449  \nKönig, D., 372, 449  \nKorte, B., 659  \nKruskal's Algorithm, 143–144  \nwith clustering, 159–160  \ndata structures for  \npointer -based, 154–155  \nsimple, 152–153  \nimprovements, 155–157  \noptimality of, 146–147  \nproblem, 151–152"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1009})","('type', 'Document')"
"('page_content', 'valid execution of, 193 ex \nKumar , Amit, 598\nL \nLabeling Problem  \nvia local search, 682–688  \nnotes, 706  \nLabels and labeling  \ngap labeling, 445 ex \nimage, 437–438 ex \nin image segmentation, 393  \nin Preflow-Push Algorithm, 360–364, 445 ex \nLandscape in local search, 662  \nconnections to optimization, 663–664  \nnotes, 705  \npotential ener gy, 662–663  \nVertex Cover Problem, 664–666  \nLaptops on wireless networks, 427–428 ex \nLast-in, first-out (LIFO) order , 90 \nLateness, minimizing, 125–126  \nalgorithms for  \nanalyzing, 128–131  \ndesigning, 126–128  \nextensions for , 131  \nnotes, 206  \nin schedulable jobs, 334 ex \nLawler , E. L.  \nmatroids, 207  \nNP-completeness, 529  \nscheduling, 206  \nLayers in breadth-first search, 79–81  \nLeast-Recently-Used (LRU) principle  \nin caching, 136–137, 751–752  \nnotes, 794  \nLeast squares, Segmented Least Squares Problem, 261  \nalgorithm for  \nanalyzing, 266  \ndesigning, 264–266')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1010})","('type', 'Document')"
"('page_content', 'notes, 335  \nproblem, 261–264  \nLeaves and leaf nodes, in trees, 77, 559  \nLecture Planning Problem, 502–505 ex \nLEDA (Library of Ef ficient Algorithms and Datastructures), 71  \nLee, Lillian, 336  \nLeighton, F . T., 765, 794  \nLelewer , Debra, 206  \nLengths  \nof edges and paths in shortest paths, 137, 290  \nof paths in Disjoint Paths Problem, 627–628  \nof strings, 463  \nLenstra, J. K.  \nlocal search, 705  \nrounding algorithm, 660  \nscheduling, 206  \nLevin, L., 467, 529, 543  \nLibrary of Ef ficient Algorithms and Datastructures (LEDA), 71  \nLicenses, software, 185–187 ex \nLIFO (last-in, first-out) order , 90 \nLight fixtures, er gonomics of, 416–417 ex \nLikelihood in image segmentation, 393  \nLimits on approximability , 644  \nLin, S., 681, 705  \nLine of best fit, 261–262  \nLinear equations  \nmod 2, 779–782 ex \nsolving, 631  \nLinear programming and rounding, 630–631  \nfor approximation, 600  \ngeneral techniques, 631–633  \nInteger Programming Problem, 633–635  \nfor load balancing, 637  \nalgorithm design and analysis for , 638–643  \nproblem, 637–638  \nnotes, 659–660  \nfor V ertex Cover , 635–637')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1011})","('type', 'Document')"
"('page_content', 'Linear Programming Problem, 631–632  \nLinear space, sequence alignment in, 284  \nalgorithm design for , 285–288  \nproblem, 284–285  \nLinear time, 48–50  \nfor closest pair of points, 748–750  \ngraph search, 87  \nLinearity of expectation, 720–724  \nLinked lists, 44–45  \nLinked sets of nodes, 585–586  \nLists  \nadjacency , 87–89, 93  \nmerging, 48–50  \nin Stable Matching Algorithm, 42–45  \nLiu, T . H., 206  \nLlewellyn, Donna, 250  \nLo, Andrew , 336  \nLoad balancing  \ngreedy algorithm for , 600–606  \nlinear programming for , 637  \nalgorithm design and analysis for , 638–643  \nproblem, 637–638  \nrandomized algorithms for , 760–762  \nLocal minima in local search, 248–249 ex, 662, 665  \nLocal optima  \nin Hopfield neural networks, 671  \nin Labeling Problem, 682–689  \nin Maximum-Cut Problem, 677–678  \nLocal search, 661–662  \nbest-response dynamics as, 690, 693–695  \ndefinitions and examples, 691–693  \nNash equilibria in, 696–700  \nproblem, 690–691  \nquestions, 695–696  \nclassification via, 681–682  \nalgorithm analysis for , 687–689  \nalgorithm design for , 683–687')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1012})","('type', 'Document')"
"('page_content', 'notes, 706  \nproblem, 682–683  \nHopfield neural networks, 671  \nalgorithm analysis for , 674–675  \nalgorithm design for , 672–673  \nlocal optima in, 671  \nproblem, 671–672  \nfor Maximum-Cut Problem approximation, 676–679  \nMetropolis algorithm, 666–669  \nneighbor relations in, 663–664, 679–681  \nnotes, 660  \noptimization problems, 662  \nconnections to, 663–664  \npotential ener gy, 662–663  \nVertex Cover Problem, 664–666  \nsimulated annealing, 669–670  \nLocality of reference, 136, 751  \nLocation problems, 606, 659  \nLogarithms in asymptotic bounds, 41  \nLombardi, Mark, 1 10 ex \nLookup operation  \nfor closest pair of points, 748–749  \nfor dictionaries, 735–736, 738  \nLoops, running time of, 51–53  \nLovász, L., 659  \nLow-Diameter Clustering Problem, 515–516 ex \nLower bounds  \nasymptotic, 37  \ncirculations with, 382–384, 387, 414 ex \nnotes, 660  \non optimum for Load Balancing Problem, 602–603  \nLowest common ancestors, 96  \nLRU (Least-Recently-Used) principle  \nin caching, 136–137, 751–752  \nnotes, 794  \nLuby , M., 794  \nLund, C., 660')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1013})","('type', 'Document')"
"('page_content', 'M \nM-Compute-Opt algorithm, 256–257  \nMaggs, B. M., 765, 794  \nMagnanti, Thomas L., 449–450  \nMagnets, refrigerator , 507–508 ex \nMain memory , 132  \nMakeDictionary operation  \nfor closest pair of points, 745–746  \nfor hashing, 734  \nMakespans, 600–605, 654 ex \nMakeUnionFind operation, 152–156  \nManber , Udi, 450  \nMapping genomes, 279, 521 ex, 787 ex \nMaps of routes for transportation networks, 74  \nMargins in pretty-printing, 317–319 ex \nMarketing, viral, 524 ex \nMarking algorithms for randomized caching, 750, 752–753  \nanalyzing, 753–755  \nnotes, 794  \nrandomized, 755–758  \nMartello, S., 335, 529  \nMatching, 337  \n3-Dimensional Matching Problem  \nNP-completeness, 481–485  \npolynomial time in, 656 ex \nproblem, 481  \n4-Dimensional Matching Problem, 507 ex \nbase-pair , 274  \nin bipartite graphs. See Bipartite Matching Problem  \nin load balancing, 638  \nMinimum-Cost Perfect Matching Problem, 405–406  \nalgorithm design and analysis for , 405–410  \neconomic interpretation of, 410–41 1 \nnotes, 449  \nin packet switching, 798, 801–803  \nin sequences, 278–280  \nin Stable Matching Problem. See Stable Matching Problem')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1014})","('type', 'Document')"
"('page_content', 'Mathews, D. H., 335  \nMatrices  \nadjacency , 87–89  \nentries in, 428 ex \nin linear programming, 631–632  \nMatroids, 207  \nMAX-3-SA T \nalgorithm design and analysis for , 725–726  \ngood assignments for , 726–727  \nnotes, 793  \nproblem, 724–725  \nrandom assignment for , 725–726, 787 ex\nMax-Flow Min-Cut Theorem, 348–352  \nfor Baseball Elimination Problem, 403  \nfor disjoint paths, 376–377  \ngood characterizations via, 497  \nwith node capacities, 420–421 ex \nMaximum 3-Dimensional Matching Problem, 656 ex \nMaximum, computing in linear time, 48  \nMaximum-Cut Problem in local search, 676, 683  \nalgorithms for  \nanalyzing, 677–679  \ndesigning, 676–677  \nfor graph partitioning, 680–681  \nMaximum Disjoint Paths Problem, 624  \ngreedy approximation algorithm for , 625–627  \npricing algorithm for , 628–630  \nproblem, 624–625  \nMaximum-Flow Problem  \nalgorithm for  \nanalyzing, 344–346  \ndesigning, 340–344  \nextensions, 378–379  \ncirculations with demands, 379–382  \ncirculations with demands and lower bounds, 382–384  \nwith node capacities, 420–421 ex \nnotes, 448')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1015})","('type', 'Document')"
"('page_content', ""problem, 338–340  \nMaximum Matching Problem. See Bipartite Matching Problem  \nMaximum spacing, clusterings of, 158–159  \nMaximum-W eight Independent Set Problem  \nusing tree decompositions, 572, 580–584  \non trees, 560–562  \nMaze-Solving Problem, 78–79  \nMcGeoch, L. A., 794  \nMcGuire, C. B., 706  \nMcKeown, N., 799  \nMedian-finding, 209, 727  \nalgorithm for  \nanalyzing, 730–731  \ndesigning, 728–730  \napproximation for , 791 ex \nproblem, 727–728  \nMedical consulting firm, 412–414 ex, 425–426 ex \nMehlhorn, K., 71  \nMemoization, 256  \nover subproblems, 258–260  \nfor W eighted Interval Scheduling  \nProblem, 256–257  \nMemory hierarchies, 131–132  \nMenger , K., 377, 449  \nMenger's Theorem, 377  \nMerge-and-Count algorithm, 223–225  \nMergesort Algorithm, 210–21 1 \nas example of general approach, 21 1–212  \nnotes, 249  \nrunning times for , 50–51  \nrecurrences for , 212–214  \nMerging \ninversions in, 221–225  \nsorted lists, 48–50  \nMeta-search tools, 222  \nMetropolis, N., 666, 705  \nMetropolis algorithm, 666–669"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1016})","('type', 'Document')"
"('page_content', ""Meyer , A., 543, 551  \nMiller , G., 598  \nMinimum-altitude connected subgraphs, 199 ex \nMinimum-bottleneck spanning trees, 192 ex \nMinimum Cardinality V ertex Cover Problem, 793 ex \nMinimum-Cost Arborescence Problem, 1 16, 177  \ngreedy algorithms for  \nanalyzing, 181–183  \ndesigning, 179–181  \nproblem, 177–179  \nMinimum-Cost Dominating Set Problem, 597 ex \nMinimum-Cost Path Problem. See Shortest Path Problem  \nMinimum-Cost Flow Problem, 449  \nMinimum-Cost Perfect Matching Problem, 405–406  \nalgorithm design and analysis for , 405–410  \neconomic interpretation of, 410–41 1 \nnotes, 449  \nMinimum cuts  \nin Baseball Elimination Problem, 403–404  \nglobal, 714  \nalgorithm analysis for , 716–718  \nalgorithm design for , 715–716  \nnumber of, 718–719  \nproblem, 714–715  \nin image segmentation, 393  \nKarger's algorithm for , 790 ex \nin local search, 684  \nin Maximum-Flow Problem, 340  \nin networks, 346  \nalgorithm analysis for , 346–348  \nmaximum flow with, 348–352  \nnotes, 793  \nin Project Selection Problem, 397–399  \nMinimum Spanning T ree Problem, 1 16 \ngreedy algorithms for  \nanalyzing, 144–149  \ndesigning, 143–144"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1017})","('type', 'Document')"
"('page_content', 'extensions, 150–151  \nnotes, 206  \nproblem, 142–143  \nMinimum spanning trees  \nfor clustering, 157–159  \nmembership in, 188 ex \nMinimum-weight Steiner trees, 204 ex, 335 ex \nMinimum W eight V ertex Cover Problem, 793 ex \nMismatch costs, 280  \nMismatches in sequences, 278–280  \nMitzenmacher , M., 793–794  \nMobile computing, base stations for , 417–418 ex \nMobile robots, 104–106 ex \nMobile wireless networks, 324–325 ex \nMod 2 linear equations, 779–782 ex \nModified Quicksort algorithm, 732–734  \nMolecules  \nclosest pair of points in, 226  \nentropy of, 547–550 ex \nprotein, 651–652 ex \nRNA, 273–274  \nMonderer , D., 706  \nMonitoring networks, 423–424 ex \nMonotone formulas, 507 ex \nMonotone QSA T, 550 ex \nMonotone Satisfiability , 507 ex \nMorse, Samuel, 163  \nMorse code, 163  \nMost favorable Nash equilibrium solutions, 694–695  \nMotwani, R., 793–794  \nMulti-phase greedy algorithms, 177  \nanalyzing, 181–183  \ndesigning, 179–181  \nproblem, 177–179  \nMulti-way choices in dynamic programming, 261  \nalgorithm for  \nanalyzing, 266')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1018})","('type', 'Document')"
"('page_content', 'designing, 264–266  \nproblem, 261–264  \nfor shortest paths, 293  \nMulticast, 690  \nMulticommodity Flow Problem, 382  \nMultigraphs in Contraction Algorithm, 715  \nMultiple Interval Scheduling, 512 ex \nMultiplication  \ninteger , 209, 231  \nalgorithm analysis for , 233–234  \nalgorithm design for , 232–233  \nnotes, 250  \nproblem, 231–232  \npolynomials via convolution, 235, 238–239  \nMultivariable Polynomial Minimization Problem, 520 ex \nMutual reachability , 98–99  \nMutually reachable nodes, 98–99\nN \nN-node trees, 78  \nNabokov , Vladimir , 107 ex \nNäher , S., 71  \nNash, John, 692  \nNash equilibria  \ndefinitions and examples, 691–693  \nfinding, 696–700  \nnotes, 706  \nproblem, 690–691  \nquestions, 695–696  \nNational Resident Matching Problem, 3, 23–24 ex \nNatural brute-force algorithm, 31–32  \nNatural disasters, 419 ex \nNau, Dana, 552  \nNear -trees, 200 ex \nNearby Electromagnetic Observation Problem, 512–513 ex \nNeedleman, S., 279  \nNegation with Boolean variables, 459  \nNegative cycles, 301')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1019})","('type', 'Document')"
"('page_content', 'algorithms for  \ndesigning and analyzing, 302–304  \nextensions, 304–307  \nin Minimum-Cost Perfect Matching Problem, 406  \nproblem, 301–302  \nrelation to shortest paths, 291–294  \nNeighborhoods  \nin Hopfield neural networks, 677  \nin Image Segmentation Problem, 682  \nin local search, 663–664, 685–687  \nin Maximum-Cut Problem, 680  \nNemhauser , G. L., 206  \nNesetril, J., 206  \nNested loops, running time of, 51–53  \nNesting arrangement for boxes, 434–435 ex \nNetwork design, in Minimum Spanning T ree Problem, 142–143, 150  \nNetwork flow , 337–338  \nAirline Scheduling Problem, 387  \nalgorithm analysis for , 390–391  \nalgorithm design for , 389–390  \nproblem, 387–389  \nBaseball Elimination Problem, 400  \nalgorithm design and analysis for , 402–403  \ncharacterization in, 403–404  \nproblem, 400–401  \nBipartite Matching Problem. See Bipartite Matching Problem  \nDisjoint Paths Problem, 373–374  \nalgorithm analysis for , 375–377  \nalgorithm design for , 374–375  \nalgorithm extensions for , 377–378  \nproblem, 374  \ngood augmenting paths for , 352  \nalgorithm analysis for , 354–356  \nalgorithm design for , 352–354  \nalgorithm extensions for , 356–357  \nfinding, 412 ex \nImage Segmentation Problem, 391–392')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1020})","('type', 'Document')"
"('page_content', 'algorithm for , 393–395  \nproblem, 392–393  \nMaximum-Flow Problem. See Maximum-Flow Problem  \nPreflow-Push Maximum-Flow Algorithm, 357  \nalgorithm analysis for , 361–365  \nalgorithm design for , 357–361  \nalgorithm extensions for , 365  \nalgorithm implementation for , 365–367  \nProject Selection Problem, 396–399  \nNetworks  \ngraphs as models of, 75–76  \nneural. See Hopfield neural networks  \nrouting in. See Routing in networks  \nsocial, 75–76, 1 10–1 11 ex \nwireless, 108–109 ex, 324–325 ex \nNewborn, M., 551–552  \nNielsen, Morten N., 207  \nNode-Disjoint Paths Problem, 597 ex \nNode-separation property , 575–576  \nNodes  \nin binary trees, 108 ex \ncentral, 429 ex \ndegrees of, 88  \ndepth of, 167  \ndiscovering, 92  \nin graphs, 13, 73–74  \nfor heaps, 59–60  \nheights of, 358–359  \nlinked sets of, 585–586  \nlocal minimum, 248 ex \nin network models, 338–339  \nprices on, 407–410  \nin shortest paths, 137  \nNonadopters in human behaviors, 523 ex \nNoncrossing conditions in RNA base-pair matching, 274  \nNondeterministic search, 464n  \nNonsaturating push operations, 363–364, 446 ex')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1021})","('type', 'Document')"
"('page_content', 'Norvig, P ., 552  \nNowakowski, R., 551  \nNP and NP-completeness, 451–452, 466  \nCircuit Satisfiability Problem, 466–470  \nco-NP and asymmetry in, 495–497  \nefficient certification in, 463–466  \nGraph Coloring, 485–490  \nindependent sets, 17  \nnotes, 529, 659  \nnumerical problems, 490–495  \npartitioning problems, 481–485  \npolynomial-time reductions, 452–454  \nIndependent Set in, 454–456  \nTuring, 473  \nVertex Cover in, 456–459  \nproofs for , 470–473  \nSatisfiability Problem in, 459–463  \nsequencing problems, 473–474  \nHamiltonian Cycle Problem, 474–479  \nHamiltonian Path Problem, 480–481  \nTraveling Salesman Problem, 474, 479  \ntaxonomy of, 497–500  \nNP-hard problems, 553–554  \ntaxonomy of, 497–500  \non trees, 558  \nCircular -Arc Coloring Problem. See Circular -Arc Coloring Problem  \ndecompositions. See Tree decompositions  \ngreedy algorithm for , 558–560  \nMaximum-W eight Independent Set Problem, 560–562  \nVertex Cover Problem, 554–555  \nalgorithm analysis for , 557  \nalgorithm design for , 555–557  \nNull pointers in linked lists, 44  \nNumber Partitioning Problem, 518 ex \nNumerical problems, 490, 499  \nin scheduling, 493–494  \nSubset Sum Problem, 491–495')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1022})","('type', 'Document')"
"('page_content', 'O \nO notation  \nin asymptotic order of growth, 36–38  \nexercise for , 65–66 ex \nO(n2) time, 51–52  \nO(n3) time, 52–53  \nO(nk) time, 53–54  \nO(n log n) time, 50–51  \nObjective function in Linear Programming Problem, 632  \nOdd cycles and graph bipartiteness, 95  \nOff-center splitters in median-finding, 730  \nOffering prices in combinatorial auctions, 51 1 ex \nOfman, Y ., 250  \nOmega notation  \nin asymptotic order of growth, 37–38  \nexercise, 66 ex,68 ex \nOn-line algorithms, 48  \nfor caching, 751  \nfor Interval Scheduling Problem, 121  \nnotes, 794  \nOne-pass auction, 788–789 ex \nOpen-Pit Mining Problem, 397  \nOperators in planning problems, 534, 538–540  \nOpportunity cycles, 324 ex \nOptimal caching  \ngreedy algorithms for  \ndesigning and analyzing, 133–136  \nextensions, 136–137  \nnotes, 206  \nproblem, 131–133  \nOptimal prefix codes, 165–166, 170–173  \nOptimal radius in Center Selection Problem, 607–610  \nOptimal schedules in minimizing lateness, 128–131  \nOral history study , 112 ex \nOrder of growth, asymptotic. See Asymptotic order of growth  \nOrdered graphs, characteristics of, 313 ex \nOrdered pairs as representation of directed graph edges, 73')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1023})","('type', 'Document')"
"('page_content', 'Ordering, topological, 102  \ncomputing, 101  \nin DAGs, 102, 104 ex,107 ex \nnode deletions in, 102–104  \nOrlin, James B., 449–450  \nOutput buf fers in packet switching, 796–801\nOutput cushions in packet switching, 801  \nOutput queueing in packet switching, 796–797  \nOverlay networks, 784–785 ex \nOvermars, M., 250\nP \nP class. See Polynomial time  \nPacket routing, 762–763  \nalgorithm for  \nanalyzing, 767–769  \ndesigning, 765–767  \nnotes, 794  \nproblem, 763–765  \nPacket switching  \nalgorithm for  \nanalyzing, 803–804  \ndesigning, 800–803  \nproblem, 796–800  \nPackets, 763  \nPacking problems, 456, 498  \nPairs of points, closest. See Closest pair of points  \nPapadimitriou, Christos H.  \ncircular arc coloring, 529  \ncomplexity theory , 551  \ngame theory , 706  \nParameterized complexity , 598  \nParents in trees, 77  \nParsing algorithms for context-free grammars, 272  \nPartial assignment, 591–594 ex \nPartial products in integer multiplication, 232  \nPartial substitution  \nin sequence alignment recurrence, 289')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1024})","('type', 'Document')"
"('page_content', 'in unrolling recurrences, 214, 217–219, 243–244 ex \nPartial tree decomposition, 588–590  \nPartitioning problems, 498–499  \n3-Dimensional Matching Problem, 481–485  \nGraph Coloring Problem, 485–486  \nInterval Partitioning Problem, 121–125, 566  \nlocal search for , 680–681  \nMaximum Cut Problem, 676  \nnotes, 705  \nNumber Partitioning Problem, 518 ex \nSegmented Least Squares Problem, 263–265  \nPath Coloring Problem, 563–565  \nPath decomposition, 376  \nPath Selection Problem, 508 ex \nPath vector protocols, 301  \nPaths, 76–77  \naugmenting. See Augmenting paths  \ndisjoint. See Disjoint Paths Problem  \nshortest. See Shortest Path Problem  \nPatterns  \nin related recurrences, 221  \nin unrolling recurrences, 213, 215, 218  \nPauses in Morse code, 163  \nPeer-to-peer systems, 784–785 ex \nPeering relationships in communication networks, 75  \nPerfect Assembly Problem, 521 ex \nPerfect matching, 337  \nin Bipartite Matching Problem, 14–16, 371–373, 404–405  \nin Gale-Shapley algorithm, 8  \nin Stable Matching Problem, 4–5  \nPermutations  \nof database tables, 439–440 ex \nin sequencing problems, 474  \nPhases for marking algorithms, 752–753  \nPicard, J., 450  \nPicnic exercise, 327 ex \nPieces in tree decompositions, 574')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1025})","('type', 'Document')"
"('page_content', 'Ping commands, 424 ex \nPixels  \ncompression of images, 176  \nin image segmentation, 392–394  \nin local search algorithm, 682  \nPlacement costs, 323–324 ex \nPlanning  \ncontingency , 535  \nnotes, 552  \nin PSP ACE, 533–535, 538  \nalgorithm analysis for , 542–543  \nalgorithm design for , 540–542  \nproblem, 538–540  \nPlot Fulfillment Problem, 510 ex \nPlotkin, S., 659  \nP = NP question, 465  \nPointer -based structures for Union-Find, 154–156  \nPointer graphs in negative cycle detection algorithm, 304–306  \nPointers  \nfor heaps, 59–60  \nin linked lists, 44  \nin Union-Find data structure, 154–157  \nPoints, closest pairs of. See Closest pair of points  \nPolitics, gerrymandering in, 331–332 ex \nPolymer models, 547–550 ex \nPolynomial Minimization Problem, 520 ex \nPolynomial space. See PSPACE  \nPolynomial time, 34, 463–464  \napproximation scheme, 644–645  \nin asymptotic bounds, 40–41  \nas definition of ef ficiency , 32–35  \nin efficient certification, 463  \nnotes, 70–71  \nreductions, 452–454  \nIndependent Set in, 454–456  \nTuring, 473  \nVertex Cover in, 456–459')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1026})","('type', 'Document')"
"('page_content', 'Polynomial-time algorithm, 33  \nPolynomially bounded numbers, subset sums with, 494–495  \nPolynomials, recursive procedures for , 240–241  \ninterpolation, 238, 241–242  \nmultiplication, 235  \nPorteous, B., 449  \nPorting software, 433 ex \nPotential functions  \nin Nash equilibrium, 700  \nnotes, 706  \nfor push operations, 364  \nPrabhakar , B., 799  \nPrecedence constraints in Project Selection Problem, 396–397  \nPrecedence relations in directed acyclic graphs, 100  \nPreference lists in Stable Matching Problem, 4–5  \nPreferences in Stable Matching Problem, 4  \nPrefix codes, 164–165  \nbinary trees for , 166–169  \noptimal, 165–166, 170–173  \nPrefix events in infinite sample spaces, 775  \nPreflow-Push Maximum-Flow Algorithm, 357  \nanalyzing, 361–365  \ndesigning, 357–361  \nextensions, 365  \nimplementing, 365  \nnotes, 449  \nvariants, 444–446 ex \nPreflows, 357–358  \nPreparata, F . P., 249  \nPreprocessing for data structures, 43  \nPrerequisite lists in planning problems, 534, 538  \nPress, W . H., 250  \nPretty-printing, 317–319 ex \nPrice of stability  \nin Nash equilibrium, 698–699  \nnotes, 706  \nPrices')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1027})","('type', 'Document')"
"('page_content', ""economic interpretation of, 410–41 1 \nfair, 620–621  \nin Minimum-Cost Perfect Matching Problem, 407–410  \nPricing (primal-dual) methods, 206  \nfor approximation, 599–600  \nDisjoint Paths Problem, 624–630  \nVertex Cover Problem, 618–623  \nnotes, 659  \nPrimal-dual methods. See Pricing methods  \nPrim's Algorithm  \nimplementing, 149–150  \noptimality , 146–147  \nfor spanning trees, 143–144  \nPrinting, 317–319 ex \nPriority queues, 57–58  \nfor Dijkstra's Algorithm, 141–142  \nheaps for . See Heaps  \nfor Huf fman's Algorithm, 175  \nnotes, 70  \nfor Prim's Algorithm, 150  \nPriority values, 57–58  \nProbabilistic method  \nfor MAX-3-SA T problem, 726  \nnotes, 793  \nProbability , 707  \nChernof f bounds, 758–760  \nconditional, 771–772  \nof events, 709–710, 769–770  \nprobability spaces in  \nfinite, 769–771  \ninfinite, 774–776  \nUnion Bound in, 772–774  \nProbability mass, 769  \nProbing nodes, 248 ex \nProcess Naming Problem, 770  \nProgress measures  \nfor best-response dynamics, 697"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1028})","('type', 'Document')"
"('page_content', 'in Ford-Fulkerson Algorithm, 344–345  \nin Gale-Shapley algorithm, 7–8  \nin Hopfield neural networks, 674  \nProject Selection Problem, 396  \nalgorithm for  \nanalyzing, 398–399  \ndesigning, 397–398  \nproblem, 396–397  \nProjections of database tables, 439–440 ex \nProposed distances for closest pair of points, 743–745  \nProtein molecules, 651–652 ex \nPseudo-code, 35–36  \nPseudo-knotting, 274  \nPseudo-polynomial time  \nin augmenting paths, 356–357  \nefficiency of, 271  \nin Knapsack Problem, 645  \nin Subset Sum Problem, 491\nPSPACE, 531–533  \ncompleteness in, 18, 543–547  \nfor games, 535–538, 544–547  \nplanning problems in, 533–535, 538  \nalgorithm analysis for , 542–543  \nalgorithm design for , 540–542  \nproblem, 538–540  \nquantification in, 534–538  \nPull-based Bellman-Ford algorithm, 298  \nPure output queueing in packet switching, 796  \nPush-based Bellman-Ford algorithm, 298–299  \nPush-Based-Shortest-Path algorithm, 299  \nPush operations in preflow , 360, 446 ex \nPushing flow in network models, 341\nQ \nQSA T (Quantified 3-SA T), 535–536  \nalgorithm for  \nanalyzing, 537–538  \ndesigning, 536–537')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1029})","('type', 'Document')"
"('page_content', ""extensions, 538  \nmonotone, 550 ex \nnotes, 551  \nin PSP ACE completeness, 543–545  \nQuadratic time, 51–52  \nQuantification in PSP ACE, 534–538  \nQuantifiers in PSP ACE completeness, 544  \nQueue management policy , 763  \nQueues  \nfor graph traversal, 89–90  \nfor Huf fman's Algorithm, 175  \nin packet routing, 763  \nin packet switching, 796–797  \npriority . See Priority queues  \nQuicksort, 731–734\nR \nRabin, M. O., 70, 794  \nRackof f, Charles, 207  \nRadio interference, 512–513 ex \nRadzik, T omasz, 336  \nRaghavan, P ., 793  \nRandom assignment  \nfor linear equations mod 2, 780–781 ex \nfor MAX-3-SA T problem, 725–726, 787 ex \nRandom variables, 719–720  \nwith convolution, 237  \nexpectation of, 719–720  \nlinearity of expectation, 720–724  \nRandomized algorithms, 707–708  \nfor approximation algorithms, 660, 724–727, 779–782 ex, 787–788 ex,\n792–793 ex \ncaching. See Randomized caching  \nChernof f bounds, 758–760  \nclosest pair of points, 741–742  \nalgorithm analysis for , 746–747  \nalgorithm design for , 742–746  \nlinear expected running time for , 748–750"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1030})","('type', 'Document')"
"('page_content', 'notes, 794  \nproblem, 742  \ncontention resolution, 708–709  \nalgorithm analysis for , 709–714  \nalgorithm design for , 709  \nnotes, 793  \nproblem, 709  \nrandomization in, 782–784 ex \ndivide-and-conquer approach, 209, 727  \nmedian-finding, 727–731  \nQuicksort, 731–734  \nglobal minimum cuts, 714  \nalgorithm analysis for , 716–718  \nalgorithm design for , 715–716  \nnumber of, 718–719  \nproblem, 714–715  \nhashing, 734  \ndata structure analysis for , 740–741  \ndata structure design for , 735–740  \nproblem, 734–735  \nfor load balancing, 760–762  \nfor MAX-3-SA T, 724–727  \nnotes, 793  \nfor packet routing, 762–763  \nalgorithm analysis for , 767–769  \nalgorithm design for , 765–767  \nnotes, 794  \nproblem, 763–765  \nprobability . See Probability  \nrandom variables and expectations in, 719–724  \nRandomized caching, 750  \nmarking algorithms for , 752–753  \nanalyzing, 753–755  \nnotes, 794  \nrandomized, 755–758  \nnotes, 794  \nproblem, 750–752')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1031})","('type', 'Document')"
"('page_content', 'Rankings, comparing, 221–222  \nRanks in Stable Matching Problem, 4  \nRao, S., 765, 794  \nRatlif f, H., 450  \nRearrangeable matrices, 428 ex \nRebooting computers, 320–322 ex \nReconciliation of checks, 430 ex \nRecurrences and recurrence relations, 209  \nfor divide-and-conquer algorithms, 210–21 1 \napproaches to, 21 1–212  \nsubstitutions in, 213–214  \nunrolling recurrences in, 212–213, 244 ex \nin sequence alignment, 285–286, 289–290  \nsubproblems in, 215–220  \nin W eighted Interval Scheduling Problem, 257  \nRecursive-Multiple algorithm, 233–234  \nRecursive procedures  \nfor depth-first search, 85, 92  \nfor dynamic programming, 259–260  \nfor W eighted Interval Scheduling Problem, 252–256  \nReduced costs of edges, 409  \nReduced schedules in optimal caching, 134–135  \nReductions  \npolynomial-time, 452–454  \nTuring, Cook, and Karp, 473  \nin PSP ACE completeness, 546  \ntransitivity of, 462–463  \nReed, B., 598  \nRefrigerator magnets, 507–508 ex \nRegister allocation, 486  \nRelabel operations in preflow , 360–364, 445 ex \nRelease times, 137, 493, 500  \nRepresentative sets for protein molecules, 651–652 ex \nRequests in interval scheduling, 13–14  \nResidual graphs, 341–345  \nin Minimum-Cost Perfect Matching Problem, 405  \nfor preflows, 358–359')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1032})","('type', 'Document')"
"('page_content', 'Resource allocation  \nin Airline Scheduling, 387  \nin Bipartite Matching, 14–16  \nin Center Selection, 606–607  \nin Interval Scheduling, 13–14, 1 16 \nin Load Balancing, 600, 637  \nin W avelength-Division Multiplexing, 563–564  \nResource Reservation Problem, 506 ex \nReusing space, 537–538, 541  \nReverse-Delete Algorithm, 144, 148–149  \nRinnooy Kan, A. H. G., 206  \nRising trends, 327–328 ex \nRNA Secondary Structure Prediction Problem, 272–273  \nalgorithm for , 275–278  \nnotes, 335  \nproblem, 273–275  \nRobertson, N., 598  \nRobots, mobile, 104–106 ex \nRosenbluth, A. W ., 666  \nRosenbluth, M. N., 666  \nRooted trees  \narborescences as, 177-179  \nfor clock signals, 200 ex \ndescription, 77–78  \nfor prefix codes, 166  \nrounding fractional solutions via, 639–643  \nRoots of unity with convolution, 239  \nRosenthal, R. W ., 706  \nRoss, S., 335  \nROTC picnic exercise, 327 ex \nRoughgarden, T ., 706  \nRounding  \nfor Knapsack Problem, 645  \nin linear programming. See Linear programming and rounding  \nRoute maps for transportation networks, 74  \nRouter paths, 297–301  \nRouting in networks')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1033})","('type', 'Document')"
"('page_content', ""game theory in, 690  \ndefinitions and examples, 691–693  \nand local search, 693–695  \nNash equilibria in, 696–700  \nproblem, 690–691  \nquestions, 695–696  \nInternet  \ndisjoint paths in, 624–625  \nnotes, 336  \nshortest paths in, 297–301  \nnotes, 336  \npacket, 762–763  \nalgorithm analysis for , 767–769  \nalgorithm design for , 765–767  \nproblem, 763–765  \nRouting requests in Maximum Disjoint Paths Problem, 624  \nRSA cryptosystem, 491  \nRubik's Cube  \nas planning problem, 534  \nvs. T etris, 795  \nRun forever , algorithms that  \ndescription, 795–796  \npacket switching  \nalgorithm analysis for , 803–804  \nalgorithm design for , 800–803  \nproblem, 796–800  \nRunning times, 47–48  \ncubic, 52–53  \nexercises, 65–69 ex \nlinear , 48–50  \nin Maximum-Flow Problem, 344–346  \nO(nk), 53–54  \nO(n log n), 50–51  \nquadratic, 51–52  \nsublinear , 56 \nworst-case, 31–32  \nRussell, S., 552"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1034})","('type', 'Document')"
"('page_content', 'S \nS-t connectivity , 78, 84  \nS-t Disjoint Paths Problem, 374  \nSahni, Sartaj, 660  \nSample space, 769, 774–776  \nSankof f, D., 335  \nSatisfiability (SA T) Problem  \n3-SA T. See 3-SA T Problem  \nNP completeness, 466–473  \nrelation to PSP ACE completeness, 543  \nreductions and, 459–463  \nSatisfiable clauses, 459  \nSatisfying assignments with Boolean variables, 459  \nSaturating push operations, 363–364, 446 ex \nSavage, John E., 551  \nSavitch, W ., 541, 552  \nScaling behavior of polynomial time, 33  \nScaling Max-Flow Algorithm, 353–356  \nScaling parameter in augmenting paths, 353  \nScaling phase in Scaling Max-Flow Algorithm, 354–356  \nSchaefer , Thomas, 552  \nScheduling  \nAirline Scheduling Problem, 387  \nalgorithm analysis for , 390–391  \nalgorithm design for , 389–390  \nproblem, 387–389  \ncarpool, 431 ex \nDaily Special Scheduling Problem, 526 ex \ninterference-free, 105 ex \ninterval. See Interval Scheduling Problem  \nKnapsack Problem. See Knapsack Problem  \nLoad Balancing Problem. See Load Balancing Problem  \nfor minimizing lateness. See Lateness, minimizing  \nMultiple Interval Scheduling, NP-completeness of, 512 ex \nnumerical problems in, 493–494, 500  \noptimal caching  \ngreedy algorithm design and analysis for , 133–136')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1035})","('type', 'Document')"
"('page_content', 'greedy algorithm extensions for , 136–137  \nproblem, 131–133  \nin packet routing. See Packet routing\nprocessors, 442–443 ex \nshipping, 25–26 ex \ntriathalons, 191 ex \nfor weighted sums of completion times, 194–195 ex \nSchoning, Uwe, 598  \nSchrijver , A., 449  \nSchwartzkopf, O., 250  \nSearch space, 32, 47–48  \nSearch  \nbinary  \nin arrays, 44  \nin Center Selection Problem, 610  \nsublinear time in, 56  \nbreadth-first, 79–82  \nfor bipartiteness, 94–96  \nfor connectivity , 79–81  \nfor directed graphs, 97–98  \nimplementing, 90–92  \nin planning problems, 541  \nfor shortest paths, 140  \nbrute-force, 31–32  \ndepth-first, 83–86  \nfor connectivity , 83–86  \nfor directed graphs, 97–98  \nimplementing, 92–94  \nin planning problems, 541  \nlocal. See Local search  \nSecondary struc ture, RNA. See RNA Secondary Structure Prediction\nProblem  \nSegmentation, image, 391–392  \nalgorithm for , 393–395  \nlocal search in, 681–682  \nproblem, 392–393  \ntool design for , 436–438 ex')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1036})","('type', 'Document')"
"('page_content', 'Segmented Least Squares Problem, 261  \nalgorithm for  \nanalyzing, 266  \ndesigning, 264–266  \nnotes, 335  \nproblem, 261–264  \nsegments in, 263  \nSeheult, A., 449  \nSeidel, R., 794  \nSelection in median-finding, 728–730  \nSelf-avoiding walks, 547–550 ex \nSelf-enforcing processes, 1  \nSeparation for disjoint paths, 377  \nSeparation penalty in image segmentation, 393, 683  \nSequence alignment, 278, 280  \nalgorithms for  \nanalyzing, 282–284  \ndesigning, 281–282  \nfor biological sequences, 279–280, 652 ex \nin linear space, 284  \nalgorithm design for , 285–288  \nproblem, 284–285  \nnotes, 335  \nproblem, 278–281  \nand Segmented Least Squares, 309–31 1 ex \nSequencing problems, 473–474, 499  \nHamiltonian Cycle Problem, 474–479  \nHamiltonian Path Problem, 480–481  \nTraveling Salesman Problem, 474, 479  \nSet Cover Problem, 456–459, 498, 612  \napproximation algorithm for  \nanalyzing, 613–617  \ndesigning, 613  \nlimits on approximability , 644  \nnotes, 659  \nproblem, 456–459, 612–613  \nrelation to V ertex Cover Problem, 618–620')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1037})","('type', 'Document')"
"('page_content', 'Set Packing Problem, 456, 498  \nSeymour , P. D., 598  \nShamir , Ron, 1 13 \nShamos, M. I.  \nclosest pair of points, 226  \ndivide-and-conquer , 250  \nShannon, Claude E., 169–170, 206  \nShannon-Fano codes, 169–170  \nShapley , Lloyd, 1–3, 28, 706, 786 ex \nShapley value, 786 ex \nSharing  \napartment expenses, 429–430 ex \nedge costs, 690  \nInternet service expenses, 690–700, 785–786 ex \nShmoys, David B.  \ngreedy algorithm for Center Selection, 659  \nrounding algorithm for Knapsack, 660  \nscheduling, 206  \nShortest-First greedy algorithm, 649–651 ex \nShortest Path Problem, 1 16, 137, 290  \nbicriteria, 530  \ndistance vector protocols  \ndescription, 297–300  \nproblems, 300–301  \nGalactic, 527 ex \ngreedy algorithms for  \nanalyzing, 138–142  \ndesigning, 137–138  \nwith minimum spanning trees, 189 ex \nnegative cycles in graphs, 301  \nalgorithm design and analysis, 302–304  \nproblem, 301–302  \nwith negative edge lengths  \ndesigning and analyzing, 291–294  \nextensions, 294–297  \nnotes, 206, 335–336  \nproblem, 290–291')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1038})","('type', 'Document')"
"('page_content', 'Signals and signal processing  \nclock, 199 ex \nwith convolution, 235–236  \ninterleaving, 329 ex \nnotes, 250  \nsmoothing, 209, 236  \nSignificant improvements in neighbor labeling, 689  \nSignificant inversion, 246 ex \nSimilarity between strings, 278–279  \nSimple paths in graphs, 76  \nSimplex method in linear programming, 633  \nSimulated annealing  \nnotes, 705  \ntechnique, 669–670  \nSingle-flip neighborhood in Hopfield neural networks, 677  \nSingle-flip rule in Maximum-Cut Problem, 680  \nSingle-link clustering, 159, 206  \nSink conditions for preflows, 358–359  \nSink nodes in network models, 338–339  \nSinks in circulation, 379–381  \nSipser , Michael  \npolynomial time, 70  \nP = NP question, 529  \nSix Degrees of Kevin Bacon game, 448 ex \nSkeletons of graphs, 517–518 ex \nSkew , zero, 201 ex \nSlack  \nin minimizing lateness, 127  \nin packet switching, 801–802  \nSleator , D. D.  \nLRU, 137  \nRandomized Marking algorithm, 794  \nSmid, Michiel, 249  \nSmoothing signals, 209, 236\nSocial networks  \nas graphs, 75–76  \npaths in, 1 10–1 11 ex')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1039})","('type', 'Document')"
"('page_content', 'Social optimum vs. Nash equilibria, 692–693, 699  \nSolitaire puzzles, 534  \nSort-and-Count algorithm, 225  \nSorted-Balance algorithm, 605  \nSorted lists, mer ging, 48–50  \nSorting  \nfor Load Balancing Problem, 604–606  \nMergesort Algorithm, 210–21 1 \napproaches to, 21 1–212  \nrunning times for , 50–51  \nsubstitutions in, 213–214  \nunrolling recurrences in, 212–213  \nO(n log n) time, 50–51  \npriority queues for , 58 \nQuicksort, 731–734  \ntopological, 101–104, 104 ex,107 ex \nSource conditions for preflows, 358–359  \nSource nodes, 338–339, 690  \nSources  \nin circulation, 379–381  \nin Maximum-Flow Problems, 339  \nSpace complexity , 531–532  \nSpace-Ef ficient-Alignment algorithm, 285–286  \nSpacing of clusterings, 158–159  \nSpanning T ree Problem. See Minimum Spanning T ree Problem  \nSpanning trees  \nand arborescences. See Minimum- Cost Arborescence Problem  \ncombinatorial structure of, 202–203 ex \nSparse graphs, 88  \nSpell-checkers, 279  \nSpencer , J., 793–794  \nSplitters  \nin median-finding, 728–730  \nin Quicksort, 732  \nStability in generalized Stable Matching Problem, 23–24 ex \nStable configurations in Hopfield neural networks, 671, 676, 700, 702–703\nex')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1040})","('type', 'Document')"
"('page_content', 'Stable matching, 4–5  \nStable Matching Problem, 1, 802–803  \nalgorithms for  \nanalyzing, 7–9  \ndesigning, 5–6  \nextensions, 9–12  \nimplementing, 45–47  \nlists and arrays in, 42–45  \nexercises, 19–25 ex \nand Gale-Shapley algorithm, 8–9  \nnotes, 28  \nproblem, 1–5  \nsearch space for , 32 \ntruthfulness in, 27–28 ex \nStacks for graph traversal, 89–90  \nStale items in randomized marking algorithm, 756–757  \nStar W ars series, 526–527 ex \nStart nodes in shortest paths, 137  \nStartHeap operation, 64  \nState-flipping algorithm  \nin Hopfield neural networks, 673–677  \nas local search, 683  \nState flipping neighborhood in Image Segmentation Problem, 682  \nStatistical mechanics, 663  \nStaying ahead in greedy algorithms, 1 15–1 16 \nin Appalachian T rail exercise, 184 ex \nin Interval Scheduling Problem, 1 19–120  \nfor shortest paths, 139  \nStearns, R. E., 70  \nSteepness conditions for preflows, 358–359  \nSteiner trees, 204 ex, 334–335 ex, 527 ex \nSteps in algorithms, 35–36  \nStewart, John W ., 336  \nStewart, Potter , 207  \nStochastic dynamic programming, 335  \nStockmeyer , L., 543, 551  \nStocks')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1041})","('type', 'Document')"
"('page_content', 'investment simulation, 244–246 ex \nrising trends in, 327–328 ex \nStopping points in Appalachian T rail exercise, 183–185 ex \nStopping signals for shortest paths, 297  \nStork, D., 206  \nStrategic Advertising Problem, 508–509 ex \nStream ciphers with feedback, 792 ex \nStress-testing jars, 69–70 ex \nStrings  \nchromosome, 521 ex \nconcatenating, 308–309 ex,517 ex \nencoding. See Huffman codes  \nlength of, 463  \nsimilarity between, 278–279  \nStrong components in directed graphs, 99  \nStrong instability in Stable Matching Problem, 24–25 ex \nStrongly connected directed graphs, 77, 98–99  \nStrongly independent sets, 519 ex \nStrongly polynomial algorithms, 356–357  \nSubgraphs  \nconnected, 199 ex \ndense, 788 ex \nSublinear time, 56  \nSubproblems  \nin divide-and-conquer techniques, 215–220  \nin dynamic programming, 251, 258–260  \nin Mer gesort Algorithm, 210  \nwith Quicksort, 733  \nfor W eighted Interval Scheduling Problem, 254, 258–260  \nSubsequences, 190 ex \nSubset Sum Problem, 266–267, 491, 499  \nalgorithms for  \nanalyzing, 270–271  \ndesigning, 268–270  \nextensions, 271–272  \nhardness in, 493–494  \nrelation to Knapsack Problem, 645, 648, 657–658 ex')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1042})","('type', 'Document')"
"('page_content', 'NP-completeness of, 492–493  \nwith polynomially bounded numbers, 494–495  \nSubsquares for closest pair of points, 743–746  \nSubstitution  \nin sequence alignment, 289  \nin unrolling recurrences, 213–214, 217–219, 243–244 ex \nSuccess events, 710–712  \nSudan, Madhu, 794  \nSumming in unrolling recurrences, 213, 216–217  \nSums of functions in asymptotic growth rates, 39–40  \nSupernodes  \nin Contraction Algorithm, 715  \nin minimum-cost arborescences, 181  \nSupervisory committee exercise, 196 ex \nSupply in circulation, 379  \nSurface removal, hidden, 248 ex \nSurvey Design Problem, 384–385  \nalgorithm for  \nanalyzing, 386–387  \ndesigning, 386  \nproblem, 385–386  \nSuspicious Coalition Problem, 500–502 ex \nSwapping rows in matrices, 428 ex \nSwitched data streams, 26–27 ex \nSwitching  \nalgorithm for  \nanalyzing, 803–804  \ndesigning, 800–803  \nin communications networks, 26–27 ex \nproblem, 796–800  \nSwitching time in Broadcast T ime Problem, 528 ex \nSymbols, encoding. See Huffman codes  \nSymmetry-breaking, randomization for , 708–709\nT \nTables, hash, 736–738, 760  \nTails of edges, 73  \nTardos, É.')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1043})","('type', 'Document')"
"('page_content', 'disjoint paths problem, 659  \ngame theory , 706  \nnetwork flow , 448  \nrounding algorithm, 660  \nTarget sequences, 309  \nTarjan, R. E.\ngraph traversal, 1 13 \nLRU, 137  \nonline algorithms, 794  \npolynomial time, 70–71  \nPreflow-Push Algorithm, 449  \nTaxonomy of NP-completeness, 497–500  \nTelegraph, 163  \nTeller, A. H., 666  \nTeller, E., 666  \nTemperature in simulated annealing, 669–670  \nTerminal nodes, 690  \nTerminals in Steiner trees, 204 ex, 334–335 ex \nTermination in Maximum-Flow Problem, 344–346  \nTesting bipartiteness, 94–96  \nTetris, 795  \nTheta in asymptotic order of growth, 37–38  \nThomas, J., 206  \nThomassen, C., 598  \nThresholds  \napproximation, 660  \nin human behaviors, 523 ex \nThymine, 273  \nTight bounds, asymptotic, 37–38  \nTight nodes in pricing method, 621  \nTime-series data mining, 190 ex \nTime-stamps for transactions, 196–197 ex \nTime to leave in packet switching, 800  \nTime-varying edge costs, 202 ex \nTiming circuits, 200 ex \nToft, B., 598  \nTop-down approach for data compression, 169–170')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1044})","('type', 'Document')"
"('page_content', 'Topological ordering, 102  \ncomputing, 101  \nin DAGs, 102, 104 ex,107 ex \nToth, P . \nKnapsack Problem, 335  \nSubset Sum, 529  \nTours in T raveling Salesman Problem, 474  \nTovey , Craig, 250  \nTrace data for networked computers, 1 11 ex \nTracing back in dynamic programming, 257  \nTrading in barter economies, 521–522 ex \nTrading cycles, 324 ex \nTraffic \nin Disjoint Paths Problem, 373  \nin Minimum Spanning T ree Problem, 150  \nin networks, 339, 625  \nTransactions  \napproximate time-stamps for , 196–197 ex \nvia shortest paths, 290  \nTransitivity  \nof asymptotic growth rates, 38–39  \nof reductions, 462–463  \nTransmitters in wireless networks, 776–779 ex \nTransportation networks, graphs as models of, 74  \nTraveling Salesman Problem, 499  \ndistance in, 474  \nnotes, 529  \nNP-completeness of, 479  \nrunning times for , 55–56  \nTraversal of graphs, 78–79  \nbreadth-first search for , 79–82  \nconnected components via, 82–83, 86–87  \ndepth-first search for , 83–86  \nTraverso, Paolo, 552  \nTree decompositions, 572–573  \nalgorithm for , 585–591  \ndynamic programming using, 580–584')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1045})","('type', 'Document')"
"('page_content', 'notes, 598  \nproblem, 584–585  \nproperties in, 575–580  \ntree-width in, 584–590  \ndefining, 573–575, 578–579  \nnotes, 598  \nTrees, 77–78  \nand arborescences. See Minimum- Cost Arborescence Problem  \nbinary  \nnodes in, 108 ex \nfor prefix codes, 166–169  \nbreadth-first search, 80–81  \ndepth-first search, 84–85  \nin Mini mum Spanning Tree Problem. See Minimum Spanning Tree\nProblem  \nNP-hard problems on, 558  \ndecompositions. See Tree decompositions  \nMaximum-W eight Independent Set Problem, 560–562  \nof possibilities, 557  \nTree-width. See Tree decompositions  \nTriangle inequality , 203 ex, 334–335 ex, 606  \nTriangulated cycle graphs, 596–597 ex \nTriathalon scheduling, 191 ex \nTrick, Michael, 250  \nTruth assignments  \nwith Boolean variables, 459  \nconsistent, 592 ex \nTruthfulness in Stable Matching Problem, 27–28 ex \nTucker , A., 598  \nTuring, Alan, 551  \nTuring A ward lecture, 70  \n“Twelve Days of Christmas,” 69 ex \nTwo-Label Image Segmentation, 391–392, 682\nU \nUnderspecified algorithms  \ngraph traversal, 83  \nFord-Fulkerson, 351–352')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1046})","('type', 'Document')"
"('page_content', 'Gale-Shapley , 10 \nPreflow-Push, 361  \nUndetermined variables, 591 ex \nUndirected Edge-Disjoint Paths Problem, 374  \nUndirected Feedback Set Problem, 520 ex \nUndirected graphs, 74  \nconnected, 76–77  \ndisjoint paths in, 377–378  \nin image segmentation, 392  \nnumber of global minimum cuts in, 718–719  \nUnfairness in Gale-Shapley algorithm, 9–10  \nUniform-depth case of Circular Arc Coloring, 566–567  \nUnimodal sequences, 242 ex \nUnion Bound, 709, 712–713  \nfor contention resolution, 712–713  \nfor load balancing, 761–762  \nfor packet routing, 767–768  \nin probability , 772–774  \nUnion-Find data structure, 151–152  \nimprovements, 155–157  \npointer -based, 154–157  \nsimple, 152–153  \nUnion operation, 152–154  \nUniversal hash functions, 738–740, 749–750  \nUnrolling recurrences  \nin Mer gesort Algorithm, 212–213  \nsubproblems in, 215–220  \nsubstitutions in, 213–214, 217–219  \nin unimodal sequence exercise, 244 ex \nUnweighted case in V ertex Cover Problem, 618  \nUpfal, E., 793–794  \nUplink transmitters, 776–777 ex \nUpper bounds, asymptotic, 36–37  \nUpstream nodes in flow networks, 429 ex \nUpstream points in communications networks, 26–27 ex \nUser-friendly houses, 416–417 ex \nUsing up All the Refrigerator Magnets Problem, 507–508 ex')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1047})","('type', 'Document')"
"('page_content', ""V \nValid execution of Kruskal's algorithm, 193 ex \nValid partners in Gale-Shapley algorithm, 10–12  \nValid stopping points in Appalachian T rail exercise, 183–184 ex \nValidation functions in barter economy , 522 ex \nValues  \nof flows in network models, 339  \nof keys in priority queues, 57–58  \nVan Kreveld, M., 250  \nVariable-length encoding schemes, 163\nVariables  \nadding in dynamic programming, 266, 276  \nBoolean, 459–460  \nrandom, 719–720  \nwith convolution, 237  \nlinearity of expectation, 720–724  \nVazirani, V . V., 659–660  \nVecchi, M. P ., 669, 705  \nVectors, sums of, 234–235  \nVeksler , Olga, 449–450, 706  \nVertex Cover Problem, 498, 554–555  \nand Integer Programming Problem, 633–635  \nlinear programming for . See Linear programming and rounding  \nin local search, 664–666  \nnotes, 659–660  \noptimal algorithms for  \nanalyzing, 557  \ndesigning, 555–557  \nin polynomial-time reductions, 454–459  \npricing methods, 618  \nalgorithm analysis for , 622–623  \nalgorithm design for , 620–622  \nproblem, 618–619  \nproblem, 555  \nrandomized approximation algorithm for , 792–793 ex \nVertices of graphs, 74  \nViral marketing phenomenon, 524 ex"")","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1048})","('type', 'Document')"
"('page_content', 'Virtual places in hypertext fiction, 509 ex \nVirus tracking, 1 11–112 ex \nVLSI chips, 200 ex \nVon Neumann, John, 249  \nVoting  \nexpected value in, 782 ex \ngerrymandering in, 331–332 ex\nW \nWagner , R., 336  \nWalks, self-avoiding, 547–550 ex \nWall Str eet,115 \nWater in shortest path problem, 140–141  \nWaterman, M., 335  \nWatson, J., 273  \nWatts, D. J., 1 13 \nWavelength assignment for wireless networks, 486  \nWavelength-division multiplexing (WDM), 563–564  \nWayne, Kevin, 449  \nWeak instability in Stable Matching Problem, 25 ex \nWeaver , W., 206  \nWegman, M. L., 794  \nWeighted Interval Scheduling Problem, 14, 122, 252  \nalgorithms for  \ndesigning, 252–256  \nmemoized recursion, 256–257  \nrelation to billboard placement, 309 ex \nsubproblems in, 254, 258–260  \nWeighted sums of completion times, 194–195 ex \nWeighted V ertex Cover Problem, 618, 631  \nas generalization of V ertex Cover , 633–635  \nnotes, 659–660  \nWeights  \nof edges in Hopfield neural networks, 671  \nin infinite sample spaces, 775  \nin Knapsack Problem, 267–272, 657–658 ex \nof nodes, 657 ex \nin Set Cover Problem, 612')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1049})","('type', 'Document')"
"('page_content', 'of Steiner trees, 204 ex \nin Vertex Cover Problem, 618  \nWell-centered splitters  \nin median-finding, 729–730  \nin Quicksort, 732  \nWidth, tree, in tree decompositions. See Tree decompositions  \nWilliams, J. W . J., 70  \nWilliams, R yan, 552  \nWilliamson, D. P ., 659  \nWinner Determination for Combinatorial Auctions problem, 51 1–512 ex \nWinsten, C. B., 706  \nWireless networks  \nad hoc, 435–436 ex \nfor laptops, 427–428 ex \nnodes in, 108–109 ex, 324–325 ex \ntransmitters for , 776–779 ex \nwavelength assignment for , 486  \nWitten, I. H., 206  \nWoo, Maverick, 530, 552  \nWord-of-mouth ef fects, 524 ex \nWord processors, 317–319 ex \nWord segmentation problem, 316–318 ex \nWorld W ide W eb \nadvertising, 422–423 ex, 508–508 ex \ndiameter of, 109–1 10 ex \nas directed graph, 75  \nmeta-search tools on, 222  \nWorst-case analysis, 31–32  \nWorst-case running times, 31–32  \nWorst valid partners in Gale-Shapley algorithm, 1 1–12  \nWosley , L. A., 206  \nWunsch, C., 279\nY \nYoung, N. E., 794\nZ \nZabih, Ramin D., 449–450, 706  \nZeroskew ,201 ex')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1050})","('type', 'Document')"
"('page_content', 'Zero-W eight-Cycle problem, 513 ex \nZones  \nin Competitive Facility Location Problem, 18  \nin Evasive Path Problem, 510–51 1 ex \nZuker , M., 335')","('metadata', {'source': 'Preprocessing/Data/Orginal/CPSC320.pdf', 'page': 1051})","('type', 'Document')"
